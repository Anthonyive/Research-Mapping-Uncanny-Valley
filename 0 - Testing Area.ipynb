{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "I feel creepy. (Score: 0.0888)\n",
      "I feel terrifying. (Score: 0.0292)\n",
      "I feel frightening. (Score: 0.0197)\n",
      "I feel chilling. (Score: -0.0419)\n",
      "I feel scaried. (Score: -0.0801)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A horrible curse befell my girlfriend and now she can only eat human meat.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "I feel terrifying. (Score: 0.2653)\n",
      "I feel scaried. (Score: 0.1889)\n",
      "I feel creepy. (Score: 0.1667)\n",
      "I feel frightening. (Score: 0.1488)\n",
      "I feel chilling. (Score: 0.0610)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Apple tress can grow as tall as 20 feet.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "I feel frightening. (Score: -0.0347)\n",
      "I feel terrifying. (Score: -0.0469)\n",
      "I feel scaried. (Score: -0.0677)\n",
      "I feel chilling. (Score: -0.0813)\n",
      "I feel creepy. (Score: -0.1176)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['I feel creepy.',\n",
    "          'I feel scaried.',\n",
    "          'I feel chilling.',\n",
    "          'I feel terrifying.',\n",
    "          'I feel frightening.'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['A cheetah chases prey on across a field.', 'A horrible curse befell my girlfriend and now she can only eat human meat.', \"Apple tress can grow as tall as 20 feet.\"]\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use torch.topk to find the highest 5 scores\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: %.4f)\" % (score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antho\\Documents\\Research-Mapping-Uncanny-Valley\\.venv\\creepyvenv\\lib\\site-packages\\tqdm\\std.py:703: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.gui import tqdm as tqdm_gui\n",
    "\n",
    "tqdm.pandas(ncols=50)  # can use tqdm_gui, optional kwargs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████| 15487/15487 [00:03<00:00, 4072.47it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_data(csv_in):\n",
    "    csv_read = pd.read_csv(csv_in)\n",
    "\n",
    "    # extract columns we want\n",
    "    csv = csv_read[['id', 'title', 'selftext', 'score']]\n",
    "    \n",
    "    # drop removed, deleted, and nas\n",
    "    csv = csv[csv.selftext != '[removed]']\n",
    "    csv = csv[csv.selftext != '[deleted]']\n",
    "    csv.dropna(subset = [\"selftext\"], inplace=True)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    This insane regex is written by kerim from here:\n",
    "    https://stackoverflow.com/questions/14081050/remove-all-forms-of-urls-from-a-given-string-in-python\n",
    "    '''\n",
    "    url_regex = r'''(\\(|\\\")?(?:http|https)\\S+(?(1)[\\)|\\\"]|)'''\n",
    "    csv.selftext = csv.selftext.str.replace(url_regex, '', flags=re.M)\n",
    "    \n",
    "    # clean html, something like &amp;\n",
    "    def clean_html(row):\n",
    "        from bs4 import BeautifulSoup\n",
    "        from html import unescape\n",
    "\n",
    "        soup = BeautifulSoup(unescape(row), 'lxml')\n",
    "        return soup.text\n",
    "    \n",
    "    csv.selftext = csv.selftext.progress_apply(clean_html)\n",
    "        \n",
    "    return csv\n",
    "\n",
    "nosleep2020 = clean_data('./Creepy Data/NoSleep/NoSleep/RS_2020_nosleep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gxsa0i</td>\n",
       "      <td>Do NOT Open Your Eyes... (Pt. 1)</td>\n",
       "      <td>This is the only rule of our household. If you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gxs6jf</td>\n",
       "      <td>Do NOT open your eyes. (The Beginning)</td>\n",
       "      <td>This is the only rule of our household. If you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gxrytp</td>\n",
       "      <td>My Best Friend Saw Bugs Under His Skin</td>\n",
       "      <td>It is hard for me to talk about my old friend ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gxrnj7</td>\n",
       "      <td>I picked up a hitchhiker by mistake, now he's ...</td>\n",
       "      <td>They say the devil is in the details.  Well th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gxrm8v</td>\n",
       "      <td>I'm tasked with killing nameless things out in...</td>\n",
       "      <td>“Any sign of ‘em yet?” \\n\\nI continued staring...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21218</th>\n",
       "      <td>eihp0m</td>\n",
       "      <td>Hylophobia</td>\n",
       "      <td>*There is no cure for trauma. Once it enters t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21219</th>\n",
       "      <td>eihmg7</td>\n",
       "      <td>I adopted my late sisters orphaned child. This...</td>\n",
       "      <td>I knew Persephone would need time to adjust, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21221</th>\n",
       "      <td>eihgtp</td>\n",
       "      <td>My first paranormal experience!!</td>\n",
       "      <td>This isnt much, but this is surely the first u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21223</th>\n",
       "      <td>eigzgj</td>\n",
       "      <td>I met the demon under my bed... Its not what I...</td>\n",
       "      <td>Okay. for context, this story started about a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21225</th>\n",
       "      <td>eiggxr</td>\n",
       "      <td>The Perfect Wife</td>\n",
       "      <td>​\\n\\nI  was never able to find love, therefore...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15487 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0      gxsa0i                   Do NOT Open Your Eyes... (Pt. 1)   \n",
       "1      gxs6jf             Do NOT open your eyes. (The Beginning)   \n",
       "3      gxrytp             My Best Friend Saw Bugs Under His Skin   \n",
       "5      gxrnj7  I picked up a hitchhiker by mistake, now he's ...   \n",
       "6      gxrm8v  I'm tasked with killing nameless things out in...   \n",
       "...       ...                                                ...   \n",
       "21218  eihp0m                                         Hylophobia   \n",
       "21219  eihmg7  I adopted my late sisters orphaned child. This...   \n",
       "21221  eihgtp                   My first paranormal experience!!   \n",
       "21223  eigzgj  I met the demon under my bed... Its not what I...   \n",
       "21225  eiggxr                                   The Perfect Wife   \n",
       "\n",
       "                                                selftext  score  \n",
       "0      This is the only rule of our household. If you...      1  \n",
       "1      This is the only rule of our household. If you...      1  \n",
       "3      It is hard for me to talk about my old friend ...      1  \n",
       "5      They say the devil is in the details.  Well th...      1  \n",
       "6      “Any sign of ‘em yet?” \\n\\nI continued staring...      1  \n",
       "...                                                  ...    ...  \n",
       "21218  *There is no cure for trauma. Once it enters t...      1  \n",
       "21219  I knew Persephone would need time to adjust, b...      1  \n",
       "21221  This isnt much, but this is surely the first u...      1  \n",
       "21223  Okay. for context, this story started about a ...      1  \n",
       "21225  ​\\n\\nI  was never able to find love, therefore...      1  \n",
       "\n",
       "[15487 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nosleep2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61    [Part 1]\\n\\n*\"Jaaaaacckkk…\"*\\n\\n\"Demetri?\" I g...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nosleep2020.loc[[61],:].selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Part 1]\n",
      "\n",
      "*\"Jaaaaacckkk…\"*\n",
      "\n",
      "\"Demetri?\" I grabbed his shoulders and shook him, \"Did you-\"\n",
      "\n",
      "*\"Jaaahhh.\"* The low whisper came to my ears again.\n",
      "\n",
      "\"Who's there?…\"\n",
      "\n",
      "I strained my eyes, but the darkness was\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[Part 1]\\n\\n*\"Jaaaaacckkk…\"*\\n\\n\"Demetri?\" I grabbed his shoulders and shook him, \"Did you-\"\\n\\n*\"Jaaahhh.\"* The low whisper came to my ears again.\\n\\n\"Who\\'s there?…\"\\n\\nI strained my eyes, but the darkness was'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = nosleep2020.iloc[45,:].selftext\n",
    "\n",
    "# re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', '', text, flags=re.MULTILINE)\n",
    "print(text[:200])\n",
    "re.sub(r'(?:http|https):\\/\\/?.*(?=\\))', '', text)[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nosleep2020.to_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        This is the only rule of our household. If you...\n",
      "1        This is the only rule of our household. If you...\n",
      "3        It is hard for me to talk about my old friend ...\n",
      "5        They say the devil is in the details.  Well th...\n",
      "6        “Any sign of ‘em yet?” \\n\\nI continued staring...\n",
      "                               ...                        \n",
      "21218    *There is no cure for trauma. Once it enters t...\n",
      "21219    I knew Persephone would need time to adjust, b...\n",
      "21221    This isnt much, but this is surely the first u...\n",
      "21223    Okay. for context, this story started about a ...\n",
      "21225    ​\\n\\nI  was never able to find love...\n",
      "Name: selftext, Length: 15487, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "\n",
    "soup = BeautifulSoup(unescape(str(nosleep2020.selftext)), 'lxml')\n",
    "print(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-28f7521b5cf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_lg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselftext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Research-Mapping-Uncanny-Valley\\.venv\\creepyvenv\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Research-Mapping-Uncanny-Valley\\.venv\\creepyvenv\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(creepy.selftext[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(doc.sents):\n",
    "    encoded_text = np.expand_dims(embedder.encode(sent.text), axis = 0)\n",
    "    if idx == 0:\n",
    "        x = encoded_text\n",
    "    else:\n",
    "        x = np.append(x, encoded_text, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 10, 8), dtype=float32, numpy=\n",
       "array([[[-0.8919805 , -1.4307563 ,  0.15166256, ..., -1.7649478 ,\n",
       "         -1.021099  , -0.02627978],\n",
       "        [-1.4783181 ,  0.08943315,  0.17854673, ..., -0.19954081,\n",
       "          0.83018124, -0.5244327 ],\n",
       "        [ 0.4220114 ,  0.46339417, -0.79892176, ..., -0.19948697,\n",
       "          1.6006763 ,  1.775066  ],\n",
       "        ...,\n",
       "        [ 0.06492849, -1.7639278 , -0.27689138, ..., -0.0975803 ,\n",
       "         -0.55004656, -0.36803925],\n",
       "        [ 0.21676254,  0.46872047, -0.4581078 , ...,  0.57250595,\n",
       "          0.94552565,  0.69256175],\n",
       "        [-0.21706009,  1.0176384 , -0.29759172, ...,  0.10234821,\n",
       "         -0.7302468 , -0.10730033]],\n",
       "\n",
       "       [[ 0.70369136, -1.492371  , -0.00349201, ...,  0.27868918,\n",
       "          0.00752653, -1.2992821 ],\n",
       "        [-0.6542289 ,  1.655241  ,  0.5115025 , ...,  0.9593869 ,\n",
       "          0.02697794, -0.33769584],\n",
       "        [-0.6231138 ,  2.0751064 , -0.18052201, ..., -0.32436767,\n",
       "         -1.58487   ,  0.23079748],\n",
       "        ...,\n",
       "        [ 0.34623948, -0.6061341 ,  0.6046219 , ...,  0.59148204,\n",
       "          0.52786857,  1.0259186 ],\n",
       "        [ 1.4534197 , -0.48743206, -1.9399943 , ..., -1.383842  ,\n",
       "         -0.72536916,  0.08401131],\n",
       "        [ 0.12095169, -1.4706234 , -1.0866276 , ..., -0.13907197,\n",
       "          1.1877521 ,  0.88498414]],\n",
       "\n",
       "       [[ 1.5381111 ,  1.7943208 , -1.8118631 , ...,  0.51485467,\n",
       "         -1.5077109 ,  0.73991245],\n",
       "        [-0.12317562,  0.8019065 ,  0.23181851, ..., -1.8284345 ,\n",
       "          0.39918098, -0.42935404],\n",
       "        [ 0.5489498 ,  0.29058492, -0.7163982 , ..., -0.15996805,\n",
       "          0.7234546 ,  1.6929523 ],\n",
       "        ...,\n",
       "        [-1.5192128 , -0.6432286 ,  0.09102363, ...,  0.36311132,\n",
       "         -0.11855694,  0.26303554],\n",
       "        [ 1.5733589 , -0.48040214, -0.3102734 , ..., -0.7709761 ,\n",
       "          0.31788594, -0.41791776],\n",
       "        [-1.0632298 ,  0.73812604,  0.13090684, ..., -0.10609443,\n",
       "         -0.680478  ,  1.0416461 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.09556957,  1.3478434 ,  0.09041398, ...,  0.96595293,\n",
       "         -1.1162318 ,  0.66081053],\n",
       "        [ 1.5366329 , -0.53437346, -0.18271637, ..., -0.10972424,\n",
       "          0.84558105,  0.4825357 ],\n",
       "        [ 0.6946907 ,  1.0760901 , -0.6282669 , ..., -0.4771344 ,\n",
       "         -0.10791536,  0.6387555 ],\n",
       "        ...,\n",
       "        [-0.9492747 ,  1.0810653 , -0.5208035 , ...,  0.62055755,\n",
       "         -0.61695814,  0.8248391 ],\n",
       "        [ 1.0583895 ,  0.03736502, -0.5435381 , ...,  1.5400387 ,\n",
       "          0.03794611,  1.6306831 ],\n",
       "        [ 0.52607465,  1.0557736 ,  0.10045443, ...,  1.2906582 ,\n",
       "          0.34316638,  0.07289706]],\n",
       "\n",
       "       [[ 0.31008828, -0.48749736, -0.8629992 , ..., -0.72362596,\n",
       "          0.35882205,  0.3956305 ],\n",
       "        [ 0.34895587, -1.7468438 ,  0.44164196, ...,  2.2342968 ,\n",
       "          0.21330787, -0.7474117 ],\n",
       "        [-0.4820205 , -0.8684077 ,  0.81925076, ...,  0.2288416 ,\n",
       "          0.25693366,  2.1310766 ],\n",
       "        ...,\n",
       "        [-0.18733983, -0.0263906 , -1.1225334 , ...,  1.6538315 ,\n",
       "         -0.04926474,  1.3674538 ],\n",
       "        [-0.02061714, -0.86114126,  0.60299295, ...,  1.2489537 ,\n",
       "         -0.46712533,  0.14558421],\n",
       "        [-1.0051517 , -0.522422  , -0.8683605 , ..., -0.64168906,\n",
       "          1.2092884 , -1.0277344 ]],\n",
       "\n",
       "       [[ 0.6761186 , -0.40471044,  1.0049759 , ..., -0.989711  ,\n",
       "          0.19694547, -0.66273236],\n",
       "        [-0.80405515, -0.4514382 ,  2.2694142 , ..., -1.2888895 ,\n",
       "          0.49643135,  0.07977428],\n",
       "        [ 0.5526255 ,  0.24187207,  1.4495387 , ...,  0.9620111 ,\n",
       "         -2.2466807 ,  1.1059195 ],\n",
       "        ...,\n",
       "        [-0.8373081 , -0.25999016, -0.11890558, ..., -1.1348801 ,\n",
       "         -0.1783902 ,  0.613148  ],\n",
       "        [ 0.7638512 ,  0.36922157,  0.82043165, ...,  0.19487207,\n",
       "          0.99174756, -1.5156589 ],\n",
       "        [-0.73393244,  0.1543688 , -0.99476254, ..., -1.1591582 ,\n",
       "          0.6415371 , -0.8322137 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal([32, 10, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
      "INFO:absl:Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: imdb_reviews/plain_text/1.0.0\n",
      "INFO:absl:Load dataset info from /var/folders/xg/vnbr1nbs5pv86wd58cwl_mxm0000gn/T/tmpnja58or5tfds\n",
      "INFO:absl:Field info.config_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.config_description from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Generating dataset imdb_reviews (/Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104fb5ed3dd94963a0ce9567e5959007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Completed...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f5899a607d4843aac9332a446fd241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Dl Size...'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:URL http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz already downloaded: reusing /Users/anthony/tensorflow_datasets/downloads/ai.stanfor.edu_amaas_sentime_aclImdb_v1PaujRp-TxjBWz59jHXsMDm5WiexbxzaFQkEnXc3Tvo8.tar.gz.\n",
      "INFO:absl:Generating split train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75ecf9a564747488b9775a3beb19b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteSM226Q/imdb_reviews-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d883d4d7b3410b811b37beb9e68ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Done writing /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteSM226Q/imdb_reviews-train.tfrecord. Shard lengths: [25000]\n",
      "INFO:absl:Generating split test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4384eec4a7b43acacfb54fc8ed00c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteSM226Q/imdb_reviews-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f4dce4164d43a18428573e6e2da4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Done writing /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteSM226Q/imdb_reviews-test.tfrecord. Shard lengths: [25000]\n",
      "INFO:absl:Generating split unsupervised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1727ff25819b4e06a87b83c31159687b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteSM226Q/imdb_reviews-unsupervised.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acdd77a7051425d8bbd941c8a17101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Done writing /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteSM226Q/imdb_reviews-unsupervised.tfrecord. Shard lengths: [50000]\n",
      "INFO:absl:Skipping computing stats for mode ComputeStatsMode.SKIP.\n",
      "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n",
      "INFO:absl:Constructing tf.data.Dataset for split None, from /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /Users/anthony/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load('imdb_reviews', as_supervised = True, with_info = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 300)\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"<br\\\\s*/?>\", b\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [word for word, count in vocabulary.most_common()[:vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepyvenv",
   "language": "python",
   "name": "creepyvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
