{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "%rm -rf ./my_logs/\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy = pd.read_pickle('./pickles/new/creepy_with_log.pickle')\n",
    "noncreepy = pd.read_pickle('./pickles/new/non-creepy_with_log.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy_sum_vec_with_log_prepended = creepy.loc[:,'sum_vec_with_log_prepended'].copy()\n",
    "noncreepy_sum_vec_with_log_prepended = noncreepy.loc[:,'sum_vec_with_log_prepended'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy_features = pd.DataFrame(creepy_sum_vec_with_log_prepended.to_list()).to_numpy(dtype = float)\n",
    "creepy_labels = np.ones(len(creepy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncreepy_features = pd.DataFrame(noncreepy_sum_vec_with_log_prepended.to_list()).to_numpy(dtype = float)\n",
    "noncreepy_labels = np.zeros(len(noncreepy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.69813472   2.94098592  -5.6173358  ...  -4.59305143   0.358845\n",
      "   -9.06916523]\n",
      " [  0.69813472   2.94098592  -5.6173358  ...  -4.59305143   0.358845\n",
      "   -9.06916523]\n",
      " [  0.69813472 -19.20127296 -13.71549892 ...  18.18037987 -16.4872303\n",
      "   -6.75176859]\n",
      " ...\n",
      " [  0.69813472  -0.78924334   0.29064384 ...   1.36802995  -3.79267383\n",
      "   -1.91743255]\n",
      " [  0.69813472   2.08661604  -1.43281949 ...  -1.90943027   3.40888762\n",
      "    0.54635704]\n",
      " [  0.69813472  -1.46298337  -2.17777109 ...   1.96948338  -0.8519302\n",
      "   -2.56011105]] [1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "features = np.concatenate((creepy_features, noncreepy_features))\n",
    "labels = np.concatenate((creepy_labels, noncreepy_labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37846, 769) (37846,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.69813472  -2.90996027  -1.23474753 ...  -0.19339755  -5.26129436\n",
      "    0.6633786 ]\n",
      " [  0.69813472  -3.29692101  -4.52724075 ...   5.32049847  -6.84156275\n",
      "    5.25241518]\n",
      " [  0.69813472 -28.04434395  -1.474015   ...   1.37907588 -20.54758263\n",
      "  -12.68095112]\n",
      " ...\n",
      " [  0.69813472  -0.47868153   1.5586319  ...   0.27552071  -0.43390483\n",
      "   -0.19845644]\n",
      " [  0.69813472  -0.55444252   0.20812306 ...   0.2975263   -0.31782681\n",
      "    0.16983366]\n",
      " [  0.69813472  -0.34803268  -0.304665   ...   0.62482435  -0.17880447\n",
      "    0.32536349]] [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "features, labels = shuffle(features, labels)\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.92562187 0.59973403 ... 0.84290253 0.4675179  0.42122507]\n",
      " [0.         0.92549847 0.59764788 ... 0.84685788 0.46616054 0.42283638]\n",
      " [0.         0.91760653 0.59958243 ... 0.84403053 0.45438785 0.41653957]\n",
      " ...\n",
      " [0.         0.9263972  0.60150394 ... 0.8432389  0.47166435 0.42092246]\n",
      " [0.         0.92637304 0.60064825 ... 0.84325469 0.47176405 0.42105177]\n",
      " [0.         0.92643886 0.60032334 ... 0.84348947 0.47188346 0.42110638]] [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "print(scaled_features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] 70% train, 15% val, 15% test\n",
    " - Train: 26500\n",
    " - Valid: 5677\n",
    " - Test: 5669\n",
    "- [ ] 80% train, 10% val, 10% test\n",
    "- [ ] 60% train, 20% val, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = scaled_features[:26500], scaled_features[26500:26500+5677], scaled_features[26500+5677:]\n",
    "y_train, y_valid, y_test = labels[:26500], labels[26500:26500+5677], labels[26500+5677:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KerasRegressor method to fine-tuning neural network hyperparameters (Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=2, n_neurons=300, learning_rate=3e-3, input_shape=(769,)):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid')) # here the units must be 1 in order for binary classifications to work\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(lr=learning_rate), # you can tune the learning rate here. Default lr = 0.01\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.7965 - val_loss: 0.2952 - val_accuracy: 0.8674\n",
      "Epoch 2/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8832 - val_loss: 0.2395 - val_accuracy: 0.9021\n",
      "Epoch 3/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.8916 - val_loss: 0.2449 - val_accuracy: 0.8961\n",
      "Epoch 4/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.9018 - val_loss: 0.3774 - val_accuracy: 0.8640\n",
      "Epoch 5/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9014 - val_loss: 0.2372 - val_accuracy: 0.9068\n",
      "Epoch 6/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9096 - val_loss: 0.2222 - val_accuracy: 0.9265\n",
      "Epoch 7/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9085 - val_loss: 0.2674 - val_accuracy: 0.9086\n",
      "Epoch 8/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.9096 - val_loss: 0.2587 - val_accuracy: 0.9137\n",
      "Epoch 9/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.9105 - val_loss: 0.2789 - val_accuracy: 0.9028\n",
      "Epoch 10/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2383 - accuracy: 0.9115 - val_loss: 0.2411 - val_accuracy: 0.9065\n",
      "Epoch 11/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2278 - accuracy: 0.9147 - val_loss: 0.1837 - val_accuracy: 0.9352\n",
      "Epoch 12/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2282 - accuracy: 0.9171 - val_loss: 0.1859 - val_accuracy: 0.9345\n",
      "Epoch 13/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2285 - accuracy: 0.9176 - val_loss: 0.1979 - val_accuracy: 0.9348\n",
      "Epoch 14/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9237 - val_loss: 0.2101 - val_accuracy: 0.9294\n",
      "Epoch 15/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2252 - accuracy: 0.9196 - val_loss: 0.2394 - val_accuracy: 0.9220\n",
      "Epoch 16/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2192 - accuracy: 0.9219 - val_loss: 0.1841 - val_accuracy: 0.9415\n",
      "Epoch 17/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2125 - accuracy: 0.9231 - val_loss: 0.1738 - val_accuracy: 0.9420\n",
      "Epoch 18/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9244 - val_loss: 0.1826 - val_accuracy: 0.9341\n",
      "Epoch 19/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2172 - accuracy: 0.9211 - val_loss: 0.1877 - val_accuracy: 0.9410\n",
      "Epoch 20/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2132 - accuracy: 0.9233 - val_loss: 0.1771 - val_accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2216 - accuracy: 0.9210 - val_loss: 0.1771 - val_accuracy: 0.9424\n",
      "Epoch 22/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2034 - accuracy: 0.9278 - val_loss: 0.3195 - val_accuracy: 0.8871\n",
      "Epoch 23/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2119 - accuracy: 0.9258 - val_loss: 0.1650 - val_accuracy: 0.9438\n",
      "Epoch 24/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2056 - accuracy: 0.9281 - val_loss: 0.1704 - val_accuracy: 0.9438\n",
      "Epoch 25/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9302 - val_loss: 0.1622 - val_accuracy: 0.9466\n",
      "Epoch 26/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9301 - val_loss: 0.2033 - val_accuracy: 0.9271\n",
      "Epoch 27/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9315 - val_loss: 0.1600 - val_accuracy: 0.9472\n",
      "Epoch 28/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9332 - val_loss: 0.1977 - val_accuracy: 0.9336\n",
      "Epoch 29/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1973 - accuracy: 0.9297 - val_loss: 0.1859 - val_accuracy: 0.9338\n",
      "Epoch 30/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1946 - accuracy: 0.9323 - val_loss: 0.1605 - val_accuracy: 0.9475\n",
      "Epoch 31/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1900 - accuracy: 0.9342 - val_loss: 0.2721 - val_accuracy: 0.9036\n",
      "Epoch 32/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9353 - val_loss: 0.1592 - val_accuracy: 0.9486\n",
      "Epoch 33/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9340 - val_loss: 0.1549 - val_accuracy: 0.9498\n",
      "Epoch 34/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1843 - accuracy: 0.9363 - val_loss: 0.6189 - val_accuracy: 0.6089\n",
      "Epoch 35/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1923 - accuracy: 0.9330 - val_loss: 0.1603 - val_accuracy: 0.9456\n",
      "Epoch 36/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.9349 - val_loss: 0.1808 - val_accuracy: 0.9413\n",
      "Epoch 37/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9355 - val_loss: 0.1552 - val_accuracy: 0.9494\n",
      "Epoch 38/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9337 - val_loss: 0.2332 - val_accuracy: 0.9146\n",
      "Epoch 39/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.9411 - val_loss: 0.1453 - val_accuracy: 0.9519\n",
      "Epoch 40/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1939 - accuracy: 0.9329 - val_loss: 0.1447 - val_accuracy: 0.9530\n",
      "Epoch 41/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.9388 - val_loss: 0.1481 - val_accuracy: 0.9521\n",
      "Epoch 42/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.9365 - val_loss: 0.2225 - val_accuracy: 0.9332\n",
      "Epoch 43/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.9424 - val_loss: 0.1387 - val_accuracy: 0.9553\n",
      "Epoch 44/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1719 - accuracy: 0.9408 - val_loss: 0.1374 - val_accuracy: 0.9558\n",
      "Epoch 45/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1715 - accuracy: 0.9421 - val_loss: 0.1397 - val_accuracy: 0.9568\n",
      "Epoch 46/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.9397 - val_loss: 0.1653 - val_accuracy: 0.9482\n",
      "Epoch 47/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9391 - val_loss: 0.1452 - val_accuracy: 0.9565\n",
      "Epoch 48/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1673 - accuracy: 0.9439 - val_loss: 0.1596 - val_accuracy: 0.9475\n",
      "Epoch 49/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1687 - accuracy: 0.9428 - val_loss: 0.1443 - val_accuracy: 0.9547\n",
      "Epoch 50/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1603 - accuracy: 0.9457 - val_loss: 0.1312 - val_accuracy: 0.9579\n",
      "Epoch 51/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1620 - accuracy: 0.9448 - val_loss: 0.1338 - val_accuracy: 0.9588\n",
      "Epoch 52/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9462 - val_loss: 0.1310 - val_accuracy: 0.9590\n",
      "Epoch 53/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1651 - accuracy: 0.9444 - val_loss: 0.2213 - val_accuracy: 0.9207\n",
      "Epoch 54/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.9437 - val_loss: 0.1439 - val_accuracy: 0.9551\n",
      "Epoch 55/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1600 - accuracy: 0.9475 - val_loss: 0.3899 - val_accuracy: 0.8788\n",
      "Epoch 56/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1675 - accuracy: 0.9438 - val_loss: 0.1334 - val_accuracy: 0.9591\n",
      "Epoch 57/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1605 - accuracy: 0.9457 - val_loss: 0.1277 - val_accuracy: 0.9605\n",
      "Epoch 58/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9504 - val_loss: 0.2570 - val_accuracy: 0.9128\n",
      "Epoch 59/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1593 - accuracy: 0.9463 - val_loss: 0.2150 - val_accuracy: 0.9237\n",
      "Epoch 60/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1504 - accuracy: 0.9498 - val_loss: 0.1245 - val_accuracy: 0.9616\n",
      "Epoch 61/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1513 - accuracy: 0.9505 - val_loss: 0.5598 - val_accuracy: 0.8395\n",
      "Epoch 62/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9415 - val_loss: 0.3939 - val_accuracy: 0.8608\n",
      "Epoch 63/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1560 - accuracy: 0.9478 - val_loss: 0.2787 - val_accuracy: 0.9123\n",
      "Epoch 64/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9439 - val_loss: 0.1464 - val_accuracy: 0.9521\n",
      "Epoch 65/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1505 - accuracy: 0.9494 - val_loss: 0.2352 - val_accuracy: 0.9292\n",
      "Epoch 66/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1698 - accuracy: 0.9450 - val_loss: 0.1404 - val_accuracy: 0.9535\n",
      "Epoch 67/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1538 - accuracy: 0.9480 - val_loss: 0.1663 - val_accuracy: 0.9484\n",
      "Epoch 68/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9494 - val_loss: 0.1222 - val_accuracy: 0.9628\n",
      "Epoch 69/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9499 - val_loss: 0.1290 - val_accuracy: 0.9595\n",
      "Epoch 70/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1601 - accuracy: 0.9473 - val_loss: 0.1326 - val_accuracy: 0.9563\n",
      "Epoch 71/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1549 - accuracy: 0.9500 - val_loss: 0.1417 - val_accuracy: 0.9538\n",
      "Epoch 72/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1639 - accuracy: 0.9457 - val_loss: 0.2836 - val_accuracy: 0.9123\n",
      "Epoch 73/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9508 - val_loss: 0.1778 - val_accuracy: 0.9401\n",
      "Epoch 74/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9484 - val_loss: 0.1625 - val_accuracy: 0.9454\n",
      "Epoch 75/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9489 - val_loss: 0.2012 - val_accuracy: 0.9391\n",
      "Epoch 76/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1475 - accuracy: 0.9521 - val_loss: 0.1281 - val_accuracy: 0.9611\n",
      "Epoch 77/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1471 - accuracy: 0.9513 - val_loss: 0.1203 - val_accuracy: 0.9621\n",
      "Epoch 78/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9508 - val_loss: 0.1354 - val_accuracy: 0.9561\n",
      "Epoch 79/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9498 - val_loss: 0.2402 - val_accuracy: 0.9160\n",
      "Epoch 80/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9495 - val_loss: 0.1508 - val_accuracy: 0.9551\n",
      "Epoch 81/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1387 - accuracy: 0.9550 - val_loss: 0.1481 - val_accuracy: 0.9521\n",
      "Epoch 82/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1450 - accuracy: 0.9519 - val_loss: 0.1350 - val_accuracy: 0.9560\n",
      "Epoch 83/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1450 - accuracy: 0.9537 - val_loss: 0.4481 - val_accuracy: 0.8126\n",
      "Epoch 84/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1520 - accuracy: 0.9505 - val_loss: 0.1218 - val_accuracy: 0.9634\n",
      "Epoch 85/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1514 - accuracy: 0.9498 - val_loss: 0.1186 - val_accuracy: 0.9646\n",
      "Epoch 86/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9489 - val_loss: 0.1270 - val_accuracy: 0.9584\n",
      "Epoch 87/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1439 - accuracy: 0.9530 - val_loss: 0.1171 - val_accuracy: 0.9648\n",
      "Epoch 88/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9526 - val_loss: 0.1178 - val_accuracy: 0.9634\n",
      "Epoch 89/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1528 - accuracy: 0.9501 - val_loss: 0.2945 - val_accuracy: 0.9014\n",
      "Epoch 90/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1437 - accuracy: 0.9524 - val_loss: 0.1157 - val_accuracy: 0.9642\n",
      "Epoch 91/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1549 - accuracy: 0.9491 - val_loss: 0.1429 - val_accuracy: 0.9519\n",
      "Epoch 92/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1419 - accuracy: 0.9535 - val_loss: 0.1266 - val_accuracy: 0.9588\n",
      "Epoch 93/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9547 - val_loss: 0.1340 - val_accuracy: 0.9574\n",
      "Epoch 94/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9539 - val_loss: 0.1424 - val_accuracy: 0.9528\n",
      "Epoch 95/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1556 - accuracy: 0.9476 - val_loss: 0.1186 - val_accuracy: 0.9637\n",
      "Epoch 96/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9540 - val_loss: 0.1162 - val_accuracy: 0.9635\n",
      "Epoch 97/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1392 - accuracy: 0.9542 - val_loss: 0.1220 - val_accuracy: 0.9623\n",
      "Epoch 98/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9521 - val_loss: 0.1205 - val_accuracy: 0.9616\n",
      "Epoch 99/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9524 - val_loss: 0.1502 - val_accuracy: 0.9523\n",
      "Epoch 100/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1449 - accuracy: 0.9527 - val_loss: 0.1174 - val_accuracy: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f60f82fa370>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs = 100, \n",
    "             validation_data=(X_valid,y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6817 - accuracy: 0.5898 - val_loss: 0.6679 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6647 - accuracy: 0.5913 - val_loss: 0.6511 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.6695 - val_loss: 0.5331 - val_accuracy: 0.7391\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3910 - accuracy: 0.8600 - val_loss: 0.3368 - val_accuracy: 0.9204\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.8914 - val_loss: 0.2612 - val_accuracy: 0.9031\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2669 - accuracy: 0.8979 - val_loss: 0.2899 - val_accuracy: 0.8744\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2598 - accuracy: 0.9009 - val_loss: 0.2475 - val_accuracy: 0.9207\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9043 - val_loss: 0.2816 - val_accuracy: 0.9193\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.9071 - val_loss: 0.2684 - val_accuracy: 0.9216\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9071 - val_loss: 0.2272 - val_accuracy: 0.9176\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2405 - accuracy: 0.9101 - val_loss: 0.2271 - val_accuracy: 0.9228\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.9086 - val_loss: 0.2442 - val_accuracy: 0.9228\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.9098 - val_loss: 0.2510 - val_accuracy: 0.8991\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.9114 - val_loss: 0.2261 - val_accuracy: 0.9265\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.9115 - val_loss: 0.2146 - val_accuracy: 0.9241\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.9128 - val_loss: 0.2198 - val_accuracy: 0.9139\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2309 - accuracy: 0.9133 - val_loss: 0.2185 - val_accuracy: 0.9273\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2288 - accuracy: 0.9126 - val_loss: 0.2157 - val_accuracy: 0.9195\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2261 - accuracy: 0.9140 - val_loss: 0.2125 - val_accuracy: 0.9269\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.9147 - val_loss: 0.2456 - val_accuracy: 0.9038\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2250 - accuracy: 0.9142 - val_loss: 0.2073 - val_accuracy: 0.9269\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2283 - accuracy: 0.9138 - val_loss: 0.2383 - val_accuracy: 0.9206\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9153 - val_loss: 0.2074 - val_accuracy: 0.9258\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2244 - accuracy: 0.9149 - val_loss: 0.2143 - val_accuracy: 0.9294\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2235 - accuracy: 0.9159 - val_loss: 0.2032 - val_accuracy: 0.9278\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2196 - accuracy: 0.9191 - val_loss: 0.2029 - val_accuracy: 0.9273\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2196 - accuracy: 0.9181 - val_loss: 0.2130 - val_accuracy: 0.9186\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2211 - accuracy: 0.9168 - val_loss: 0.2042 - val_accuracy: 0.9302\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2178 - accuracy: 0.9200 - val_loss: 0.2092 - val_accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2234 - accuracy: 0.9176 - val_loss: 0.2108 - val_accuracy: 0.9204\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2185 - accuracy: 0.9176 - val_loss: 0.2034 - val_accuracy: 0.9269\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2155 - accuracy: 0.9176 - val_loss: 0.1983 - val_accuracy: 0.9317\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9209 - val_loss: 0.2124 - val_accuracy: 0.9273\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9196 - val_loss: 0.2396 - val_accuracy: 0.9105\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2152 - accuracy: 0.9196 - val_loss: 0.2055 - val_accuracy: 0.9306\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9199 - val_loss: 0.2018 - val_accuracy: 0.9269\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9200 - val_loss: 0.1964 - val_accuracy: 0.9309\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2095 - accuracy: 0.9211 - val_loss: 0.1952 - val_accuracy: 0.9313\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2168 - accuracy: 0.9191 - val_loss: 0.1994 - val_accuracy: 0.9278\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9224 - val_loss: 0.1920 - val_accuracy: 0.9327\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9226 - val_loss: 0.1932 - val_accuracy: 0.9317\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9221 - val_loss: 0.1933 - val_accuracy: 0.9313\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2102 - accuracy: 0.9214 - val_loss: 0.2106 - val_accuracy: 0.9269\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9226 - val_loss: 0.1899 - val_accuracy: 0.9357\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9234 - val_loss: 0.1979 - val_accuracy: 0.9274\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2093 - accuracy: 0.9221 - val_loss: 0.1889 - val_accuracy: 0.9331\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9214 - val_loss: 0.1929 - val_accuracy: 0.9317\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9236 - val_loss: 0.1969 - val_accuracy: 0.9273\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2073 - accuracy: 0.9232 - val_loss: 0.1866 - val_accuracy: 0.9364\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2015 - accuracy: 0.9274 - val_loss: 0.1861 - val_accuracy: 0.9345\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9236 - val_loss: 0.1867 - val_accuracy: 0.9364\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9247 - val_loss: 0.2570 - val_accuracy: 0.9066\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2043 - accuracy: 0.9235 - val_loss: 0.1848 - val_accuracy: 0.9369\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2053 - accuracy: 0.9236 - val_loss: 0.2088 - val_accuracy: 0.9234\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9258 - val_loss: 0.1825 - val_accuracy: 0.9378\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9266 - val_loss: 0.1830 - val_accuracy: 0.9350\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1998 - accuracy: 0.9261 - val_loss: 0.2367 - val_accuracy: 0.9140\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9264 - val_loss: 0.2011 - val_accuracy: 0.9315\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2008 - accuracy: 0.9257 - val_loss: 0.2025 - val_accuracy: 0.9306\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9283 - val_loss: 0.1801 - val_accuracy: 0.9380\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.9272 - val_loss: 0.1802 - val_accuracy: 0.9387\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1982 - accuracy: 0.9271 - val_loss: 0.1789 - val_accuracy: 0.9392\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9278 - val_loss: 0.1794 - val_accuracy: 0.9364\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9287 - val_loss: 0.1801 - val_accuracy: 0.9362\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1980 - accuracy: 0.9277 - val_loss: 0.2188 - val_accuracy: 0.9195\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1938 - accuracy: 0.9288 - val_loss: 0.1770 - val_accuracy: 0.9403\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1914 - accuracy: 0.9311 - val_loss: 0.1978 - val_accuracy: 0.9278\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.9285 - val_loss: 0.1870 - val_accuracy: 0.9331\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9307 - val_loss: 0.1781 - val_accuracy: 0.9368\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.9288 - val_loss: 0.1749 - val_accuracy: 0.9398\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9317 - val_loss: 0.1820 - val_accuracy: 0.9346\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1917 - accuracy: 0.9305 - val_loss: 0.1907 - val_accuracy: 0.9348\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.9298 - val_loss: 0.1779 - val_accuracy: 0.9364\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9320 - val_loss: 0.1703 - val_accuracy: 0.9424\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1879 - accuracy: 0.9312 - val_loss: 0.1740 - val_accuracy: 0.9385\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.9317 - val_loss: 0.1807 - val_accuracy: 0.9387\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.9318 - val_loss: 0.1729 - val_accuracy: 0.9417\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.9347 - val_loss: 0.1686 - val_accuracy: 0.9445\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.9336 - val_loss: 0.1799 - val_accuracy: 0.9392\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.9328 - val_loss: 0.1715 - val_accuracy: 0.9403\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1844 - accuracy: 0.9349 - val_loss: 0.1825 - val_accuracy: 0.9361\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1805 - accuracy: 0.9350 - val_loss: 0.1668 - val_accuracy: 0.9440\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.9320 - val_loss: 0.1711 - val_accuracy: 0.9396\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.9360 - val_loss: 0.1990 - val_accuracy: 0.9318\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9362 - val_loss: 0.1630 - val_accuracy: 0.9447\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.9342 - val_loss: 0.1781 - val_accuracy: 0.9399\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.9359 - val_loss: 0.1621 - val_accuracy: 0.9443\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9350 - val_loss: 0.1701 - val_accuracy: 0.9405\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.9350 - val_loss: 0.1644 - val_accuracy: 0.9443\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9335 - val_loss: 0.1636 - val_accuracy: 0.9454\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9390 - val_loss: 0.1630 - val_accuracy: 0.9459\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9372 - val_loss: 0.2051 - val_accuracy: 0.9308\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9372 - val_loss: 0.1581 - val_accuracy: 0.9465\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.9364 - val_loss: 0.1651 - val_accuracy: 0.9442\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.9368 - val_loss: 0.1564 - val_accuracy: 0.9491\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1713 - accuracy: 0.9395 - val_loss: 0.1574 - val_accuracy: 0.9459\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.9415 - val_loss: 0.1610 - val_accuracy: 0.9461\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9388 - val_loss: 0.1543 - val_accuracy: 0.9479\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9375 - val_loss: 0.2065 - val_accuracy: 0.9253\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1716 - accuracy: 0.9388 - val_loss: 0.1715 - val_accuracy: 0.9424\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9417\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6735 - accuracy: 0.5946 - val_loss: 0.6690 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6682 - accuracy: 0.5946 - val_loss: 0.6618 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6560 - accuracy: 0.5951 - val_loss: 0.6422 - val_accuracy: 0.6037\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6067 - accuracy: 0.6669 - val_loss: 0.5299 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8394 - val_loss: 0.3445 - val_accuracy: 0.8795\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8900 - val_loss: 0.2645 - val_accuracy: 0.8987\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.9030 - val_loss: 0.2459 - val_accuracy: 0.9200\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2392 - accuracy: 0.9083 - val_loss: 0.2273 - val_accuracy: 0.9197\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2341 - accuracy: 0.9119 - val_loss: 0.2197 - val_accuracy: 0.9200\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2310 - accuracy: 0.9141 - val_loss: 0.2279 - val_accuracy: 0.9072\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2254 - accuracy: 0.9146 - val_loss: 0.2209 - val_accuracy: 0.9246\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9154 - val_loss: 0.2160 - val_accuracy: 0.9236\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9154 - val_loss: 0.2136 - val_accuracy: 0.9221\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9159 - val_loss: 0.2096 - val_accuracy: 0.9239\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2198 - accuracy: 0.9171 - val_loss: 0.2140 - val_accuracy: 0.9174\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.9188 - val_loss: 0.2110 - val_accuracy: 0.9269\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9200 - val_loss: 0.2063 - val_accuracy: 0.9250\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9212 - val_loss: 0.2058 - val_accuracy: 0.9258\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2221 - accuracy: 0.9160 - val_loss: 0.2038 - val_accuracy: 0.9258\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2186 - accuracy: 0.9179 - val_loss: 0.2056 - val_accuracy: 0.9267\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9186 - val_loss: 0.2208 - val_accuracy: 0.9139\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9193 - val_loss: 0.2077 - val_accuracy: 0.9230\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2204 - accuracy: 0.9175 - val_loss: 0.2529 - val_accuracy: 0.9017\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2130 - accuracy: 0.9200 - val_loss: 0.2095 - val_accuracy: 0.9276\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9213 - val_loss: 0.2039 - val_accuracy: 0.9297\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9199 - val_loss: 0.2002 - val_accuracy: 0.9280\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2119 - accuracy: 0.9215 - val_loss: 0.2262 - val_accuracy: 0.9211\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9212 - val_loss: 0.2015 - val_accuracy: 0.9276\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9222 - val_loss: 0.1988 - val_accuracy: 0.9308\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2104 - accuracy: 0.9234 - val_loss: 0.2032 - val_accuracy: 0.9301\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2068 - accuracy: 0.9239 - val_loss: 0.2424 - val_accuracy: 0.9140\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2062 - accuracy: 0.9244 - val_loss: 0.1970 - val_accuracy: 0.9278\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9239 - val_loss: 0.1954 - val_accuracy: 0.9288\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9230 - val_loss: 0.1959 - val_accuracy: 0.9313\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9236 - val_loss: 0.1960 - val_accuracy: 0.9308\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9258 - val_loss: 0.2129 - val_accuracy: 0.9258\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9232 - val_loss: 0.1943 - val_accuracy: 0.9317\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.9231 - val_loss: 0.2056 - val_accuracy: 0.9290\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9260 - val_loss: 0.1997 - val_accuracy: 0.9265\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 3ms/step - loss: 0.2056 - accuracy: 0.9256 - val_loss: 0.1985 - val_accuracy: 0.9264\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2027 - accuracy: 0.9235 - val_loss: 0.1929 - val_accuracy: 0.9327\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.9234 - val_loss: 0.1941 - val_accuracy: 0.9329\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9230 - val_loss: 0.1999 - val_accuracy: 0.9309\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9240 - val_loss: 0.1946 - val_accuracy: 0.9267\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1993 - accuracy: 0.9268 - val_loss: 0.1876 - val_accuracy: 0.9334\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1998 - accuracy: 0.9257 - val_loss: 0.1986 - val_accuracy: 0.9250\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9267 - val_loss: 0.1927 - val_accuracy: 0.9341\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9273 - val_loss: 0.2042 - val_accuracy: 0.9223\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9282 - val_loss: 0.1960 - val_accuracy: 0.9299\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1988 - accuracy: 0.9253 - val_loss: 0.1901 - val_accuracy: 0.9327\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1944 - accuracy: 0.9286 - val_loss: 0.1839 - val_accuracy: 0.9324\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9278 - val_loss: 0.1857 - val_accuracy: 0.9359\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9274 - val_loss: 0.1805 - val_accuracy: 0.9359\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9292 - val_loss: 0.1844 - val_accuracy: 0.9362\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9287 - val_loss: 0.1896 - val_accuracy: 0.9325\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.9311 - val_loss: 0.1763 - val_accuracy: 0.9362\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.9316 - val_loss: 0.2522 - val_accuracy: 0.9100\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9317 - val_loss: 0.1793 - val_accuracy: 0.9362\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.9305 - val_loss: 0.1800 - val_accuracy: 0.9361\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9311 - val_loss: 0.1782 - val_accuracy: 0.9424\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9304 - val_loss: 0.1980 - val_accuracy: 0.9280\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9324 - val_loss: 0.1688 - val_accuracy: 0.9373\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.9345 - val_loss: 0.1657 - val_accuracy: 0.9389\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.9335 - val_loss: 0.1849 - val_accuracy: 0.9366\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.9334 - val_loss: 0.1746 - val_accuracy: 0.9339\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.9352 - val_loss: 0.1621 - val_accuracy: 0.9387\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1720 - accuracy: 0.9363 - val_loss: 0.1805 - val_accuracy: 0.9420\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.9364 - val_loss: 0.1542 - val_accuracy: 0.9436\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1699 - accuracy: 0.9358 - val_loss: 0.1689 - val_accuracy: 0.9565\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9368 - val_loss: 0.1890 - val_accuracy: 0.9302\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9403 - val_loss: 0.1662 - val_accuracy: 0.9339\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1619 - accuracy: 0.9405 - val_loss: 0.2600 - val_accuracy: 0.8998\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1599 - accuracy: 0.9424 - val_loss: 0.1485 - val_accuracy: 0.9567\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1620 - accuracy: 0.9402 - val_loss: 0.1429 - val_accuracy: 0.9475\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1580 - accuracy: 0.9430 - val_loss: 0.1421 - val_accuracy: 0.9472\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9426 - val_loss: 0.1392 - val_accuracy: 0.9510\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9414 - val_loss: 0.1351 - val_accuracy: 0.9575\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9470 - val_loss: 0.1457 - val_accuracy: 0.9449\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1477 - accuracy: 0.9472 - val_loss: 0.1324 - val_accuracy: 0.9602\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9437 - val_loss: 0.2215 - val_accuracy: 0.8991\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9453 - val_loss: 0.1309 - val_accuracy: 0.9620\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1426 - accuracy: 0.9496 - val_loss: 0.1395 - val_accuracy: 0.9586\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1438 - accuracy: 0.9477 - val_loss: 0.1329 - val_accuracy: 0.9556\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9459 - val_loss: 0.1856 - val_accuracy: 0.9325\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1413 - accuracy: 0.9492 - val_loss: 0.1254 - val_accuracy: 0.9556\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9461 - val_loss: 0.1247 - val_accuracy: 0.9570\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1368 - accuracy: 0.9518 - val_loss: 0.1767 - val_accuracy: 0.9378\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9510 - val_loss: 0.1443 - val_accuracy: 0.9526\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1389 - accuracy: 0.9530 - val_loss: 0.1417 - val_accuracy: 0.9516\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9453 - val_loss: 0.1996 - val_accuracy: 0.9265\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1418 - accuracy: 0.9501 - val_loss: 0.1260 - val_accuracy: 0.9572\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9518 - val_loss: 0.1500 - val_accuracy: 0.9489\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.9520 - val_loss: 0.1342 - val_accuracy: 0.9583\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9489 - val_loss: 0.1188 - val_accuracy: 0.9605\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1399 - accuracy: 0.9515 - val_loss: 0.1881 - val_accuracy: 0.9324\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1394 - accuracy: 0.9516 - val_loss: 0.1234 - val_accuracy: 0.9611\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1311 - accuracy: 0.9548 - val_loss: 0.1186 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9525 - val_loss: 0.1680 - val_accuracy: 0.9436\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1335 - accuracy: 0.9524 - val_loss: 0.1262 - val_accuracy: 0.9595\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1350 - accuracy: 0.9538 - val_loss: 0.1153 - val_accuracy: 0.9627\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9608\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6792 - accuracy: 0.5916 - val_loss: 0.6719 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6748 - accuracy: 0.5916 - val_loss: 0.6701 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6724 - accuracy: 0.5916 - val_loss: 0.6665 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6639 - accuracy: 0.5916 - val_loss: 0.6438 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.6831 - val_loss: 0.4982 - val_accuracy: 0.8591\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4197 - accuracy: 0.8514 - val_loss: 0.3583 - val_accuracy: 0.8792\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8763 - val_loss: 0.3084 - val_accuracy: 0.9063\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2916 - accuracy: 0.8891 - val_loss: 0.2708 - val_accuracy: 0.8906\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.8962 - val_loss: 0.2661 - val_accuracy: 0.9190\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9005 - val_loss: 0.2580 - val_accuracy: 0.8873\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.9041 - val_loss: 0.2511 - val_accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2452 - accuracy: 0.9071 - val_loss: 0.2364 - val_accuracy: 0.9047\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2425 - accuracy: 0.9090 - val_loss: 0.2461 - val_accuracy: 0.9232\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.9096 - val_loss: 0.2431 - val_accuracy: 0.9237\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.9107 - val_loss: 0.2258 - val_accuracy: 0.9218\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2361 - accuracy: 0.9102 - val_loss: 0.2206 - val_accuracy: 0.9218\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2330 - accuracy: 0.9129 - val_loss: 0.2439 - val_accuracy: 0.8984\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2310 - accuracy: 0.9141 - val_loss: 0.2195 - val_accuracy: 0.9147\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9150 - val_loss: 0.2146 - val_accuracy: 0.9200\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.9141 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9174 - val_loss: 0.2112 - val_accuracy: 0.9236\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2240 - accuracy: 0.9179 - val_loss: 0.2139 - val_accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9168 - val_loss: 0.2089 - val_accuracy: 0.9241\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.9177 - val_loss: 0.2126 - val_accuracy: 0.9207\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2216 - accuracy: 0.9186 - val_loss: 0.2092 - val_accuracy: 0.9250\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2203 - accuracy: 0.9179 - val_loss: 0.2175 - val_accuracy: 0.9260\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9179 - val_loss: 0.2072 - val_accuracy: 0.9250\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2190 - accuracy: 0.9197 - val_loss: 0.2054 - val_accuracy: 0.9244\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2206 - accuracy: 0.9177 - val_loss: 0.2057 - val_accuracy: 0.9258\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9203 - val_loss: 0.2077 - val_accuracy: 0.9234\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9192 - val_loss: 0.2107 - val_accuracy: 0.9281\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2177 - accuracy: 0.9203 - val_loss: 0.2032 - val_accuracy: 0.9267\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9191 - val_loss: 0.2027 - val_accuracy: 0.9276\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2173 - accuracy: 0.9201 - val_loss: 0.2027 - val_accuracy: 0.9257\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2191 - accuracy: 0.9203 - val_loss: 0.2146 - val_accuracy: 0.9195\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2170 - accuracy: 0.9208 - val_loss: 0.2027 - val_accuracy: 0.9290\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2160 - accuracy: 0.9213 - val_loss: 0.2022 - val_accuracy: 0.9267\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2148 - accuracy: 0.9210 - val_loss: 0.2020 - val_accuracy: 0.9273\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9213 - val_loss: 0.2097 - val_accuracy: 0.9220\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9228 - val_loss: 0.2017 - val_accuracy: 0.9276\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2126 - accuracy: 0.9230 - val_loss: 0.2256 - val_accuracy: 0.9135\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.9221 - val_loss: 0.2024 - val_accuracy: 0.9276\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.9231 - val_loss: 0.2018 - val_accuracy: 0.9278\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9217 - val_loss: 0.1970 - val_accuracy: 0.9280\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.9227 - val_loss: 0.1981 - val_accuracy: 0.9302\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9223 - val_loss: 0.2064 - val_accuracy: 0.9276\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.9235 - val_loss: 0.1961 - val_accuracy: 0.9318\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2080 - accuracy: 0.9243 - val_loss: 0.2164 - val_accuracy: 0.9179\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9225 - val_loss: 0.2033 - val_accuracy: 0.9258\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9223 - val_loss: 0.1973 - val_accuracy: 0.9292\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9231 - val_loss: 0.1938 - val_accuracy: 0.9292\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9250 - val_loss: 0.2228 - val_accuracy: 0.9202\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9240 - val_loss: 0.2248 - val_accuracy: 0.9193\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9239 - val_loss: 0.1952 - val_accuracy: 0.9294\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9251 - val_loss: 0.1991 - val_accuracy: 0.9297\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2056 - accuracy: 0.9249 - val_loss: 0.1918 - val_accuracy: 0.9308\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9255 - val_loss: 0.2238 - val_accuracy: 0.9181\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2092 - accuracy: 0.9243 - val_loss: 0.2231 - val_accuracy: 0.9200\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2053 - accuracy: 0.9258 - val_loss: 0.1901 - val_accuracy: 0.9343\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9258 - val_loss: 0.2101 - val_accuracy: 0.9221\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9254 - val_loss: 0.1921 - val_accuracy: 0.9331\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2042 - accuracy: 0.9251 - val_loss: 0.1898 - val_accuracy: 0.9327\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.9239 - val_loss: 0.1997 - val_accuracy: 0.9285\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.9269 - val_loss: 0.1886 - val_accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9273 - val_loss: 0.1876 - val_accuracy: 0.9355\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2007 - accuracy: 0.9283 - val_loss: 0.1910 - val_accuracy: 0.9341\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2010 - accuracy: 0.9265 - val_loss: 0.2079 - val_accuracy: 0.9232\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9272 - val_loss: 0.1864 - val_accuracy: 0.9352\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2023 - accuracy: 0.9278 - val_loss: 0.1865 - val_accuracy: 0.9354\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9291 - val_loss: 0.1880 - val_accuracy: 0.9322\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9285 - val_loss: 0.1847 - val_accuracy: 0.9366\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9294 - val_loss: 0.1848 - val_accuracy: 0.9357\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9272 - val_loss: 0.1838 - val_accuracy: 0.9373\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2020 - accuracy: 0.9264 - val_loss: 0.1861 - val_accuracy: 0.9357\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9291 - val_loss: 0.1880 - val_accuracy: 0.9355\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9300 - val_loss: 0.1833 - val_accuracy: 0.9359\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9295 - val_loss: 0.1829 - val_accuracy: 0.9366\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9295 - val_loss: 0.1845 - val_accuracy: 0.9380\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9285 - val_loss: 0.1846 - val_accuracy: 0.9341\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9291 - val_loss: 0.1826 - val_accuracy: 0.9380\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1953 - accuracy: 0.9296 - val_loss: 0.1884 - val_accuracy: 0.9329\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1949 - accuracy: 0.9313 - val_loss: 0.2037 - val_accuracy: 0.9262\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9294 - val_loss: 0.2132 - val_accuracy: 0.9207\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1943 - accuracy: 0.9309 - val_loss: 0.1791 - val_accuracy: 0.9376\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9303 - val_loss: 0.2065 - val_accuracy: 0.9250\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9293 - val_loss: 0.1785 - val_accuracy: 0.9394\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9308 - val_loss: 0.1791 - val_accuracy: 0.9383\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9318 - val_loss: 0.1870 - val_accuracy: 0.9371\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.9316 - val_loss: 0.1766 - val_accuracy: 0.9387\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9308 - val_loss: 0.1797 - val_accuracy: 0.9366\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1931 - accuracy: 0.9294 - val_loss: 0.1760 - val_accuracy: 0.9392\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9307 - val_loss: 0.1925 - val_accuracy: 0.9295\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9314 - val_loss: 0.1823 - val_accuracy: 0.9352\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.9296 - val_loss: 0.1813 - val_accuracy: 0.9354\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1907 - accuracy: 0.9321 - val_loss: 0.1845 - val_accuracy: 0.9357\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9319 - val_loss: 0.1948 - val_accuracy: 0.9318\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9305 - val_loss: 0.1839 - val_accuracy: 0.9350\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.9324 - val_loss: 0.1734 - val_accuracy: 0.9410\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1947 - accuracy: 0.9309 - val_loss: 0.1753 - val_accuracy: 0.9392\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.9326 - val_loss: 0.1868 - val_accuracy: 0.9343\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9303\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6239 - val_loss: 0.6130 - val_accuracy: 0.6392\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.7022 - val_loss: 0.5751 - val_accuracy: 0.7486\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5595 - accuracy: 0.7379 - val_loss: 0.5413 - val_accuracy: 0.7405\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7599 - val_loss: 0.5176 - val_accuracy: 0.7384\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7766 - val_loss: 0.4980 - val_accuracy: 0.8082\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7893 - val_loss: 0.4803 - val_accuracy: 0.8194\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.8010 - val_loss: 0.4635 - val_accuracy: 0.7851\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8103 - val_loss: 0.4504 - val_accuracy: 0.8291\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8168 - val_loss: 0.4375 - val_accuracy: 0.8101\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.8257 - val_loss: 0.4271 - val_accuracy: 0.8122\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4215 - accuracy: 0.8293 - val_loss: 0.4186 - val_accuracy: 0.8101\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4123 - accuracy: 0.8349 - val_loss: 0.4114 - val_accuracy: 0.8085\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4043 - accuracy: 0.8383 - val_loss: 0.4006 - val_accuracy: 0.8432\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8423 - val_loss: 0.3954 - val_accuracy: 0.8612\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3895 - accuracy: 0.8439 - val_loss: 0.3882 - val_accuracy: 0.8614\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8484 - val_loss: 0.3806 - val_accuracy: 0.8504\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.8514 - val_loss: 0.3772 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8523 - val_loss: 0.3697 - val_accuracy: 0.8501\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3659 - accuracy: 0.8548 - val_loss: 0.3650 - val_accuracy: 0.8624\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8567 - val_loss: 0.3608 - val_accuracy: 0.8665\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8609 - val_loss: 0.3562 - val_accuracy: 0.8631\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8605 - val_loss: 0.3523 - val_accuracy: 0.8654\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8621 - val_loss: 0.3490 - val_accuracy: 0.8598\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8643 - val_loss: 0.3465 - val_accuracy: 0.8541\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8654 - val_loss: 0.3598 - val_accuracy: 0.9086\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8688 - val_loss: 0.3435 - val_accuracy: 0.8478\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8696 - val_loss: 0.3531 - val_accuracy: 0.8300\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8692 - val_loss: 0.3350 - val_accuracy: 0.8855\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8735 - val_loss: 0.3305 - val_accuracy: 0.8674\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8722 - val_loss: 0.3335 - val_accuracy: 0.8964\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8729 - val_loss: 0.3260 - val_accuracy: 0.8674\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8729 - val_loss: 0.3234 - val_accuracy: 0.8704\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8758 - val_loss: 0.3332 - val_accuracy: 0.8468\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.8753 - val_loss: 0.3194 - val_accuracy: 0.8704\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8761 - val_loss: 0.3168 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8775 - val_loss: 0.3264 - val_accuracy: 0.9095\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.8781 - val_loss: 0.3132 - val_accuracy: 0.8844\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3098 - accuracy: 0.8789 - val_loss: 0.3161 - val_accuracy: 0.9015\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8796 - val_loss: 0.3122 - val_accuracy: 0.8970\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8793 - val_loss: 0.3078 - val_accuracy: 0.8844\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8814 - val_loss: 0.3093 - val_accuracy: 0.8996\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8819 - val_loss: 0.3078 - val_accuracy: 0.8691\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8804 - val_loss: 0.3068 - val_accuracy: 0.9022\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8842 - val_loss: 0.3022 - val_accuracy: 0.8924\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2999 - accuracy: 0.8843 - val_loss: 0.3027 - val_accuracy: 0.8733\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8834 - val_loss: 0.3000 - val_accuracy: 0.8781\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2961 - accuracy: 0.8842 - val_loss: 0.2994 - val_accuracy: 0.8760\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2946 - accuracy: 0.8851 - val_loss: 0.2971 - val_accuracy: 0.8948\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2942 - accuracy: 0.8867 - val_loss: 0.2996 - val_accuracy: 0.8716\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8874 - val_loss: 0.2941 - val_accuracy: 0.8924\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2910 - accuracy: 0.8868 - val_loss: 0.2933 - val_accuracy: 0.8959\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8871 - val_loss: 0.2925 - val_accuracy: 0.8820\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.8871 - val_loss: 0.2909 - val_accuracy: 0.8860\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.8876 - val_loss: 0.2898 - val_accuracy: 0.8866\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8876 - val_loss: 0.2885 - val_accuracy: 0.8933\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8900 - val_loss: 0.2878 - val_accuracy: 0.8876\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.8896 - val_loss: 0.2888 - val_accuracy: 0.9054\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.8905 - val_loss: 0.2888 - val_accuracy: 0.8783\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8895 - val_loss: 0.2914 - val_accuracy: 0.9125\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.8900 - val_loss: 0.2848 - val_accuracy: 0.9029\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.8904 - val_loss: 0.2849 - val_accuracy: 0.9056\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.8912 - val_loss: 0.2827 - val_accuracy: 0.8881\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8917 - val_loss: 0.2814 - val_accuracy: 0.9012\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8933 - val_loss: 0.2803 - val_accuracy: 0.8934\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.8932 - val_loss: 0.2826 - val_accuracy: 0.8816\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8939 - val_loss: 0.2786 - val_accuracy: 0.8973\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.8935 - val_loss: 0.2779 - val_accuracy: 0.8955\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.8939 - val_loss: 0.2791 - val_accuracy: 0.9077\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8946 - val_loss: 0.2767 - val_accuracy: 0.8933\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.8931 - val_loss: 0.2854 - val_accuracy: 0.8737\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8944 - val_loss: 0.2753 - val_accuracy: 0.8933\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.8936 - val_loss: 0.2743 - val_accuracy: 0.9019\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.8936 - val_loss: 0.2735 - val_accuracy: 0.9019\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.8951 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.8952 - val_loss: 0.2722 - val_accuracy: 0.9021\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.8964 - val_loss: 0.2844 - val_accuracy: 0.8725\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8964 - val_loss: 0.2726 - val_accuracy: 0.8896\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.8956 - val_loss: 0.2703 - val_accuracy: 0.8994\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.8971 - val_loss: 0.2712 - val_accuracy: 0.9096\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.8975 - val_loss: 0.2704 - val_accuracy: 0.9095\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.8965 - val_loss: 0.2730 - val_accuracy: 0.9146\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.8982 - val_loss: 0.2701 - val_accuracy: 0.8901\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.8972 - val_loss: 0.2734 - val_accuracy: 0.9174\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.8984 - val_loss: 0.2688 - val_accuracy: 0.8910\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.8981 - val_loss: 0.2667 - val_accuracy: 0.9084\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.8992 - val_loss: 0.2721 - val_accuracy: 0.8827\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.9000 - val_loss: 0.2666 - val_accuracy: 0.8938\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2638 - accuracy: 0.8990 - val_loss: 0.2652 - val_accuracy: 0.8977\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.8998 - val_loss: 0.2686 - val_accuracy: 0.9163\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8996 - val_loss: 0.2652 - val_accuracy: 0.8941\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2624 - accuracy: 0.9000 - val_loss: 0.2633 - val_accuracy: 0.9012\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.8998 - val_loss: 0.2634 - val_accuracy: 0.9116\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9014 - val_loss: 0.2627 - val_accuracy: 0.9107\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.9003 - val_loss: 0.2614 - val_accuracy: 0.9058\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2606 - accuracy: 0.9002 - val_loss: 0.2611 - val_accuracy: 0.9045\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.9008 - val_loss: 0.2650 - val_accuracy: 0.8894\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.9017 - val_loss: 0.2610 - val_accuracy: 0.9126\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.9015 - val_loss: 0.2627 - val_accuracy: 0.8927\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2592 - accuracy: 0.9002 - val_loss: 0.2600 - val_accuracy: 0.9128\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9017 - val_loss: 0.2587 - val_accuracy: 0.9051\n",
      "277/277 [==============================] - 0s 926us/step - loss: 0.2491 - accuracy: 0.9049\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6572 - accuracy: 0.6083 - val_loss: 0.6271 - val_accuracy: 0.6747\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6062 - accuracy: 0.6823 - val_loss: 0.5831 - val_accuracy: 0.6775\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7281 - val_loss: 0.5505 - val_accuracy: 0.7546\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7536 - val_loss: 0.5244 - val_accuracy: 0.7897\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.7762 - val_loss: 0.5032 - val_accuracy: 0.8103\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.7945 - val_loss: 0.4818 - val_accuracy: 0.7895\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.8019 - val_loss: 0.4656 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4560 - accuracy: 0.8141 - val_loss: 0.4537 - val_accuracy: 0.8369\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.8197 - val_loss: 0.4394 - val_accuracy: 0.8237\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4297 - accuracy: 0.8265 - val_loss: 0.4359 - val_accuracy: 0.7810\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.8344 - val_loss: 0.4184 - val_accuracy: 0.8214\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4086 - accuracy: 0.8370 - val_loss: 0.4109 - val_accuracy: 0.8147\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8431 - val_loss: 0.4013 - val_accuracy: 0.8446\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3918 - accuracy: 0.8464 - val_loss: 0.3984 - val_accuracy: 0.8705\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8501 - val_loss: 0.3881 - val_accuracy: 0.8364\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3771 - accuracy: 0.8531 - val_loss: 0.3818 - val_accuracy: 0.8401\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3712 - accuracy: 0.8555 - val_loss: 0.3752 - val_accuracy: 0.8487\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8587 - val_loss: 0.3728 - val_accuracy: 0.8367\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8607 - val_loss: 0.3651 - val_accuracy: 0.8497\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8624 - val_loss: 0.3602 - val_accuracy: 0.8566\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8627 - val_loss: 0.3594 - val_accuracy: 0.8822\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8668 - val_loss: 0.3532 - val_accuracy: 0.8503\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8668 - val_loss: 0.3506 - val_accuracy: 0.8820\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8693 - val_loss: 0.3444 - val_accuracy: 0.8684\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8705 - val_loss: 0.3447 - val_accuracy: 0.8490\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8713 - val_loss: 0.3430 - val_accuracy: 0.8915\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8716 - val_loss: 0.3350 - val_accuracy: 0.8654\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8753 - val_loss: 0.3319 - val_accuracy: 0.8725\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.8759 - val_loss: 0.3312 - val_accuracy: 0.8608\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8768 - val_loss: 0.3270 - val_accuracy: 0.8679\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8777 - val_loss: 0.3241 - val_accuracy: 0.8741\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8780 - val_loss: 0.3267 - val_accuracy: 0.8578\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8799 - val_loss: 0.3200 - val_accuracy: 0.8848\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3088 - accuracy: 0.8810 - val_loss: 0.3173 - val_accuracy: 0.8807\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.8810 - val_loss: 0.3161 - val_accuracy: 0.8878\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8837 - val_loss: 0.3133 - val_accuracy: 0.8813\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.8828 - val_loss: 0.3160 - val_accuracy: 0.9007\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8828 - val_loss: 0.3126 - val_accuracy: 0.8674\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.8841 - val_loss: 0.3090 - val_accuracy: 0.8917\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8871 - val_loss: 0.3070 - val_accuracy: 0.8915\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8882 - val_loss: 0.3054 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.8857 - val_loss: 0.3096 - val_accuracy: 0.9058\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2920 - accuracy: 0.8868 - val_loss: 0.3033 - val_accuracy: 0.8748\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.8870 - val_loss: 0.3001 - val_accuracy: 0.8859\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8876 - val_loss: 0.3002 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.8884 - val_loss: 0.2997 - val_accuracy: 0.9008\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.8902 - val_loss: 0.2981 - val_accuracy: 0.8762\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8908 - val_loss: 0.3006 - val_accuracy: 0.8693\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.8906 - val_loss: 0.2959 - val_accuracy: 0.8765\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.8907 - val_loss: 0.2929 - val_accuracy: 0.8957\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.8909 - val_loss: 0.2913 - val_accuracy: 0.8888\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.8923 - val_loss: 0.2903 - val_accuracy: 0.8934\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.8916 - val_loss: 0.2920 - val_accuracy: 0.8774\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.8929 - val_loss: 0.2901 - val_accuracy: 0.8804\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8930 - val_loss: 0.2900 - val_accuracy: 0.9063\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.8938 - val_loss: 0.2861 - val_accuracy: 0.8911\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.8946 - val_loss: 0.2851 - val_accuracy: 0.8913\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8948 - val_loss: 0.2841 - val_accuracy: 0.8934\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.8952 - val_loss: 0.2843 - val_accuracy: 0.8857\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.8954 - val_loss: 0.2888 - val_accuracy: 0.8744\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2708 - accuracy: 0.8951 - val_loss: 0.2887 - val_accuracy: 0.9149\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8960 - val_loss: 0.2868 - val_accuracy: 0.9125\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8956 - val_loss: 0.2950 - val_accuracy: 0.9207\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2679 - accuracy: 0.8977 - val_loss: 0.2790 - val_accuracy: 0.8973\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.8959 - val_loss: 0.2782 - val_accuracy: 0.8978\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.8968 - val_loss: 0.2775 - val_accuracy: 0.9003\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.8968 - val_loss: 0.2815 - val_accuracy: 0.8800\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.8979 - val_loss: 0.2804 - val_accuracy: 0.9117\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.8983 - val_loss: 0.2767 - val_accuracy: 0.9068\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.8975 - val_loss: 0.2762 - val_accuracy: 0.8881\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.8986 - val_loss: 0.2738 - val_accuracy: 0.8982\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.8983 - val_loss: 0.2737 - val_accuracy: 0.8933\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2609 - accuracy: 0.9003 - val_loss: 0.2734 - val_accuracy: 0.8917\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.8996 - val_loss: 0.2725 - val_accuracy: 0.9061\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9009 - val_loss: 0.2713 - val_accuracy: 0.8992\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.8988 - val_loss: 0.2705 - val_accuracy: 0.9017\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.8997 - val_loss: 0.2721 - val_accuracy: 0.9112\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9003 - val_loss: 0.2700 - val_accuracy: 0.8952\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.9008 - val_loss: 0.2691 - val_accuracy: 0.8973\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.9012 - val_loss: 0.2682 - val_accuracy: 0.9019\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2566 - accuracy: 0.9007 - val_loss: 0.2678 - val_accuracy: 0.9005\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9009 - val_loss: 0.2726 - val_accuracy: 0.8848\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9008 - val_loss: 0.2667 - val_accuracy: 0.9061\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9022 - val_loss: 0.2663 - val_accuracy: 0.8998\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.9016 - val_loss: 0.2689 - val_accuracy: 0.8885\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9024 - val_loss: 0.2690 - val_accuracy: 0.9165\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9037 - val_loss: 0.2644 - val_accuracy: 0.9052\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9037 - val_loss: 0.2678 - val_accuracy: 0.9165\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9025 - val_loss: 0.2642 - val_accuracy: 0.8980\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9032 - val_loss: 0.2635 - val_accuracy: 0.8987\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.9028 - val_loss: 0.2645 - val_accuracy: 0.9133\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9022 - val_loss: 0.2633 - val_accuracy: 0.9128\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.9038 - val_loss: 0.2696 - val_accuracy: 0.9221\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9047 - val_loss: 0.2613 - val_accuracy: 0.9014\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.9050 - val_loss: 0.2645 - val_accuracy: 0.8901\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9042 - val_loss: 0.2637 - val_accuracy: 0.8908\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9036 - val_loss: 0.2602 - val_accuracy: 0.9007\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.9046 - val_loss: 0.2614 - val_accuracy: 0.8948\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9050 - val_loss: 0.2623 - val_accuracy: 0.9170\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9054 - val_loss: 0.2615 - val_accuracy: 0.9169\n",
      "277/277 [==============================] - 0s 910us/step - loss: 0.2731 - accuracy: 0.9124\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6442 - accuracy: 0.6239 - val_loss: 0.6159 - val_accuracy: 0.7166\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6945 - val_loss: 0.5740 - val_accuracy: 0.6778\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5613 - accuracy: 0.7344 - val_loss: 0.5403 - val_accuracy: 0.7460\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7545 - val_loss: 0.5164 - val_accuracy: 0.7428\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5101 - accuracy: 0.7753 - val_loss: 0.4951 - val_accuracy: 0.7717\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7906 - val_loss: 0.4777 - val_accuracy: 0.7888\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.8031 - val_loss: 0.4637 - val_accuracy: 0.7777\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.8088 - val_loss: 0.4527 - val_accuracy: 0.7763\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.8162 - val_loss: 0.4380 - val_accuracy: 0.7992\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8242 - val_loss: 0.4347 - val_accuracy: 0.8700\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4258 - accuracy: 0.8315 - val_loss: 0.4249 - val_accuracy: 0.7874\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8342 - val_loss: 0.4112 - val_accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.8377 - val_loss: 0.4009 - val_accuracy: 0.8482\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8427 - val_loss: 0.3934 - val_accuracy: 0.8460\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8462 - val_loss: 0.3902 - val_accuracy: 0.8695\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3862 - accuracy: 0.8506 - val_loss: 0.3881 - val_accuracy: 0.8832\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3802 - accuracy: 0.8531 - val_loss: 0.3799 - val_accuracy: 0.8260\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3756 - accuracy: 0.8525 - val_loss: 0.3698 - val_accuracy: 0.8490\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8579 - val_loss: 0.3661 - val_accuracy: 0.8455\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8586 - val_loss: 0.3610 - val_accuracy: 0.8682\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8594 - val_loss: 0.3569 - val_accuracy: 0.8704\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3561 - accuracy: 0.8622 - val_loss: 0.3536 - val_accuracy: 0.8485\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8628 - val_loss: 0.3549 - val_accuracy: 0.8906\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8655 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8662 - val_loss: 0.3422 - val_accuracy: 0.8575\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8666 - val_loss: 0.3396 - val_accuracy: 0.8807\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8680 - val_loss: 0.3361 - val_accuracy: 0.8600\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8695 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8718 - val_loss: 0.3360 - val_accuracy: 0.8982\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8739 - val_loss: 0.3284 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8738 - val_loss: 0.3242 - val_accuracy: 0.8725\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8757 - val_loss: 0.3218 - val_accuracy: 0.8730\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8767 - val_loss: 0.3231 - val_accuracy: 0.8594\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8765 - val_loss: 0.3176 - val_accuracy: 0.8822\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.8784 - val_loss: 0.3223 - val_accuracy: 0.9019\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8792 - val_loss: 0.3131 - val_accuracy: 0.8779\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3141 - accuracy: 0.8806 - val_loss: 0.3127 - val_accuracy: 0.8688\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3128 - accuracy: 0.8807 - val_loss: 0.3097 - val_accuracy: 0.8744\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8808 - val_loss: 0.3076 - val_accuracy: 0.8832\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8836 - val_loss: 0.3057 - val_accuracy: 0.8799\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3073 - accuracy: 0.8828 - val_loss: 0.3061 - val_accuracy: 0.8961\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3054 - accuracy: 0.8840 - val_loss: 0.3036 - val_accuracy: 0.8929\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8850 - val_loss: 0.3008 - val_accuracy: 0.8871\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8854 - val_loss: 0.2999 - val_accuracy: 0.8765\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3010 - accuracy: 0.8854 - val_loss: 0.2977 - val_accuracy: 0.8890\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2994 - accuracy: 0.8867 - val_loss: 0.2963 - val_accuracy: 0.8894\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8869 - val_loss: 0.2951 - val_accuracy: 0.8911\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8871 - val_loss: 0.2952 - val_accuracy: 0.9001\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8874 - val_loss: 0.2928 - val_accuracy: 0.8938\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8889 - val_loss: 0.2910 - val_accuracy: 0.8887\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.8882 - val_loss: 0.2917 - val_accuracy: 0.9007\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8887 - val_loss: 0.2891 - val_accuracy: 0.8968\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.8897 - val_loss: 0.2899 - val_accuracy: 0.9040\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8912 - val_loss: 0.2864 - val_accuracy: 0.8871\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8902 - val_loss: 0.2910 - val_accuracy: 0.9105\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2870 - accuracy: 0.8905 - val_loss: 0.2843 - val_accuracy: 0.8878\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2866 - accuracy: 0.8923 - val_loss: 0.2874 - val_accuracy: 0.8746\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2859 - accuracy: 0.8912 - val_loss: 0.2821 - val_accuracy: 0.8920\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.8923 - val_loss: 0.2811 - val_accuracy: 0.8952\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8927 - val_loss: 0.2821 - val_accuracy: 0.9058\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8933 - val_loss: 0.2794 - val_accuracy: 0.8885\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2813 - accuracy: 0.8936 - val_loss: 0.2823 - val_accuracy: 0.9096\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.8942 - val_loss: 0.2792 - val_accuracy: 0.8823\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.8939 - val_loss: 0.2807 - val_accuracy: 0.8778\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8951 - val_loss: 0.2756 - val_accuracy: 0.8915\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.8948 - val_loss: 0.2764 - val_accuracy: 0.9066\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.8949 - val_loss: 0.2742 - val_accuracy: 0.8910\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8962 - val_loss: 0.2729 - val_accuracy: 0.8968\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8965 - val_loss: 0.2722 - val_accuracy: 0.9005\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8960 - val_loss: 0.2715 - val_accuracy: 0.8938\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.8959 - val_loss: 0.2728 - val_accuracy: 0.8853\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8966 - val_loss: 0.2770 - val_accuracy: 0.8772\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2726 - accuracy: 0.8970 - val_loss: 0.2692 - val_accuracy: 0.9012\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.8979 - val_loss: 0.2692 - val_accuracy: 0.9063\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2714 - accuracy: 0.8968 - val_loss: 0.2776 - val_accuracy: 0.9202\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2709 - accuracy: 0.8977 - val_loss: 0.2669 - val_accuracy: 0.9005\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2705 - accuracy: 0.8976 - val_loss: 0.2662 - val_accuracy: 0.9005\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2698 - accuracy: 0.8986 - val_loss: 0.2655 - val_accuracy: 0.9003\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.8980 - val_loss: 0.2653 - val_accuracy: 0.8941\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.8977 - val_loss: 0.2651 - val_accuracy: 0.8933\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2681 - accuracy: 0.8994 - val_loss: 0.2722 - val_accuracy: 0.8779\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.8996 - val_loss: 0.2743 - val_accuracy: 0.9221\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.8996 - val_loss: 0.2627 - val_accuracy: 0.8966\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2661 - accuracy: 0.8984 - val_loss: 0.2670 - val_accuracy: 0.8829\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.9009 - val_loss: 0.2626 - val_accuracy: 0.8929\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.8999 - val_loss: 0.2609 - val_accuracy: 0.9068\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2649 - accuracy: 0.9004 - val_loss: 0.2621 - val_accuracy: 0.8913\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.8998 - val_loss: 0.2608 - val_accuracy: 0.9114\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.9005 - val_loss: 0.2624 - val_accuracy: 0.9154\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8999 - val_loss: 0.2590 - val_accuracy: 0.9107\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9019 - val_loss: 0.2581 - val_accuracy: 0.9001\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2618 - accuracy: 0.9012 - val_loss: 0.2575 - val_accuracy: 0.9015\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.9021 - val_loss: 0.2568 - val_accuracy: 0.9036\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9024 - val_loss: 0.2563 - val_accuracy: 0.9054\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.9020 - val_loss: 0.2591 - val_accuracy: 0.8908\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.9035 - val_loss: 0.2554 - val_accuracy: 0.9040\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.9036 - val_loss: 0.2602 - val_accuracy: 0.9190\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9026 - val_loss: 0.2572 - val_accuracy: 0.8931\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2584 - accuracy: 0.9034 - val_loss: 0.2592 - val_accuracy: 0.8883\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.9028 - val_loss: 0.2540 - val_accuracy: 0.9123\n",
      "277/277 [==============================] - 0s 917us/step - loss: 0.2463 - accuracy: 0.9090\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6330 - accuracy: 0.6445 - val_loss: 0.5327 - val_accuracy: 0.7055\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8415 - val_loss: 0.2974 - val_accuracy: 0.8860\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2853 - accuracy: 0.8891 - val_loss: 0.2513 - val_accuracy: 0.9031\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2634 - accuracy: 0.9000 - val_loss: 0.2411 - val_accuracy: 0.9190\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2510 - accuracy: 0.9036 - val_loss: 0.2636 - val_accuracy: 0.9211\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.9080 - val_loss: 0.2266 - val_accuracy: 0.9096\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.9090 - val_loss: 0.2134 - val_accuracy: 0.9227\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2368 - accuracy: 0.9104 - val_loss: 0.2468 - val_accuracy: 0.9220\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2333 - accuracy: 0.9108 - val_loss: 0.2130 - val_accuracy: 0.9287\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2319 - accuracy: 0.9133 - val_loss: 0.2405 - val_accuracy: 0.9193\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9166 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2241 - accuracy: 0.9164 - val_loss: 0.2318 - val_accuracy: 0.9088\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.9159 - val_loss: 0.2214 - val_accuracy: 0.9128\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2199 - accuracy: 0.9165 - val_loss: 0.2704 - val_accuracy: 0.8952\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2171 - accuracy: 0.9185 - val_loss: 0.2234 - val_accuracy: 0.9146\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2172 - accuracy: 0.9187 - val_loss: 0.2007 - val_accuracy: 0.9234\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9178 - val_loss: 0.1886 - val_accuracy: 0.9297\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2076 - accuracy: 0.9218 - val_loss: 0.1830 - val_accuracy: 0.9338\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2050 - accuracy: 0.9227 - val_loss: 0.1799 - val_accuracy: 0.9376\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2028 - accuracy: 0.9231 - val_loss: 0.2347 - val_accuracy: 0.9042\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2051 - accuracy: 0.9229 - val_loss: 0.1767 - val_accuracy: 0.9354\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9261 - val_loss: 0.1704 - val_accuracy: 0.9403\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9282 - val_loss: 0.1888 - val_accuracy: 0.9345\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.9270 - val_loss: 0.1693 - val_accuracy: 0.9389\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.9301 - val_loss: 0.1595 - val_accuracy: 0.9468\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.9324 - val_loss: 0.1556 - val_accuracy: 0.9479\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.9326 - val_loss: 0.1507 - val_accuracy: 0.9493\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.9363 - val_loss: 0.1457 - val_accuracy: 0.9510\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.9362 - val_loss: 0.1419 - val_accuracy: 0.9498\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1662 - accuracy: 0.9381 - val_loss: 0.1501 - val_accuracy: 0.9591\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1668 - accuracy: 0.9406 - val_loss: 0.1698 - val_accuracy: 0.9389\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9370 - val_loss: 0.1964 - val_accuracy: 0.9271\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9395 - val_loss: 0.1974 - val_accuracy: 0.9260\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1640 - accuracy: 0.9414 - val_loss: 0.1298 - val_accuracy: 0.9609\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1524 - accuracy: 0.9446 - val_loss: 0.1319 - val_accuracy: 0.9551\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1516 - accuracy: 0.9456 - val_loss: 0.8160 - val_accuracy: 0.5313\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1695 - accuracy: 0.9388 - val_loss: 0.1578 - val_accuracy: 0.9424\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9455 - val_loss: 0.1310 - val_accuracy: 0.9556\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.9465 - val_loss: 0.2203 - val_accuracy: 0.9221\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9484 - val_loss: 0.1210 - val_accuracy: 0.9598\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9487 - val_loss: 0.1201 - val_accuracy: 0.9627\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9512 - val_loss: 0.2102 - val_accuracy: 0.9253\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1602 - accuracy: 0.9432 - val_loss: 0.1445 - val_accuracy: 0.9484\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9451 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9447 - val_loss: 0.1262 - val_accuracy: 0.9579\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1485 - accuracy: 0.9480 - val_loss: 0.1374 - val_accuracy: 0.9577\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9511 - val_loss: 0.1148 - val_accuracy: 0.9628\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1552 - accuracy: 0.9447 - val_loss: 0.1362 - val_accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9498 - val_loss: 0.1426 - val_accuracy: 0.9501\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9491 - val_loss: 0.1625 - val_accuracy: 0.9459\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9492 - val_loss: 0.1239 - val_accuracy: 0.9595\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1536 - accuracy: 0.9455 - val_loss: 0.1972 - val_accuracy: 0.9174\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9494 - val_loss: 0.2133 - val_accuracy: 0.9267\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1407 - accuracy: 0.9505 - val_loss: 0.1285 - val_accuracy: 0.9553\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.9521 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9506 - val_loss: 0.1383 - val_accuracy: 0.9526\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.9534 - val_loss: 0.1132 - val_accuracy: 0.9635\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9514 - val_loss: 0.1357 - val_accuracy: 0.9524\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9485 - val_loss: 0.1264 - val_accuracy: 0.9563\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1340 - accuracy: 0.9531 - val_loss: 0.1451 - val_accuracy: 0.9482\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.9544 - val_loss: 0.1144 - val_accuracy: 0.9605\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1360 - accuracy: 0.9526 - val_loss: 0.1140 - val_accuracy: 0.9635\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9521 - val_loss: 0.1331 - val_accuracy: 0.9547\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9498 - val_loss: 0.1109 - val_accuracy: 0.9660\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1308 - accuracy: 0.9549 - val_loss: 0.1196 - val_accuracy: 0.9588\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1363 - accuracy: 0.9522 - val_loss: 0.1418 - val_accuracy: 0.9523\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1316 - accuracy: 0.9537 - val_loss: 0.1464 - val_accuracy: 0.9491\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1359 - accuracy: 0.9521 - val_loss: 0.1092 - val_accuracy: 0.9655\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9546 - val_loss: 0.1135 - val_accuracy: 0.9618\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9551 - val_loss: 0.1060 - val_accuracy: 0.9667\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9547 - val_loss: 0.1118 - val_accuracy: 0.9628\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.9541 - val_loss: 0.1177 - val_accuracy: 0.9611\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9585 - val_loss: 0.1094 - val_accuracy: 0.9639\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1318 - accuracy: 0.9548 - val_loss: 0.1217 - val_accuracy: 0.9590\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9558 - val_loss: 0.1200 - val_accuracy: 0.9581\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1235 - accuracy: 0.9586 - val_loss: 0.4309 - val_accuracy: 0.8723\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9529 - val_loss: 0.1622 - val_accuracy: 0.9417\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9541 - val_loss: 0.1225 - val_accuracy: 0.9581\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1266 - accuracy: 0.9557 - val_loss: 0.1100 - val_accuracy: 0.9648\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1272 - accuracy: 0.9557 - val_loss: 0.1335 - val_accuracy: 0.9531\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9516\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.6621 - val_loss: 0.5504 - val_accuracy: 0.6981\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8631 - val_loss: 0.2759 - val_accuracy: 0.8885\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.8979 - val_loss: 0.2490 - val_accuracy: 0.9176\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9041 - val_loss: 0.2409 - val_accuracy: 0.9019\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.9085 - val_loss: 0.3186 - val_accuracy: 0.9035\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2329 - accuracy: 0.9109 - val_loss: 0.2245 - val_accuracy: 0.9276\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2286 - accuracy: 0.9147 - val_loss: 0.2183 - val_accuracy: 0.9290\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2240 - accuracy: 0.9145 - val_loss: 0.2179 - val_accuracy: 0.9285\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2183 - accuracy: 0.9182 - val_loss: 0.2067 - val_accuracy: 0.9306\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9178 - val_loss: 0.2113 - val_accuracy: 0.9169\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9189 - val_loss: 0.1959 - val_accuracy: 0.9290\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9195 - val_loss: 0.1950 - val_accuracy: 0.9260\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2148 - accuracy: 0.9195 - val_loss: 0.1919 - val_accuracy: 0.9290\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2075 - accuracy: 0.9229 - val_loss: 0.1908 - val_accuracy: 0.9331\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2049 - accuracy: 0.9237 - val_loss: 0.1868 - val_accuracy: 0.9343\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9238 - val_loss: 0.1890 - val_accuracy: 0.9281\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.9235 - val_loss: 0.2304 - val_accuracy: 0.9133\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2004 - accuracy: 0.9260 - val_loss: 0.1839 - val_accuracy: 0.9302\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1988 - accuracy: 0.9263 - val_loss: 0.2098 - val_accuracy: 0.9274\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9269 - val_loss: 0.1847 - val_accuracy: 0.9297\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9271 - val_loss: 0.1855 - val_accuracy: 0.9369\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9290 - val_loss: 0.1816 - val_accuracy: 0.9391\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9277 - val_loss: 0.1707 - val_accuracy: 0.9394\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9284 - val_loss: 0.1689 - val_accuracy: 0.9413\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9306 - val_loss: 0.1710 - val_accuracy: 0.9369\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1927 - accuracy: 0.9307 - val_loss: 0.1698 - val_accuracy: 0.9406\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.9354 - val_loss: 0.1755 - val_accuracy: 0.9355\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.9357 - val_loss: 0.2015 - val_accuracy: 0.9285\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.9353 - val_loss: 0.1533 - val_accuracy: 0.9466\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9385 - val_loss: 0.1464 - val_accuracy: 0.9501\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9381 - val_loss: 0.1462 - val_accuracy: 0.9491\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1728 - accuracy: 0.9371 - val_loss: 0.1650 - val_accuracy: 0.9408\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1574 - accuracy: 0.9442 - val_loss: 0.1463 - val_accuracy: 0.9472\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1539 - accuracy: 0.9442 - val_loss: 0.1656 - val_accuracy: 0.9413\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1565 - accuracy: 0.9430 - val_loss: 0.1510 - val_accuracy: 0.9489\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9433 - val_loss: 0.1296 - val_accuracy: 0.9542\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.9470 - val_loss: 0.1875 - val_accuracy: 0.9369\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9444 - val_loss: 0.1365 - val_accuracy: 0.9510\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9459 - val_loss: 0.1267 - val_accuracy: 0.9546\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9466 - val_loss: 0.1501 - val_accuracy: 0.9465\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1400 - accuracy: 0.9519 - val_loss: 0.1910 - val_accuracy: 0.9308\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1404 - accuracy: 0.9497 - val_loss: 0.1296 - val_accuracy: 0.9533\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1403 - accuracy: 0.9505 - val_loss: 0.2022 - val_accuracy: 0.9285\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1380 - accuracy: 0.9521 - val_loss: 0.1160 - val_accuracy: 0.9625\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9499 - val_loss: 0.1707 - val_accuracy: 0.9392\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1411 - accuracy: 0.9526 - val_loss: 0.1381 - val_accuracy: 0.9540\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1445 - accuracy: 0.9496 - val_loss: 0.1386 - val_accuracy: 0.9530\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9520 - val_loss: 0.1141 - val_accuracy: 0.9612\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9557 - val_loss: 0.1511 - val_accuracy: 0.9461\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1442 - accuracy: 0.9506 - val_loss: 0.1841 - val_accuracy: 0.9385\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1448 - accuracy: 0.9510 - val_loss: 0.1264 - val_accuracy: 0.9583\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9543 - val_loss: 0.1202 - val_accuracy: 0.9586\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1424 - accuracy: 0.9515 - val_loss: 0.1149 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1342 - accuracy: 0.9530 - val_loss: 0.1526 - val_accuracy: 0.9461\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1363 - accuracy: 0.9523 - val_loss: 0.1141 - val_accuracy: 0.9623\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9553 - val_loss: 0.3176 - val_accuracy: 0.8792\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9492 - val_loss: 0.1509 - val_accuracy: 0.9459\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1333 - accuracy: 0.9542 - val_loss: 0.2433 - val_accuracy: 0.9125\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1383 - accuracy: 0.9520 - val_loss: 0.1456 - val_accuracy: 0.9507\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1424 - accuracy: 0.9518 - val_loss: 0.1154 - val_accuracy: 0.9616\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9568 - val_loss: 0.1132 - val_accuracy: 0.9614\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1325 - accuracy: 0.9540 - val_loss: 0.1168 - val_accuracy: 0.9628\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1317 - accuracy: 0.9544 - val_loss: 0.1363 - val_accuracy: 0.9535\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9523 - val_loss: 0.1095 - val_accuracy: 0.9649\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1416 - accuracy: 0.9503 - val_loss: 0.1124 - val_accuracy: 0.9644\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1249 - accuracy: 0.9562 - val_loss: 0.1405 - val_accuracy: 0.9528\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1360 - accuracy: 0.9526 - val_loss: 0.1387 - val_accuracy: 0.9538\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1268 - accuracy: 0.9571 - val_loss: 0.1052 - val_accuracy: 0.9658\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9547 - val_loss: 0.1403 - val_accuracy: 0.9535\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9569 - val_loss: 0.1830 - val_accuracy: 0.9350\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9572 - val_loss: 0.1237 - val_accuracy: 0.9575\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1284 - accuracy: 0.9562 - val_loss: 0.1131 - val_accuracy: 0.9623\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1227 - accuracy: 0.9584 - val_loss: 0.1176 - val_accuracy: 0.9602\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9518 - val_loss: 0.1131 - val_accuracy: 0.9625\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.9586 - val_loss: 0.2207 - val_accuracy: 0.9232\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9536 - val_loss: 0.1118 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1352 - accuracy: 0.9540 - val_loss: 0.1222 - val_accuracy: 0.9579\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9593 - val_loss: 0.1020 - val_accuracy: 0.9685\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9521 - val_loss: 0.1047 - val_accuracy: 0.9657\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1260 - accuracy: 0.9574 - val_loss: 0.1326 - val_accuracy: 0.9563\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1219 - accuracy: 0.9591 - val_loss: 0.1057 - val_accuracy: 0.9649\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9551 - val_loss: 0.1098 - val_accuracy: 0.9635\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1281 - accuracy: 0.9570 - val_loss: 0.1087 - val_accuracy: 0.9644\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1288 - accuracy: 0.9559 - val_loss: 0.1020 - val_accuracy: 0.9701\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9560 - val_loss: 0.1096 - val_accuracy: 0.9646\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9521 - val_loss: 0.2058 - val_accuracy: 0.9304\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9577 - val_loss: 0.1037 - val_accuracy: 0.9688\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1296 - accuracy: 0.9553 - val_loss: 0.1988 - val_accuracy: 0.9301\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9586 - val_loss: 0.1108 - val_accuracy: 0.9637\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1200 - accuracy: 0.9595 - val_loss: 0.1066 - val_accuracy: 0.9676\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1194 - accuracy: 0.9590 - val_loss: 0.1015 - val_accuracy: 0.9685\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1263 - accuracy: 0.9575 - val_loss: 0.1304 - val_accuracy: 0.9567\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1226 - accuracy: 0.9585 - val_loss: 0.1652 - val_accuracy: 0.9431\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1269 - accuracy: 0.9573 - val_loss: 0.1244 - val_accuracy: 0.9593\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1162 - accuracy: 0.9617 - val_loss: 0.1097 - val_accuracy: 0.9641\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1244 - accuracy: 0.9582 - val_loss: 0.1909 - val_accuracy: 0.9362\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1175 - accuracy: 0.9608 - val_loss: 0.1354 - val_accuracy: 0.9549\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1220 - accuracy: 0.9585 - val_loss: 0.1134 - val_accuracy: 0.9620\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9578 - val_loss: 0.2542 - val_accuracy: 0.8903\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1264 - accuracy: 0.9576 - val_loss: 0.1028 - val_accuracy: 0.9672\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9660\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6386 - accuracy: 0.6340 - val_loss: 0.5499 - val_accuracy: 0.6928\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4001 - accuracy: 0.8430 - val_loss: 0.3474 - val_accuracy: 0.8295\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.8917 - val_loss: 0.3171 - val_accuracy: 0.8564\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9033 - val_loss: 0.2376 - val_accuracy: 0.9244\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9089 - val_loss: 0.2411 - val_accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.9122 - val_loss: 0.2155 - val_accuracy: 0.9280\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2316 - accuracy: 0.9144 - val_loss: 0.2315 - val_accuracy: 0.9044\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2298 - accuracy: 0.9165 - val_loss: 0.2006 - val_accuracy: 0.9253\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2203 - accuracy: 0.9197 - val_loss: 0.3729 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9193 - val_loss: 0.2338 - val_accuracy: 0.9059\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2150 - accuracy: 0.9221 - val_loss: 0.2212 - val_accuracy: 0.9133\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2227 - accuracy: 0.9182 - val_loss: 0.2145 - val_accuracy: 0.9281\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2159 - accuracy: 0.9215 - val_loss: 0.1975 - val_accuracy: 0.9331\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9258 - val_loss: 0.3483 - val_accuracy: 0.8682\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2104 - accuracy: 0.9248 - val_loss: 0.1835 - val_accuracy: 0.9320\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9253 - val_loss: 0.2580 - val_accuracy: 0.8927\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9245 - val_loss: 0.1954 - val_accuracy: 0.9258\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9270 - val_loss: 0.1905 - val_accuracy: 0.9288\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9259 - val_loss: 0.1943 - val_accuracy: 0.9288\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2024 - accuracy: 0.9245 - val_loss: 0.1719 - val_accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9281 - val_loss: 0.1905 - val_accuracy: 0.9387\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9337 - val_loss: 0.1830 - val_accuracy: 0.9399\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9289 - val_loss: 0.2493 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9343 - val_loss: 0.1606 - val_accuracy: 0.9475\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.9338 - val_loss: 0.1574 - val_accuracy: 0.9493\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9356 - val_loss: 0.1725 - val_accuracy: 0.9352\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.9363 - val_loss: 0.1472 - val_accuracy: 0.9523\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1693 - accuracy: 0.9390 - val_loss: 0.1557 - val_accuracy: 0.9450\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.9386 - val_loss: 0.1670 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1612 - accuracy: 0.9412 - val_loss: 0.1387 - val_accuracy: 0.9517\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1525 - accuracy: 0.9461 - val_loss: 0.2371 - val_accuracy: 0.9133\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9452 - val_loss: 0.2119 - val_accuracy: 0.9271\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9479 - val_loss: 0.1369 - val_accuracy: 0.9524\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1502 - accuracy: 0.9460 - val_loss: 0.2503 - val_accuracy: 0.9065\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9445 - val_loss: 0.1282 - val_accuracy: 0.9570\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9492 - val_loss: 0.1542 - val_accuracy: 0.9420\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1409 - accuracy: 0.9510 - val_loss: 0.1179 - val_accuracy: 0.9639\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1441 - accuracy: 0.9498 - val_loss: 0.1430 - val_accuracy: 0.9479\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1508 - accuracy: 0.9470 - val_loss: 0.2419 - val_accuracy: 0.9165\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1520 - accuracy: 0.9483 - val_loss: 0.2507 - val_accuracy: 0.9109\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1398 - accuracy: 0.9529 - val_loss: 0.1209 - val_accuracy: 0.9600\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9495 - val_loss: 0.1464 - val_accuracy: 0.9477\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1420 - accuracy: 0.9510 - val_loss: 0.2061 - val_accuracy: 0.9153\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1435 - accuracy: 0.9506 - val_loss: 0.1150 - val_accuracy: 0.9627\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9544 - val_loss: 0.1196 - val_accuracy: 0.9614\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1379 - accuracy: 0.9531 - val_loss: 0.1558 - val_accuracy: 0.9494\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9512 - val_loss: 0.1113 - val_accuracy: 0.9651\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1399 - accuracy: 0.9515 - val_loss: 0.2089 - val_accuracy: 0.9285\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9530 - val_loss: 0.1104 - val_accuracy: 0.9664\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9475 - val_loss: 0.1298 - val_accuracy: 0.9556\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1386 - accuracy: 0.9521 - val_loss: 0.1226 - val_accuracy: 0.9611\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9510 - val_loss: 0.1298 - val_accuracy: 0.9567\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9542 - val_loss: 0.1137 - val_accuracy: 0.9646\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9553 - val_loss: 0.2652 - val_accuracy: 0.9079\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9518 - val_loss: 0.1206 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1540 - accuracy: 0.9454 - val_loss: 0.1196 - val_accuracy: 0.9642\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1375 - accuracy: 0.9530 - val_loss: 0.1172 - val_accuracy: 0.9628\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1368 - accuracy: 0.9525 - val_loss: 0.1209 - val_accuracy: 0.9611\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1392 - accuracy: 0.9512 - val_loss: 0.1357 - val_accuracy: 0.9533\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9508\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6604 - accuracy: 0.5975 - val_loss: 0.6362 - val_accuracy: 0.6174\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6257 - accuracy: 0.6461 - val_loss: 0.6087 - val_accuracy: 0.6459\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6865 - val_loss: 0.5838 - val_accuracy: 0.6951\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5768 - accuracy: 0.7133 - val_loss: 0.5632 - val_accuracy: 0.7069\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5565 - accuracy: 0.7351 - val_loss: 0.5484 - val_accuracy: 0.7777\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7497 - val_loss: 0.5313 - val_accuracy: 0.7812\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7642 - val_loss: 0.5155 - val_accuracy: 0.7731\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5107 - accuracy: 0.7733 - val_loss: 0.5029 - val_accuracy: 0.7603\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4984 - accuracy: 0.7842 - val_loss: 0.4923 - val_accuracy: 0.7988\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7902 - val_loss: 0.4809 - val_accuracy: 0.7853\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7983 - val_loss: 0.4721 - val_accuracy: 0.7763\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.8037 - val_loss: 0.4629 - val_accuracy: 0.7856\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.8085 - val_loss: 0.4541 - val_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.8158 - val_loss: 0.4467 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.8179 - val_loss: 0.4431 - val_accuracy: 0.8492\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8217 - val_loss: 0.4332 - val_accuracy: 0.8092\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4290 - accuracy: 0.8233 - val_loss: 0.4300 - val_accuracy: 0.8526\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8288 - val_loss: 0.4212 - val_accuracy: 0.8344\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4180 - accuracy: 0.8323 - val_loss: 0.4161 - val_accuracy: 0.8386\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8337 - val_loss: 0.4116 - val_accuracy: 0.8468\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8375 - val_loss: 0.4064 - val_accuracy: 0.8448\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4030 - accuracy: 0.8381 - val_loss: 0.4019 - val_accuracy: 0.8469\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3984 - accuracy: 0.8391 - val_loss: 0.3978 - val_accuracy: 0.8339\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8415 - val_loss: 0.3943 - val_accuracy: 0.8564\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8434 - val_loss: 0.3915 - val_accuracy: 0.8279\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3862 - accuracy: 0.8453 - val_loss: 0.3857 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3826 - accuracy: 0.8472 - val_loss: 0.3862 - val_accuracy: 0.8254\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3787 - accuracy: 0.8490 - val_loss: 0.3801 - val_accuracy: 0.8383\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3754 - accuracy: 0.8517 - val_loss: 0.3855 - val_accuracy: 0.8138\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3723 - accuracy: 0.8517 - val_loss: 0.3810 - val_accuracy: 0.8173\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8538 - val_loss: 0.3698 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3657 - accuracy: 0.8553 - val_loss: 0.3668 - val_accuracy: 0.8619\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8573 - val_loss: 0.3671 - val_accuracy: 0.8395\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8575 - val_loss: 0.3616 - val_accuracy: 0.8651\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8586 - val_loss: 0.3611 - val_accuracy: 0.8765\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.8600 - val_loss: 0.3594 - val_accuracy: 0.8793\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8610 - val_loss: 0.3542 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8619 - val_loss: 0.3523 - val_accuracy: 0.8688\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8630 - val_loss: 0.3506 - val_accuracy: 0.8735\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8630 - val_loss: 0.3492 - val_accuracy: 0.8772\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8641 - val_loss: 0.3459 - val_accuracy: 0.8624\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8669 - val_loss: 0.3476 - val_accuracy: 0.8482\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8652 - val_loss: 0.3422 - val_accuracy: 0.8633\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8682 - val_loss: 0.3419 - val_accuracy: 0.8823\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.8685 - val_loss: 0.3393 - val_accuracy: 0.8783\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8688 - val_loss: 0.3382 - val_accuracy: 0.8593\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8701 - val_loss: 0.3352 - val_accuracy: 0.8739\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8707 - val_loss: 0.3335 - val_accuracy: 0.8695\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8703 - val_loss: 0.3321 - val_accuracy: 0.8762\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8713 - val_loss: 0.3306 - val_accuracy: 0.8769\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8713 - val_loss: 0.3294 - val_accuracy: 0.8809\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8734 - val_loss: 0.3291 - val_accuracy: 0.8623\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8734 - val_loss: 0.3262 - val_accuracy: 0.8799\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8735 - val_loss: 0.3247 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8742 - val_loss: 0.3276 - val_accuracy: 0.8962\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8756 - val_loss: 0.3229 - val_accuracy: 0.8672\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8770 - val_loss: 0.3206 - val_accuracy: 0.8797\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3179 - accuracy: 0.8765 - val_loss: 0.3222 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8758 - val_loss: 0.3195 - val_accuracy: 0.8892\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8772 - val_loss: 0.3179 - val_accuracy: 0.8881\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8771 - val_loss: 0.3166 - val_accuracy: 0.8871\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8787 - val_loss: 0.3153 - val_accuracy: 0.8866\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.8789 - val_loss: 0.3145 - val_accuracy: 0.8887\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3104 - accuracy: 0.8785 - val_loss: 0.3143 - val_accuracy: 0.8924\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3099 - accuracy: 0.8802 - val_loss: 0.3122 - val_accuracy: 0.8739\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.8788 - val_loss: 0.3126 - val_accuracy: 0.8940\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8805 - val_loss: 0.3111 - val_accuracy: 0.8927\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3063 - accuracy: 0.8800 - val_loss: 0.3086 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3057 - accuracy: 0.8803 - val_loss: 0.3077 - val_accuracy: 0.8807\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3051 - accuracy: 0.8806 - val_loss: 0.3074 - val_accuracy: 0.8908\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8814 - val_loss: 0.3058 - val_accuracy: 0.8822\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3028 - accuracy: 0.8818 - val_loss: 0.3051 - val_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3020 - accuracy: 0.8816 - val_loss: 0.3041 - val_accuracy: 0.8862\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3011 - accuracy: 0.8824 - val_loss: 0.3043 - val_accuracy: 0.8756\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3003 - accuracy: 0.8828 - val_loss: 0.3040 - val_accuracy: 0.8739\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8831 - val_loss: 0.3015 - val_accuracy: 0.8874\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2987 - accuracy: 0.8845 - val_loss: 0.3059 - val_accuracy: 0.9058\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2981 - accuracy: 0.8827 - val_loss: 0.3001 - val_accuracy: 0.8818\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2970 - accuracy: 0.8842 - val_loss: 0.3012 - val_accuracy: 0.8741\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2957 - accuracy: 0.8838 - val_loss: 0.2985 - val_accuracy: 0.8832\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.8843 - val_loss: 0.2977 - val_accuracy: 0.8904\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.8845 - val_loss: 0.2968 - val_accuracy: 0.8864\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8858 - val_loss: 0.2978 - val_accuracy: 0.8769\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.8851 - val_loss: 0.2957 - val_accuracy: 0.8829\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8851 - val_loss: 0.2947 - val_accuracy: 0.8918\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2920 - accuracy: 0.8861 - val_loss: 0.2941 - val_accuracy: 0.8931\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8870 - val_loss: 0.2941 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8870 - val_loss: 0.2964 - val_accuracy: 0.8742\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.8871 - val_loss: 0.2921 - val_accuracy: 0.8864\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8879 - val_loss: 0.2914 - val_accuracy: 0.8938\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.8876 - val_loss: 0.2916 - val_accuracy: 0.8823\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8881 - val_loss: 0.2922 - val_accuracy: 0.9036\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8885 - val_loss: 0.2897 - val_accuracy: 0.8962\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.8894 - val_loss: 0.2889 - val_accuracy: 0.8896\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2860 - accuracy: 0.8887 - val_loss: 0.2935 - val_accuracy: 0.8742\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2853 - accuracy: 0.8898 - val_loss: 0.2880 - val_accuracy: 0.8978\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.8889 - val_loss: 0.2879 - val_accuracy: 0.8843\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.8897 - val_loss: 0.2866 - val_accuracy: 0.8908\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.8894 - val_loss: 0.2864 - val_accuracy: 0.8881\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.8902 - val_loss: 0.2859 - val_accuracy: 0.8881\n",
      "277/277 [==============================] - 0s 912us/step - loss: 0.2767 - accuracy: 0.8903\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6582 - accuracy: 0.6018 - val_loss: 0.6378 - val_accuracy: 0.6097\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.6469 - val_loss: 0.6079 - val_accuracy: 0.6512\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6875 - val_loss: 0.5844 - val_accuracy: 0.7205\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5738 - accuracy: 0.7134 - val_loss: 0.5620 - val_accuracy: 0.7129\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.7339 - val_loss: 0.5434 - val_accuracy: 0.7397\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7529 - val_loss: 0.5289 - val_accuracy: 0.7277\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5195 - accuracy: 0.7643 - val_loss: 0.5133 - val_accuracy: 0.7685\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.7796 - val_loss: 0.5008 - val_accuracy: 0.7842\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4933 - accuracy: 0.7874 - val_loss: 0.4927 - val_accuracy: 0.7481\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.7946 - val_loss: 0.4794 - val_accuracy: 0.8076\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4705 - accuracy: 0.8016 - val_loss: 0.4800 - val_accuracy: 0.8638\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8100 - val_loss: 0.4604 - val_accuracy: 0.7890\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.8142 - val_loss: 0.4521 - val_accuracy: 0.8091\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8178 - val_loss: 0.4456 - val_accuracy: 0.8307\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.8229 - val_loss: 0.4382 - val_accuracy: 0.8297\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8266 - val_loss: 0.4313 - val_accuracy: 0.8261\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4239 - accuracy: 0.8321 - val_loss: 0.4260 - val_accuracy: 0.8087\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4179 - accuracy: 0.8345 - val_loss: 0.4199 - val_accuracy: 0.8191\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8378 - val_loss: 0.4172 - val_accuracy: 0.8066\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8395 - val_loss: 0.4095 - val_accuracy: 0.8420\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8411 - val_loss: 0.4047 - val_accuracy: 0.8314\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3963 - accuracy: 0.8436 - val_loss: 0.4016 - val_accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3914 - accuracy: 0.8470 - val_loss: 0.3958 - val_accuracy: 0.8490\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8480 - val_loss: 0.3915 - val_accuracy: 0.8496\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8515 - val_loss: 0.3938 - val_accuracy: 0.8772\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.8520 - val_loss: 0.3839 - val_accuracy: 0.8540\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3750 - accuracy: 0.8539 - val_loss: 0.3806 - val_accuracy: 0.8434\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8551 - val_loss: 0.3769 - val_accuracy: 0.8476\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8561 - val_loss: 0.3736 - val_accuracy: 0.8594\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8584 - val_loss: 0.3705 - val_accuracy: 0.8496\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8587 - val_loss: 0.3673 - val_accuracy: 0.8556\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3579 - accuracy: 0.8613 - val_loss: 0.3645 - val_accuracy: 0.8557\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.8624 - val_loss: 0.3619 - val_accuracy: 0.8533\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8625 - val_loss: 0.3614 - val_accuracy: 0.8448\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8629 - val_loss: 0.3575 - val_accuracy: 0.8503\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8649 - val_loss: 0.3547 - val_accuracy: 0.8559\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8652 - val_loss: 0.3521 - val_accuracy: 0.8665\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8684 - val_loss: 0.3517 - val_accuracy: 0.8497\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8678 - val_loss: 0.3495 - val_accuracy: 0.8501\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.8677 - val_loss: 0.3456 - val_accuracy: 0.8698\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8705 - val_loss: 0.3458 - val_accuracy: 0.8827\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8707 - val_loss: 0.3428 - val_accuracy: 0.8793\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8725 - val_loss: 0.3441 - val_accuracy: 0.8482\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8721 - val_loss: 0.3379 - val_accuracy: 0.8652\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8732 - val_loss: 0.3419 - val_accuracy: 0.8940\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8740 - val_loss: 0.3341 - val_accuracy: 0.8709\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8741 - val_loss: 0.3329 - val_accuracy: 0.8783\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.8749 - val_loss: 0.3342 - val_accuracy: 0.8559\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3205 - accuracy: 0.8758 - val_loss: 0.3293 - val_accuracy: 0.8707\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8758 - val_loss: 0.3283 - val_accuracy: 0.8807\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8774 - val_loss: 0.3263 - val_accuracy: 0.8714\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3155 - accuracy: 0.8767 - val_loss: 0.3248 - val_accuracy: 0.8744\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.8779 - val_loss: 0.3235 - val_accuracy: 0.8718\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.8795 - val_loss: 0.3227 - val_accuracy: 0.8841\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8787 - val_loss: 0.3252 - val_accuracy: 0.8587\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3098 - accuracy: 0.8802 - val_loss: 0.3194 - val_accuracy: 0.8744\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.8790 - val_loss: 0.3193 - val_accuracy: 0.8888\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8808 - val_loss: 0.3184 - val_accuracy: 0.8904\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.8816 - val_loss: 0.3163 - val_accuracy: 0.8864\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.8807 - val_loss: 0.3151 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.8822 - val_loss: 0.3164 - val_accuracy: 0.8658\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8822 - val_loss: 0.3123 - val_accuracy: 0.8807\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3012 - accuracy: 0.8832 - val_loss: 0.3143 - val_accuracy: 0.8661\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.8832 - val_loss: 0.3105 - val_accuracy: 0.8862\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.8833 - val_loss: 0.3097 - val_accuracy: 0.8885\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2978 - accuracy: 0.8844 - val_loss: 0.3088 - val_accuracy: 0.8749\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8836 - val_loss: 0.3086 - val_accuracy: 0.8920\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2959 - accuracy: 0.8859 - val_loss: 0.3064 - val_accuracy: 0.8869\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2952 - accuracy: 0.8869 - val_loss: 0.3057 - val_accuracy: 0.8892\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2939 - accuracy: 0.8860 - val_loss: 0.3045 - val_accuracy: 0.8866\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2930 - accuracy: 0.8876 - val_loss: 0.3042 - val_accuracy: 0.8917\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8864 - val_loss: 0.3027 - val_accuracy: 0.8852\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2913 - accuracy: 0.8872 - val_loss: 0.3018 - val_accuracy: 0.8866\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8864 - val_loss: 0.3059 - val_accuracy: 0.8670\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.8888 - val_loss: 0.3006 - val_accuracy: 0.8804\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2886 - accuracy: 0.8874 - val_loss: 0.3032 - val_accuracy: 0.9031\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.8897 - val_loss: 0.2988 - val_accuracy: 0.8910\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.8884 - val_loss: 0.2978 - val_accuracy: 0.8874\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8895 - val_loss: 0.2973 - val_accuracy: 0.8911\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8897 - val_loss: 0.2987 - val_accuracy: 0.9008\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.8902 - val_loss: 0.2969 - val_accuracy: 0.8991\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.8892 - val_loss: 0.2949 - val_accuracy: 0.8906\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8902 - val_loss: 0.2977 - val_accuracy: 0.9045\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8906 - val_loss: 0.2956 - val_accuracy: 0.9019\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.8910 - val_loss: 0.2942 - val_accuracy: 0.8800\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2812 - accuracy: 0.8914 - val_loss: 0.2922 - val_accuracy: 0.8873\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.8899 - val_loss: 0.2917 - val_accuracy: 0.8860\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8914 - val_loss: 0.2908 - val_accuracy: 0.8892\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8915 - val_loss: 0.2915 - val_accuracy: 0.9008\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.8915 - val_loss: 0.2898 - val_accuracy: 0.8959\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2776 - accuracy: 0.8937 - val_loss: 0.2903 - val_accuracy: 0.9015\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8914 - val_loss: 0.2897 - val_accuracy: 0.9015\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.8944 - val_loss: 0.2881 - val_accuracy: 0.8869\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2756 - accuracy: 0.8925 - val_loss: 0.2872 - val_accuracy: 0.8954\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8936 - val_loss: 0.2945 - val_accuracy: 0.9135\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8939 - val_loss: 0.2859 - val_accuracy: 0.8920\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.8941 - val_loss: 0.2878 - val_accuracy: 0.9056\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.8961 - val_loss: 0.2853 - val_accuracy: 0.8878\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8938 - val_loss: 0.2844 - val_accuracy: 0.8910\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.8941 - val_loss: 0.2838 - val_accuracy: 0.8913\n",
      "277/277 [==============================] - 0s 887us/step - loss: 0.2935 - accuracy: 0.8845\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6645 - accuracy: 0.5939 - val_loss: 0.6445 - val_accuracy: 0.6051\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.6335 - val_loss: 0.6137 - val_accuracy: 0.6481\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.6762 - val_loss: 0.5942 - val_accuracy: 0.7513\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5830 - accuracy: 0.7042 - val_loss: 0.5724 - val_accuracy: 0.7714\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5635 - accuracy: 0.7311 - val_loss: 0.5500 - val_accuracy: 0.7492\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7432 - val_loss: 0.5336 - val_accuracy: 0.7317\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7557 - val_loss: 0.5223 - val_accuracy: 0.8015\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7682 - val_loss: 0.5071 - val_accuracy: 0.7465\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7789 - val_loss: 0.4940 - val_accuracy: 0.7680\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7875 - val_loss: 0.4846 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4827 - accuracy: 0.7926 - val_loss: 0.4742 - val_accuracy: 0.8078\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7990 - val_loss: 0.4654 - val_accuracy: 0.8149\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.8070 - val_loss: 0.4564 - val_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.8109 - val_loss: 0.4505 - val_accuracy: 0.8362\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.8165 - val_loss: 0.4414 - val_accuracy: 0.8124\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8198 - val_loss: 0.4349 - val_accuracy: 0.8274\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4345 - accuracy: 0.8224 - val_loss: 0.4316 - val_accuracy: 0.8504\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.8283 - val_loss: 0.4230 - val_accuracy: 0.8131\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8303 - val_loss: 0.4172 - val_accuracy: 0.8388\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4172 - accuracy: 0.8325 - val_loss: 0.4125 - val_accuracy: 0.8194\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4120 - accuracy: 0.8365 - val_loss: 0.4072 - val_accuracy: 0.8434\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8388 - val_loss: 0.4024 - val_accuracy: 0.8418\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8396 - val_loss: 0.4011 - val_accuracy: 0.8631\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3980 - accuracy: 0.8430 - val_loss: 0.3955 - val_accuracy: 0.8242\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8464 - val_loss: 0.3902 - val_accuracy: 0.8376\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8476 - val_loss: 0.3860 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8476 - val_loss: 0.3849 - val_accuracy: 0.8665\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8494 - val_loss: 0.3790 - val_accuracy: 0.8483\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3797 - accuracy: 0.8512 - val_loss: 0.3758 - val_accuracy: 0.8510\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3762 - accuracy: 0.8520 - val_loss: 0.3727 - val_accuracy: 0.8564\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3730 - accuracy: 0.8564 - val_loss: 0.3711 - val_accuracy: 0.8672\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8558 - val_loss: 0.3667 - val_accuracy: 0.8587\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3673 - accuracy: 0.8565 - val_loss: 0.3638 - val_accuracy: 0.8570\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8593 - val_loss: 0.3615 - val_accuracy: 0.8508\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8601 - val_loss: 0.3586 - val_accuracy: 0.8623\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3591 - accuracy: 0.8595 - val_loss: 0.3560 - val_accuracy: 0.8623\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3566 - accuracy: 0.8612 - val_loss: 0.3538 - val_accuracy: 0.8665\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8637 - val_loss: 0.3517 - val_accuracy: 0.8547\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8636 - val_loss: 0.3533 - val_accuracy: 0.8855\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8651 - val_loss: 0.3470 - val_accuracy: 0.8603\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8660 - val_loss: 0.3463 - val_accuracy: 0.8772\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8662 - val_loss: 0.3430 - val_accuracy: 0.8700\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8674 - val_loss: 0.3408 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8675 - val_loss: 0.3392 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3401 - accuracy: 0.8694 - val_loss: 0.3412 - val_accuracy: 0.8887\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8691 - val_loss: 0.3360 - val_accuracy: 0.8760\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8702 - val_loss: 0.3338 - val_accuracy: 0.8733\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8709 - val_loss: 0.3331 - val_accuracy: 0.8815\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8722 - val_loss: 0.3345 - val_accuracy: 0.8526\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8734 - val_loss: 0.3298 - val_accuracy: 0.8623\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8735 - val_loss: 0.3299 - val_accuracy: 0.8878\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8735 - val_loss: 0.3262 - val_accuracy: 0.8792\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3266 - accuracy: 0.8737 - val_loss: 0.3284 - val_accuracy: 0.8924\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3254 - accuracy: 0.8745 - val_loss: 0.3248 - val_accuracy: 0.8869\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8754 - val_loss: 0.3224 - val_accuracy: 0.8852\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8764 - val_loss: 0.3201 - val_accuracy: 0.8725\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8763 - val_loss: 0.3252 - val_accuracy: 0.9010\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8787 - val_loss: 0.3175 - val_accuracy: 0.8776\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8777 - val_loss: 0.3237 - val_accuracy: 0.8543\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3175 - accuracy: 0.8785 - val_loss: 0.3165 - val_accuracy: 0.8878\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8801 - val_loss: 0.3140 - val_accuracy: 0.8811\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8787 - val_loss: 0.3129 - val_accuracy: 0.8822\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3142 - accuracy: 0.8805 - val_loss: 0.3130 - val_accuracy: 0.8689\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8794 - val_loss: 0.3106 - val_accuracy: 0.8765\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3117 - accuracy: 0.8806 - val_loss: 0.3145 - val_accuracy: 0.9014\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3103 - accuracy: 0.8827 - val_loss: 0.3085 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.8810 - val_loss: 0.3079 - val_accuracy: 0.8876\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3092 - accuracy: 0.8818 - val_loss: 0.3064 - val_accuracy: 0.8853\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.8830 - val_loss: 0.3070 - val_accuracy: 0.8929\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3068 - accuracy: 0.8827 - val_loss: 0.3053 - val_accuracy: 0.8730\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.8825 - val_loss: 0.3034 - val_accuracy: 0.8829\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8834 - val_loss: 0.3025 - val_accuracy: 0.8830\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8825 - val_loss: 0.3017 - val_accuracy: 0.8790\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.8845 - val_loss: 0.3044 - val_accuracy: 0.8675\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.8848 - val_loss: 0.3007 - val_accuracy: 0.8760\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8849 - val_loss: 0.2990 - val_accuracy: 0.8818\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3009 - accuracy: 0.8859 - val_loss: 0.2982 - val_accuracy: 0.8880\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.8867 - val_loss: 0.2978 - val_accuracy: 0.8913\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8859 - val_loss: 0.2998 - val_accuracy: 0.8702\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2982 - accuracy: 0.8856 - val_loss: 0.2961 - val_accuracy: 0.8792\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.8874 - val_loss: 0.2955 - val_accuracy: 0.8929\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2963 - accuracy: 0.8870 - val_loss: 0.2941 - val_accuracy: 0.8871\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.8877 - val_loss: 0.2933 - val_accuracy: 0.8883\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8864 - val_loss: 0.3038 - val_accuracy: 0.9147\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8880 - val_loss: 0.2926 - val_accuracy: 0.8793\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8876 - val_loss: 0.2918 - val_accuracy: 0.8961\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8881 - val_loss: 0.2906 - val_accuracy: 0.8915\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2919 - accuracy: 0.8889 - val_loss: 0.2897 - val_accuracy: 0.8892\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2914 - accuracy: 0.8887 - val_loss: 0.2891 - val_accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2908 - accuracy: 0.8902 - val_loss: 0.2894 - val_accuracy: 0.8802\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2905 - accuracy: 0.8897 - val_loss: 0.2876 - val_accuracy: 0.8896\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8893 - val_loss: 0.2877 - val_accuracy: 0.8825\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.8895 - val_loss: 0.2867 - val_accuracy: 0.8859\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8900 - val_loss: 0.2862 - val_accuracy: 0.8850\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.8899 - val_loss: 0.2875 - val_accuracy: 0.9051\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8904 - val_loss: 0.2893 - val_accuracy: 0.9084\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8913 - val_loss: 0.2910 - val_accuracy: 0.9121\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.8925 - val_loss: 0.2835 - val_accuracy: 0.8874\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.8912 - val_loss: 0.2826 - val_accuracy: 0.8913\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8917 - val_loss: 0.2830 - val_accuracy: 0.8844\n",
      "277/277 [==============================] - 0s 875us/step - loss: 0.2723 - accuracy: 0.8859\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6738 - accuracy: 0.5903 - val_loss: 0.6662 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6666 - accuracy: 0.5914 - val_loss: 0.6604 - val_accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6601 - accuracy: 0.5921 - val_loss: 0.6535 - val_accuracy: 0.6049\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6534 - accuracy: 0.5981 - val_loss: 0.6471 - val_accuracy: 0.6051\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6472 - accuracy: 0.6049 - val_loss: 0.6407 - val_accuracy: 0.6171\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6412 - accuracy: 0.6146 - val_loss: 0.6351 - val_accuracy: 0.6299\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6353 - accuracy: 0.6247 - val_loss: 0.6290 - val_accuracy: 0.6278\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6295 - accuracy: 0.6325 - val_loss: 0.6250 - val_accuracy: 0.6623\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6240 - accuracy: 0.6450 - val_loss: 0.6181 - val_accuracy: 0.6449\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6187 - accuracy: 0.6504 - val_loss: 0.6130 - val_accuracy: 0.6516\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6136 - accuracy: 0.6585 - val_loss: 0.6093 - val_accuracy: 0.6857\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6088 - accuracy: 0.6669 - val_loss: 0.6038 - val_accuracy: 0.6838\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.6747 - val_loss: 0.5992 - val_accuracy: 0.6896\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6819 - val_loss: 0.5943 - val_accuracy: 0.6697\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6851 - val_loss: 0.5903 - val_accuracy: 0.7057\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6923 - val_loss: 0.5852 - val_accuracy: 0.6968\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5855 - accuracy: 0.6970 - val_loss: 0.5834 - val_accuracy: 0.7349\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5813 - accuracy: 0.7077 - val_loss: 0.5770 - val_accuracy: 0.6924\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5773 - accuracy: 0.7075 - val_loss: 0.5729 - val_accuracy: 0.7079\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5731 - accuracy: 0.7127 - val_loss: 0.5690 - val_accuracy: 0.7120\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.7167 - val_loss: 0.5654 - val_accuracy: 0.7065\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7201 - val_loss: 0.5622 - val_accuracy: 0.7375\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5617 - accuracy: 0.7258 - val_loss: 0.5580 - val_accuracy: 0.7261\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7301 - val_loss: 0.5545 - val_accuracy: 0.7226\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5546 - accuracy: 0.7320 - val_loss: 0.5512 - val_accuracy: 0.7215\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7372 - val_loss: 0.5478 - val_accuracy: 0.7333\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7402 - val_loss: 0.5447 - val_accuracy: 0.7284\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7430 - val_loss: 0.5415 - val_accuracy: 0.7426\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7476 - val_loss: 0.5384 - val_accuracy: 0.7367\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7482 - val_loss: 0.5355 - val_accuracy: 0.7354\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7497 - val_loss: 0.5334 - val_accuracy: 0.7666\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7553 - val_loss: 0.5298 - val_accuracy: 0.7573\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7578\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7610 - val_loss: 0.5241 - val_accuracy: 0.7544\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7620 - val_loss: 0.5216 - val_accuracy: 0.7638\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5210 - accuracy: 0.7638 - val_loss: 0.5190 - val_accuracy: 0.7643\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7672 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7680 - val_loss: 0.5138 - val_accuracy: 0.7594\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7702 - val_loss: 0.5117 - val_accuracy: 0.7735\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7730 - val_loss: 0.5094 - val_accuracy: 0.7782\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7732 - val_loss: 0.5072 - val_accuracy: 0.7837\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7765 - val_loss: 0.5042 - val_accuracy: 0.7724\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7724\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.7813 - val_loss: 0.5004 - val_accuracy: 0.7553\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4989 - accuracy: 0.7820 - val_loss: 0.4975 - val_accuracy: 0.7687\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4967 - accuracy: 0.7821 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.7855 - val_loss: 0.4931 - val_accuracy: 0.7761\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4925 - accuracy: 0.7850 - val_loss: 0.4912 - val_accuracy: 0.7735\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7860 - val_loss: 0.4898 - val_accuracy: 0.7953\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.7878 - val_loss: 0.4873 - val_accuracy: 0.7881\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7886 - val_loss: 0.4862 - val_accuracy: 0.8022\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7908 - val_loss: 0.4852 - val_accuracy: 0.8124\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4823 - accuracy: 0.7921 - val_loss: 0.4816 - val_accuracy: 0.7798\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7935 - val_loss: 0.4797 - val_accuracy: 0.7823\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.7963 - val_loss: 0.4790 - val_accuracy: 0.7694\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7951 - val_loss: 0.4761 - val_accuracy: 0.7951\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7982 - val_loss: 0.4742 - val_accuracy: 0.7883\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4731 - accuracy: 0.7972 - val_loss: 0.4727 - val_accuracy: 0.8017\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.7995 - val_loss: 0.4713 - val_accuracy: 0.8075\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4695 - accuracy: 0.8017 - val_loss: 0.4692 - val_accuracy: 0.8022\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4679 - accuracy: 0.8017 - val_loss: 0.4685 - val_accuracy: 0.8159\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4663 - accuracy: 0.8038 - val_loss: 0.4661 - val_accuracy: 0.8075\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.8034 - val_loss: 0.4642 - val_accuracy: 0.8018\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8053 - val_loss: 0.4627 - val_accuracy: 0.7951\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.8050 - val_loss: 0.4611 - val_accuracy: 0.7957\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.8062 - val_loss: 0.4598 - val_accuracy: 0.7918\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4583 - accuracy: 0.8068 - val_loss: 0.4583 - val_accuracy: 0.8108\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8094 - val_loss: 0.4566 - val_accuracy: 0.8047\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8082 - val_loss: 0.4552 - val_accuracy: 0.8096\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.8110 - val_loss: 0.4537 - val_accuracy: 0.8092\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.8104 - val_loss: 0.4528 - val_accuracy: 0.8212\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.8122 - val_loss: 0.4508 - val_accuracy: 0.8039\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4491 - accuracy: 0.8130 - val_loss: 0.4495 - val_accuracy: 0.8154\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4477 - accuracy: 0.8157 - val_loss: 0.4480 - val_accuracy: 0.8096\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8156 - val_loss: 0.4467 - val_accuracy: 0.8047\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.8163 - val_loss: 0.4453 - val_accuracy: 0.8073\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8156 - val_loss: 0.4441 - val_accuracy: 0.8165\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8171 - val_loss: 0.4427 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8181 - val_loss: 0.4418 - val_accuracy: 0.8251\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4397 - accuracy: 0.8184 - val_loss: 0.4403 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8188 - val_loss: 0.4393 - val_accuracy: 0.8279\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8217 - val_loss: 0.4379 - val_accuracy: 0.8254\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4359 - accuracy: 0.8208 - val_loss: 0.4369 - val_accuracy: 0.8305\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8207 - val_loss: 0.4353 - val_accuracy: 0.8205\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4333 - accuracy: 0.8226 - val_loss: 0.4343 - val_accuracy: 0.8110\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4322 - accuracy: 0.8225 - val_loss: 0.4329 - val_accuracy: 0.8202\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4309 - accuracy: 0.8225 - val_loss: 0.4320 - val_accuracy: 0.8302\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4298 - accuracy: 0.8243 - val_loss: 0.4306 - val_accuracy: 0.8202\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.8242 - val_loss: 0.4296 - val_accuracy: 0.8311\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4271 - accuracy: 0.8253 - val_loss: 0.4284 - val_accuracy: 0.8305\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4263 - accuracy: 0.8269 - val_loss: 0.4272 - val_accuracy: 0.8165\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8266 - val_loss: 0.4260 - val_accuracy: 0.8247\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4240 - accuracy: 0.8267 - val_loss: 0.4251 - val_accuracy: 0.8184\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4227 - accuracy: 0.8280 - val_loss: 0.4239 - val_accuracy: 0.8205\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4218 - accuracy: 0.8280 - val_loss: 0.4228 - val_accuracy: 0.8297\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4207 - accuracy: 0.8296 - val_loss: 0.4220 - val_accuracy: 0.8194\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4196 - accuracy: 0.8301 - val_loss: 0.4208 - val_accuracy: 0.8288\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4186 - accuracy: 0.8296 - val_loss: 0.4197 - val_accuracy: 0.8295\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8306 - val_loss: 0.4190 - val_accuracy: 0.8209\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4166 - accuracy: 0.8302 - val_loss: 0.4178 - val_accuracy: 0.8288\n",
      "277/277 [==============================] - 0s 882us/step - loss: 0.4147 - accuracy: 0.8329\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6721 - accuracy: 0.5942 - val_loss: 0.6663 - val_accuracy: 0.6005\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6650 - accuracy: 0.5947 - val_loss: 0.6593 - val_accuracy: 0.6005\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6583 - accuracy: 0.5955 - val_loss: 0.6533 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6516 - accuracy: 0.6000 - val_loss: 0.6463 - val_accuracy: 0.6081\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6454 - accuracy: 0.6087 - val_loss: 0.6401 - val_accuracy: 0.6139\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6393 - accuracy: 0.6154 - val_loss: 0.6343 - val_accuracy: 0.6241\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6332 - accuracy: 0.6274 - val_loss: 0.6292 - val_accuracy: 0.6218\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6275 - accuracy: 0.6338 - val_loss: 0.6250 - val_accuracy: 0.6651\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.6445 - val_loss: 0.6178 - val_accuracy: 0.6449\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6167 - accuracy: 0.6517 - val_loss: 0.6127 - val_accuracy: 0.6577\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6115 - accuracy: 0.6600 - val_loss: 0.6101 - val_accuracy: 0.7005\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6065 - accuracy: 0.6688 - val_loss: 0.6037 - val_accuracy: 0.6896\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6015 - accuracy: 0.6770 - val_loss: 0.5982 - val_accuracy: 0.6813\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6802 - val_loss: 0.5937 - val_accuracy: 0.6893\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6894 - val_loss: 0.5892 - val_accuracy: 0.6939\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5876 - accuracy: 0.6938 - val_loss: 0.5848 - val_accuracy: 0.6919\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7004 - val_loss: 0.5806 - val_accuracy: 0.6970\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5788 - accuracy: 0.7058 - val_loss: 0.5772 - val_accuracy: 0.6870\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7079 - val_loss: 0.5746 - val_accuracy: 0.7421\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5707 - accuracy: 0.7173 - val_loss: 0.5690 - val_accuracy: 0.6972\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7185 - val_loss: 0.5665 - val_accuracy: 0.7470\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7246 - val_loss: 0.5615 - val_accuracy: 0.7368\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5587 - accuracy: 0.7284 - val_loss: 0.5573 - val_accuracy: 0.7252\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5548 - accuracy: 0.7298 - val_loss: 0.5548 - val_accuracy: 0.7483\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5512 - accuracy: 0.7373 - val_loss: 0.5503 - val_accuracy: 0.7231\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7375 - val_loss: 0.5470 - val_accuracy: 0.7407\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7435 - val_loss: 0.5440 - val_accuracy: 0.7231\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7442 - val_loss: 0.5411 - val_accuracy: 0.7227\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7471 - val_loss: 0.5376 - val_accuracy: 0.7511\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7522 - val_loss: 0.5344 - val_accuracy: 0.7389\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7515 - val_loss: 0.5318 - val_accuracy: 0.7603\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7571 - val_loss: 0.5286 - val_accuracy: 0.7546\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7586 - val_loss: 0.5257 - val_accuracy: 0.7472\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5225 - accuracy: 0.7610 - val_loss: 0.5229 - val_accuracy: 0.7509\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7639 - val_loss: 0.5209 - val_accuracy: 0.7411\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7659 - val_loss: 0.5175 - val_accuracy: 0.7613\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.7680 - val_loss: 0.5150 - val_accuracy: 0.7548\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5116 - accuracy: 0.7710 - val_loss: 0.5127 - val_accuracy: 0.7745\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5088 - accuracy: 0.7739 - val_loss: 0.5099 - val_accuracy: 0.7622\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.7734 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7775 - val_loss: 0.5053 - val_accuracy: 0.7758\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5014 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7844\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.7798 - val_loss: 0.5005 - val_accuracy: 0.7742\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7819 - val_loss: 0.4983 - val_accuracy: 0.7721\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4944 - accuracy: 0.7843 - val_loss: 0.4962 - val_accuracy: 0.7823\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4921 - accuracy: 0.7859 - val_loss: 0.4951 - val_accuracy: 0.7999\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4900 - accuracy: 0.7910 - val_loss: 0.4920 - val_accuracy: 0.7692\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.7888 - val_loss: 0.4898 - val_accuracy: 0.7869\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.7920 - val_loss: 0.4886 - val_accuracy: 0.7636\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.7903 - val_loss: 0.4857 - val_accuracy: 0.7888\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4813 - accuracy: 0.7948 - val_loss: 0.4838 - val_accuracy: 0.7759\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.7948 - val_loss: 0.4817 - val_accuracy: 0.7890\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7957 - val_loss: 0.4806 - val_accuracy: 0.8059\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.7999 - val_loss: 0.4779 - val_accuracy: 0.7860\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.7988 - val_loss: 0.4761 - val_accuracy: 0.7950\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.8018 - val_loss: 0.4743 - val_accuracy: 0.7826\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.8023 - val_loss: 0.4724 - val_accuracy: 0.7987\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.8036 - val_loss: 0.4705 - val_accuracy: 0.7965\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4658 - accuracy: 0.8055 - val_loss: 0.4688 - val_accuracy: 0.7930\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4639 - accuracy: 0.8057 - val_loss: 0.4671 - val_accuracy: 0.8018\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4622 - accuracy: 0.8066 - val_loss: 0.4653 - val_accuracy: 0.7962\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4603 - accuracy: 0.8082 - val_loss: 0.4641 - val_accuracy: 0.8119\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.8105 - val_loss: 0.4624 - val_accuracy: 0.8119\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4568 - accuracy: 0.8103 - val_loss: 0.4607 - val_accuracy: 0.8122\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8124 - val_loss: 0.4587 - val_accuracy: 0.8015\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.8139 - val_loss: 0.4572 - val_accuracy: 0.7978\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4518 - accuracy: 0.8141 - val_loss: 0.4558 - val_accuracy: 0.7951\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8137 - val_loss: 0.4542 - val_accuracy: 0.8018\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4486 - accuracy: 0.8150 - val_loss: 0.4528 - val_accuracy: 0.7992\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4472 - accuracy: 0.8163 - val_loss: 0.4512 - val_accuracy: 0.8047\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4456 - accuracy: 0.8191 - val_loss: 0.4509 - val_accuracy: 0.7899\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8180 - val_loss: 0.4483 - val_accuracy: 0.8061\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.8200 - val_loss: 0.4471 - val_accuracy: 0.8022\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4412 - accuracy: 0.8193 - val_loss: 0.4456 - val_accuracy: 0.8163\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8202 - val_loss: 0.4445 - val_accuracy: 0.8242\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.8242 - val_loss: 0.4428 - val_accuracy: 0.8120\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4369 - accuracy: 0.8220 - val_loss: 0.4415 - val_accuracy: 0.8180\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4355 - accuracy: 0.8247 - val_loss: 0.4403 - val_accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.8248 - val_loss: 0.4393 - val_accuracy: 0.8286\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8263 - val_loss: 0.4377 - val_accuracy: 0.8112\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.8263 - val_loss: 0.4365 - val_accuracy: 0.8105\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8263 - val_loss: 0.4351 - val_accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.8270 - val_loss: 0.4339 - val_accuracy: 0.8193\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4277 - accuracy: 0.8273 - val_loss: 0.4331 - val_accuracy: 0.8087\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.8270 - val_loss: 0.4316 - val_accuracy: 0.8293\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4249 - accuracy: 0.8293 - val_loss: 0.4306 - val_accuracy: 0.8341\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4238 - accuracy: 0.8291 - val_loss: 0.4291 - val_accuracy: 0.8279\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4285 - val_accuracy: 0.8105\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4214 - accuracy: 0.8314 - val_loss: 0.4268 - val_accuracy: 0.8291\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4203 - accuracy: 0.8328 - val_loss: 0.4257 - val_accuracy: 0.8184\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4191 - accuracy: 0.8322 - val_loss: 0.4247 - val_accuracy: 0.8365\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4176 - accuracy: 0.8343 - val_loss: 0.4238 - val_accuracy: 0.8143\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4168 - accuracy: 0.8334 - val_loss: 0.4224 - val_accuracy: 0.8355\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4154 - accuracy: 0.8352 - val_loss: 0.4215 - val_accuracy: 0.8175\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.8349 - val_loss: 0.4203 - val_accuracy: 0.8210\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4133 - accuracy: 0.8343 - val_loss: 0.4193 - val_accuracy: 0.8371\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8346 - val_loss: 0.4185 - val_accuracy: 0.8408\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.8379 - val_loss: 0.4171 - val_accuracy: 0.8297\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8377 - val_loss: 0.4162 - val_accuracy: 0.8381\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8382 - val_loss: 0.4153 - val_accuracy: 0.8244\n",
      "277/277 [==============================] - 0s 850us/step - loss: 0.4216 - accuracy: 0.8151\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6808 - accuracy: 0.5699 - val_loss: 0.6626 - val_accuracy: 0.6003\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.5919 - val_loss: 0.6569 - val_accuracy: 0.6024\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6582 - accuracy: 0.5939 - val_loss: 0.6515 - val_accuracy: 0.6089\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6523 - accuracy: 0.6000 - val_loss: 0.6453 - val_accuracy: 0.6153\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6464 - accuracy: 0.6076 - val_loss: 0.6393 - val_accuracy: 0.6197\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6159 - val_loss: 0.6337 - val_accuracy: 0.6220\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6353 - accuracy: 0.6258 - val_loss: 0.6288 - val_accuracy: 0.6243\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6307 - val_loss: 0.6230 - val_accuracy: 0.6401\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.6412 - val_loss: 0.6188 - val_accuracy: 0.6646\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.6491 - val_loss: 0.6139 - val_accuracy: 0.6766\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6148 - accuracy: 0.6587 - val_loss: 0.6100 - val_accuracy: 0.6961\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6102 - accuracy: 0.6658 - val_loss: 0.6034 - val_accuracy: 0.6634\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6056 - accuracy: 0.6722 - val_loss: 0.5987 - val_accuracy: 0.6752\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6784 - val_loss: 0.5943 - val_accuracy: 0.6748\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5967 - accuracy: 0.6832 - val_loss: 0.5902 - val_accuracy: 0.6806\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5925 - accuracy: 0.6891 - val_loss: 0.5861 - val_accuracy: 0.6930\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6932 - val_loss: 0.5825 - val_accuracy: 0.7085\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5844 - accuracy: 0.6962 - val_loss: 0.5804 - val_accuracy: 0.7361\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7116\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.7086 - val_loss: 0.5705 - val_accuracy: 0.7180\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5729 - accuracy: 0.7125 - val_loss: 0.5667 - val_accuracy: 0.7226\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7152 - val_loss: 0.5641 - val_accuracy: 0.7395\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7242 - val_loss: 0.5596 - val_accuracy: 0.7120\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5619 - accuracy: 0.7220 - val_loss: 0.5568 - val_accuracy: 0.7430\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7307 - val_loss: 0.5526 - val_accuracy: 0.7330\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7327 - val_loss: 0.5502 - val_accuracy: 0.7486\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5518 - accuracy: 0.7374 - val_loss: 0.5463 - val_accuracy: 0.7375\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7393 - val_loss: 0.5432 - val_accuracy: 0.7340\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7413 - val_loss: 0.5412 - val_accuracy: 0.7611\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7453 - val_loss: 0.5379 - val_accuracy: 0.7596\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7476 - val_loss: 0.5348 - val_accuracy: 0.7597\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7522 - val_loss: 0.5315 - val_accuracy: 0.7509\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7518 - val_loss: 0.5301 - val_accuracy: 0.7745\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7545 - val_loss: 0.5259 - val_accuracy: 0.7516\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7566 - val_loss: 0.5242 - val_accuracy: 0.7733\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5254 - accuracy: 0.7601 - val_loss: 0.5210 - val_accuracy: 0.7675\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.7618 - val_loss: 0.5181 - val_accuracy: 0.7557\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5204 - accuracy: 0.7630 - val_loss: 0.5161 - val_accuracy: 0.7736\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7659 - val_loss: 0.5136 - val_accuracy: 0.7744\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7692 - val_loss: 0.5116 - val_accuracy: 0.7825\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.7702 - val_loss: 0.5100 - val_accuracy: 0.7916\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5106 - accuracy: 0.7734 - val_loss: 0.5062 - val_accuracy: 0.7752\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7821\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7757 - val_loss: 0.5015 - val_accuracy: 0.7766\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7777 - val_loss: 0.4998 - val_accuracy: 0.7870\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5013 - accuracy: 0.7781 - val_loss: 0.4970 - val_accuracy: 0.7751\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7799 - val_loss: 0.4953 - val_accuracy: 0.7872\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4969 - accuracy: 0.7823 - val_loss: 0.4934 - val_accuracy: 0.7928\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7844 - val_loss: 0.4906 - val_accuracy: 0.7768\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7844 - val_loss: 0.4891 - val_accuracy: 0.7918\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4908 - accuracy: 0.7867 - val_loss: 0.4867 - val_accuracy: 0.7830\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.7882 - val_loss: 0.4849 - val_accuracy: 0.7879\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4868 - accuracy: 0.7896 - val_loss: 0.4832 - val_accuracy: 0.7928\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7929 - val_loss: 0.4812 - val_accuracy: 0.7782\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4831 - accuracy: 0.7920 - val_loss: 0.4792 - val_accuracy: 0.7858\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.7924 - val_loss: 0.4779 - val_accuracy: 0.8015\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4793 - accuracy: 0.7958 - val_loss: 0.4757 - val_accuracy: 0.7856\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4776 - accuracy: 0.7956 - val_loss: 0.4739 - val_accuracy: 0.7897\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7982 - val_loss: 0.4721 - val_accuracy: 0.7907\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4740 - accuracy: 0.7981 - val_loss: 0.4704 - val_accuracy: 0.7953\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4721 - accuracy: 0.8009 - val_loss: 0.4686 - val_accuracy: 0.7914\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.8012 - val_loss: 0.4672 - val_accuracy: 0.8059\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4687 - accuracy: 0.8006 - val_loss: 0.4657 - val_accuracy: 0.8082\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.8016 - val_loss: 0.4655 - val_accuracy: 0.8267\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.8047 - val_loss: 0.4621 - val_accuracy: 0.8054\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8053 - val_loss: 0.4606 - val_accuracy: 0.7911\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.8047 - val_loss: 0.4591 - val_accuracy: 0.8087\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4605 - accuracy: 0.8062 - val_loss: 0.4582 - val_accuracy: 0.8196\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4591 - accuracy: 0.8078 - val_loss: 0.4559 - val_accuracy: 0.8069\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.8073 - val_loss: 0.4561 - val_accuracy: 0.8323\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4561 - accuracy: 0.8092 - val_loss: 0.4536 - val_accuracy: 0.8202\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4547 - accuracy: 0.8120 - val_loss: 0.4516 - val_accuracy: 0.8089\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8106 - val_loss: 0.4504 - val_accuracy: 0.8154\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4519 - accuracy: 0.8121 - val_loss: 0.4495 - val_accuracy: 0.8249\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.8145 - val_loss: 0.4474 - val_accuracy: 0.8069\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4490 - accuracy: 0.8143 - val_loss: 0.4461 - val_accuracy: 0.8083\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.8146 - val_loss: 0.4452 - val_accuracy: 0.8254\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4462 - accuracy: 0.8159 - val_loss: 0.4438 - val_accuracy: 0.8246\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.8162 - val_loss: 0.4423 - val_accuracy: 0.8205\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8189 - val_loss: 0.4410 - val_accuracy: 0.8076\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.8171 - val_loss: 0.4400 - val_accuracy: 0.8263\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4411 - accuracy: 0.8188 - val_loss: 0.4384 - val_accuracy: 0.8124\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8185 - val_loss: 0.4374 - val_accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8222 - val_loss: 0.4360 - val_accuracy: 0.8177\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8214 - val_loss: 0.4348 - val_accuracy: 0.8173\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8216 - val_loss: 0.4343 - val_accuracy: 0.8355\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8226 - val_loss: 0.4329 - val_accuracy: 0.8325\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.8235 - val_loss: 0.4319 - val_accuracy: 0.8362\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4329 - accuracy: 0.8257 - val_loss: 0.4304 - val_accuracy: 0.8126\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8247 - val_loss: 0.4291 - val_accuracy: 0.8231\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.8262 - val_loss: 0.4284 - val_accuracy: 0.8346\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8256 - val_loss: 0.4278 - val_accuracy: 0.8408\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4284 - accuracy: 0.8286 - val_loss: 0.4259 - val_accuracy: 0.8274\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4273 - accuracy: 0.8275 - val_loss: 0.4251 - val_accuracy: 0.8362\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4260 - accuracy: 0.8285 - val_loss: 0.4245 - val_accuracy: 0.8413\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8288 - val_loss: 0.4250 - val_accuracy: 0.8494\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4241 - accuracy: 0.8302 - val_loss: 0.4218 - val_accuracy: 0.8360\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8317 - val_loss: 0.4212 - val_accuracy: 0.8143\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4220 - accuracy: 0.8293 - val_loss: 0.4197 - val_accuracy: 0.8323\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4209 - accuracy: 0.8312 - val_loss: 0.4187 - val_accuracy: 0.8263\n",
      "277/277 [==============================] - 0s 863us/step - loss: 0.4096 - accuracy: 0.8330\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6408 - accuracy: 0.6440 - val_loss: 0.6492 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.6914 - val_loss: 0.4105 - val_accuracy: 0.8848\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3683 - accuracy: 0.8499 - val_loss: 0.4837 - val_accuracy: 0.8284\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8881 - val_loss: 1.2219 - val_accuracy: 0.3995\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8709 - val_loss: 0.2268 - val_accuracy: 0.9110\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8915 - val_loss: 0.2480 - val_accuracy: 0.9232\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.8976 - val_loss: 0.4190 - val_accuracy: 0.8379\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2700 - accuracy: 0.8973 - val_loss: 0.2274 - val_accuracy: 0.9257\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9062 - val_loss: 0.4164 - val_accuracy: 0.8712\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9048 - val_loss: 0.2234 - val_accuracy: 0.9154\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2700 - accuracy: 0.8986 - val_loss: 0.1966 - val_accuracy: 0.9352\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2593 - accuracy: 0.9044 - val_loss: 0.2092 - val_accuracy: 0.9297\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.9110 - val_loss: 0.1935 - val_accuracy: 0.9339\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2552 - accuracy: 0.9054 - val_loss: 0.2375 - val_accuracy: 0.9066\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9115 - val_loss: 0.2397 - val_accuracy: 0.9047\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.9125 - val_loss: 0.4916 - val_accuracy: 0.7129\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.9011 - val_loss: 0.1832 - val_accuracy: 0.9348\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2302 - accuracy: 0.9159 - val_loss: 0.1975 - val_accuracy: 0.9267\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.9115 - val_loss: 0.1877 - val_accuracy: 0.9327\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2317 - accuracy: 0.9171 - val_loss: 0.3127 - val_accuracy: 0.8732\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9211 - val_loss: 0.2588 - val_accuracy: 0.9028\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2118 - accuracy: 0.9227 - val_loss: 0.7392 - val_accuracy: 0.4696\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2198 - accuracy: 0.9230 - val_loss: 0.4134 - val_accuracy: 0.8138\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2270 - accuracy: 0.9174 - val_loss: 0.1753 - val_accuracy: 0.9405\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.9236 - val_loss: 0.2886 - val_accuracy: 0.9112\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2141 - accuracy: 0.9227 - val_loss: 0.1730 - val_accuracy: 0.9376\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2228 - accuracy: 0.9196 - val_loss: 0.2487 - val_accuracy: 0.9003\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2076 - accuracy: 0.9243 - val_loss: 0.1776 - val_accuracy: 0.9368\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9246 - val_loss: 0.1699 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2064 - accuracy: 0.9252 - val_loss: 0.1966 - val_accuracy: 0.9339\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2048 - accuracy: 0.9269 - val_loss: 0.4174 - val_accuracy: 0.8718\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9250 - val_loss: 0.3182 - val_accuracy: 0.8818\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.9230 - val_loss: 0.2017 - val_accuracy: 0.9243\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2026 - accuracy: 0.9277 - val_loss: 0.1996 - val_accuracy: 0.9297\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9265 - val_loss: 0.1617 - val_accuracy: 0.9457\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.9279 - val_loss: 0.1770 - val_accuracy: 0.9357\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9306 - val_loss: 0.1628 - val_accuracy: 0.9454\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9305 - val_loss: 0.1602 - val_accuracy: 0.9452\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9323 - val_loss: 0.1715 - val_accuracy: 0.9440\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9338 - val_loss: 0.1546 - val_accuracy: 0.9487\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9341 - val_loss: 0.1993 - val_accuracy: 0.9318\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9290 - val_loss: 0.1768 - val_accuracy: 0.9389\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1912 - accuracy: 0.9322 - val_loss: 0.1811 - val_accuracy: 0.9345\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.9352 - val_loss: 0.1713 - val_accuracy: 0.9394\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9321 - val_loss: 0.1793 - val_accuracy: 0.9369\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.9388 - val_loss: 0.5573 - val_accuracy: 0.8508\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9320 - val_loss: 0.1767 - val_accuracy: 0.9389\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1852 - accuracy: 0.9362 - val_loss: 0.1475 - val_accuracy: 0.9526\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9342 - val_loss: 0.1615 - val_accuracy: 0.9470\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1945 - accuracy: 0.9317 - val_loss: 0.1687 - val_accuracy: 0.9419\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.9363 - val_loss: 0.1455 - val_accuracy: 0.9523\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.9398 - val_loss: 0.1562 - val_accuracy: 0.9480\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.9376 - val_loss: 0.1436 - val_accuracy: 0.9533\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9387 - val_loss: 0.1509 - val_accuracy: 0.9510\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.9376 - val_loss: 0.1687 - val_accuracy: 0.9447\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9391 - val_loss: 0.1401 - val_accuracy: 0.9542\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.9386 - val_loss: 0.1474 - val_accuracy: 0.9509\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1709 - accuracy: 0.9410 - val_loss: 0.2826 - val_accuracy: 0.9019\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9425 - val_loss: 0.1682 - val_accuracy: 0.9514\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.9410 - val_loss: 0.1745 - val_accuracy: 0.9454\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9369 - val_loss: 0.1501 - val_accuracy: 0.9489\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.9375 - val_loss: 0.1373 - val_accuracy: 0.9577\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9454 - val_loss: 0.1950 - val_accuracy: 0.9294\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1717 - accuracy: 0.9424 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1670 - accuracy: 0.9433 - val_loss: 0.2103 - val_accuracy: 0.9466\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9402 - val_loss: 0.2242 - val_accuracy: 0.9260\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.9416 - val_loss: 0.1389 - val_accuracy: 0.9553\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9415 - val_loss: 0.1408 - val_accuracy: 0.9505\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1712 - accuracy: 0.9412 - val_loss: 0.1456 - val_accuracy: 0.9509\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1495 - accuracy: 0.9503 - val_loss: 0.1339 - val_accuracy: 0.9584\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1681 - accuracy: 0.9439 - val_loss: 0.1883 - val_accuracy: 0.9309\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1695 - accuracy: 0.9434 - val_loss: 0.1502 - val_accuracy: 0.9521\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1602 - accuracy: 0.9453 - val_loss: 0.1304 - val_accuracy: 0.9590\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1636 - accuracy: 0.9446 - val_loss: 0.1450 - val_accuracy: 0.9517\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1697 - accuracy: 0.9444 - val_loss: 0.7122 - val_accuracy: 0.5094\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1645 - accuracy: 0.9444 - val_loss: 0.1932 - val_accuracy: 0.9324\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9465 - val_loss: 0.2458 - val_accuracy: 0.9169\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9433 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1585 - accuracy: 0.9473 - val_loss: 0.1377 - val_accuracy: 0.9542\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1691 - accuracy: 0.9432 - val_loss: 0.1311 - val_accuracy: 0.9593\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1594 - accuracy: 0.9462 - val_loss: 0.1717 - val_accuracy: 0.9428\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1513 - accuracy: 0.9489 - val_loss: 0.1696 - val_accuracy: 0.9431\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1736 - accuracy: 0.9411 - val_loss: 0.2917 - val_accuracy: 0.8955\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8906\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6621 - accuracy: 0.6105 - val_loss: 0.6386 - val_accuracy: 0.6465\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4170 - accuracy: 0.8193 - val_loss: 0.2279 - val_accuracy: 0.9128\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3030 - accuracy: 0.8836 - val_loss: 0.2794 - val_accuracy: 0.9100\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3064 - accuracy: 0.8848 - val_loss: 0.2300 - val_accuracy: 0.9114\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9014 - val_loss: 0.2688 - val_accuracy: 0.8964\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.8983 - val_loss: 0.2200 - val_accuracy: 0.9213\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2653 - accuracy: 0.9000 - val_loss: 0.3272 - val_accuracy: 0.8610\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9016 - val_loss: 0.2291 - val_accuracy: 0.9285\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9104 - val_loss: 0.2002 - val_accuracy: 0.9299\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9061 - val_loss: 0.2880 - val_accuracy: 0.8802\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.9089 - val_loss: 0.2152 - val_accuracy: 0.9246\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9061 - val_loss: 0.1973 - val_accuracy: 0.9317\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.9095 - val_loss: 0.2243 - val_accuracy: 0.9133\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2384 - accuracy: 0.9105 - val_loss: 0.2078 - val_accuracy: 0.9278\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2358 - accuracy: 0.9128 - val_loss: 0.2052 - val_accuracy: 0.9223\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9141 - val_loss: 0.2742 - val_accuracy: 0.8998\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2350 - accuracy: 0.9143 - val_loss: 0.2203 - val_accuracy: 0.9142\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2265 - accuracy: 0.9165 - val_loss: 0.1827 - val_accuracy: 0.9387\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.9141 - val_loss: 0.3089 - val_accuracy: 0.8645\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.9216 - val_loss: 0.2320 - val_accuracy: 0.9214\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.9218 - val_loss: 0.2049 - val_accuracy: 0.9239\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.9217 - val_loss: 0.6014 - val_accuracy: 0.8358\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2225 - accuracy: 0.9178 - val_loss: 0.1720 - val_accuracy: 0.9408\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2207 - accuracy: 0.9211 - val_loss: 0.1771 - val_accuracy: 0.9412\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9236 - val_loss: 0.2249 - val_accuracy: 0.9089\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.9266 - val_loss: 0.1978 - val_accuracy: 0.9251\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9238 - val_loss: 0.2363 - val_accuracy: 0.9105\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9232 - val_loss: 0.1964 - val_accuracy: 0.9309\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9259 - val_loss: 0.1736 - val_accuracy: 0.9436\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2022 - accuracy: 0.9269 - val_loss: 0.2709 - val_accuracy: 0.8952\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9230 - val_loss: 0.2702 - val_accuracy: 0.9228\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1989 - accuracy: 0.9286 - val_loss: 0.1705 - val_accuracy: 0.9422\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2027 - accuracy: 0.9292 - val_loss: 0.1652 - val_accuracy: 0.9452\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9290 - val_loss: 0.1690 - val_accuracy: 0.9445\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9224 - val_loss: 0.3213 - val_accuracy: 0.8809\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9311 - val_loss: 0.1616 - val_accuracy: 0.9459\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9298 - val_loss: 0.1650 - val_accuracy: 0.9454\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9307 - val_loss: 0.1737 - val_accuracy: 0.9389\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9310 - val_loss: 0.1867 - val_accuracy: 0.9308\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9344 - val_loss: 0.1656 - val_accuracy: 0.9413\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.9314 - val_loss: 0.1591 - val_accuracy: 0.9449\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9326 - val_loss: 0.2269 - val_accuracy: 0.9084\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.9339 - val_loss: 0.1742 - val_accuracy: 0.9410\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9317 - val_loss: 0.2070 - val_accuracy: 0.9228\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9363 - val_loss: 0.2803 - val_accuracy: 0.9022\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.9379 - val_loss: 0.2348 - val_accuracy: 0.9095\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1945 - accuracy: 0.9306 - val_loss: 0.2094 - val_accuracy: 0.9258\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9341 - val_loss: 0.1776 - val_accuracy: 0.9383\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9357 - val_loss: 0.2320 - val_accuracy: 0.9132\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.9342 - val_loss: 0.2091 - val_accuracy: 0.9177\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.9364 - val_loss: 0.2103 - val_accuracy: 0.9251\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9206\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5804 - accuracy: 0.7112 - val_loss: 0.6838 - val_accuracy: 0.6491\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6886 - val_loss: 0.5969 - val_accuracy: 0.6436\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.8080 - val_loss: 0.3290 - val_accuracy: 0.8864\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8863 - val_loss: 0.2221 - val_accuracy: 0.9179\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.8997 - val_loss: 0.3160 - val_accuracy: 0.8712\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.8952 - val_loss: 0.4119 - val_accuracy: 0.8473\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.9027 - val_loss: 0.4433 - val_accuracy: 0.8476\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.9070 - val_loss: 0.2716 - val_accuracy: 0.9007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9106 - val_loss: 0.2235 - val_accuracy: 0.9135\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.9118 - val_loss: 0.2025 - val_accuracy: 0.9290\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.9105 - val_loss: 0.1966 - val_accuracy: 0.9339\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2404 - accuracy: 0.9154 - val_loss: 0.2094 - val_accuracy: 0.9243\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.9126 - val_loss: 0.2375 - val_accuracy: 0.9089\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9100 - val_loss: 0.2175 - val_accuracy: 0.9186\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.9088 - val_loss: 0.2443 - val_accuracy: 0.9112\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2238 - accuracy: 0.9184 - val_loss: 0.4007 - val_accuracy: 0.8686\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2321 - accuracy: 0.9144 - val_loss: 0.2846 - val_accuracy: 0.9073\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.9115 - val_loss: 0.2094 - val_accuracy: 0.9237\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2328 - accuracy: 0.9166 - val_loss: 0.1877 - val_accuracy: 0.9378\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2291 - accuracy: 0.9166 - val_loss: 0.2178 - val_accuracy: 0.9158\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2249 - accuracy: 0.9196 - val_loss: 0.2083 - val_accuracy: 0.9230\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2225 - accuracy: 0.9192 - val_loss: 0.9636 - val_accuracy: 0.3997\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9042 - val_loss: 0.2211 - val_accuracy: 0.9230\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.9214 - val_loss: 0.2782 - val_accuracy: 0.8933\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2171 - accuracy: 0.9201 - val_loss: 0.2126 - val_accuracy: 0.9223\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2156 - accuracy: 0.9219 - val_loss: 0.2217 - val_accuracy: 0.9239\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9260 - val_loss: 0.1805 - val_accuracy: 0.9394\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9270 - val_loss: 0.1696 - val_accuracy: 0.9420\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.9278 - val_loss: 0.3083 - val_accuracy: 0.8973\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2143 - accuracy: 0.9228 - val_loss: 0.2044 - val_accuracy: 0.9239\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9246 - val_loss: 0.1832 - val_accuracy: 0.9336\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9268 - val_loss: 0.1980 - val_accuracy: 0.9369\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9279 - val_loss: 0.1631 - val_accuracy: 0.9435\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9312 - val_loss: 0.1605 - val_accuracy: 0.9461\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9285 - val_loss: 0.1914 - val_accuracy: 0.9280\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.9326 - val_loss: 0.3869 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2025 - accuracy: 0.9255 - val_loss: 0.1906 - val_accuracy: 0.9258\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.9340 - val_loss: 0.1600 - val_accuracy: 0.9440\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9352 - val_loss: 0.2175 - val_accuracy: 0.9181\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1928 - accuracy: 0.9311 - val_loss: 0.3344 - val_accuracy: 0.8802\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9332 - val_loss: 0.1488 - val_accuracy: 0.9482\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.9360 - val_loss: 0.1998 - val_accuracy: 0.9299\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.9366 - val_loss: 0.2388 - val_accuracy: 0.8962\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.9385 - val_loss: 0.1437 - val_accuracy: 0.9561\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1628 - accuracy: 0.9428 - val_loss: 0.1380 - val_accuracy: 0.9523\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.9380 - val_loss: 0.1375 - val_accuracy: 0.9609\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1915 - accuracy: 0.9344 - val_loss: 0.1676 - val_accuracy: 0.9375\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.9388 - val_loss: 0.1755 - val_accuracy: 0.9346\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.9410 - val_loss: 0.3600 - val_accuracy: 0.8790\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.9392 - val_loss: 0.1531 - val_accuracy: 0.9473\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.9415 - val_loss: 0.1339 - val_accuracy: 0.9577\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1618 - accuracy: 0.9460 - val_loss: 0.2296 - val_accuracy: 0.9230\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.9415 - val_loss: 0.1707 - val_accuracy: 0.9417\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1667 - accuracy: 0.9428 - val_loss: 0.1300 - val_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1599 - accuracy: 0.9450 - val_loss: 0.1450 - val_accuracy: 0.9533\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9392 - val_loss: 0.2399 - val_accuracy: 0.9035\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.9378 - val_loss: 0.1799 - val_accuracy: 0.9503\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9445 - val_loss: 0.2760 - val_accuracy: 0.9070\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1668 - accuracy: 0.9440 - val_loss: 0.1393 - val_accuracy: 0.9618\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.9405 - val_loss: 0.1354 - val_accuracy: 0.9575\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1591 - accuracy: 0.9478 - val_loss: 0.1367 - val_accuracy: 0.9547\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1628 - accuracy: 0.9463 - val_loss: 0.1470 - val_accuracy: 0.9494\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.9441 - val_loss: 0.1396 - val_accuracy: 0.9618\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9450 - val_loss: 0.2426 - val_accuracy: 0.9265\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.9188\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6903 - val_loss: 0.4356 - val_accuracy: 0.7835\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8684 - val_loss: 0.3166 - val_accuracy: 0.9251\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.8939 - val_loss: 0.2508 - val_accuracy: 0.8896\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9044 - val_loss: 0.2907 - val_accuracy: 0.8737\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.9070 - val_loss: 0.2627 - val_accuracy: 0.8869\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2333 - accuracy: 0.9101 - val_loss: 0.2153 - val_accuracy: 0.9139\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2304 - accuracy: 0.9129 - val_loss: 0.6316 - val_accuracy: 0.6701\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2318 - accuracy: 0.9131 - val_loss: 0.1970 - val_accuracy: 0.9317\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9175 - val_loss: 0.3991 - val_accuracy: 0.8459\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9104 - val_loss: 0.2295 - val_accuracy: 0.9260\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9188 - val_loss: 0.2173 - val_accuracy: 0.9144\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2130 - accuracy: 0.9198 - val_loss: 0.4391 - val_accuracy: 0.8159\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9197 - val_loss: 0.1876 - val_accuracy: 0.9299\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2114 - accuracy: 0.9209 - val_loss: 0.2102 - val_accuracy: 0.9281\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2038 - accuracy: 0.9240 - val_loss: 0.2305 - val_accuracy: 0.9036\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9238 - val_loss: 0.1829 - val_accuracy: 0.9392\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9219 - val_loss: 0.1764 - val_accuracy: 0.9392\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9283 - val_loss: 0.1992 - val_accuracy: 0.9304\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1934 - accuracy: 0.9268 - val_loss: 0.1667 - val_accuracy: 0.9401\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9259 - val_loss: 0.1603 - val_accuracy: 0.9422\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1923 - accuracy: 0.9282 - val_loss: 0.1920 - val_accuracy: 0.9295\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.9311 - val_loss: 0.1584 - val_accuracy: 0.9415\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.9287 - val_loss: 0.1603 - val_accuracy: 0.9440\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.9329 - val_loss: 0.1740 - val_accuracy: 0.9355\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9302 - val_loss: 0.2413 - val_accuracy: 0.9029\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.9354 - val_loss: 0.1945 - val_accuracy: 0.9264\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.9341 - val_loss: 0.1451 - val_accuracy: 0.9486\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9418 - val_loss: 0.1301 - val_accuracy: 0.9553\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1647 - accuracy: 0.9405 - val_loss: 0.1560 - val_accuracy: 0.9443\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.9393 - val_loss: 0.1472 - val_accuracy: 0.9486\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9420 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1593 - accuracy: 0.9442 - val_loss: 0.1444 - val_accuracy: 0.9472\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1431 - accuracy: 0.9493 - val_loss: 0.1224 - val_accuracy: 0.9597\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1529 - accuracy: 0.9443 - val_loss: 0.1293 - val_accuracy: 0.9540\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9466 - val_loss: 0.1462 - val_accuracy: 0.9482\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9492 - val_loss: 0.1161 - val_accuracy: 0.9627\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1459 - accuracy: 0.9488 - val_loss: 0.5809 - val_accuracy: 0.7506\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1524 - accuracy: 0.9470 - val_loss: 0.1455 - val_accuracy: 0.9501\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1660 - accuracy: 0.9414 - val_loss: 0.1235 - val_accuracy: 0.9591\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1465 - accuracy: 0.9494 - val_loss: 0.1684 - val_accuracy: 0.9346\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1412 - accuracy: 0.9495 - val_loss: 0.1684 - val_accuracy: 0.9394\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9500 - val_loss: 0.1549 - val_accuracy: 0.9472\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1473 - accuracy: 0.9488 - val_loss: 0.1150 - val_accuracy: 0.9639\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1580 - accuracy: 0.9439 - val_loss: 0.2789 - val_accuracy: 0.8832\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.9517 - val_loss: 0.1364 - val_accuracy: 0.9549\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9491 - val_loss: 0.1808 - val_accuracy: 0.9361\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1423 - accuracy: 0.9512 - val_loss: 0.1661 - val_accuracy: 0.9369\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1386 - accuracy: 0.9511 - val_loss: 0.1098 - val_accuracy: 0.9653\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1466 - accuracy: 0.9487 - val_loss: 0.3799 - val_accuracy: 0.8816\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9505 - val_loss: 0.1919 - val_accuracy: 0.9336\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1379 - accuracy: 0.9523 - val_loss: 0.2974 - val_accuracy: 0.9040\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9514 - val_loss: 0.1115 - val_accuracy: 0.9634\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1388 - accuracy: 0.9514 - val_loss: 0.1967 - val_accuracy: 0.9315\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1375 - accuracy: 0.9529 - val_loss: 0.1423 - val_accuracy: 0.9507\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1361 - accuracy: 0.9545 - val_loss: 0.2282 - val_accuracy: 0.9088\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1462 - accuracy: 0.9491 - val_loss: 0.1127 - val_accuracy: 0.9646\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9495 - val_loss: 0.1642 - val_accuracy: 0.9435\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9536 - val_loss: 0.1135 - val_accuracy: 0.9657\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9648\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.6924 - val_loss: 0.4146 - val_accuracy: 0.8714\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8750 - val_loss: 0.2673 - val_accuracy: 0.8881\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.8954 - val_loss: 0.2483 - val_accuracy: 0.9232\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.9060 - val_loss: 0.2519 - val_accuracy: 0.9255\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2324 - accuracy: 0.9127 - val_loss: 0.2173 - val_accuracy: 0.9274\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2300 - accuracy: 0.9128 - val_loss: 0.2270 - val_accuracy: 0.9079\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2325 - accuracy: 0.9124 - val_loss: 0.3434 - val_accuracy: 0.8660\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9159 - val_loss: 0.1990 - val_accuracy: 0.9295\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9198 - val_loss: 0.2158 - val_accuracy: 0.9144\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2214 - accuracy: 0.9175 - val_loss: 0.2020 - val_accuracy: 0.9214\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2074 - accuracy: 0.9254 - val_loss: 0.1886 - val_accuracy: 0.9315\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9227 - val_loss: 0.1893 - val_accuracy: 0.9304\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2033 - accuracy: 0.9249 - val_loss: 0.2678 - val_accuracy: 0.8982\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2040 - accuracy: 0.9253 - val_loss: 0.1819 - val_accuracy: 0.9339\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2004 - accuracy: 0.9253 - val_loss: 0.1913 - val_accuracy: 0.9355\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9259 - val_loss: 0.1843 - val_accuracy: 0.9362\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9275 - val_loss: 0.2220 - val_accuracy: 0.9223\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2080 - accuracy: 0.9239 - val_loss: 0.2028 - val_accuracy: 0.9288\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9285 - val_loss: 0.2068 - val_accuracy: 0.9225\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9266 - val_loss: 0.1721 - val_accuracy: 0.9373\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9297 - val_loss: 0.2285 - val_accuracy: 0.9197\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9302 - val_loss: 0.1664 - val_accuracy: 0.9401\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9303 - val_loss: 0.1981 - val_accuracy: 0.9376\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.9309 - val_loss: 0.1825 - val_accuracy: 0.9350\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9328 - val_loss: 0.2085 - val_accuracy: 0.9251\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9358 - val_loss: 0.2051 - val_accuracy: 0.9199\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9352 - val_loss: 0.1816 - val_accuracy: 0.9324\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9383 - val_loss: 0.1482 - val_accuracy: 0.9491\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9337 - val_loss: 0.1543 - val_accuracy: 0.9436\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9363 - val_loss: 0.2052 - val_accuracy: 0.9221\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9394 - val_loss: 0.1468 - val_accuracy: 0.9517\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1665 - accuracy: 0.9418 - val_loss: 0.1451 - val_accuracy: 0.9542\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9403 - val_loss: 0.1492 - val_accuracy: 0.9463\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1546 - accuracy: 0.9454 - val_loss: 0.2205 - val_accuracy: 0.9234\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1670 - accuracy: 0.9395 - val_loss: 0.1393 - val_accuracy: 0.9533\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1533 - accuracy: 0.9470 - val_loss: 0.1512 - val_accuracy: 0.9470\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1630 - accuracy: 0.9405 - val_loss: 0.1616 - val_accuracy: 0.9456\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1502 - accuracy: 0.9468 - val_loss: 0.1535 - val_accuracy: 0.9496\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1489 - accuracy: 0.9480 - val_loss: 0.1289 - val_accuracy: 0.9547\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1564 - accuracy: 0.9448 - val_loss: 0.1463 - val_accuracy: 0.9484\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9499 - val_loss: 0.1443 - val_accuracy: 0.9494\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9442 - val_loss: 0.1280 - val_accuracy: 0.9551\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9479 - val_loss: 0.1507 - val_accuracy: 0.9480\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9468 - val_loss: 0.1219 - val_accuracy: 0.9591\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9510 - val_loss: 0.1196 - val_accuracy: 0.9612\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9508 - val_loss: 0.1841 - val_accuracy: 0.9341\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1444 - accuracy: 0.9513 - val_loss: 0.1208 - val_accuracy: 0.9616\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1523 - accuracy: 0.9463 - val_loss: 0.2125 - val_accuracy: 0.9341\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9474 - val_loss: 0.1557 - val_accuracy: 0.9433\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1546 - accuracy: 0.9469 - val_loss: 0.1831 - val_accuracy: 0.9338\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1556 - accuracy: 0.9462 - val_loss: 0.1753 - val_accuracy: 0.9424\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.9490 - val_loss: 0.1311 - val_accuracy: 0.9560\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1405 - accuracy: 0.9512 - val_loss: 0.1183 - val_accuracy: 0.9616\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9519 - val_loss: 0.1363 - val_accuracy: 0.9538\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1391 - accuracy: 0.9515 - val_loss: 0.1599 - val_accuracy: 0.9461\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9509 - val_loss: 0.1127 - val_accuracy: 0.9637\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1429 - accuracy: 0.9519 - val_loss: 0.1909 - val_accuracy: 0.9218\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.9518 - val_loss: 0.1367 - val_accuracy: 0.9537\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1319 - accuracy: 0.9552 - val_loss: 0.1287 - val_accuracy: 0.9563\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1376 - accuracy: 0.9527 - val_loss: 0.1132 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1391 - accuracy: 0.9518 - val_loss: 0.1318 - val_accuracy: 0.9637\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1316 - accuracy: 0.9552 - val_loss: 0.1173 - val_accuracy: 0.9628\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9553 - val_loss: 0.1160 - val_accuracy: 0.9632\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9512 - val_loss: 0.3334 - val_accuracy: 0.8684\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1370 - accuracy: 0.9528 - val_loss: 0.1319 - val_accuracy: 0.9570\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1345 - accuracy: 0.9545 - val_loss: 0.2119 - val_accuracy: 0.9246\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9210\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.6606 - val_loss: 0.4920 - val_accuracy: 0.8140\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3855 - accuracy: 0.8511 - val_loss: 0.3038 - val_accuracy: 0.8596\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.8923 - val_loss: 0.3401 - val_accuracy: 0.9054\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.9023 - val_loss: 0.2388 - val_accuracy: 0.8999\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.9084 - val_loss: 0.2222 - val_accuracy: 0.9260\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.9099 - val_loss: 0.2248 - val_accuracy: 0.9265\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2321 - accuracy: 0.9128 - val_loss: 0.2097 - val_accuracy: 0.9280\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2317 - accuracy: 0.9135 - val_loss: 0.7143 - val_accuracy: 0.5799\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.9058 - val_loss: 0.2253 - val_accuracy: 0.9269\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2206 - accuracy: 0.9180 - val_loss: 0.2148 - val_accuracy: 0.9283\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2172 - accuracy: 0.9191 - val_loss: 0.2070 - val_accuracy: 0.9177\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2217 - accuracy: 0.9183 - val_loss: 0.1945 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.9210 - val_loss: 0.1983 - val_accuracy: 0.9239\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.9200 - val_loss: 0.2022 - val_accuracy: 0.9311\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2115 - accuracy: 0.9227 - val_loss: 0.2227 - val_accuracy: 0.9158\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2167 - accuracy: 0.9211 - val_loss: 0.1833 - val_accuracy: 0.9338\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2169 - accuracy: 0.9206 - val_loss: 0.1838 - val_accuracy: 0.9331\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9235 - val_loss: 0.1855 - val_accuracy: 0.9313\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9234 - val_loss: 0.1807 - val_accuracy: 0.9336\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2044 - accuracy: 0.9259 - val_loss: 0.7799 - val_accuracy: 0.4696\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2133 - accuracy: 0.9192 - val_loss: 0.1873 - val_accuracy: 0.9292\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9256 - val_loss: 0.1722 - val_accuracy: 0.9380\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9291 - val_loss: 0.1741 - val_accuracy: 0.9369\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1993 - accuracy: 0.9265 - val_loss: 0.2982 - val_accuracy: 0.8908\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1927 - accuracy: 0.9298 - val_loss: 0.1889 - val_accuracy: 0.9318\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9273 - val_loss: 0.2329 - val_accuracy: 0.9112\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9290 - val_loss: 0.1767 - val_accuracy: 0.9376\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9291 - val_loss: 0.1777 - val_accuracy: 0.9357\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9261 - val_loss: 0.1555 - val_accuracy: 0.9461\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.9334 - val_loss: 0.3359 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.9332 - val_loss: 0.2358 - val_accuracy: 0.9119\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1727 - accuracy: 0.9371 - val_loss: 0.1487 - val_accuracy: 0.9470\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1687 - accuracy: 0.9385 - val_loss: 0.1429 - val_accuracy: 0.9477\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.9349 - val_loss: 0.1904 - val_accuracy: 0.9334\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1662 - accuracy: 0.9404 - val_loss: 0.1360 - val_accuracy: 0.9560\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9411 - val_loss: 0.1307 - val_accuracy: 0.9565\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1625 - accuracy: 0.9407 - val_loss: 0.1476 - val_accuracy: 0.9503\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9445 - val_loss: 0.2330 - val_accuracy: 0.9153\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9433 - val_loss: 0.2453 - val_accuracy: 0.9081\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9469 - val_loss: 0.1998 - val_accuracy: 0.9184\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1606 - accuracy: 0.9419 - val_loss: 0.1216 - val_accuracy: 0.9611\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9477 - val_loss: 0.2789 - val_accuracy: 0.9040\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1569 - accuracy: 0.9448 - val_loss: 0.1747 - val_accuracy: 0.9373\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1596 - accuracy: 0.9445 - val_loss: 0.1204 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9515 - val_loss: 0.1272 - val_accuracy: 0.9561\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9484 - val_loss: 0.4208 - val_accuracy: 0.8765\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1515 - accuracy: 0.9466 - val_loss: 0.1314 - val_accuracy: 0.9546\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1472 - accuracy: 0.9490 - val_loss: 0.1633 - val_accuracy: 0.9410\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1538 - accuracy: 0.9467 - val_loss: 0.2403 - val_accuracy: 0.9121\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9429 - val_loss: 0.1667 - val_accuracy: 0.9383\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9497 - val_loss: 0.1242 - val_accuracy: 0.9634\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9488 - val_loss: 0.7029 - val_accuracy: 0.6044\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1477 - accuracy: 0.9498 - val_loss: 0.6583 - val_accuracy: 0.6775\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1435 - accuracy: 0.9523 - val_loss: 0.2020 - val_accuracy: 0.9228\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9256\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5886 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6775 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6736 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5949\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5937 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6760 - accuracy: 0.5946 - val_loss: 0.6725 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6745 - accuracy: 0.5946 - val_loss: 0.6702 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6744 - accuracy: 0.5946 - val_loss: 0.6716 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6759 - accuracy: 0.5946 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6737 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5884\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5888 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5916 - val_loss: 0.6742 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6763 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6763 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5942\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6806 - accuracy: 0.5899 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6771 - accuracy: 0.5913 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6735 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5949\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5935 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6756 - accuracy: 0.5946 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6757 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6755 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5884\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.5897 - val_loss: 0.6737 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5916 - val_loss: 0.6739 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5916 - val_loss: 0.6739 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5942\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.5597 - val_loss: 0.6758 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6771 - accuracy: 0.5914 - val_loss: 0.6706 - val_accuracy: 0.6005\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6714 - accuracy: 0.5914 - val_loss: 0.6647 - val_accuracy: 0.6005\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6658 - accuracy: 0.5916 - val_loss: 0.6598 - val_accuracy: 0.6023\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6603 - accuracy: 0.5934 - val_loss: 0.6541 - val_accuracy: 0.6049\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.5975 - val_loss: 0.6485 - val_accuracy: 0.6072\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6497 - accuracy: 0.6032 - val_loss: 0.6435 - val_accuracy: 0.6130\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6104 - val_loss: 0.6385 - val_accuracy: 0.6158\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6393 - accuracy: 0.6170 - val_loss: 0.6347 - val_accuracy: 0.6408\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6346 - accuracy: 0.6263 - val_loss: 0.6289 - val_accuracy: 0.6283\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6297 - accuracy: 0.6322 - val_loss: 0.6245 - val_accuracy: 0.6468\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.6411 - val_loss: 0.6203 - val_accuracy: 0.6584\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6204 - accuracy: 0.6483 - val_loss: 0.6162 - val_accuracy: 0.6715\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6157 - accuracy: 0.6573 - val_loss: 0.6107 - val_accuracy: 0.6539\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6114 - accuracy: 0.6622 - val_loss: 0.6064 - val_accuracy: 0.6614\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6069 - accuracy: 0.6691 - val_loss: 0.6024 - val_accuracy: 0.6748\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6028 - accuracy: 0.6745 - val_loss: 0.5988 - val_accuracy: 0.6937\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5988 - accuracy: 0.6826 - val_loss: 0.5944 - val_accuracy: 0.6699\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5948 - accuracy: 0.6867 - val_loss: 0.5913 - val_accuracy: 0.6662\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6894 - val_loss: 0.5868 - val_accuracy: 0.6995\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6972 - val_loss: 0.5829 - val_accuracy: 0.6914\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5834 - accuracy: 0.7012 - val_loss: 0.5794 - val_accuracy: 0.7046\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5797 - accuracy: 0.7064 - val_loss: 0.5759 - val_accuracy: 0.7094\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5759 - accuracy: 0.7117 - val_loss: 0.5726 - val_accuracy: 0.6970\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7142 - val_loss: 0.5691 - val_accuracy: 0.7192\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.7162 - val_loss: 0.5664 - val_accuracy: 0.7338\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5659 - accuracy: 0.7208 - val_loss: 0.5627 - val_accuracy: 0.7284\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7244 - val_loss: 0.5595 - val_accuracy: 0.7291\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5594 - accuracy: 0.7291 - val_loss: 0.5565 - val_accuracy: 0.7331\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.7293 - val_loss: 0.5540 - val_accuracy: 0.7423\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5534 - accuracy: 0.7336 - val_loss: 0.5513 - val_accuracy: 0.7486\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7372 - val_loss: 0.5479 - val_accuracy: 0.7305\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.7390 - val_loss: 0.5451 - val_accuracy: 0.7323\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7408 - val_loss: 0.5425 - val_accuracy: 0.7463\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7461 - val_loss: 0.5404 - val_accuracy: 0.7564\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7490 - val_loss: 0.5380 - val_accuracy: 0.7631\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7496 - val_loss: 0.5346 - val_accuracy: 0.7532\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7522 - val_loss: 0.5336 - val_accuracy: 0.7751\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7538 - val_loss: 0.5300 - val_accuracy: 0.7641\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7575 - val_loss: 0.5276 - val_accuracy: 0.7655\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7585 - val_loss: 0.5247 - val_accuracy: 0.7534\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7603 - val_loss: 0.5226 - val_accuracy: 0.7648\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5217 - accuracy: 0.7636 - val_loss: 0.5202 - val_accuracy: 0.7645\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5194 - accuracy: 0.7663 - val_loss: 0.5179 - val_accuracy: 0.7509\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7653 - val_loss: 0.5155 - val_accuracy: 0.7566\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7687 - val_loss: 0.5135 - val_accuracy: 0.7707\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5126 - accuracy: 0.7711 - val_loss: 0.5113 - val_accuracy: 0.7722\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5103 - accuracy: 0.7727 - val_loss: 0.5091 - val_accuracy: 0.7699\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7739 - val_loss: 0.5082 - val_accuracy: 0.7897\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5061 - accuracy: 0.7770 - val_loss: 0.5049 - val_accuracy: 0.7715\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7757 - val_loss: 0.5048 - val_accuracy: 0.7999\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7808 - val_loss: 0.5014 - val_accuracy: 0.7855\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7881\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4981 - accuracy: 0.7822 - val_loss: 0.4975 - val_accuracy: 0.7645\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4962 - accuracy: 0.7840 - val_loss: 0.4957 - val_accuracy: 0.7863\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7846 - val_loss: 0.4937 - val_accuracy: 0.7705\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4925 - accuracy: 0.7841 - val_loss: 0.4925 - val_accuracy: 0.7946\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7863 - val_loss: 0.4902 - val_accuracy: 0.7881\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.7895 - val_loss: 0.4884 - val_accuracy: 0.7759\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7872 - val_loss: 0.4871 - val_accuracy: 0.7964\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7904 - val_loss: 0.4864 - val_accuracy: 0.8094\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7938 - val_loss: 0.4835 - val_accuracy: 0.7932\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4820 - accuracy: 0.7941 - val_loss: 0.4816 - val_accuracy: 0.7823\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4805 - accuracy: 0.7932 - val_loss: 0.4800 - val_accuracy: 0.7890\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7950 - val_loss: 0.4793 - val_accuracy: 0.8078\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4769 - accuracy: 0.7962 - val_loss: 0.4769 - val_accuracy: 0.7818\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7969 - val_loss: 0.4753 - val_accuracy: 0.7948\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4738 - accuracy: 0.7985 - val_loss: 0.4737 - val_accuracy: 0.7976\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4723 - accuracy: 0.7999 - val_loss: 0.4722 - val_accuracy: 0.7855\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.7992 - val_loss: 0.4708 - val_accuracy: 0.8025\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4692 - accuracy: 0.8010 - val_loss: 0.4693 - val_accuracy: 0.8032\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.8030 - val_loss: 0.4683 - val_accuracy: 0.8120\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.8037 - val_loss: 0.4669 - val_accuracy: 0.8119\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.8044 - val_loss: 0.4649 - val_accuracy: 0.7955\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4634 - accuracy: 0.8034 - val_loss: 0.4636 - val_accuracy: 0.8048\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8048 - val_loss: 0.4627 - val_accuracy: 0.8143\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.8073 - val_loss: 0.4612 - val_accuracy: 0.8117\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.8071 - val_loss: 0.4598 - val_accuracy: 0.8122\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8091 - val_loss: 0.4585 - val_accuracy: 0.7932\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.8088 - val_loss: 0.4569 - val_accuracy: 0.8015\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4552 - accuracy: 0.8084 - val_loss: 0.4559 - val_accuracy: 0.8145\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4539 - accuracy: 0.8101 - val_loss: 0.4543 - val_accuracy: 0.8057\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8120 - val_loss: 0.4531 - val_accuracy: 0.8091\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4513 - accuracy: 0.8118 - val_loss: 0.4526 - val_accuracy: 0.8249\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8130 - val_loss: 0.4507 - val_accuracy: 0.8091\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.8134 - val_loss: 0.4496 - val_accuracy: 0.8136\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8143 - val_loss: 0.4483 - val_accuracy: 0.8129\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4464 - accuracy: 0.8145 - val_loss: 0.4472 - val_accuracy: 0.8142\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4453 - accuracy: 0.8143 - val_loss: 0.4460 - val_accuracy: 0.8126\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4440 - accuracy: 0.8156 - val_loss: 0.4449 - val_accuracy: 0.8122\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4429 - accuracy: 0.8168 - val_loss: 0.4438 - val_accuracy: 0.8180\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4418 - accuracy: 0.8179 - val_loss: 0.4428 - val_accuracy: 0.8230\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4405 - accuracy: 0.8195 - val_loss: 0.4415 - val_accuracy: 0.8165\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4394 - accuracy: 0.8194 - val_loss: 0.4404 - val_accuracy: 0.8126\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.8197 - val_loss: 0.4393 - val_accuracy: 0.8142\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4372 - accuracy: 0.8199 - val_loss: 0.4386 - val_accuracy: 0.8288\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8215 - val_loss: 0.4372 - val_accuracy: 0.8145\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8202 - val_loss: 0.4361 - val_accuracy: 0.8226\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4338 - accuracy: 0.8210 - val_loss: 0.4355 - val_accuracy: 0.8323\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8221 - val_loss: 0.4340 - val_accuracy: 0.8198\n",
      "277/277 [==============================] - 0s 905us/step - loss: 0.4315 - accuracy: 0.8254\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6826 - accuracy: 0.5811 - val_loss: 0.6740 - val_accuracy: 0.6008\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6739 - accuracy: 0.5946 - val_loss: 0.6683 - val_accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6679 - accuracy: 0.5947 - val_loss: 0.6625 - val_accuracy: 0.6008\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6624 - accuracy: 0.5951 - val_loss: 0.6571 - val_accuracy: 0.6047\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6565 - accuracy: 0.5980 - val_loss: 0.6512 - val_accuracy: 0.6054\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6510 - accuracy: 0.6020 - val_loss: 0.6458 - val_accuracy: 0.6095\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6454 - accuracy: 0.6088 - val_loss: 0.6421 - val_accuracy: 0.6324\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6403 - accuracy: 0.6166 - val_loss: 0.6354 - val_accuracy: 0.6264\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6349 - accuracy: 0.6247 - val_loss: 0.6311 - val_accuracy: 0.6392\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6301 - accuracy: 0.6299 - val_loss: 0.6265 - val_accuracy: 0.6503\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.6399 - val_loss: 0.6210 - val_accuracy: 0.6373\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6205 - accuracy: 0.6461 - val_loss: 0.6164 - val_accuracy: 0.6525\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6160 - accuracy: 0.6535 - val_loss: 0.6125 - val_accuracy: 0.6699\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6114 - accuracy: 0.6611 - val_loss: 0.6076 - val_accuracy: 0.6586\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6069 - accuracy: 0.6672 - val_loss: 0.6034 - val_accuracy: 0.6641\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6027 - accuracy: 0.6726 - val_loss: 0.5994 - val_accuracy: 0.6799\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5983 - accuracy: 0.6788 - val_loss: 0.5959 - val_accuracy: 0.6963\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6856 - val_loss: 0.5916 - val_accuracy: 0.6946\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5902 - accuracy: 0.6907 - val_loss: 0.5885 - val_accuracy: 0.7111\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5865 - accuracy: 0.6993 - val_loss: 0.5841 - val_accuracy: 0.6833\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5826 - accuracy: 0.7003 - val_loss: 0.5803 - val_accuracy: 0.6910\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5789 - accuracy: 0.7034 - val_loss: 0.5767 - val_accuracy: 0.7062\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5755 - accuracy: 0.7092 - val_loss: 0.5732 - val_accuracy: 0.7078\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7110 - val_loss: 0.5702 - val_accuracy: 0.7227\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7156 - val_loss: 0.5677 - val_accuracy: 0.7381\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7206 - val_loss: 0.5633 - val_accuracy: 0.7256\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5615 - accuracy: 0.7249 - val_loss: 0.5601 - val_accuracy: 0.7108\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.7275 - val_loss: 0.5568 - val_accuracy: 0.7305\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5548 - accuracy: 0.7312 - val_loss: 0.5539 - val_accuracy: 0.7171\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7322 - val_loss: 0.5512 - val_accuracy: 0.7402\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7378 - val_loss: 0.5484 - val_accuracy: 0.7456\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7426 - val_loss: 0.5450 - val_accuracy: 0.7358\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7433 - val_loss: 0.5424 - val_accuracy: 0.7305\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7449 - val_loss: 0.5395 - val_accuracy: 0.7386\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7493 - val_loss: 0.5369 - val_accuracy: 0.7416\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7490 - val_loss: 0.5344 - val_accuracy: 0.7395\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7516 - val_loss: 0.5326 - val_accuracy: 0.7645\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5293 - accuracy: 0.7578 - val_loss: 0.5301 - val_accuracy: 0.7340\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5270 - accuracy: 0.7562 - val_loss: 0.5274 - val_accuracy: 0.7648\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7609 - val_loss: 0.5248 - val_accuracy: 0.7416\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5218 - accuracy: 0.7600 - val_loss: 0.5224 - val_accuracy: 0.7652\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5192 - accuracy: 0.7627 - val_loss: 0.5198 - val_accuracy: 0.7571\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5169 - accuracy: 0.7658 - val_loss: 0.5175 - val_accuracy: 0.7650\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7691 - val_loss: 0.5161 - val_accuracy: 0.7414\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5123 - accuracy: 0.7675 - val_loss: 0.5130 - val_accuracy: 0.7675\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5098 - accuracy: 0.7718 - val_loss: 0.5110 - val_accuracy: 0.7721\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5076 - accuracy: 0.7744 - val_loss: 0.5086 - val_accuracy: 0.7685\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5052 - accuracy: 0.7756 - val_loss: 0.5072 - val_accuracy: 0.7842\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5010 - accuracy: 0.7793 - val_loss: 0.5025 - val_accuracy: 0.7648\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4990 - accuracy: 0.7804 - val_loss: 0.5005 - val_accuracy: 0.7652\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4969 - accuracy: 0.7811 - val_loss: 0.4988 - val_accuracy: 0.7846\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4948 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7687\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4928 - accuracy: 0.7846 - val_loss: 0.4946 - val_accuracy: 0.7770\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4907 - accuracy: 0.7864 - val_loss: 0.4927 - val_accuracy: 0.7749\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4889 - accuracy: 0.7891 - val_loss: 0.4913 - val_accuracy: 0.7670\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7875 - val_loss: 0.4891 - val_accuracy: 0.7800\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4852 - accuracy: 0.7909 - val_loss: 0.4873 - val_accuracy: 0.7839\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4834 - accuracy: 0.7925 - val_loss: 0.4858 - val_accuracy: 0.7909\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4815 - accuracy: 0.7942 - val_loss: 0.4839 - val_accuracy: 0.7789\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4798 - accuracy: 0.7940 - val_loss: 0.4839 - val_accuracy: 0.8113\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4782 - accuracy: 0.7976 - val_loss: 0.4806 - val_accuracy: 0.7913\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7971 - val_loss: 0.4789 - val_accuracy: 0.7876\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4747 - accuracy: 0.7983 - val_loss: 0.4778 - val_accuracy: 0.8034\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4729 - accuracy: 0.8005 - val_loss: 0.4757 - val_accuracy: 0.7862\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4715 - accuracy: 0.8017 - val_loss: 0.4743 - val_accuracy: 0.7839\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.8008 - val_loss: 0.4728 - val_accuracy: 0.7830\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8017 - val_loss: 0.4723 - val_accuracy: 0.8142\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4666 - accuracy: 0.8045 - val_loss: 0.4695 - val_accuracy: 0.7913\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.8057 - val_loss: 0.4681 - val_accuracy: 0.7899\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4635 - accuracy: 0.8059 - val_loss: 0.4666 - val_accuracy: 0.7930\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4617 - accuracy: 0.8082 - val_loss: 0.4655 - val_accuracy: 0.7865\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.8073 - val_loss: 0.4639 - val_accuracy: 0.8076\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4588 - accuracy: 0.8101 - val_loss: 0.4624 - val_accuracy: 0.7916\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4575 - accuracy: 0.8107 - val_loss: 0.4611 - val_accuracy: 0.7911\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4560 - accuracy: 0.8110 - val_loss: 0.4595 - val_accuracy: 0.8069\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4544 - accuracy: 0.8120 - val_loss: 0.4582 - val_accuracy: 0.7946\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8103 - val_loss: 0.4570 - val_accuracy: 0.8128\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.8137 - val_loss: 0.4555 - val_accuracy: 0.8099\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8145 - val_loss: 0.4541 - val_accuracy: 0.8015\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4489 - accuracy: 0.8150 - val_loss: 0.4530 - val_accuracy: 0.7976\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8145 - val_loss: 0.4516 - val_accuracy: 0.8098\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4461 - accuracy: 0.8177 - val_loss: 0.4503 - val_accuracy: 0.8085\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.8178 - val_loss: 0.4491 - val_accuracy: 0.8017\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.8182 - val_loss: 0.4478 - val_accuracy: 0.8076\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4424 - accuracy: 0.8191 - val_loss: 0.4466 - val_accuracy: 0.8133\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4458 - val_accuracy: 0.8219\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4398 - accuracy: 0.8207 - val_loss: 0.4455 - val_accuracy: 0.8355\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8219 - val_loss: 0.4430 - val_accuracy: 0.8112\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4374 - accuracy: 0.8228 - val_loss: 0.4419 - val_accuracy: 0.8140\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4362 - accuracy: 0.8223 - val_loss: 0.4407 - val_accuracy: 0.8138\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4350 - accuracy: 0.8236 - val_loss: 0.4397 - val_accuracy: 0.8203\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4338 - accuracy: 0.8241 - val_loss: 0.4384 - val_accuracy: 0.8140\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4326 - accuracy: 0.8248 - val_loss: 0.4373 - val_accuracy: 0.8122\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4315 - accuracy: 0.8253 - val_loss: 0.4362 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4303 - accuracy: 0.8262 - val_loss: 0.4351 - val_accuracy: 0.8165\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.8280 - val_loss: 0.4340 - val_accuracy: 0.8165\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.8267 - val_loss: 0.4333 - val_accuracy: 0.8309\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4269 - accuracy: 0.8284 - val_loss: 0.4319 - val_accuracy: 0.8200\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4259 - accuracy: 0.8287 - val_loss: 0.4312 - val_accuracy: 0.8112\n",
      "277/277 [==============================] - 0s 833us/step - loss: 0.4376 - accuracy: 0.8035\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6774 - accuracy: 0.5844 - val_loss: 0.6693 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6702 - accuracy: 0.5916 - val_loss: 0.6646 - val_accuracy: 0.6012\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6645 - accuracy: 0.5921 - val_loss: 0.6588 - val_accuracy: 0.6035\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.5941 - val_loss: 0.6525 - val_accuracy: 0.6044\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6541 - accuracy: 0.5976 - val_loss: 0.6475 - val_accuracy: 0.6105\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6488 - accuracy: 0.6043 - val_loss: 0.6424 - val_accuracy: 0.6179\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6436 - accuracy: 0.6116 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6388 - accuracy: 0.6182 - val_loss: 0.6325 - val_accuracy: 0.6333\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6340 - accuracy: 0.6256 - val_loss: 0.6277 - val_accuracy: 0.6385\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6294 - accuracy: 0.6328 - val_loss: 0.6229 - val_accuracy: 0.6366\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6247 - accuracy: 0.6396 - val_loss: 0.6198 - val_accuracy: 0.6729\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6203 - accuracy: 0.6499 - val_loss: 0.6138 - val_accuracy: 0.6549\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6158 - accuracy: 0.6556 - val_loss: 0.6094 - val_accuracy: 0.6634\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6114 - accuracy: 0.6631 - val_loss: 0.6052 - val_accuracy: 0.6685\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6074 - accuracy: 0.6683 - val_loss: 0.6022 - val_accuracy: 0.6983\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.6742 - val_loss: 0.5975 - val_accuracy: 0.6949\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6819 - val_loss: 0.5933 - val_accuracy: 0.6935\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5955 - accuracy: 0.6836 - val_loss: 0.5894 - val_accuracy: 0.6902\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5916 - accuracy: 0.6890 - val_loss: 0.5865 - val_accuracy: 0.7120\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5881 - accuracy: 0.6951 - val_loss: 0.5821 - val_accuracy: 0.6946\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5843 - accuracy: 0.6983 - val_loss: 0.5799 - val_accuracy: 0.7264\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5810 - accuracy: 0.7045 - val_loss: 0.5756 - val_accuracy: 0.7159\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7057 - val_loss: 0.5725 - val_accuracy: 0.7257\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5744 - accuracy: 0.7077 - val_loss: 0.5690 - val_accuracy: 0.7249\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7152 - val_loss: 0.5655 - val_accuracy: 0.7162\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7171 - val_loss: 0.5631 - val_accuracy: 0.7379\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7219 - val_loss: 0.5597 - val_accuracy: 0.7361\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5618 - accuracy: 0.7273 - val_loss: 0.5568 - val_accuracy: 0.7379\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5589 - accuracy: 0.7271 - val_loss: 0.5542 - val_accuracy: 0.7474\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5558 - accuracy: 0.7322 - val_loss: 0.5504 - val_accuracy: 0.7293\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.7344 - val_loss: 0.5475 - val_accuracy: 0.7296\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7354 - val_loss: 0.5455 - val_accuracy: 0.7534\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7395 - val_loss: 0.5420 - val_accuracy: 0.7492\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7434 - val_loss: 0.5398 - val_accuracy: 0.7566\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7456 - val_loss: 0.5372 - val_accuracy: 0.7622\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7476 - val_loss: 0.5345 - val_accuracy: 0.7622\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7494 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7525 - val_loss: 0.5290 - val_accuracy: 0.7530\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7533 - val_loss: 0.5265 - val_accuracy: 0.7523\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5288 - accuracy: 0.7577 - val_loss: 0.5243 - val_accuracy: 0.7596\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5265 - accuracy: 0.7606 - val_loss: 0.5219 - val_accuracy: 0.7525\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7593 - val_loss: 0.5202 - val_accuracy: 0.7703\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5223 - accuracy: 0.7628 - val_loss: 0.5181 - val_accuracy: 0.7736\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7661 - val_loss: 0.5155 - val_accuracy: 0.7675\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5176 - accuracy: 0.7679 - val_loss: 0.5134 - val_accuracy: 0.7525\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7659 - val_loss: 0.5113 - val_accuracy: 0.7717\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5134 - accuracy: 0.7713 - val_loss: 0.5092 - val_accuracy: 0.7735\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5113 - accuracy: 0.7729 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5093 - accuracy: 0.7729 - val_loss: 0.5049 - val_accuracy: 0.7729\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5073 - accuracy: 0.7733 - val_loss: 0.5029 - val_accuracy: 0.7699\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5051 - accuracy: 0.7763 - val_loss: 0.5011 - val_accuracy: 0.7802\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7803 - val_loss: 0.4990 - val_accuracy: 0.7714\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5014 - accuracy: 0.7786 - val_loss: 0.4972 - val_accuracy: 0.7754\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4993 - accuracy: 0.7806 - val_loss: 0.4959 - val_accuracy: 0.7900\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4976 - accuracy: 0.7820 - val_loss: 0.4935 - val_accuracy: 0.7715\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4957 - accuracy: 0.7839 - val_loss: 0.4920 - val_accuracy: 0.7883\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4940 - accuracy: 0.7856 - val_loss: 0.4901 - val_accuracy: 0.7842\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4921 - accuracy: 0.7881 - val_loss: 0.4884 - val_accuracy: 0.7712\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4905 - accuracy: 0.7866 - val_loss: 0.4868 - val_accuracy: 0.7906\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4887 - accuracy: 0.7894 - val_loss: 0.4850 - val_accuracy: 0.7897\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7905 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7894 - val_loss: 0.4821 - val_accuracy: 0.7999\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4836 - accuracy: 0.7931 - val_loss: 0.4816 - val_accuracy: 0.8124\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4820 - accuracy: 0.7953 - val_loss: 0.4787 - val_accuracy: 0.7957\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4804 - accuracy: 0.7942 - val_loss: 0.4770 - val_accuracy: 0.7951\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4787 - accuracy: 0.7953 - val_loss: 0.4760 - val_accuracy: 0.8064\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.7969 - val_loss: 0.4738 - val_accuracy: 0.7869\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.7973 - val_loss: 0.4726 - val_accuracy: 0.8024\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4743 - accuracy: 0.7981 - val_loss: 0.4708 - val_accuracy: 0.7950\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.7988 - val_loss: 0.4702 - val_accuracy: 0.8129\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4712 - accuracy: 0.8006 - val_loss: 0.4682 - val_accuracy: 0.8068\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.8026 - val_loss: 0.4671 - val_accuracy: 0.8122\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4684 - accuracy: 0.8018 - val_loss: 0.4656 - val_accuracy: 0.8117\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8038 - val_loss: 0.4637 - val_accuracy: 0.8020\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4656 - accuracy: 0.8045 - val_loss: 0.4623 - val_accuracy: 0.8038\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4641 - accuracy: 0.8038 - val_loss: 0.4626 - val_accuracy: 0.8265\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4629 - accuracy: 0.8058 - val_loss: 0.4597 - val_accuracy: 0.8066\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4613 - accuracy: 0.8070 - val_loss: 0.4587 - val_accuracy: 0.8138\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.8068 - val_loss: 0.4577 - val_accuracy: 0.8186\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4587 - accuracy: 0.8090 - val_loss: 0.4559 - val_accuracy: 0.7941\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4574 - accuracy: 0.8083 - val_loss: 0.4549 - val_accuracy: 0.8179\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4562 - accuracy: 0.8108 - val_loss: 0.4532 - val_accuracy: 0.8018\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4550 - accuracy: 0.8103 - val_loss: 0.4525 - val_accuracy: 0.8194\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4537 - accuracy: 0.8124 - val_loss: 0.4510 - val_accuracy: 0.8170\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4525 - accuracy: 0.8113 - val_loss: 0.4496 - val_accuracy: 0.8135\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4510 - accuracy: 0.8119 - val_loss: 0.4491 - val_accuracy: 0.8277\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4500 - accuracy: 0.8139 - val_loss: 0.4475 - val_accuracy: 0.8191\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4488 - accuracy: 0.8151 - val_loss: 0.4464 - val_accuracy: 0.8230\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8159 - val_loss: 0.4450 - val_accuracy: 0.8193\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4466 - accuracy: 0.8164 - val_loss: 0.4438 - val_accuracy: 0.8186\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4454 - accuracy: 0.8159 - val_loss: 0.4429 - val_accuracy: 0.8223\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4440 - accuracy: 0.8172 - val_loss: 0.4421 - val_accuracy: 0.8291\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8192 - val_loss: 0.4408 - val_accuracy: 0.8272\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4420 - accuracy: 0.8188 - val_loss: 0.4393 - val_accuracy: 0.8124\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4409 - accuracy: 0.8191 - val_loss: 0.4385 - val_accuracy: 0.8247\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4399 - accuracy: 0.8203 - val_loss: 0.4372 - val_accuracy: 0.8165\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8202 - val_loss: 0.4367 - val_accuracy: 0.8316\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4376 - accuracy: 0.8226 - val_loss: 0.4351 - val_accuracy: 0.8173\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4367 - accuracy: 0.8217 - val_loss: 0.4341 - val_accuracy: 0.8138\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4356 - accuracy: 0.8216 - val_loss: 0.4339 - val_accuracy: 0.8379\n",
      "277/277 [==============================] - 0s 848us/step - loss: 0.4254 - accuracy: 0.8411\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f61df81c100>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-beb0a2675d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m rnd_search_cv.fit(X_train, y_train, epochs = 100, \n\u001b[0m\u001b[1;32m      9\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f61df81c100>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3,4,5,6],\n",
    "    \"n_neurons\": np.arange(1,600),\n",
    "    \"learning_rate\": reciprocal(1e-5,0.01),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs = 100, \n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.2062939642434896e-05, 'n_hidden': 6, 'n_neurons': 426}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12700140476226807"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b8ba0c4ba001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run this line of code if you are sure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# run this line of code if you are sure \n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=32,\n",
    "                                        max_value=512,\n",
    "                                        step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=list(np.linspace(start=1e-5, stop=10, num=500)))),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [1e-05, 0.020050060120240482, 0.04009012024048097, 0.06013018036072145, 0.08017024048096193, 0.10021030060120241, 0.12025036072144289, 0.1402904208416834, 0.16033048096192387, 0.18037054108216435, 0.20041060120240484, 0.22045066132264532, 0.2404907214428858, 0.2605307815631263, 0.28057084168336677, 0.3006109018036072, 0.32065096192384773, 0.34069102204408824, 0.3607310821643287, 0.38077114228456915, 0.40081120240480966, 0.4208512625250502, 0.44089132264529063, 0.4609313827655311, 0.4809714428857716, 0.501011503006012, 0.5210515631262526, 0.541091623246493, 0.5611316833667335, 0.581171743486974, 0.6012118036072144, 0.6212518637274549, 0.6412919238476954, 0.6613319839679359, 0.6813720440881764, 0.7014121042084168, 0.7214521643286573, 0.7414922244488978, 0.7615322845691382, 0.7815723446893788, 0.8016124048096193, 0.8216524649298598, 0.8416925250501003, 0.8617325851703407, 0.8817726452905812, 0.9018127054108217, 0.9218527655310621, 0.9418928256513026, 0.9619328857715431, 0.9819729458917836, 1.0020130060120243, 1.0220530661322647, 1.0420931262525053, 1.0621331863727457, 1.082173246492986, 1.1022133066132267, 1.122253366733467, 1.1422934268537075, 1.1623334869739481, 1.1823735470941885, 1.202413607214429, 1.2224536673346695, 1.24249372745491, 1.2625337875751506, 1.282573847695391, 1.3026139078156314, 1.322653967935872, 1.3426940280561124, 1.362734088176353, 1.3827741482965934, 1.4028142084168338, 1.4228542685370744, 1.4428943286573148, 1.4629343887775552, 1.4829744488977958, 1.5030145090180362, 1.5230545691382766, 1.5430946292585173, 1.5631346893787577, 1.5831747494989983, 1.6032148096192387, 1.623254869739479, 1.6432949298597197, 1.66333498997996, 1.6833750501002007, 1.7034151102204411, 1.7234551703406815, 1.7434952304609221, 1.7635352905811625, 1.783575350701403, 1.8036154108216436, 1.823655470941884, 1.8436955310621244, 1.863735591182365, 1.8837756513026054, 1.903815711422846, 1.9238557715430864, 1.9438958316633268, 1.9639358917835674, 1.9839759519038078, 2.0040160120240484, 2.0240560721442886, 2.0440961322645292, 2.06413619238477, 2.0841762525050105, 2.1042163126252507, 2.1242563727454913, 2.144296432865732, 2.164336492985972, 2.1843765531062127, 2.2044166132264533, 2.2244566733466935, 2.244496733466934, 2.2645367935871747, 2.284576853707415, 2.3046169138276555, 2.324656973947896, 2.3446970340681363, 2.364737094188377, 2.3847771543086176, 2.4048172144288578, 2.4248572745490984, 2.444897334669339, 2.4649373947895796, 2.48497745490982, 2.5050175150300604, 2.525057575150301, 2.5450976352705412, 2.565137695390782, 2.5851777555110225, 2.6052178156312626, 2.6252578757515033, 2.645297935871744, 2.665337995991984, 2.6853780561122247, 2.7054181162324653, 2.725458176352706, 2.745498236472946, 2.7655382965931867, 2.7855783567134274, 2.8056184168336675, 2.825658476953908, 2.8456985370741488, 2.865738597194389, 2.8857786573146296, 2.90581871743487, 2.9258587775551104, 2.945898837675351, 2.9659388977955916, 2.985978957915832, 3.0060190180360724, 3.026059078156313, 3.046099138276553, 3.066139198396794, 3.0861792585170345, 3.106219318637275, 3.1262593787575153, 3.146299438877756, 3.1663394989979965, 3.1863795591182367, 3.2064196192384773, 3.226459679358718, 3.246499739478958, 3.2665397995991987, 3.2865798597194393, 3.3066199198396795, 3.32665997995992, 3.3467000400801608, 3.3667401002004014, 3.3867801603206416, 3.406820220440882, 3.426860280561123, 3.446900340681363, 3.4669404008016036, 3.486980460921844, 3.5070205210420844, 3.527060581162325, 3.5471006412825656, 3.567140701402806, 3.5871807615230464, 3.607220821643287, 3.6272608817635272, 3.647300941883768, 3.6673410020040085, 3.6873810621242487, 3.7074211222444893, 3.72746118236473, 3.7475012424849705, 3.7675413026052107, 3.7875813627254513, 3.807621422845692, 3.827661482965932, 3.8477015430861727, 3.8677416032064134, 3.8877816633266535, 3.907821723446894, 3.927861783567135, 3.947901843687375, 3.9679419038076156, 3.987981963927856, 4.008022024048096, 4.0280620841683366, 4.048102144288577, 4.068142204408818, 4.088182264529058, 4.108222324649298, 4.128262384769539, 4.148302444889779, 4.1683425050100205, 4.188382565130261, 4.208422625250501, 4.228462685370742, 4.248502745490982, 4.268542805611222, 4.288582865731463, 4.3086229258517035, 4.328662985971944, 4.348703046092185, 4.368743106212425, 4.388783166332665, 4.408823226452906, 4.428863286573146, 4.4489033466933865, 4.468943406813628, 4.488983466933868, 4.509023527054108, 4.529063587174349, 4.549103647294589, 4.569143707414829, 4.58918376753507, 4.609223827655311, 4.629263887775551, 4.649303947895792, 4.669344008016032, 4.689384068136272, 4.709424128256513, 4.729464188376753, 4.749504248496994, 4.769544308617235, 4.789584368737475, 4.809624428857715, 4.829664488977956, 4.849704549098196, 4.869744609218437, 4.8897846693386775, 4.909824729458918, 4.929864789579159, 4.949904849699399, 4.969944909819639, 4.98998496993988, 5.01002503006012, 5.0300650901803605, 5.050105150300602, 5.070145210420842, 5.090185270541082, 5.110225330661323, 5.130265390781563, 5.150305450901803, 5.170345511022044, 5.190385571142285, 5.210425631262525, 5.230465691382766, 5.250505751503006, 5.270545811623246, 5.290585871743487, 5.3106259318637274, 5.330665991983968, 5.350706052104209, 5.370746112224449, 5.390786172344689, 5.41082623246493, 5.43086629258517, 5.450906352705411, 5.4709464128256515, 5.490986472945892, 5.511026533066133, 5.531066593186373, 5.551106653306613, 5.571146713426854, 5.591186773547094, 5.6112268336673345, 5.631266893787576, 5.651306953907816, 5.671347014028056, 5.691387074148297, 5.711427134268537, 5.731467194388777, 5.7515072545090185, 5.771547314629259, 5.791587374749499, 5.81162743486974, 5.83166749498998, 5.85170755511022, 5.871747615230461, 5.8917876753507015, 5.911827735470942, 5.931867795591183, 5.951907855711423, 5.971947915831663, 5.991987975951904, 6.012028036072144, 6.0320680961923845, 6.0521081563126256, 6.072148216432866, 6.092188276553106, 6.112228336673347, 6.132268396793587, 6.152308456913828, 6.172348517034068, 6.192388577154309, 6.21242863727455, 6.23246869739479, 6.25250875751503, 6.272548817635271, 6.292588877755511, 6.312628937875751, 6.3326689979959925, 6.352709058116233, 6.372749118236473, 6.392789178356714, 6.412829238476954, 6.432869298597194, 6.452909358717435, 6.4729494188376755, 6.492989478957916, 6.513029539078157, 6.533069599198397, 6.553109659318637, 6.573149719438878, 6.593189779559118, 6.6132298396793585, 6.6332698997996, 6.65330995991984, 6.67335002004008, 6.693390080160321, 6.713430140280561, 6.733470200400802, 6.753510260521042, 6.773550320641283, 6.793590380761524, 6.813630440881764, 6.833670501002004, 6.853710561122245, 6.873750621242485, 6.893790681362725, 6.9138307414829665, 6.933870801603207, 6.953910861723447, 6.973950921843688, 6.993990981963928, 7.014031042084168, 7.034071102204409, 7.0541111623246495, 7.07415122244489, 7.094191282565131, 7.114231342685371, 7.134271402805611, 7.154311462925852, 7.174351523046092, 7.1943915831663325, 7.214431643286574, 7.234471703406814, 7.254511763527054, 7.274551823647295, 7.294591883767535, 7.314631943887775, 7.334672004008016, 7.354712064128257, 7.374752124248497, 7.394792184368738, 7.414832244488978, 7.434872304609219, 7.454912364729459, 7.4749524248496995, 7.4949924849699405, 7.515032545090181, 7.535072605210421, 7.555112665330662, 7.575152725450902, 7.595192785571142, 7.615232845691383, 7.6352729058116235, 7.655312965931864, 7.675353026052105, 7.695393086172345, 7.715433146292585, 7.735473206412826, 7.755513266533066, 7.775553326653307, 7.795593386773548, 7.815633446893788, 7.835673507014028, 7.855713567134269, 7.875753627254509, 7.895793687374749, 7.9158337474949905, 7.935873807615231, 7.955913867735471, 7.975953927855712, 7.995993987975952, 8.016034048096193, 8.036074108216432, 8.056114168336673, 8.076154228456915, 8.096194288577154, 8.116234348697395, 8.136274408817636, 8.156314468937875, 8.176354529058116, 8.196394589178357, 8.216434649298597, 8.236474709418838, 8.256514769539079, 8.276554829659318, 8.29659488977956, 8.3166349498998, 8.336675010020041, 8.35671507014028, 8.376755130260522, 8.396795190380763, 8.416835250501002, 8.436875310621243, 8.456915370741484, 8.476955430861723, 8.496995490981964, 8.517035551102206, 8.537075611222445, 8.557115671342686, 8.577155731462927, 8.597195791583166, 8.617235851703407, 8.637275911823648, 8.657315971943888, 8.677356032064129, 8.69739609218437, 8.717436152304609, 8.73747621242485, 8.757516272545091, 8.77755633266533, 8.797596392785572, 8.817636452905813, 8.837676513026052, 8.857716573146293, 8.877756633266534, 8.897796693386773, 8.917836753507014, 8.937876813627256, 8.957916873747495, 8.977956933867736, 8.997996993987977, 9.018037054108216, 9.038077114228457, 9.058117174348698, 9.078157234468938, 9.098197294589179, 9.11823735470942, 9.138277414829659, 9.1583174749499, 9.178357535070141, 9.19839759519038, 9.218437655310622, 9.238477715430863, 9.258517775551102, 9.278557835671343, 9.298597895791584, 9.318637955911823, 9.338678016032064, 9.358718076152305, 9.378758136272545, 9.398798196392786, 9.418838256513027, 9.438878316633266, 9.458918376753507, 9.478958436873748, 9.498998496993988, 9.519038557114229, 9.53907861723447, 9.559118677354709, 9.57915873747495, 9.599198797595191, 9.61923885771543, 9.639278917835671, 9.659318977955913, 9.679359038076154, 9.699399098196393, 9.719439158316634, 9.739479218436875, 9.759519278557114, 9.779559338677355, 9.799599398797596, 9.819639458917836, 9.839679519038077, 9.859719579158318, 9.879759639278557, 9.899799699398798, 9.91983975951904, 9.939879819639279, 9.95991987975952, 9.97995993987976, 10.0]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.68 - ETA: 1s - loss: 259.0526 - accuracy: 0.52 - ETA: 1s - loss: 129.8933 - accuracy: 0.52 - ETA: 0s - loss: 89.1579 - accuracy: 0.5355 - ETA: 0s - loss: 68.9138 - accuracy: 0.529 - ETA: 0s - loss: 55.2876 - accuracy: 0.527 - ETA: 0s - loss: 46.2012 - accuracy: 0.529 - ETA: 0s - loss: 39.5601 - accuracy: 0.531 - ETA: 0s - loss: 34.9650 - accuracy: 0.534 - ETA: 0s - loss: 31.2495 - accuracy: 0.531 - ETA: 0s - loss: 28.1542 - accuracy: 0.534 - ETA: 0s - loss: 25.7879 - accuracy: 0.530 - ETA: 0s - loss: 23.6893 - accuracy: 0.530 - ETA: 0s - loss: 22.0484 - accuracy: 0.532 - ETA: 0s - loss: 20.5900 - accuracy: 0.532 - ETA: 0s - loss: 19.1786 - accuracy: 0.533 - ETA: 0s - loss: 18.0146 - accuracy: 0.532 - ETA: 0s - loss: 17.0464 - accuracy: 0.531 - ETA: 0s - loss: 16.1302 - accuracy: 0.531 - ETA: 0s - loss: 15.3555 - accuracy: 0.531 - ETA: 0s - loss: 14.6364 - accuracy: 0.530 - ETA: 0s - loss: 13.9350 - accuracy: 0.530 - ETA: 0s - loss: 13.3468 - accuracy: 0.529 - ETA: 0s - loss: 12.9143 - accuracy: 0.530 - 1s 2ms/step - loss: 12.7670 - accuracy: 0.5298 - val_loss: 0.7122 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.65 - ETA: 1s - loss: 1.7838 - accuracy: 0.54 - ETA: 1s - loss: 1.2569 - accuracy: 0.54 - ETA: 1s - loss: 1.1267 - accuracy: 0.52 - ETA: 0s - loss: 1.0363 - accuracy: 0.52 - ETA: 0s - loss: 0.9892 - accuracy: 0.52 - ETA: 0s - loss: 0.9589 - accuracy: 0.52 - ETA: 0s - loss: 0.9468 - accuracy: 0.52 - ETA: 0s - loss: 0.9268 - accuracy: 0.52 - ETA: 0s - loss: 0.9047 - accuracy: 0.52 - ETA: 0s - loss: 0.8918 - accuracy: 0.52 - ETA: 0s - loss: 0.8851 - accuracy: 0.52 - ETA: 0s - loss: 0.8736 - accuracy: 0.52 - ETA: 0s - loss: 0.8655 - accuracy: 0.52 - ETA: 0s - loss: 0.8548 - accuracy: 0.53 - ETA: 0s - loss: 0.8493 - accuracy: 0.53 - ETA: 0s - loss: 0.8501 - accuracy: 0.52 - ETA: 0s - loss: 0.8497 - accuracy: 0.52 - ETA: 0s - loss: 0.8437 - accuracy: 0.52 - ETA: 0s - loss: 0.8377 - accuracy: 0.52 - ETA: 0s - loss: 0.8318 - accuracy: 0.53 - ETA: 0s - loss: 0.8280 - accuracy: 0.53 - ETA: 0s - loss: 0.8233 - accuracy: 0.53 - ETA: 0s - loss: 0.8221 - accuracy: 0.53 - ETA: 0s - loss: 0.8198 - accuracy: 0.53 - 1s 2ms/step - loss: 0.8196 - accuracy: 0.5311 - val_loss: 1.1006 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.1784 - accuracy: 0.34 - ETA: 1s - loss: 0.8403 - accuracy: 0.50 - ETA: 1s - loss: 0.8231 - accuracy: 0.52 - ETA: 1s - loss: 0.7898 - accuracy: 0.52 - ETA: 0s - loss: 0.7960 - accuracy: 0.52 - ETA: 0s - loss: 0.7839 - accuracy: 0.53 - ETA: 0s - loss: 0.7751 - accuracy: 0.53 - ETA: 0s - loss: 0.7744 - accuracy: 0.53 - ETA: 0s - loss: 0.7825 - accuracy: 0.53 - ETA: 0s - loss: 0.7756 - accuracy: 0.53 - ETA: 0s - loss: 0.7718 - accuracy: 0.53 - ETA: 0s - loss: 0.7749 - accuracy: 0.53 - ETA: 0s - loss: 0.7762 - accuracy: 0.52 - ETA: 0s - loss: 0.7724 - accuracy: 0.53 - ETA: 0s - loss: 0.7712 - accuracy: 0.53 - ETA: 0s - loss: 0.7699 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - ETA: 0s - loss: 0.7688 - accuracy: 0.53 - ETA: 0s - loss: 0.7716 - accuracy: 0.53 - ETA: 0s - loss: 0.7711 - accuracy: 0.53 - ETA: 0s - loss: 0.7677 - accuracy: 0.53 - ETA: 0s - loss: 0.7687 - accuracy: 0.53 - ETA: 0s - loss: 0.7685 - accuracy: 0.53 - ETA: 0s - loss: 0.7669 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7669 - accuracy: 0.5318 - val_loss: 0.7113 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7191 - accuracy: 0.34 - ETA: 1s - loss: 0.7945 - accuracy: 0.51 - ETA: 1s - loss: 0.7875 - accuracy: 0.50 - ETA: 1s - loss: 0.7869 - accuracy: 0.51 - ETA: 1s - loss: 0.7848 - accuracy: 0.51 - ETA: 0s - loss: 0.7750 - accuracy: 0.53 - ETA: 0s - loss: 0.7750 - accuracy: 0.53 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7742 - accuracy: 0.52 - ETA: 0s - loss: 0.7735 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7734 - accuracy: 0.52 - ETA: 0s - loss: 0.7773 - accuracy: 0.52 - ETA: 0s - loss: 0.7712 - accuracy: 0.52 - ETA: 0s - loss: 0.7768 - accuracy: 0.52 - ETA: 0s - loss: 0.7739 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7757 - accuracy: 0.52 - ETA: 0s - loss: 0.7735 - accuracy: 0.52 - ETA: 0s - loss: 0.7732 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.52 - ETA: 0s - loss: 0.7692 - accuracy: 0.52 - ETA: 0s - loss: 0.7683 - accuracy: 0.52 - ETA: 0s - loss: 0.7676 - accuracy: 0.52 - ETA: 0s - loss: 0.7680 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - 2s 2ms/step - loss: 0.7695 - accuracy: 0.5263 - val_loss: 0.7045 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.62 - ETA: 1s - loss: 0.7684 - accuracy: 0.50 - ETA: 1s - loss: 0.7439 - accuracy: 0.52 - ETA: 1s - loss: 0.7397 - accuracy: 0.52 - ETA: 1s - loss: 0.7430 - accuracy: 0.52 - ETA: 0s - loss: 0.7359 - accuracy: 0.53 - ETA: 0s - loss: 0.7559 - accuracy: 0.52 - ETA: 0s - loss: 0.7558 - accuracy: 0.52 - ETA: 0s - loss: 0.7547 - accuracy: 0.53 - ETA: 0s - loss: 0.7484 - accuracy: 0.53 - ETA: 0s - loss: 0.7527 - accuracy: 0.53 - ETA: 0s - loss: 0.7565 - accuracy: 0.53 - ETA: 0s - loss: 0.7535 - accuracy: 0.53 - ETA: 0s - loss: 0.7529 - accuracy: 0.53 - ETA: 0s - loss: 0.7583 - accuracy: 0.52 - ETA: 0s - loss: 0.7580 - accuracy: 0.52 - ETA: 0s - loss: 0.7582 - accuracy: 0.53 - ETA: 0s - loss: 0.7563 - accuracy: 0.53 - ETA: 0s - loss: 0.7589 - accuracy: 0.53 - ETA: 0s - loss: 0.7610 - accuracy: 0.53 - ETA: 0s - loss: 0.7587 - accuracy: 0.53 - ETA: 0s - loss: 0.7627 - accuracy: 0.53 - ETA: 0s - loss: 0.7626 - accuracy: 0.53 - ETA: 0s - loss: 0.7667 - accuracy: 0.52 - ETA: 0s - loss: 0.7656 - accuracy: 0.52 - 1s 2ms/step - loss: 0.7671 - accuracy: 0.5280 - val_loss: 0.9081 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6027 - accuracy: 0.75 - ETA: 1s - loss: 35.2568 - accuracy: 0.570 - ETA: 1s - loss: 19.3793 - accuracy: 0.561 - ETA: 1s - loss: 13.3368 - accuracy: 0.559 - ETA: 1s - loss: 10.3226 - accuracy: 0.559 - ETA: 0s - loss: 8.5132 - accuracy: 0.559 - ETA: 0s - loss: 7.2012 - accuracy: 0.54 - ETA: 0s - loss: 6.4227 - accuracy: 0.55 - ETA: 0s - loss: 5.7323 - accuracy: 0.55 - ETA: 0s - loss: 5.2025 - accuracy: 0.54 - ETA: 0s - loss: 4.7622 - accuracy: 0.54 - ETA: 0s - loss: 4.3730 - accuracy: 0.54 - ETA: 0s - loss: 4.0788 - accuracy: 0.54 - ETA: 0s - loss: 3.8141 - accuracy: 0.54 - ETA: 0s - loss: 3.5919 - accuracy: 0.54 - ETA: 0s - loss: 3.3992 - accuracy: 0.54 - ETA: 0s - loss: 3.2466 - accuracy: 0.54 - ETA: 0s - loss: 3.0937 - accuracy: 0.54 - ETA: 0s - loss: 2.9621 - accuracy: 0.54 - ETA: 0s - loss: 2.8468 - accuracy: 0.54 - ETA: 0s - loss: 2.7410 - accuracy: 0.54 - ETA: 0s - loss: 2.6550 - accuracy: 0.54 - ETA: 0s - loss: 2.5684 - accuracy: 0.54 - ETA: 0s - loss: 2.4857 - accuracy: 0.53 - ETA: 0s - loss: 2.4169 - accuracy: 0.53 - 1s 2ms/step - loss: 2.3683 - accuracy: 0.5357 - val_loss: 1.8196 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.4375 - accuracy: 0.68 - ETA: 1s - loss: 0.7785 - accuracy: 0.52 - ETA: 1s - loss: 0.7969 - accuracy: 0.51 - ETA: 1s - loss: 0.7795 - accuracy: 0.52 - ETA: 1s - loss: 0.7789 - accuracy: 0.52 - ETA: 1s - loss: 0.7670 - accuracy: 0.52 - ETA: 1s - loss: 0.7650 - accuracy: 0.53 - ETA: 1s - loss: 0.7647 - accuracy: 0.53 - ETA: 0s - loss: 0.7637 - accuracy: 0.53 - ETA: 0s - loss: 0.7654 - accuracy: 0.53 - ETA: 0s - loss: 0.7648 - accuracy: 0.53 - ETA: 0s - loss: 0.7665 - accuracy: 0.53 - ETA: 0s - loss: 0.7661 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7680 - accuracy: 0.53 - ETA: 0s - loss: 0.7700 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7644 - accuracy: 0.53 - ETA: 0s - loss: 0.7631 - accuracy: 0.53 - ETA: 0s - loss: 0.7941 - accuracy: 0.53 - ETA: 0s - loss: 0.7937 - accuracy: 0.53 - ETA: 0s - loss: 0.7939 - accuracy: 0.53 - ETA: 0s - loss: 0.7918 - accuracy: 0.53 - ETA: 0s - loss: 0.7914 - accuracy: 0.53 - ETA: 0s - loss: 0.7947 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7932 - accuracy: 0.5316 - val_loss: 0.7286 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.65 - ETA: 1s - loss: 0.8165 - accuracy: 0.53 - ETA: 1s - loss: 0.7916 - accuracy: 0.53 - ETA: 1s - loss: 0.8005 - accuracy: 0.52 - ETA: 1s - loss: 0.7966 - accuracy: 0.52 - ETA: 1s - loss: 0.7912 - accuracy: 0.52 - ETA: 0s - loss: 0.7811 - accuracy: 0.52 - ETA: 0s - loss: 0.7804 - accuracy: 0.52 - ETA: 0s - loss: 0.7844 - accuracy: 0.52 - ETA: 0s - loss: 0.7856 - accuracy: 0.52 - ETA: 0s - loss: 0.7802 - accuracy: 0.52 - ETA: 0s - loss: 0.7758 - accuracy: 0.52 - ETA: 0s - loss: 0.7747 - accuracy: 0.52 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7735 - accuracy: 0.53 - ETA: 0s - loss: 0.7750 - accuracy: 0.52 - ETA: 0s - loss: 0.7732 - accuracy: 0.52 - ETA: 0s - loss: 0.7751 - accuracy: 0.52 - ETA: 0s - loss: 0.7748 - accuracy: 0.52 - ETA: 0s - loss: 0.7761 - accuracy: 0.52 - ETA: 0s - loss: 0.7753 - accuracy: 0.52 - ETA: 0s - loss: 0.7762 - accuracy: 0.52 - ETA: 0s - loss: 0.7734 - accuracy: 0.52 - ETA: 0s - loss: 0.7722 - accuracy: 0.52 - ETA: 0s - loss: 0.7713 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7695 - accuracy: 0.5304 - val_loss: 1.1560 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.4429 - accuracy: 0.50 - ETA: 1s - loss: 0.7752 - accuracy: 0.52 - ETA: 1s - loss: 0.7651 - accuracy: 0.53 - ETA: 1s - loss: 0.7557 - accuracy: 0.53 - ETA: 0s - loss: 0.7595 - accuracy: 0.53 - ETA: 0s - loss: 0.7617 - accuracy: 0.52 - ETA: 0s - loss: 0.7713 - accuracy: 0.52 - ETA: 0s - loss: 0.7749 - accuracy: 0.52 - ETA: 0s - loss: 0.7795 - accuracy: 0.52 - ETA: 0s - loss: 0.7823 - accuracy: 0.52 - ETA: 0s - loss: 0.7755 - accuracy: 0.53 - ETA: 0s - loss: 0.7721 - accuracy: 0.53 - ETA: 0s - loss: 0.7728 - accuracy: 0.53 - ETA: 0s - loss: 0.7721 - accuracy: 0.53 - ETA: 0s - loss: 0.7727 - accuracy: 0.53 - ETA: 0s - loss: 0.7748 - accuracy: 0.53 - ETA: 0s - loss: 0.7756 - accuracy: 0.53 - ETA: 0s - loss: 0.7732 - accuracy: 0.53 - ETA: 0s - loss: 0.7726 - accuracy: 0.53 - ETA: 0s - loss: 0.7740 - accuracy: 0.53 - ETA: 0s - loss: 0.7729 - accuracy: 0.53 - ETA: 0s - loss: 0.7745 - accuracy: 0.53 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7751 - accuracy: 0.53 - ETA: 0s - loss: 0.7738 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7757 - accuracy: 0.5329 - val_loss: 0.7497 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.53 - ETA: 1s - loss: 0.8154 - accuracy: 0.50 - ETA: 1s - loss: 0.7759 - accuracy: 0.53 - ETA: 1s - loss: 0.7929 - accuracy: 0.51 - ETA: 1s - loss: 0.7880 - accuracy: 0.51 - ETA: 1s - loss: 0.7811 - accuracy: 0.52 - ETA: 0s - loss: 0.7747 - accuracy: 0.51 - ETA: 0s - loss: 0.7697 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7731 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.52 - ETA: 0s - loss: 0.7658 - accuracy: 0.52 - ETA: 0s - loss: 0.7678 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - ETA: 0s - loss: 0.7655 - accuracy: 0.53 - ETA: 0s - loss: 0.7641 - accuracy: 0.53 - ETA: 0s - loss: 0.7677 - accuracy: 0.53 - ETA: 0s - loss: 0.7701 - accuracy: 0.52 - ETA: 0s - loss: 0.7671 - accuracy: 0.53 - ETA: 0s - loss: 0.7646 - accuracy: 0.53 - ETA: 0s - loss: 0.7635 - accuracy: 0.53 - ETA: 0s - loss: 0.7675 - accuracy: 0.53 - ETA: 0s - loss: 0.7658 - accuracy: 0.53 - ETA: 0s - loss: 0.7680 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7679 - accuracy: 0.5331 - val_loss: 0.7551 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8811 - accuracy: 0.31 - ETA: 1s - loss: 77.9600 - accuracy: 0.500 - ETA: 1s - loss: 40.9788 - accuracy: 0.516 - ETA: 1s - loss: 26.9634 - accuracy: 0.519 - ETA: 0s - loss: 20.5983 - accuracy: 0.526 - ETA: 0s - loss: 16.7157 - accuracy: 0.526 - ETA: 0s - loss: 14.1277 - accuracy: 0.523 - ETA: 0s - loss: 12.3521 - accuracy: 0.527 - ETA: 0s - loss: 10.8843 - accuracy: 0.529 - ETA: 0s - loss: 9.8877 - accuracy: 0.530 - ETA: 0s - loss: 8.9790 - accuracy: 0.53 - ETA: 0s - loss: 8.2521 - accuracy: 0.53 - ETA: 0s - loss: 7.6584 - accuracy: 0.53 - ETA: 0s - loss: 7.1279 - accuracy: 0.52 - ETA: 0s - loss: 6.6953 - accuracy: 0.52 - ETA: 0s - loss: 6.2746 - accuracy: 0.52 - ETA: 0s - loss: 5.9560 - accuracy: 0.52 - ETA: 0s - loss: 5.6224 - accuracy: 0.52 - ETA: 0s - loss: 5.6493 - accuracy: 0.52 - ETA: 0s - loss: 5.3782 - accuracy: 0.52 - ETA: 0s - loss: 5.1446 - accuracy: 0.52 - ETA: 0s - loss: 4.9735 - accuracy: 0.52 - ETA: 0s - loss: 4.7923 - accuracy: 0.52 - ETA: 0s - loss: 4.5904 - accuracy: 0.52 - 1s 2ms/step - loss: 4.5202 - accuracy: 0.5280 - val_loss: 0.7238 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.62 - ETA: 1s - loss: 0.7918 - accuracy: 0.53 - ETA: 1s - loss: 0.7431 - accuracy: 0.55 - ETA: 1s - loss: 0.7387 - accuracy: 0.55 - ETA: 0s - loss: 0.7358 - accuracy: 0.55 - ETA: 0s - loss: 0.7386 - accuracy: 0.55 - ETA: 0s - loss: 0.8012 - accuracy: 0.54 - ETA: 0s - loss: 0.7932 - accuracy: 0.54 - ETA: 0s - loss: 0.7961 - accuracy: 0.53 - ETA: 0s - loss: 0.7966 - accuracy: 0.53 - ETA: 0s - loss: 0.7923 - accuracy: 0.53 - ETA: 0s - loss: 0.7909 - accuracy: 0.53 - ETA: 0s - loss: 0.7884 - accuracy: 0.53 - ETA: 0s - loss: 0.7865 - accuracy: 0.52 - ETA: 0s - loss: 0.7882 - accuracy: 0.52 - ETA: 0s - loss: 0.7869 - accuracy: 0.52 - ETA: 0s - loss: 0.7840 - accuracy: 0.52 - ETA: 0s - loss: 0.7796 - accuracy: 0.52 - ETA: 0s - loss: 0.7762 - accuracy: 0.53 - ETA: 0s - loss: 0.7752 - accuracy: 0.53 - ETA: 0s - loss: 0.7715 - accuracy: 0.53 - ETA: 0s - loss: 0.7710 - accuracy: 0.53 - ETA: 0s - loss: 0.7754 - accuracy: 0.53 - ETA: 0s - loss: 0.7738 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7738 - accuracy: 0.5322 - val_loss: 1.8063 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.5049 - accuracy: 0.50 - ETA: 1s - loss: 0.7232 - accuracy: 0.56 - ETA: 1s - loss: 0.7415 - accuracy: 0.55 - ETA: 1s - loss: 0.7582 - accuracy: 0.54 - ETA: 1s - loss: 0.7876 - accuracy: 0.53 - ETA: 0s - loss: 0.7829 - accuracy: 0.52 - ETA: 0s - loss: 0.7726 - accuracy: 0.53 - ETA: 0s - loss: 0.7757 - accuracy: 0.53 - ETA: 0s - loss: 0.7725 - accuracy: 0.53 - ETA: 0s - loss: 0.7740 - accuracy: 0.53 - ETA: 0s - loss: 0.7731 - accuracy: 0.52 - ETA: 0s - loss: 0.7698 - accuracy: 0.52 - ETA: 0s - loss: 0.8014 - accuracy: 0.52 - ETA: 0s - loss: 0.7961 - accuracy: 0.53 - ETA: 0s - loss: 0.7948 - accuracy: 0.52 - ETA: 0s - loss: 0.7943 - accuracy: 0.52 - ETA: 0s - loss: 0.7960 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7910 - accuracy: 0.53 - ETA: 0s - loss: 0.7908 - accuracy: 0.53 - ETA: 0s - loss: 0.7926 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7939 - accuracy: 0.52 - ETA: 0s - loss: 0.7931 - accuracy: 0.52 - 1s 2ms/step - loss: 0.7926 - accuracy: 0.5257 - val_loss: 1.5704 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.6226 - accuracy: 0.37 - ETA: 1s - loss: 0.7855 - accuracy: 0.52 - ETA: 1s - loss: 0.7673 - accuracy: 0.52 - ETA: 1s - loss: 0.7626 - accuracy: 0.52 - ETA: 1s - loss: 0.7669 - accuracy: 0.52 - ETA: 0s - loss: 0.7653 - accuracy: 0.52 - ETA: 0s - loss: 0.7646 - accuracy: 0.53 - ETA: 0s - loss: 0.7616 - accuracy: 0.53 - ETA: 0s - loss: 0.7559 - accuracy: 0.53 - ETA: 0s - loss: 0.7524 - accuracy: 0.53 - ETA: 0s - loss: 0.7494 - accuracy: 0.53 - ETA: 0s - loss: 0.7479 - accuracy: 0.54 - ETA: 0s - loss: 0.7471 - accuracy: 0.53 - ETA: 0s - loss: 0.7463 - accuracy: 0.53 - ETA: 0s - loss: 0.7488 - accuracy: 0.53 - ETA: 0s - loss: 0.7511 - accuracy: 0.53 - ETA: 0s - loss: 0.7558 - accuracy: 0.53 - ETA: 0s - loss: 0.7567 - accuracy: 0.53 - ETA: 0s - loss: 0.7562 - accuracy: 0.53 - ETA: 0s - loss: 0.7544 - accuracy: 0.53 - ETA: 0s - loss: 0.7572 - accuracy: 0.53 - ETA: 0s - loss: 0.7563 - accuracy: 0.53 - ETA: 0s - loss: 0.7538 - accuracy: 0.53 - ETA: 0s - loss: 0.7532 - accuracy: 0.53 - ETA: 0s - loss: 0.7549 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7551 - accuracy: 0.5334 - val_loss: 1.3215 - val_accuracy: 0.3962\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9317 - accuracy: 0.59 - ETA: 1s - loss: 0.7485 - accuracy: 0.55 - ETA: 1s - loss: 0.7574 - accuracy: 0.54 - ETA: 0s - loss: 0.7621 - accuracy: 0.53 - ETA: 0s - loss: 0.7554 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7634 - accuracy: 0.53 - ETA: 0s - loss: 0.7681 - accuracy: 0.53 - ETA: 0s - loss: 0.7598 - accuracy: 0.53 - ETA: 0s - loss: 0.7595 - accuracy: 0.53 - ETA: 0s - loss: 0.7547 - accuracy: 0.53 - ETA: 0s - loss: 0.7554 - accuracy: 0.53 - ETA: 0s - loss: 0.7566 - accuracy: 0.53 - ETA: 0s - loss: 0.7578 - accuracy: 0.53 - ETA: 0s - loss: 0.7542 - accuracy: 0.53 - ETA: 0s - loss: 0.7567 - accuracy: 0.53 - ETA: 0s - loss: 0.7578 - accuracy: 0.53 - ETA: 0s - loss: 0.7580 - accuracy: 0.53 - ETA: 0s - loss: 0.7568 - accuracy: 0.53 - ETA: 0s - loss: 0.7574 - accuracy: 0.53 - ETA: 0s - loss: 0.7556 - accuracy: 0.53 - ETA: 0s - loss: 0.7618 - accuracy: 0.53 - ETA: 0s - loss: 0.7619 - accuracy: 0.53 - ETA: 0s - loss: 0.7613 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7628 - accuracy: 0.5344 - val_loss: 0.7190 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3d3482d6602d7d2b7ef8e3c0e62f8297</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 7.835673507014028</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.56 - ETA: 1s - loss: 4.8114 - accuracy: 0.50 - ETA: 1s - loss: 2.8769 - accuracy: 0.55 - ETA: 1s - loss: 2.1776 - accuracy: 0.55 - ETA: 1s - loss: 1.8237 - accuracy: 0.55 - ETA: 0s - loss: 1.5811 - accuracy: 0.55 - ETA: 0s - loss: 1.4249 - accuracy: 0.55 - ETA: 0s - loss: 1.3253 - accuracy: 0.55 - ETA: 0s - loss: 1.2472 - accuracy: 0.55 - ETA: 0s - loss: 1.1999 - accuracy: 0.55 - ETA: 0s - loss: 1.1489 - accuracy: 0.55 - ETA: 0s - loss: 1.1038 - accuracy: 0.55 - ETA: 0s - loss: 1.0672 - accuracy: 0.55 - ETA: 0s - loss: 1.0354 - accuracy: 0.56 - ETA: 0s - loss: 1.0131 - accuracy: 0.55 - ETA: 0s - loss: 0.9907 - accuracy: 0.55 - ETA: 0s - loss: 0.9709 - accuracy: 0.56 - ETA: 0s - loss: 0.9621 - accuracy: 0.56 - ETA: 0s - loss: 0.9480 - accuracy: 0.56 - ETA: 0s - loss: 0.9342 - accuracy: 0.56 - ETA: 0s - loss: 0.9216 - accuracy: 0.56 - ETA: 0s - loss: 0.9113 - accuracy: 0.56 - ETA: 0s - loss: 0.9016 - accuracy: 0.56 - ETA: 0s - loss: 0.8926 - accuracy: 0.56 - 1s 2ms/step - loss: 0.8912 - accuracy: 0.5696 - val_loss: 0.7124 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.68 - ETA: 1s - loss: 0.6681 - accuracy: 0.61 - ETA: 1s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6828 - accuracy: 0.58 - ETA: 0s - loss: 0.6802 - accuracy: 0.58 - ETA: 0s - loss: 0.6803 - accuracy: 0.58 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5677 - val_loss: 0.7112 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8482 - accuracy: 0.46 - ETA: 1s - loss: 0.6850 - accuracy: 0.58 - ETA: 1s - loss: 0.6894 - accuracy: 0.57 - ETA: 1s - loss: 0.6932 - accuracy: 0.56 - ETA: 0s - loss: 0.6932 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5711 - val_loss: 0.6902 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.62 - ETA: 1s - loss: 0.6848 - accuracy: 0.60 - ETA: 1s - loss: 0.6864 - accuracy: 0.58 - ETA: 1s - loss: 0.6873 - accuracy: 0.57 - ETA: 1s - loss: 0.6882 - accuracy: 0.56 - ETA: 0s - loss: 0.6884 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5658 - val_loss: 0.7106 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7838 - accuracy: 0.53 - ETA: 1s - loss: 0.6780 - accuracy: 0.60 - ETA: 1s - loss: 0.6853 - accuracy: 0.58 - ETA: 1s - loss: 0.6834 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5719 - val_loss: 0.7107 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.28 - ETA: 1s - loss: 6.6690 - accuracy: 0.55 - ETA: 1s - loss: 3.7156 - accuracy: 0.57 - ETA: 1s - loss: 2.7373 - accuracy: 0.56 - ETA: 1s - loss: 2.2593 - accuracy: 0.56 - ETA: 0s - loss: 1.9611 - accuracy: 0.56 - ETA: 0s - loss: 1.7587 - accuracy: 0.56 - ETA: 0s - loss: 1.6052 - accuracy: 0.56 - ETA: 0s - loss: 1.4864 - accuracy: 0.56 - ETA: 0s - loss: 1.4002 - accuracy: 0.56 - ETA: 0s - loss: 1.3329 - accuracy: 0.56 - ETA: 0s - loss: 1.2759 - accuracy: 0.56 - ETA: 0s - loss: 1.2267 - accuracy: 0.56 - ETA: 0s - loss: 1.1870 - accuracy: 0.56 - ETA: 0s - loss: 1.1510 - accuracy: 0.56 - ETA: 0s - loss: 1.1200 - accuracy: 0.56 - ETA: 0s - loss: 1.0922 - accuracy: 0.56 - ETA: 0s - loss: 1.0685 - accuracy: 0.56 - ETA: 0s - loss: 1.0454 - accuracy: 0.56 - ETA: 0s - loss: 1.0260 - accuracy: 0.56 - ETA: 0s - loss: 1.0085 - accuracy: 0.56 - ETA: 0s - loss: 0.9964 - accuracy: 0.56 - ETA: 0s - loss: 0.9819 - accuracy: 0.56 - ETA: 0s - loss: 0.9693 - accuracy: 0.56 - ETA: 0s - loss: 0.9571 - accuracy: 0.56 - 1s 2ms/step - loss: 0.9508 - accuracy: 0.5661 - val_loss: 0.9137 - val_accuracy: 0.3962\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9347 - accuracy: 0.37 - ETA: 1s - loss: 0.6879 - accuracy: 0.58 - ETA: 1s - loss: 0.6889 - accuracy: 0.56 - ETA: 1s - loss: 0.6862 - accuracy: 0.57 - ETA: 1s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6898 - accuracy: 0.5693 - val_loss: 0.9197 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9725 - accuracy: 0.34 - ETA: 1s - loss: 0.7012 - accuracy: 0.56 - ETA: 1s - loss: 0.6983 - accuracy: 0.55 - ETA: 1s - loss: 0.6945 - accuracy: 0.56 - ETA: 1s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6912 - accuracy: 0.57 - ETA: 0s - loss: 0.6912 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5682 - val_loss: 0.6924 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.68 - ETA: 1s - loss: 0.6798 - accuracy: 0.58 - ETA: 1s - loss: 0.6803 - accuracy: 0.57 - ETA: 1s - loss: 0.6865 - accuracy: 0.57 - ETA: 1s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6906 - accuracy: 0.5715 - val_loss: 0.6932 - val_accuracy: 0.3962\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.46 - ETA: 1s - loss: 0.6846 - accuracy: 0.59 - ETA: 1s - loss: 0.6907 - accuracy: 0.57 - ETA: 1s - loss: 0.6938 - accuracy: 0.56 - ETA: 1s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5677 - val_loss: 0.7104 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.1146 - accuracy: 0.40 - ETA: 1s - loss: 11.9880 - accuracy: 0.568 - ETA: 1s - loss: 6.1816 - accuracy: 0.549 - ETA: 1s - loss: 4.4995 - accuracy: 0.55 - ETA: 1s - loss: 3.4777 - accuracy: 0.56 - ETA: 0s - loss: 2.9398 - accuracy: 0.56 - ETA: 0s - loss: 2.5856 - accuracy: 0.56 - ETA: 0s - loss: 2.3085 - accuracy: 0.56 - ETA: 0s - loss: 2.1021 - accuracy: 0.56 - ETA: 0s - loss: 1.9556 - accuracy: 0.55 - ETA: 0s - loss: 1.8339 - accuracy: 0.55 - ETA: 0s - loss: 1.7267 - accuracy: 0.55 - ETA: 0s - loss: 1.6351 - accuracy: 0.55 - ETA: 0s - loss: 1.5604 - accuracy: 0.55 - ETA: 0s - loss: 1.5018 - accuracy: 0.55 - ETA: 0s - loss: 1.4465 - accuracy: 0.55 - ETA: 0s - loss: 1.4033 - accuracy: 0.55 - ETA: 0s - loss: 1.3595 - accuracy: 0.56 - ETA: 0s - loss: 1.3228 - accuracy: 0.56 - ETA: 0s - loss: 1.2894 - accuracy: 0.56 - ETA: 0s - loss: 1.2610 - accuracy: 0.56 - ETA: 0s - loss: 1.2322 - accuracy: 0.56 - ETA: 0s - loss: 1.2078 - accuracy: 0.56 - ETA: 0s - loss: 1.1851 - accuracy: 0.56 - ETA: 0s - loss: 1.1641 - accuracy: 0.56 - 1s 2ms/step - loss: 1.1565 - accuracy: 0.5652 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.59 - ETA: 1s - loss: 0.6878 - accuracy: 0.56 - ETA: 1s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6935 - accuracy: 0.55 - ETA: 0s - loss: 0.6923 - accuracy: 0.55 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5679 - val_loss: 0.6902 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.62 - ETA: 1s - loss: 0.6767 - accuracy: 0.59 - ETA: 1s - loss: 0.6840 - accuracy: 0.59 - ETA: 1s - loss: 0.6856 - accuracy: 0.58 - ETA: 1s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.56 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5689 - val_loss: 0.7106 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8153 - accuracy: 0.50 - ETA: 1s - loss: 0.6871 - accuracy: 0.58 - ETA: 1s - loss: 0.6923 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5699 - val_loss: 0.7127 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8833 - accuracy: 0.43 - ETA: 1s - loss: 0.6951 - accuracy: 0.56 - ETA: 1s - loss: 0.6925 - accuracy: 0.57 - ETA: 1s - loss: 0.6893 - accuracy: 0.58 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5667 - val_loss: 0.6933 - val_accuracy: 0.3960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3e68b6d2d15e304a028985d2cd653aa1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 4.0280620841683366</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.59 - ETA: 0s - loss: 0.7494 - accuracy: 0.57 - ETA: 0s - loss: 0.7132 - accuracy: 0.58 - ETA: 0s - loss: 0.7015 - accuracy: 0.59 - ETA: 0s - loss: 0.6927 - accuracy: 0.59 - ETA: 0s - loss: 0.6912 - accuracy: 0.59 - ETA: 0s - loss: 0.6899 - accuracy: 0.58 - ETA: 0s - loss: 0.6882 - accuracy: 0.59 - ETA: 0s - loss: 0.6868 - accuracy: 0.59 - ETA: 0s - loss: 0.6854 - accuracy: 0.59 - ETA: 0s - loss: 0.6843 - accuracy: 0.59 - ETA: 0s - loss: 0.6835 - accuracy: 0.59 - ETA: 0s - loss: 0.6831 - accuracy: 0.59 - ETA: 0s - loss: 0.6832 - accuracy: 0.59 - ETA: 0s - loss: 0.6827 - accuracy: 0.59 - ETA: 0s - loss: 0.6824 - accuracy: 0.59 - ETA: 0s - loss: 0.6820 - accuracy: 0.59 - ETA: 0s - loss: 0.6819 - accuracy: 0.59 - ETA: 0s - loss: 0.6818 - accuracy: 0.59 - ETA: 0s - loss: 0.6815 - accuracy: 0.59 - ETA: 0s - loss: 0.6812 - accuracy: 0.59 - ETA: 0s - loss: 0.6813 - accuracy: 0.59 - ETA: 0s - loss: 0.6809 - accuracy: 0.59 - ETA: 0s - loss: 0.6807 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6807 - accuracy: 0.5924 - val_loss: 0.6799 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.68 - ETA: 1s - loss: 0.6729 - accuracy: 0.60 - ETA: 1s - loss: 0.6739 - accuracy: 0.60 - ETA: 1s - loss: 0.6780 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6741 - accuracy: 0.60 - ETA: 0s - loss: 0.6736 - accuracy: 0.60 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6744 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6743 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6748 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6751 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6816 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.75 - ETA: 1s - loss: 0.6759 - accuracy: 0.60 - ETA: 1s - loss: 0.6786 - accuracy: 0.59 - ETA: 1s - loss: 0.6801 - accuracy: 0.58 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 0s - loss: 0.6796 - accuracy: 0.58 - ETA: 0s - loss: 0.6793 - accuracy: 0.58 - ETA: 0s - loss: 0.6790 - accuracy: 0.58 - ETA: 0s - loss: 0.6789 - accuracy: 0.58 - ETA: 0s - loss: 0.6781 - accuracy: 0.59 - ETA: 0s - loss: 0.6785 - accuracy: 0.58 - ETA: 0s - loss: 0.6785 - accuracy: 0.58 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6771 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7033 - accuracy: 0.53 - ETA: 1s - loss: 0.6757 - accuracy: 0.59 - ETA: 1s - loss: 0.6777 - accuracy: 0.58 - ETA: 1s - loss: 0.6783 - accuracy: 0.58 - ETA: 1s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6779 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6786 - accuracy: 0.58 - ETA: 0s - loss: 0.6784 - accuracy: 0.58 - ETA: 0s - loss: 0.6782 - accuracy: 0.58 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.78 - ETA: 1s - loss: 0.6654 - accuracy: 0.62 - ETA: 1s - loss: 0.6750 - accuracy: 0.59 - ETA: 1s - loss: 0.6736 - accuracy: 0.60 - ETA: 1s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7609 - accuracy: 0.43 - ETA: 1s - loss: 0.8527 - accuracy: 0.58 - ETA: 1s - loss: 0.7676 - accuracy: 0.59 - ETA: 1s - loss: 0.7395 - accuracy: 0.58 - ETA: 0s - loss: 0.7233 - accuracy: 0.59 - ETA: 0s - loss: 0.7147 - accuracy: 0.58 - ETA: 0s - loss: 0.7060 - accuracy: 0.59 - ETA: 0s - loss: 0.7028 - accuracy: 0.59 - ETA: 0s - loss: 0.6998 - accuracy: 0.59 - ETA: 0s - loss: 0.6977 - accuracy: 0.59 - ETA: 0s - loss: 0.6955 - accuracy: 0.59 - ETA: 0s - loss: 0.6944 - accuracy: 0.59 - ETA: 0s - loss: 0.6924 - accuracy: 0.59 - ETA: 0s - loss: 0.6907 - accuracy: 0.59 - ETA: 0s - loss: 0.6896 - accuracy: 0.59 - ETA: 0s - loss: 0.6891 - accuracy: 0.59 - ETA: 0s - loss: 0.6884 - accuracy: 0.59 - ETA: 0s - loss: 0.6883 - accuracy: 0.59 - ETA: 0s - loss: 0.6875 - accuracy: 0.59 - ETA: 0s - loss: 0.6870 - accuracy: 0.59 - ETA: 0s - loss: 0.6860 - accuracy: 0.59 - ETA: 0s - loss: 0.6862 - accuracy: 0.59 - ETA: 0s - loss: 0.6860 - accuracy: 0.59 - ETA: 0s - loss: 0.6855 - accuracy: 0.59 - ETA: 0s - loss: 0.6850 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5924 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.50 - ETA: 1s - loss: 0.6802 - accuracy: 0.58 - ETA: 1s - loss: 0.6766 - accuracy: 0.59 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 1s - loss: 0.6783 - accuracy: 0.58 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6757 - accuracy: 0.59 - ETA: 0s - loss: 0.6751 - accuracy: 0.59 - ETA: 0s - loss: 0.6753 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6716 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 1s - loss: 0.6682 - accuracy: 0.61 - ETA: 1s - loss: 0.6775 - accuracy: 0.58 - ETA: 1s - loss: 0.6778 - accuracy: 0.58 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6749 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.68 - ETA: 1s - loss: 0.6679 - accuracy: 0.61 - ETA: 1s - loss: 0.6752 - accuracy: 0.59 - ETA: 1s - loss: 0.6751 - accuracy: 0.59 - ETA: 1s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.75 - ETA: 1s - loss: 0.6788 - accuracy: 0.59 - ETA: 1s - loss: 0.6804 - accuracy: 0.58 - ETA: 1s - loss: 0.6788 - accuracy: 0.58 - ETA: 1s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6737 - accuracy: 0.59 - ETA: 0s - loss: 0.6742 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6754 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6719 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.62 - ETA: 1s - loss: 0.9888 - accuracy: 0.57 - ETA: 1s - loss: 0.8353 - accuracy: 0.58 - ETA: 0s - loss: 0.7834 - accuracy: 0.58 - ETA: 0s - loss: 0.7597 - accuracy: 0.58 - ETA: 0s - loss: 0.7451 - accuracy: 0.58 - ETA: 0s - loss: 0.7345 - accuracy: 0.58 - ETA: 0s - loss: 0.7265 - accuracy: 0.58 - ETA: 0s - loss: 0.7209 - accuracy: 0.58 - ETA: 0s - loss: 0.7169 - accuracy: 0.58 - ETA: 0s - loss: 0.7131 - accuracy: 0.58 - ETA: 0s - loss: 0.7096 - accuracy: 0.58 - ETA: 0s - loss: 0.7068 - accuracy: 0.58 - ETA: 0s - loss: 0.7047 - accuracy: 0.58 - ETA: 0s - loss: 0.7029 - accuracy: 0.58 - ETA: 0s - loss: 0.7008 - accuracy: 0.58 - ETA: 0s - loss: 0.6989 - accuracy: 0.59 - ETA: 0s - loss: 0.6982 - accuracy: 0.58 - ETA: 0s - loss: 0.6976 - accuracy: 0.58 - ETA: 0s - loss: 0.6959 - accuracy: 0.58 - ETA: 0s - loss: 0.6944 - accuracy: 0.59 - ETA: 0s - loss: 0.6935 - accuracy: 0.59 - ETA: 0s - loss: 0.6926 - accuracy: 0.59 - ETA: 0s - loss: 0.6918 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5921 - val_loss: 0.6727 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6288 - accuracy: 0.68 - ETA: 1s - loss: 0.6813 - accuracy: 0.58 - ETA: 1s - loss: 0.6717 - accuracy: 0.60 - ETA: 1s - loss: 0.6721 - accuracy: 0.60 - ETA: 0s - loss: 0.6733 - accuracy: 0.60 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6756 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5927 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.56 - ETA: 1s - loss: 0.6836 - accuracy: 0.57 - ETA: 1s - loss: 0.6814 - accuracy: 0.58 - ETA: 1s - loss: 0.6799 - accuracy: 0.58 - ETA: 1s - loss: 0.6789 - accuracy: 0.58 - ETA: 0s - loss: 0.6802 - accuracy: 0.58 - ETA: 0s - loss: 0.6793 - accuracy: 0.58 - ETA: 0s - loss: 0.6784 - accuracy: 0.59 - ETA: 0s - loss: 0.6782 - accuracy: 0.59 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6753 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5929 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.71 - ETA: 1s - loss: 0.6766 - accuracy: 0.59 - ETA: 1s - loss: 0.6794 - accuracy: 0.58 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 1s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6757 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7509 - accuracy: 0.40 - ETA: 1s - loss: 0.6796 - accuracy: 0.58 - ETA: 1s - loss: 0.6781 - accuracy: 0.59 - ETA: 1s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6754 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6731 - accuracy: 0.60 - ETA: 0s - loss: 0.6735 - accuracy: 0.60 - ETA: 0s - loss: 0.6741 - accuracy: 0.60 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6749 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6733 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2e718f4b3965c573b66000c6c8ae9e7c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.5210515631262526</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.53 - ETA: 1s - loss: 129.4386 - accuracy: 0.58 - ETA: 1s - loss: 69.5942 - accuracy: 0.5814 - ETA: 1s - loss: 46.4181 - accuracy: 0.563 - ETA: 0s - loss: 34.6711 - accuracy: 0.564 - ETA: 0s - loss: 28.1818 - accuracy: 0.563 - ETA: 0s - loss: 23.6628 - accuracy: 0.568 - ETA: 0s - loss: 20.5813 - accuracy: 0.570 - ETA: 0s - loss: 17.9823 - accuracy: 0.570 - ETA: 0s - loss: 16.0805 - accuracy: 0.565 - ETA: 0s - loss: 14.5153 - accuracy: 0.565 - ETA: 0s - loss: 13.2129 - accuracy: 0.568 - ETA: 0s - loss: 12.1573 - accuracy: 0.566 - ETA: 0s - loss: 11.2890 - accuracy: 0.565 - ETA: 0s - loss: 10.6224 - accuracy: 0.566 - ETA: 0s - loss: 9.9314 - accuracy: 0.565 - ETA: 0s - loss: 9.4058 - accuracy: 0.56 - ETA: 0s - loss: 8.8949 - accuracy: 0.56 - ETA: 0s - loss: 8.4532 - accuracy: 0.56 - ETA: 0s - loss: 8.0570 - accuracy: 0.56 - ETA: 0s - loss: 7.6990 - accuracy: 0.56 - ETA: 0s - loss: 7.3558 - accuracy: 0.56 - ETA: 0s - loss: 7.0612 - accuracy: 0.56 - ETA: 0s - loss: 6.7840 - accuracy: 0.56 - 1s 2ms/step - loss: 6.6060 - accuracy: 0.5632 - val_loss: 0.7306 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7783 - accuracy: 0.56 - ETA: 1s - loss: 0.6951 - accuracy: 0.55 - ETA: 1s - loss: 0.6912 - accuracy: 0.56 - ETA: 1s - loss: 0.6947 - accuracy: 0.56 - ETA: 1s - loss: 0.6972 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6950 - accuracy: 0.55 - ETA: 0s - loss: 0.6957 - accuracy: 0.55 - ETA: 0s - loss: 0.6966 - accuracy: 0.55 - ETA: 0s - loss: 0.6954 - accuracy: 0.55 - ETA: 0s - loss: 0.6963 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6951 - accuracy: 0.55 - ETA: 0s - loss: 0.6952 - accuracy: 0.55 - ETA: 0s - loss: 0.6970 - accuracy: 0.55 - ETA: 0s - loss: 0.6972 - accuracy: 0.55 - ETA: 0s - loss: 0.6969 - accuracy: 0.55 - ETA: 0s - loss: 0.6965 - accuracy: 0.55 - ETA: 0s - loss: 0.6956 - accuracy: 0.55 - ETA: 0s - loss: 0.6955 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6950 - accuracy: 0.55 - 1s 2ms/step - loss: 0.6954 - accuracy: 0.5572 - val_loss: 0.6923 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 1s - loss: 0.6972 - accuracy: 0.56 - ETA: 1s - loss: 0.6950 - accuracy: 0.56 - ETA: 1s - loss: 0.6926 - accuracy: 0.56 - ETA: 1s - loss: 0.6945 - accuracy: 0.55 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.7020 - accuracy: 0.55 - ETA: 0s - loss: 0.7008 - accuracy: 0.55 - ETA: 0s - loss: 0.6998 - accuracy: 0.55 - ETA: 0s - loss: 0.6974 - accuracy: 0.56 - ETA: 0s - loss: 0.6953 - accuracy: 0.56 - ETA: 0s - loss: 0.6958 - accuracy: 0.56 - ETA: 0s - loss: 0.6951 - accuracy: 0.56 - ETA: 0s - loss: 0.6942 - accuracy: 0.56 - ETA: 0s - loss: 0.6941 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6942 - accuracy: 0.56 - ETA: 0s - loss: 0.6943 - accuracy: 0.56 - ETA: 0s - loss: 0.6939 - accuracy: 0.56 - ETA: 0s - loss: 0.6940 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5624 - val_loss: 0.6940 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.37 - ETA: 1s - loss: 0.6873 - accuracy: 0.58 - ETA: 1s - loss: 0.6858 - accuracy: 0.57 - ETA: 1s - loss: 0.6881 - accuracy: 0.57 - ETA: 1s - loss: 0.6915 - accuracy: 0.55 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.56 - ETA: 0s - loss: 0.6879 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.56 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6894 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5672 - val_loss: 33.8894 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 37.4407 - accuracy: 0.562 - ETA: 1s - loss: 1.7389 - accuracy: 0.565 - ETA: 1s - loss: 1.1906 - accuracy: 0.57 - ETA: 1s - loss: 1.0311 - accuracy: 0.55 - ETA: 0s - loss: 0.9494 - accuracy: 0.56 - ETA: 0s - loss: 0.9012 - accuracy: 0.56 - ETA: 0s - loss: 0.8674 - accuracy: 0.56 - ETA: 0s - loss: 0.8414 - accuracy: 0.57 - ETA: 0s - loss: 0.8227 - accuracy: 0.57 - ETA: 0s - loss: 0.8077 - accuracy: 0.57 - ETA: 0s - loss: 0.7972 - accuracy: 0.56 - ETA: 0s - loss: 0.7869 - accuracy: 0.57 - ETA: 0s - loss: 0.7792 - accuracy: 0.57 - ETA: 0s - loss: 0.7719 - accuracy: 0.57 - ETA: 0s - loss: 0.7668 - accuracy: 0.56 - ETA: 0s - loss: 0.7618 - accuracy: 0.57 - ETA: 0s - loss: 0.7578 - accuracy: 0.56 - ETA: 0s - loss: 0.7541 - accuracy: 0.56 - ETA: 0s - loss: 0.7508 - accuracy: 0.56 - ETA: 0s - loss: 0.7483 - accuracy: 0.56 - ETA: 0s - loss: 0.7455 - accuracy: 0.56 - ETA: 0s - loss: 0.7430 - accuracy: 0.56 - ETA: 0s - loss: 0.7402 - accuracy: 0.56 - ETA: 0s - loss: 0.7381 - accuracy: 0.56 - ETA: 0s - loss: 0.7359 - accuracy: 0.56 - 1s 2ms/step - loss: 0.7355 - accuracy: 0.5683 - val_loss: 0.9401 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8039 - accuracy: 0.50 - ETA: 1s - loss: 37.2861 - accuracy: 0.546 - ETA: 1s - loss: 19.2907 - accuracy: 0.563 - ETA: 1s - loss: 13.0343 - accuracy: 0.569 - ETA: 1s - loss: 10.1326 - accuracy: 0.562 - ETA: 1s - loss: 8.3341 - accuracy: 0.560 - ETA: 0s - loss: 7.1106 - accuracy: 0.56 - ETA: 0s - loss: 6.1782 - accuracy: 0.56 - ETA: 0s - loss: 5.4649 - accuracy: 0.56 - ETA: 0s - loss: 4.9149 - accuracy: 0.56 - ETA: 0s - loss: 4.4793 - accuracy: 0.56 - ETA: 0s - loss: 4.1242 - accuracy: 0.56 - ETA: 0s - loss: 3.8317 - accuracy: 0.56 - ETA: 0s - loss: 3.5976 - accuracy: 0.56 - ETA: 0s - loss: 3.3895 - accuracy: 0.56 - ETA: 0s - loss: 3.2082 - accuracy: 0.56 - ETA: 0s - loss: 3.0507 - accuracy: 0.56 - ETA: 0s - loss: 2.9156 - accuracy: 0.57 - ETA: 0s - loss: 2.7751 - accuracy: 0.56 - ETA: 0s - loss: 2.6694 - accuracy: 0.56 - ETA: 0s - loss: 2.5739 - accuracy: 0.56 - ETA: 0s - loss: 2.4922 - accuracy: 0.56 - ETA: 0s - loss: 2.4149 - accuracy: 0.56 - ETA: 0s - loss: 2.3334 - accuracy: 0.56 - ETA: 0s - loss: 2.2674 - accuracy: 0.56 - 1s 2ms/step - loss: 2.2446 - accuracy: 0.5667 - val_loss: 0.7157 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.65 - ETA: 1s - loss: 0.6795 - accuracy: 0.59 - ETA: 1s - loss: 0.6875 - accuracy: 0.57 - ETA: 1s - loss: 0.6866 - accuracy: 0.57 - ETA: 1s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.58 - ETA: 0s - loss: 0.6866 - accuracy: 0.58 - ETA: 0s - loss: 0.6864 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6891 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5672 - val_loss: 0.7225 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8706 - accuracy: 0.46 - ETA: 1s - loss: 0.6806 - accuracy: 0.60 - ETA: 1s - loss: 0.6890 - accuracy: 0.56 - ETA: 1s - loss: 0.6925 - accuracy: 0.56 - ETA: 1s - loss: 0.6907 - accuracy: 0.57 - ETA: 1s - loss: 0.6880 - accuracy: 0.58 - ETA: 0s - loss: 0.6876 - accuracy: 0.58 - ETA: 0s - loss: 0.6871 - accuracy: 0.58 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6863 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.56 - ETA: 0s - loss: 0.6889 - accuracy: 0.56 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5698 - val_loss: 0.9378 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.0878 - accuracy: 0.53 - ETA: 1s - loss: 0.7048 - accuracy: 0.54 - ETA: 1s - loss: 0.6998 - accuracy: 0.55 - ETA: 1s - loss: 0.6995 - accuracy: 0.54 - ETA: 1s - loss: 0.6983 - accuracy: 0.54 - ETA: 1s - loss: 0.6960 - accuracy: 0.54 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6912 - accuracy: 0.55 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6899 - accuracy: 0.56 - ETA: 0s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5624 - val_loss: 0.9374 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8292 - accuracy: 0.65 - ETA: 1s - loss: 0.6958 - accuracy: 0.57 - ETA: 1s - loss: 0.6919 - accuracy: 0.57 - ETA: 1s - loss: 0.6918 - accuracy: 0.57 - ETA: 1s - loss: 0.6919 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6926 - accuracy: 0.55 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6923 - accuracy: 0.55 - ETA: 0s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6934 - accuracy: 0.55 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6935 - accuracy: 0.55 - ETA: 0s - loss: 0.6947 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6943 - accuracy: 0.55 - ETA: 0s - loss: 0.6941 - accuracy: 0.55 - ETA: 0s - loss: 0.6931 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5627 - val_loss: 0.7132 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7317 - accuracy: 0.50 - ETA: 1s - loss: 11.3495 - accuracy: 0.536 - ETA: 1s - loss: 6.3984 - accuracy: 0.537 - ETA: 1s - loss: 4.4460 - accuracy: 0.54 - ETA: 0s - loss: 3.5711 - accuracy: 0.53 - ETA: 0s - loss: 3.0405 - accuracy: 0.54 - ETA: 0s - loss: 2.6855 - accuracy: 0.54 - ETA: 0s - loss: 2.3903 - accuracy: 0.54 - ETA: 0s - loss: 2.1854 - accuracy: 0.54 - ETA: 0s - loss: 2.0291 - accuracy: 0.55 - ETA: 0s - loss: 1.8990 - accuracy: 0.55 - ETA: 0s - loss: 1.7863 - accuracy: 0.55 - ETA: 0s - loss: 1.6947 - accuracy: 0.55 - ETA: 0s - loss: 1.6185 - accuracy: 0.55 - ETA: 0s - loss: 1.5546 - accuracy: 0.55 - ETA: 0s - loss: 1.4956 - accuracy: 0.55 - ETA: 0s - loss: 1.4487 - accuracy: 0.55 - ETA: 0s - loss: 1.4043 - accuracy: 0.56 - ETA: 0s - loss: 1.3641 - accuracy: 0.55 - ETA: 0s - loss: 1.3282 - accuracy: 0.56 - ETA: 0s - loss: 1.2976 - accuracy: 0.55 - ETA: 0s - loss: 1.2693 - accuracy: 0.56 - ETA: 0s - loss: 1.2406 - accuracy: 0.56 - ETA: 0s - loss: 1.2176 - accuracy: 0.56 - ETA: 0s - loss: 1.1968 - accuracy: 0.56 - 1s 2ms/step - loss: 1.1900 - accuracy: 0.5611 - val_loss: 0.9374 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.62 - ETA: 1s - loss: 0.6998 - accuracy: 0.54 - ETA: 1s - loss: 0.6911 - accuracy: 0.56 - ETA: 1s - loss: 0.6904 - accuracy: 0.57 - ETA: 1s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6967 - accuracy: 0.55 - ETA: 0s - loss: 0.6974 - accuracy: 0.55 - ETA: 0s - loss: 0.6953 - accuracy: 0.55 - ETA: 0s - loss: 0.6939 - accuracy: 0.56 - ETA: 0s - loss: 0.6933 - accuracy: 0.56 - ETA: 0s - loss: 0.6931 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6936 - accuracy: 0.55 - ETA: 0s - loss: 0.6930 - accuracy: 0.56 - ETA: 0s - loss: 0.6945 - accuracy: 0.55 - ETA: 0s - loss: 0.6938 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6933 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6947 - accuracy: 0.55 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5594 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.65 - ETA: 1s - loss: 0.6855 - accuracy: 0.57 - ETA: 1s - loss: 0.6848 - accuracy: 0.57 - ETA: 1s - loss: 0.6935 - accuracy: 0.56 - ETA: 1s - loss: 0.6950 - accuracy: 0.56 - ETA: 0s - loss: 0.6961 - accuracy: 0.55 - ETA: 0s - loss: 0.6973 - accuracy: 0.55 - ETA: 0s - loss: 0.6978 - accuracy: 0.55 - ETA: 0s - loss: 0.6955 - accuracy: 0.55 - ETA: 0s - loss: 0.7112 - accuracy: 0.55 - ETA: 0s - loss: 0.7077 - accuracy: 0.56 - ETA: 0s - loss: 0.7068 - accuracy: 0.56 - ETA: 0s - loss: 0.7047 - accuracy: 0.56 - ETA: 0s - loss: 0.7042 - accuracy: 0.56 - ETA: 0s - loss: 0.7024 - accuracy: 0.56 - ETA: 0s - loss: 0.7014 - accuracy: 0.56 - ETA: 0s - loss: 0.7013 - accuracy: 0.56 - ETA: 0s - loss: 0.7015 - accuracy: 0.56 - ETA: 0s - loss: 0.7017 - accuracy: 0.56 - ETA: 0s - loss: 0.7015 - accuracy: 0.56 - ETA: 0s - loss: 0.7007 - accuracy: 0.56 - ETA: 0s - loss: 0.7004 - accuracy: 0.56 - ETA: 0s - loss: 0.6995 - accuracy: 0.56 - ETA: 0s - loss: 0.6985 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6989 - accuracy: 0.5648 - val_loss: 0.7132 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.62 - ETA: 1s - loss: 0.7035 - accuracy: 0.55 - ETA: 1s - loss: 0.6968 - accuracy: 0.56 - ETA: 1s - loss: 0.6979 - accuracy: 0.55 - ETA: 0s - loss: 0.6973 - accuracy: 0.54 - ETA: 0s - loss: 0.6930 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6938 - accuracy: 0.55 - ETA: 0s - loss: 0.6930 - accuracy: 0.55 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5626 - val_loss: 0.6941 - val_accuracy: 0.3960\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.46 - ETA: 1s - loss: 0.6964 - accuracy: 0.55 - ETA: 1s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5632 - val_loss: 0.6934 - val_accuracy: 0.3960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 37fbbe9491e17456b0a25398cfd9a2ef</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 4.148302444889779</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.59 - ETA: 1s - loss: 3.4077 - accuracy: 0.56 - ETA: 1s - loss: 2.1770 - accuracy: 0.56 - ETA: 1s - loss: 1.6833 - accuracy: 0.57 - ETA: 0s - loss: 1.4409 - accuracy: 0.57 - ETA: 0s - loss: 1.2902 - accuracy: 0.57 - ETA: 0s - loss: 1.1853 - accuracy: 0.57 - ETA: 0s - loss: 1.1163 - accuracy: 0.57 - ETA: 0s - loss: 1.0637 - accuracy: 0.57 - ETA: 0s - loss: 1.0239 - accuracy: 0.57 - ETA: 0s - loss: 0.9904 - accuracy: 0.57 - ETA: 0s - loss: 0.9643 - accuracy: 0.57 - ETA: 0s - loss: 0.9409 - accuracy: 0.57 - ETA: 0s - loss: 0.9223 - accuracy: 0.56 - ETA: 0s - loss: 0.9046 - accuracy: 0.56 - ETA: 0s - loss: 0.8909 - accuracy: 0.56 - ETA: 0s - loss: 0.8793 - accuracy: 0.56 - ETA: 0s - loss: 0.8692 - accuracy: 0.56 - ETA: 0s - loss: 0.8584 - accuracy: 0.57 - ETA: 0s - loss: 0.8498 - accuracy: 0.57 - ETA: 0s - loss: 0.8417 - accuracy: 0.57 - ETA: 0s - loss: 0.8353 - accuracy: 0.57 - ETA: 0s - loss: 0.8281 - accuracy: 0.57 - ETA: 0s - loss: 0.8221 - accuracy: 0.57 - 1s 2ms/step - loss: 0.8213 - accuracy: 0.5730 - val_loss: 0.6909 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.53 - ETA: 1s - loss: 0.6785 - accuracy: 0.59 - ETA: 1s - loss: 0.6838 - accuracy: 0.58 - ETA: 1s - loss: 0.6843 - accuracy: 0.58 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.56 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6941 - accuracy: 0.56 - ETA: 0s - loss: 0.6949 - accuracy: 0.56 - ETA: 0s - loss: 0.6943 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5711 - val_loss: 0.6873 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.65 - ETA: 1s - loss: 0.6892 - accuracy: 0.59 - ETA: 1s - loss: 0.6902 - accuracy: 0.57 - ETA: 1s - loss: 0.6902 - accuracy: 0.56 - ETA: 1s - loss: 0.6887 - accuracy: 0.56 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5748 - val_loss: 0.6850 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6723 - accuracy: 0.75 - ETA: 1s - loss: 0.6894 - accuracy: 0.57 - ETA: 1s - loss: 0.6892 - accuracy: 0.57 - ETA: 1s - loss: 0.6889 - accuracy: 0.57 - ETA: 1s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6846 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6856 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5755 - val_loss: 0.6941 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.62 - ETA: 1s - loss: 0.6961 - accuracy: 0.57 - ETA: 1s - loss: 0.6892 - accuracy: 0.57 - ETA: 1s - loss: 0.6863 - accuracy: 0.58 - ETA: 1s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5740 - val_loss: 0.8312 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.68 - ETA: 1s - loss: 4.6411 - accuracy: 0.54 - ETA: 1s - loss: 2.8259 - accuracy: 0.55 - ETA: 0s - loss: 2.1241 - accuracy: 0.56 - ETA: 0s - loss: 1.7918 - accuracy: 0.56 - ETA: 0s - loss: 1.5689 - accuracy: 0.57 - ETA: 0s - loss: 1.4481 - accuracy: 0.57 - ETA: 0s - loss: 1.3416 - accuracy: 0.56 - ETA: 0s - loss: 1.2630 - accuracy: 0.57 - ETA: 0s - loss: 1.2078 - accuracy: 0.57 - ETA: 0s - loss: 1.1601 - accuracy: 0.57 - ETA: 0s - loss: 1.1196 - accuracy: 0.57 - ETA: 0s - loss: 1.0856 - accuracy: 0.57 - ETA: 0s - loss: 1.0573 - accuracy: 0.57 - ETA: 0s - loss: 1.0320 - accuracy: 0.57 - ETA: 0s - loss: 1.0099 - accuracy: 0.57 - ETA: 0s - loss: 0.9914 - accuracy: 0.57 - ETA: 0s - loss: 0.9747 - accuracy: 0.57 - ETA: 0s - loss: 0.9585 - accuracy: 0.57 - ETA: 0s - loss: 0.9448 - accuracy: 0.57 - ETA: 0s - loss: 0.9316 - accuracy: 0.57 - ETA: 0s - loss: 0.9204 - accuracy: 0.57 - ETA: 0s - loss: 0.9099 - accuracy: 0.57 - ETA: 0s - loss: 0.9001 - accuracy: 0.57 - ETA: 0s - loss: 0.8920 - accuracy: 0.57 - 1s 2ms/step - loss: 0.8918 - accuracy: 0.5758 - val_loss: 0.6846 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.68 - ETA: 1s - loss: 0.6881 - accuracy: 0.56 - ETA: 1s - loss: 0.6819 - accuracy: 0.58 - ETA: 1s - loss: 0.6827 - accuracy: 0.58 - ETA: 1s - loss: 0.6823 - accuracy: 0.59 - ETA: 0s - loss: 0.6844 - accuracy: 0.58 - ETA: 0s - loss: 0.6854 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.58 - ETA: 0s - loss: 0.6847 - accuracy: 0.58 - ETA: 0s - loss: 0.6854 - accuracy: 0.58 - ETA: 0s - loss: 0.6864 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6858 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.58 - ETA: 0s - loss: 0.6855 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5769 - val_loss: 0.7061 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7463 - accuracy: 0.56 - ETA: 1s - loss: 0.6901 - accuracy: 0.55 - ETA: 1s - loss: 0.6842 - accuracy: 0.57 - ETA: 1s - loss: 0.6816 - accuracy: 0.58 - ETA: 1s - loss: 0.6815 - accuracy: 0.58 - ETA: 0s - loss: 0.6841 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.56 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6844 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6843 - accuracy: 0.57 - ETA: 0s - loss: 0.6840 - accuracy: 0.57 - ETA: 0s - loss: 0.6846 - accuracy: 0.57 - ETA: 0s - loss: 0.6851 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5726 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.62 - ETA: 1s - loss: 0.6888 - accuracy: 0.55 - ETA: 1s - loss: 0.6869 - accuracy: 0.55 - ETA: 1s - loss: 0.6825 - accuracy: 0.56 - ETA: 1s - loss: 0.6854 - accuracy: 0.56 - ETA: 1s - loss: 0.6869 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6871 - accuracy: 0.56 - ETA: 0s - loss: 0.6881 - accuracy: 0.56 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.56 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6881 - accuracy: 0.56 - ETA: 0s - loss: 0.6872 - accuracy: 0.56 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5729 - val_loss: 0.8403 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8574 - accuracy: 0.59 - ETA: 1s - loss: 0.6780 - accuracy: 0.59 - ETA: 1s - loss: 0.6806 - accuracy: 0.59 - ETA: 1s - loss: 0.6813 - accuracy: 0.59 - ETA: 0s - loss: 0.6833 - accuracy: 0.59 - ETA: 0s - loss: 0.6818 - accuracy: 0.59 - ETA: 0s - loss: 0.6815 - accuracy: 0.59 - ETA: 0s - loss: 0.6838 - accuracy: 0.58 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6851 - accuracy: 0.58 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5733 - val_loss: 0.7059 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.46 - ETA: 1s - loss: 3.2013 - accuracy: 0.53 - ETA: 1s - loss: 1.9756 - accuracy: 0.55 - ETA: 1s - loss: 1.5774 - accuracy: 0.56 - ETA: 1s - loss: 1.3652 - accuracy: 0.55 - ETA: 0s - loss: 1.2262 - accuracy: 0.55 - ETA: 0s - loss: 1.1312 - accuracy: 0.56 - ETA: 0s - loss: 1.0752 - accuracy: 0.57 - ETA: 0s - loss: 1.0232 - accuracy: 0.57 - ETA: 0s - loss: 0.9827 - accuracy: 0.57 - ETA: 0s - loss: 0.9544 - accuracy: 0.57 - ETA: 0s - loss: 0.9305 - accuracy: 0.57 - ETA: 0s - loss: 0.9101 - accuracy: 0.57 - ETA: 0s - loss: 0.8929 - accuracy: 0.57 - ETA: 0s - loss: 0.8782 - accuracy: 0.57 - ETA: 0s - loss: 0.8650 - accuracy: 0.57 - ETA: 0s - loss: 0.8538 - accuracy: 0.57 - ETA: 0s - loss: 0.8440 - accuracy: 0.57 - ETA: 0s - loss: 0.8350 - accuracy: 0.57 - ETA: 0s - loss: 0.8261 - accuracy: 0.57 - ETA: 0s - loss: 0.8195 - accuracy: 0.57 - ETA: 0s - loss: 0.8131 - accuracy: 0.57 - ETA: 0s - loss: 0.8070 - accuracy: 0.57 - ETA: 0s - loss: 0.8024 - accuracy: 0.57 - 1s 2ms/step - loss: 0.7988 - accuracy: 0.5757 - val_loss: 0.6941 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.62 - ETA: 1s - loss: 0.6828 - accuracy: 0.59 - ETA: 1s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.56 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5771 - val_loss: 0.6946 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.62 - ETA: 1s - loss: 0.6731 - accuracy: 0.61 - ETA: 1s - loss: 0.6824 - accuracy: 0.58 - ETA: 1s - loss: 0.6814 - accuracy: 0.58 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6847 - accuracy: 0.57 - ETA: 0s - loss: 0.6845 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6851 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6863 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5723 - val_loss: 0.6897 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.75 - ETA: 1s - loss: 0.6821 - accuracy: 0.56 - ETA: 1s - loss: 0.6852 - accuracy: 0.56 - ETA: 1s - loss: 0.6867 - accuracy: 0.56 - ETA: 1s - loss: 0.6867 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6854 - accuracy: 0.57 - ETA: 0s - loss: 0.6844 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6848 - accuracy: 0.57 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6916 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5774 - val_loss: 0.7030 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7422 - accuracy: 0.56 - ETA: 1s - loss: 0.7002 - accuracy: 0.56 - ETA: 1s - loss: 0.6956 - accuracy: 0.57 - ETA: 1s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.58 - ETA: 0s - loss: 0.6861 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6948 - accuracy: 0.57 - ETA: 0s - loss: 0.6951 - accuracy: 0.57 - ETA: 0s - loss: 0.6954 - accuracy: 0.57 - ETA: 0s - loss: 0.6953 - accuracy: 0.57 - ETA: 0s - loss: 0.6952 - accuracy: 0.57 - ETA: 0s - loss: 0.6949 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5723 - val_loss: 0.6916 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d4210bc23e147226bbbf82e487a3a8f3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 3.32665997995992</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1074dcd520>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f1074dcd880>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(keras.Sequential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units = 303, input_shape = (769,), activation = 'relu'),\n",
    "    keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 64, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 32, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 16, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 1, activation = 'sigmoid') # here the units must be 1 in order for binary classifications to work\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 303)               233310    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               77824     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 354,911\n",
      "Trainable params: 354,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(lr=0.000959, beta_1 = 0.9, beta_2=0.999), # you can tune the learning rate here. Default lr = 0.01\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/829 [..............................] - ETA: 0s - loss: 0.6908 - accuracy: 0.5000WARNING:tensorflow:From /Users/anthony/Documents/GitHub/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0164s). Check your callbacks.\n",
      "829/829 [==============================] - 2s 3ms/step - loss: 0.4573 - accuracy: 0.7756 - val_loss: 0.2295 - val_accuracy: 0.9088\n",
      "Epoch 2/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2800 - accuracy: 0.8934 - val_loss: 0.3194 - val_accuracy: 0.8675\n",
      "Epoch 3/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2691 - accuracy: 0.8987 - val_loss: 0.2150 - val_accuracy: 0.9214\n",
      "Epoch 4/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2680 - accuracy: 0.9014 - val_loss: 0.2777 - val_accuracy: 0.8977\n",
      "Epoch 5/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2582 - accuracy: 0.9055 - val_loss: 0.2231 - val_accuracy: 0.9156\n",
      "Epoch 6/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2506 - accuracy: 0.9085 - val_loss: 0.2494 - val_accuracy: 0.9255\n",
      "Epoch 7/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2484 - accuracy: 0.9095 - val_loss: 0.2751 - val_accuracy: 0.9022\n",
      "Epoch 8/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2468 - accuracy: 0.9104 - val_loss: 0.2194 - val_accuracy: 0.9294\n",
      "Epoch 9/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2901 - accuracy: 0.8905 - val_loss: 0.1986 - val_accuracy: 0.9264\n",
      "Epoch 10/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2382 - accuracy: 0.9124 - val_loss: 0.1938 - val_accuracy: 0.9352\n",
      "Epoch 11/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2295 - accuracy: 0.9172 - val_loss: 0.1932 - val_accuracy: 0.9357\n",
      "Epoch 12/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2250 - accuracy: 0.9180 - val_loss: 0.1846 - val_accuracy: 0.9318\n",
      "Epoch 13/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2300 - accuracy: 0.9173 - val_loss: 0.1991 - val_accuracy: 0.9366\n",
      "Epoch 14/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2213 - accuracy: 0.9195 - val_loss: 0.1767 - val_accuracy: 0.9391\n",
      "Epoch 15/30\n",
      "829/829 [==============================] - 2s 3ms/step - loss: 0.2199 - accuracy: 0.9200 - val_loss: 0.1768 - val_accuracy: 0.9375\n",
      "Epoch 16/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2173 - accuracy: 0.9235 - val_loss: 0.3235 - val_accuracy: 0.8770\n",
      "Epoch 17/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2198 - accuracy: 0.9202 - val_loss: 0.1997 - val_accuracy: 0.9368\n",
      "Epoch 18/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2086 - accuracy: 0.9251 - val_loss: 0.1800 - val_accuracy: 0.9329\n",
      "Epoch 19/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2091 - accuracy: 0.9258 - val_loss: 0.2412 - val_accuracy: 0.9130\n",
      "Epoch 20/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2145 - accuracy: 0.9245 - val_loss: 0.2648 - val_accuracy: 0.9040\n",
      "Epoch 21/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2093 - accuracy: 0.9249 - val_loss: 0.1650 - val_accuracy: 0.9435\n",
      "Epoch 22/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2026 - accuracy: 0.9297 - val_loss: 0.2304 - val_accuracy: 0.9147\n",
      "Epoch 23/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2011 - accuracy: 0.9289 - val_loss: 0.2737 - val_accuracy: 0.9068\n",
      "Epoch 24/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2127 - accuracy: 0.9230 - val_loss: 0.1981 - val_accuracy: 0.9244\n",
      "Epoch 25/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2035 - accuracy: 0.9288 - val_loss: 0.1646 - val_accuracy: 0.9410\n",
      "Epoch 26/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1982 - accuracy: 0.9303 - val_loss: 0.2012 - val_accuracy: 0.9292\n",
      "Epoch 27/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2033 - accuracy: 0.9272 - val_loss: 0.1560 - val_accuracy: 0.9466\n",
      "Epoch 28/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1898 - accuracy: 0.9337 - val_loss: 0.1578 - val_accuracy: 0.9452\n",
      "Epoch 29/30\n",
      "829/829 [==============================] - 2s 3ms/step - loss: 0.1964 - accuracy: 0.9299 - val_loss: 0.1562 - val_accuracy: 0.9465\n",
      "Epoch 30/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1954 - accuracy: 0.9313 - val_loss: 0.2259 - val_accuracy: 0.9177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 39995), started 0:03:25 ago. (Use '!kill 39995' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ccc1517227f077b5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ccc1517227f077b5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_log_dir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_log_dir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 30, \n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[tensorboard_cb])\n",
    "\n",
    "%tensorboard --logdir my_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid = True\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2354123294353485, 0.9140942096710205]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world Test (r/shortscarystories and r/self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_creepy = \"\"\"\n",
    "Irene (not her real name) was my first non-bot tinder match in three months. Things moved pretty fastwe chatted, I offered to cook dinner (Spaghetti puttanesca), then we hooked up.\n",
    "\n",
    "Irene was super hot but SUPER weird. She had a thick accent but insisted she grew up nearby, said it was a good night to make love because her goddess cycle was aligned with the moons, and totally starfished during sex.\n",
    "\n",
    "I figured - no big deal, Ill just do the adult thing and ghost her.\n",
    "\n",
    "Well that pissed Irene off. She messaged calling me a fuckboy and said, youll be sorry. I blocked her number, but the messages didnt stop. Eventually she baited me into replying:\n",
    "\n",
    "Her: Since youre alone tonight how about we have a little fun? \n",
    "\n",
    "Me: Im not alone. My housemates here. (I was lying.)\n",
    "\n",
    "Her: Surrrrrreeeeee.\n",
    "\n",
    "My bedroom door creaked open. From behind it something whispered, JJJJJJJJJJTTTTTTTBBBBBBBBBB6666666888888885555555.\n",
    "\n",
    "I thought maybe my housemate had come back and went to check it out. A dark figure almost as tall as the ceiling was creeping through the hall. I closed my bedroom door and locked it.\n",
    "\n",
    "My phone dinged.\n",
    "\n",
    "Her: I see youve met the other man in my life \n",
    "\n",
    "I thought, no big dealjust my imagination, or maybe a nightmare. Ill stay here and everythingll be alright in the morning.\n",
    "\n",
    "But I really needed to pee. Rather than wander through the empty house, I climbed out the window and urinated in the garden.\n",
    "\n",
    "When I returned, my phone dinged again.\n",
    "\n",
    "Her: Whats wrong? Afraid to go to the bathroom by yourself?\n",
    "\n",
    "Her: Look out the window. Hes outside. \n",
    "\n",
    "The figure appeared out of nowhere. Whatever it was, it wasnt human. This is the only way I can describe it: picture a living shadow with pale eyes and a tongue that doesnt fit in its mouth.\n",
    "\n",
    "It licked the window; I staggered back. The window opened (I dont know how - it doesnt unlock from the outside) and the figure poked its grinning head past the frame and into the room. I messaged Irene.\n",
    "\n",
    "Me: Im sorry. Please make it stop. Ill do ANYTHING.\n",
    "\n",
    "Her: I wish I could, but he hates seeing me upset.  If only something cheered me upOh well\n",
    "\n",
    "The figure climbed through the window and crawled along the floor, dragging its grotesque tongue across the carpet. It stood, leaned over me, then rocked its head like a seesaw.\n",
    "\n",
    "Me: Free tomorrow evening?\n",
    "\n",
    "Immediately the shadow turned and climbed back out the window.\n",
    "\n",
    "Her: Pick me up at eight. And we better have a magical timeOr else. X.\n",
    "\n",
    "So now were meeting tonight, and I have no idea what to do. I absolutely DO NOT want to date a girl who summons demons and probably gives shitty blowjobs.\n",
    "\n",
    "I need to figure out a way to make her both enjoy the date and never want to see me again.\n",
    "\n",
    "If anyone has any suggestions, Id really really appreciate it\n",
    "\"\"\"\n",
    "\n",
    "text_non_creepy = \"\"\"\n",
    "a few years ago my grandfather died and grandma was left to deal with finances for the first time in her life. mentally she was always sharp but in the months after his death she was so vulnerable. during this time some phone scammers managed to get her locked into a contract so she had to pay an extra $500/mo for electricity. i was royally pissed to say the least. worst of all, i couldn't do anything about it. eventually she was able to get out of the contract but not before she paid them thousands of dollars.\n",
    "\n",
    "as revenge, when someone tries to scam me i waste as much of their time as possible. i figure if i can slow them down for just 10-20 min it might be saving some other poor old lady from being taken advantage of. when i first started it wasn't easy. i could only keep them on the line for a few min before i broke down and started swearing at them. then i learned to keep my cool but they have ways of figuring out who is legit so i could only keep them on the line for 5 min before they would hang up. it sort of became a game where i would slowly figure out what they wanted to hear. with each call i get a little better. today i managed to keep them for 30+ min before they got frustrated and hung up.\n",
    "\n",
    "if everyone did this it would slow them down a lot. many old ladies would be saved.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.17855311,  0.99887389, -0.18185684, ..., -0.11338366,\n",
       "         0.3205308 , -0.53172874],\n",
       "       [ 7.03615729,  0.28519651, -0.21132587, ...,  0.20084164,\n",
       "        -0.19763809, -0.22631353]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creepy_vec = np.concatenate(([np.log(1310+1+0.01)],sbert_model.encode(text_creepy)))\n",
    "non_creepy_vec = np.concatenate(([np.log(1136+1+0.01)],sbert_model.encode(text_non_creepy)))\n",
    "vecs = np.array([creepy_vec, non_creepy_vec])\n",
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_vecs = scaler.fit_transform(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=100)\n",
    "scaled_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0043543e-04],\n",
       "       [9.9999774e-01]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fbe95a0ef40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepyvenv",
   "language": "python",
   "name": "creepyvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
