{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy = pd.read_pickle('./pickles/new/creepy_with_log.pickle')\n",
    "noncreepy = pd.read_pickle('./pickles/new/non-creepy_with_log.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy_sum_vec_with_log_prepended = creepy.loc[:,'sum_vec_with_log_prepended'].copy()\n",
    "noncreepy_sum_vec_with_log_prepended = noncreepy.loc[:,'sum_vec_with_log_prepended'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy_features = pd.DataFrame(creepy_sum_vec_with_log_prepended.to_list()).to_numpy(dtype = float)\n",
    "creepy_labels = np.ones(len(creepy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncreepy_features = pd.DataFrame(noncreepy_sum_vec_with_log_prepended.to_list()).to_numpy(dtype = float)\n",
    "noncreepy_labels = np.zeros(len(noncreepy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.69813472   2.94098592  -5.6173358  ...  -4.59305143   0.358845\n",
      "   -9.06916523]\n",
      " [  0.69813472   2.94098592  -5.6173358  ...  -4.59305143   0.358845\n",
      "   -9.06916523]\n",
      " [  0.69813472 -19.20127296 -13.71549892 ...  18.18037987 -16.4872303\n",
      "   -6.75176859]\n",
      " ...\n",
      " [  0.69813472  -0.78924334   0.29064384 ...   1.36802995  -3.79267383\n",
      "   -1.91743255]\n",
      " [  0.69813472   2.08661604  -1.43281949 ...  -1.90943027   3.40888762\n",
      "    0.54635704]\n",
      " [  0.69813472  -1.46298337  -2.17777109 ...   1.96948338  -0.8519302\n",
      "   -2.56011105]] [1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "features = np.concatenate((creepy_features, noncreepy_features))\n",
    "labels = np.concatenate((creepy_labels, noncreepy_labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37846, 769) (37846,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.98134720e-01 -6.79877377e+00  7.80437589e-01 ...  1.61100841e+00\n",
      "   3.57486558e+00  4.22096997e-02]\n",
      " [ 6.98134720e-01 -2.90069141e+01 -3.85387778e+00 ...  2.06084785e+01\n",
      "   1.60221519e+01  7.04003239e+00]\n",
      " [ 6.98134720e-01 -6.77775860e-01 -2.91869469e+01 ... -3.21042848e+00\n",
      "  -1.77904263e+01 -8.82744312e+00]\n",
      " ...\n",
      " [ 6.98134720e-01 -2.33818144e-02 -2.96759963e-01 ...  5.01690745e-01\n",
      "  -4.66530418e+00  1.33633763e-01]\n",
      " [ 6.98134720e-01 -1.43203437e+00 -2.02800107e+00 ... -1.37115598e+00\n",
      "  -3.82951379e+00  1.13402836e-01]\n",
      " [ 6.98134720e-01 -2.74893761e+00 -2.06984609e-01 ... -7.01506019e-01\n",
      "  -1.18252493e-01 -5.92097998e-01]] [0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "features, labels = shuffle(features, labels)\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.92438173 0.60101087 ... 0.84419691 0.47510765 0.42100696]\n",
      " [0.         0.91729957 0.59807453 ... 0.85782462 0.48579916 0.42346406]\n",
      " [0.         0.92633371 0.58202326 ... 0.84073828 0.45675609 0.41789262]\n",
      " ...\n",
      " [0.         0.9265424  0.60032835 ... 0.84340114 0.46802982 0.42103906]\n",
      " [0.         0.92609318 0.59923142 ... 0.84205767 0.46874771 0.42103196]\n",
      " [0.         0.92567322 0.60038523 ... 0.84253804 0.47193548 0.42078424]] [0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "print(scaled_features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] 70% train, 15% val, 15% test\n",
    " - Train: 26500\n",
    " - Valid: 5677\n",
    " - Test: 5669\n",
    "- [ ] 80% train, 10% val, 10% test\n",
    "- [ ] 60% train, 20% val, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = scaled_features[:26500], scaled_features[26500:26500+5677], scaled_features[26500+5677:]\n",
    "y_train, y_valid, y_test = labels[:26500], labels[26500:26500+5677], labels[26500+5677:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KerasRegressor method to fine-tuning neural network hyperparameters (Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=2, n_neurons=300, learning_rate=3e-3, input_shape=(769,)):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid')) # here the units must be 1 in order for binary classifications to work\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(lr=learning_rate), # you can tune the learning rate here. Default lr = 0.01\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.7965 - val_loss: 0.2952 - val_accuracy: 0.8674\n",
      "Epoch 2/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8832 - val_loss: 0.2395 - val_accuracy: 0.9021\n",
      "Epoch 3/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.8916 - val_loss: 0.2449 - val_accuracy: 0.8961\n",
      "Epoch 4/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.9018 - val_loss: 0.3774 - val_accuracy: 0.8640\n",
      "Epoch 5/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9014 - val_loss: 0.2372 - val_accuracy: 0.9068\n",
      "Epoch 6/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9096 - val_loss: 0.2222 - val_accuracy: 0.9265\n",
      "Epoch 7/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9085 - val_loss: 0.2674 - val_accuracy: 0.9086\n",
      "Epoch 8/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.9096 - val_loss: 0.2587 - val_accuracy: 0.9137\n",
      "Epoch 9/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.9105 - val_loss: 0.2789 - val_accuracy: 0.9028\n",
      "Epoch 10/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2383 - accuracy: 0.9115 - val_loss: 0.2411 - val_accuracy: 0.9065\n",
      "Epoch 11/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2278 - accuracy: 0.9147 - val_loss: 0.1837 - val_accuracy: 0.9352\n",
      "Epoch 12/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2282 - accuracy: 0.9171 - val_loss: 0.1859 - val_accuracy: 0.9345\n",
      "Epoch 13/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2285 - accuracy: 0.9176 - val_loss: 0.1979 - val_accuracy: 0.9348\n",
      "Epoch 14/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9237 - val_loss: 0.2101 - val_accuracy: 0.9294\n",
      "Epoch 15/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2252 - accuracy: 0.9196 - val_loss: 0.2394 - val_accuracy: 0.9220\n",
      "Epoch 16/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2192 - accuracy: 0.9219 - val_loss: 0.1841 - val_accuracy: 0.9415\n",
      "Epoch 17/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2125 - accuracy: 0.9231 - val_loss: 0.1738 - val_accuracy: 0.9420\n",
      "Epoch 18/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9244 - val_loss: 0.1826 - val_accuracy: 0.9341\n",
      "Epoch 19/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2172 - accuracy: 0.9211 - val_loss: 0.1877 - val_accuracy: 0.9410\n",
      "Epoch 20/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2132 - accuracy: 0.9233 - val_loss: 0.1771 - val_accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2216 - accuracy: 0.9210 - val_loss: 0.1771 - val_accuracy: 0.9424\n",
      "Epoch 22/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2034 - accuracy: 0.9278 - val_loss: 0.3195 - val_accuracy: 0.8871\n",
      "Epoch 23/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2119 - accuracy: 0.9258 - val_loss: 0.1650 - val_accuracy: 0.9438\n",
      "Epoch 24/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2056 - accuracy: 0.9281 - val_loss: 0.1704 - val_accuracy: 0.9438\n",
      "Epoch 25/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9302 - val_loss: 0.1622 - val_accuracy: 0.9466\n",
      "Epoch 26/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9301 - val_loss: 0.2033 - val_accuracy: 0.9271\n",
      "Epoch 27/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9315 - val_loss: 0.1600 - val_accuracy: 0.9472\n",
      "Epoch 28/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9332 - val_loss: 0.1977 - val_accuracy: 0.9336\n",
      "Epoch 29/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1973 - accuracy: 0.9297 - val_loss: 0.1859 - val_accuracy: 0.9338\n",
      "Epoch 30/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1946 - accuracy: 0.9323 - val_loss: 0.1605 - val_accuracy: 0.9475\n",
      "Epoch 31/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1900 - accuracy: 0.9342 - val_loss: 0.2721 - val_accuracy: 0.9036\n",
      "Epoch 32/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9353 - val_loss: 0.1592 - val_accuracy: 0.9486\n",
      "Epoch 33/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9340 - val_loss: 0.1549 - val_accuracy: 0.9498\n",
      "Epoch 34/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1843 - accuracy: 0.9363 - val_loss: 0.6189 - val_accuracy: 0.6089\n",
      "Epoch 35/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1923 - accuracy: 0.9330 - val_loss: 0.1603 - val_accuracy: 0.9456\n",
      "Epoch 36/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.9349 - val_loss: 0.1808 - val_accuracy: 0.9413\n",
      "Epoch 37/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9355 - val_loss: 0.1552 - val_accuracy: 0.9494\n",
      "Epoch 38/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9337 - val_loss: 0.2332 - val_accuracy: 0.9146\n",
      "Epoch 39/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.9411 - val_loss: 0.1453 - val_accuracy: 0.9519\n",
      "Epoch 40/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1939 - accuracy: 0.9329 - val_loss: 0.1447 - val_accuracy: 0.9530\n",
      "Epoch 41/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.9388 - val_loss: 0.1481 - val_accuracy: 0.9521\n",
      "Epoch 42/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.9365 - val_loss: 0.2225 - val_accuracy: 0.9332\n",
      "Epoch 43/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.9424 - val_loss: 0.1387 - val_accuracy: 0.9553\n",
      "Epoch 44/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1719 - accuracy: 0.9408 - val_loss: 0.1374 - val_accuracy: 0.9558\n",
      "Epoch 45/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1715 - accuracy: 0.9421 - val_loss: 0.1397 - val_accuracy: 0.9568\n",
      "Epoch 46/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.9397 - val_loss: 0.1653 - val_accuracy: 0.9482\n",
      "Epoch 47/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9391 - val_loss: 0.1452 - val_accuracy: 0.9565\n",
      "Epoch 48/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1673 - accuracy: 0.9439 - val_loss: 0.1596 - val_accuracy: 0.9475\n",
      "Epoch 49/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1687 - accuracy: 0.9428 - val_loss: 0.1443 - val_accuracy: 0.9547\n",
      "Epoch 50/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1603 - accuracy: 0.9457 - val_loss: 0.1312 - val_accuracy: 0.9579\n",
      "Epoch 51/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1620 - accuracy: 0.9448 - val_loss: 0.1338 - val_accuracy: 0.9588\n",
      "Epoch 52/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9462 - val_loss: 0.1310 - val_accuracy: 0.9590\n",
      "Epoch 53/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1651 - accuracy: 0.9444 - val_loss: 0.2213 - val_accuracy: 0.9207\n",
      "Epoch 54/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.9437 - val_loss: 0.1439 - val_accuracy: 0.9551\n",
      "Epoch 55/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1600 - accuracy: 0.9475 - val_loss: 0.3899 - val_accuracy: 0.8788\n",
      "Epoch 56/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1675 - accuracy: 0.9438 - val_loss: 0.1334 - val_accuracy: 0.9591\n",
      "Epoch 57/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1605 - accuracy: 0.9457 - val_loss: 0.1277 - val_accuracy: 0.9605\n",
      "Epoch 58/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9504 - val_loss: 0.2570 - val_accuracy: 0.9128\n",
      "Epoch 59/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1593 - accuracy: 0.9463 - val_loss: 0.2150 - val_accuracy: 0.9237\n",
      "Epoch 60/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1504 - accuracy: 0.9498 - val_loss: 0.1245 - val_accuracy: 0.9616\n",
      "Epoch 61/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1513 - accuracy: 0.9505 - val_loss: 0.5598 - val_accuracy: 0.8395\n",
      "Epoch 62/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9415 - val_loss: 0.3939 - val_accuracy: 0.8608\n",
      "Epoch 63/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1560 - accuracy: 0.9478 - val_loss: 0.2787 - val_accuracy: 0.9123\n",
      "Epoch 64/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9439 - val_loss: 0.1464 - val_accuracy: 0.9521\n",
      "Epoch 65/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1505 - accuracy: 0.9494 - val_loss: 0.2352 - val_accuracy: 0.9292\n",
      "Epoch 66/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1698 - accuracy: 0.9450 - val_loss: 0.1404 - val_accuracy: 0.9535\n",
      "Epoch 67/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1538 - accuracy: 0.9480 - val_loss: 0.1663 - val_accuracy: 0.9484\n",
      "Epoch 68/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9494 - val_loss: 0.1222 - val_accuracy: 0.9628\n",
      "Epoch 69/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9499 - val_loss: 0.1290 - val_accuracy: 0.9595\n",
      "Epoch 70/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1601 - accuracy: 0.9473 - val_loss: 0.1326 - val_accuracy: 0.9563\n",
      "Epoch 71/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1549 - accuracy: 0.9500 - val_loss: 0.1417 - val_accuracy: 0.9538\n",
      "Epoch 72/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1639 - accuracy: 0.9457 - val_loss: 0.2836 - val_accuracy: 0.9123\n",
      "Epoch 73/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9508 - val_loss: 0.1778 - val_accuracy: 0.9401\n",
      "Epoch 74/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9484 - val_loss: 0.1625 - val_accuracy: 0.9454\n",
      "Epoch 75/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9489 - val_loss: 0.2012 - val_accuracy: 0.9391\n",
      "Epoch 76/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1475 - accuracy: 0.9521 - val_loss: 0.1281 - val_accuracy: 0.9611\n",
      "Epoch 77/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1471 - accuracy: 0.9513 - val_loss: 0.1203 - val_accuracy: 0.9621\n",
      "Epoch 78/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9508 - val_loss: 0.1354 - val_accuracy: 0.9561\n",
      "Epoch 79/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9498 - val_loss: 0.2402 - val_accuracy: 0.9160\n",
      "Epoch 80/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9495 - val_loss: 0.1508 - val_accuracy: 0.9551\n",
      "Epoch 81/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1387 - accuracy: 0.9550 - val_loss: 0.1481 - val_accuracy: 0.9521\n",
      "Epoch 82/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1450 - accuracy: 0.9519 - val_loss: 0.1350 - val_accuracy: 0.9560\n",
      "Epoch 83/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1450 - accuracy: 0.9537 - val_loss: 0.4481 - val_accuracy: 0.8126\n",
      "Epoch 84/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1520 - accuracy: 0.9505 - val_loss: 0.1218 - val_accuracy: 0.9634\n",
      "Epoch 85/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1514 - accuracy: 0.9498 - val_loss: 0.1186 - val_accuracy: 0.9646\n",
      "Epoch 86/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9489 - val_loss: 0.1270 - val_accuracy: 0.9584\n",
      "Epoch 87/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1439 - accuracy: 0.9530 - val_loss: 0.1171 - val_accuracy: 0.9648\n",
      "Epoch 88/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9526 - val_loss: 0.1178 - val_accuracy: 0.9634\n",
      "Epoch 89/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1528 - accuracy: 0.9501 - val_loss: 0.2945 - val_accuracy: 0.9014\n",
      "Epoch 90/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1437 - accuracy: 0.9524 - val_loss: 0.1157 - val_accuracy: 0.9642\n",
      "Epoch 91/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1549 - accuracy: 0.9491 - val_loss: 0.1429 - val_accuracy: 0.9519\n",
      "Epoch 92/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1419 - accuracy: 0.9535 - val_loss: 0.1266 - val_accuracy: 0.9588\n",
      "Epoch 93/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9547 - val_loss: 0.1340 - val_accuracy: 0.9574\n",
      "Epoch 94/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9539 - val_loss: 0.1424 - val_accuracy: 0.9528\n",
      "Epoch 95/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1556 - accuracy: 0.9476 - val_loss: 0.1186 - val_accuracy: 0.9637\n",
      "Epoch 96/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9540 - val_loss: 0.1162 - val_accuracy: 0.9635\n",
      "Epoch 97/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1392 - accuracy: 0.9542 - val_loss: 0.1220 - val_accuracy: 0.9623\n",
      "Epoch 98/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9521 - val_loss: 0.1205 - val_accuracy: 0.9616\n",
      "Epoch 99/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9524 - val_loss: 0.1502 - val_accuracy: 0.9523\n",
      "Epoch 100/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1449 - accuracy: 0.9527 - val_loss: 0.1174 - val_accuracy: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f60f82fa370>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs = 100, \n",
    "             validation_data=(X_valid,y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6817 - accuracy: 0.5898 - val_loss: 0.6679 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6647 - accuracy: 0.5913 - val_loss: 0.6511 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.6695 - val_loss: 0.5331 - val_accuracy: 0.7391\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3910 - accuracy: 0.8600 - val_loss: 0.3368 - val_accuracy: 0.9204\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.8914 - val_loss: 0.2612 - val_accuracy: 0.9031\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2669 - accuracy: 0.8979 - val_loss: 0.2899 - val_accuracy: 0.8744\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2598 - accuracy: 0.9009 - val_loss: 0.2475 - val_accuracy: 0.9207\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9043 - val_loss: 0.2816 - val_accuracy: 0.9193\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.9071 - val_loss: 0.2684 - val_accuracy: 0.9216\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9071 - val_loss: 0.2272 - val_accuracy: 0.9176\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2405 - accuracy: 0.9101 - val_loss: 0.2271 - val_accuracy: 0.9228\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.9086 - val_loss: 0.2442 - val_accuracy: 0.9228\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.9098 - val_loss: 0.2510 - val_accuracy: 0.8991\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.9114 - val_loss: 0.2261 - val_accuracy: 0.9265\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.9115 - val_loss: 0.2146 - val_accuracy: 0.9241\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.9128 - val_loss: 0.2198 - val_accuracy: 0.9139\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2309 - accuracy: 0.9133 - val_loss: 0.2185 - val_accuracy: 0.9273\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2288 - accuracy: 0.9126 - val_loss: 0.2157 - val_accuracy: 0.9195\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2261 - accuracy: 0.9140 - val_loss: 0.2125 - val_accuracy: 0.9269\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.9147 - val_loss: 0.2456 - val_accuracy: 0.9038\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2250 - accuracy: 0.9142 - val_loss: 0.2073 - val_accuracy: 0.9269\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2283 - accuracy: 0.9138 - val_loss: 0.2383 - val_accuracy: 0.9206\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9153 - val_loss: 0.2074 - val_accuracy: 0.9258\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2244 - accuracy: 0.9149 - val_loss: 0.2143 - val_accuracy: 0.9294\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2235 - accuracy: 0.9159 - val_loss: 0.2032 - val_accuracy: 0.9278\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2196 - accuracy: 0.9191 - val_loss: 0.2029 - val_accuracy: 0.9273\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2196 - accuracy: 0.9181 - val_loss: 0.2130 - val_accuracy: 0.9186\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2211 - accuracy: 0.9168 - val_loss: 0.2042 - val_accuracy: 0.9302\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2178 - accuracy: 0.9200 - val_loss: 0.2092 - val_accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2234 - accuracy: 0.9176 - val_loss: 0.2108 - val_accuracy: 0.9204\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2185 - accuracy: 0.9176 - val_loss: 0.2034 - val_accuracy: 0.9269\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2155 - accuracy: 0.9176 - val_loss: 0.1983 - val_accuracy: 0.9317\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9209 - val_loss: 0.2124 - val_accuracy: 0.9273\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9196 - val_loss: 0.2396 - val_accuracy: 0.9105\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2152 - accuracy: 0.9196 - val_loss: 0.2055 - val_accuracy: 0.9306\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9199 - val_loss: 0.2018 - val_accuracy: 0.9269\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9200 - val_loss: 0.1964 - val_accuracy: 0.9309\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2095 - accuracy: 0.9211 - val_loss: 0.1952 - val_accuracy: 0.9313\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2168 - accuracy: 0.9191 - val_loss: 0.1994 - val_accuracy: 0.9278\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9224 - val_loss: 0.1920 - val_accuracy: 0.9327\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9226 - val_loss: 0.1932 - val_accuracy: 0.9317\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9221 - val_loss: 0.1933 - val_accuracy: 0.9313\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2102 - accuracy: 0.9214 - val_loss: 0.2106 - val_accuracy: 0.9269\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9226 - val_loss: 0.1899 - val_accuracy: 0.9357\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9234 - val_loss: 0.1979 - val_accuracy: 0.9274\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2093 - accuracy: 0.9221 - val_loss: 0.1889 - val_accuracy: 0.9331\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9214 - val_loss: 0.1929 - val_accuracy: 0.9317\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9236 - val_loss: 0.1969 - val_accuracy: 0.9273\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2073 - accuracy: 0.9232 - val_loss: 0.1866 - val_accuracy: 0.9364\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2015 - accuracy: 0.9274 - val_loss: 0.1861 - val_accuracy: 0.9345\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9236 - val_loss: 0.1867 - val_accuracy: 0.9364\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9247 - val_loss: 0.2570 - val_accuracy: 0.9066\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2043 - accuracy: 0.9235 - val_loss: 0.1848 - val_accuracy: 0.9369\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2053 - accuracy: 0.9236 - val_loss: 0.2088 - val_accuracy: 0.9234\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9258 - val_loss: 0.1825 - val_accuracy: 0.9378\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9266 - val_loss: 0.1830 - val_accuracy: 0.9350\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1998 - accuracy: 0.9261 - val_loss: 0.2367 - val_accuracy: 0.9140\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9264 - val_loss: 0.2011 - val_accuracy: 0.9315\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2008 - accuracy: 0.9257 - val_loss: 0.2025 - val_accuracy: 0.9306\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9283 - val_loss: 0.1801 - val_accuracy: 0.9380\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.9272 - val_loss: 0.1802 - val_accuracy: 0.9387\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1982 - accuracy: 0.9271 - val_loss: 0.1789 - val_accuracy: 0.9392\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9278 - val_loss: 0.1794 - val_accuracy: 0.9364\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9287 - val_loss: 0.1801 - val_accuracy: 0.9362\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1980 - accuracy: 0.9277 - val_loss: 0.2188 - val_accuracy: 0.9195\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1938 - accuracy: 0.9288 - val_loss: 0.1770 - val_accuracy: 0.9403\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1914 - accuracy: 0.9311 - val_loss: 0.1978 - val_accuracy: 0.9278\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.9285 - val_loss: 0.1870 - val_accuracy: 0.9331\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9307 - val_loss: 0.1781 - val_accuracy: 0.9368\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.9288 - val_loss: 0.1749 - val_accuracy: 0.9398\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9317 - val_loss: 0.1820 - val_accuracy: 0.9346\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1917 - accuracy: 0.9305 - val_loss: 0.1907 - val_accuracy: 0.9348\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.9298 - val_loss: 0.1779 - val_accuracy: 0.9364\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9320 - val_loss: 0.1703 - val_accuracy: 0.9424\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1879 - accuracy: 0.9312 - val_loss: 0.1740 - val_accuracy: 0.9385\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.9317 - val_loss: 0.1807 - val_accuracy: 0.9387\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.9318 - val_loss: 0.1729 - val_accuracy: 0.9417\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.9347 - val_loss: 0.1686 - val_accuracy: 0.9445\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.9336 - val_loss: 0.1799 - val_accuracy: 0.9392\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.9328 - val_loss: 0.1715 - val_accuracy: 0.9403\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1844 - accuracy: 0.9349 - val_loss: 0.1825 - val_accuracy: 0.9361\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1805 - accuracy: 0.9350 - val_loss: 0.1668 - val_accuracy: 0.9440\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.9320 - val_loss: 0.1711 - val_accuracy: 0.9396\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.9360 - val_loss: 0.1990 - val_accuracy: 0.9318\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9362 - val_loss: 0.1630 - val_accuracy: 0.9447\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.9342 - val_loss: 0.1781 - val_accuracy: 0.9399\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.9359 - val_loss: 0.1621 - val_accuracy: 0.9443\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9350 - val_loss: 0.1701 - val_accuracy: 0.9405\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.9350 - val_loss: 0.1644 - val_accuracy: 0.9443\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9335 - val_loss: 0.1636 - val_accuracy: 0.9454\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9390 - val_loss: 0.1630 - val_accuracy: 0.9459\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9372 - val_loss: 0.2051 - val_accuracy: 0.9308\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9372 - val_loss: 0.1581 - val_accuracy: 0.9465\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.9364 - val_loss: 0.1651 - val_accuracy: 0.9442\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.9368 - val_loss: 0.1564 - val_accuracy: 0.9491\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1713 - accuracy: 0.9395 - val_loss: 0.1574 - val_accuracy: 0.9459\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.9415 - val_loss: 0.1610 - val_accuracy: 0.9461\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9388 - val_loss: 0.1543 - val_accuracy: 0.9479\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9375 - val_loss: 0.2065 - val_accuracy: 0.9253\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1716 - accuracy: 0.9388 - val_loss: 0.1715 - val_accuracy: 0.9424\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9417\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6735 - accuracy: 0.5946 - val_loss: 0.6690 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6682 - accuracy: 0.5946 - val_loss: 0.6618 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6560 - accuracy: 0.5951 - val_loss: 0.6422 - val_accuracy: 0.6037\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6067 - accuracy: 0.6669 - val_loss: 0.5299 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8394 - val_loss: 0.3445 - val_accuracy: 0.8795\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8900 - val_loss: 0.2645 - val_accuracy: 0.8987\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.9030 - val_loss: 0.2459 - val_accuracy: 0.9200\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2392 - accuracy: 0.9083 - val_loss: 0.2273 - val_accuracy: 0.9197\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2341 - accuracy: 0.9119 - val_loss: 0.2197 - val_accuracy: 0.9200\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2310 - accuracy: 0.9141 - val_loss: 0.2279 - val_accuracy: 0.9072\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2254 - accuracy: 0.9146 - val_loss: 0.2209 - val_accuracy: 0.9246\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9154 - val_loss: 0.2160 - val_accuracy: 0.9236\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9154 - val_loss: 0.2136 - val_accuracy: 0.9221\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9159 - val_loss: 0.2096 - val_accuracy: 0.9239\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2198 - accuracy: 0.9171 - val_loss: 0.2140 - val_accuracy: 0.9174\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.9188 - val_loss: 0.2110 - val_accuracy: 0.9269\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9200 - val_loss: 0.2063 - val_accuracy: 0.9250\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9212 - val_loss: 0.2058 - val_accuracy: 0.9258\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2221 - accuracy: 0.9160 - val_loss: 0.2038 - val_accuracy: 0.9258\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2186 - accuracy: 0.9179 - val_loss: 0.2056 - val_accuracy: 0.9267\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9186 - val_loss: 0.2208 - val_accuracy: 0.9139\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9193 - val_loss: 0.2077 - val_accuracy: 0.9230\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2204 - accuracy: 0.9175 - val_loss: 0.2529 - val_accuracy: 0.9017\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2130 - accuracy: 0.9200 - val_loss: 0.2095 - val_accuracy: 0.9276\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9213 - val_loss: 0.2039 - val_accuracy: 0.9297\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9199 - val_loss: 0.2002 - val_accuracy: 0.9280\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2119 - accuracy: 0.9215 - val_loss: 0.2262 - val_accuracy: 0.9211\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9212 - val_loss: 0.2015 - val_accuracy: 0.9276\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9222 - val_loss: 0.1988 - val_accuracy: 0.9308\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2104 - accuracy: 0.9234 - val_loss: 0.2032 - val_accuracy: 0.9301\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2068 - accuracy: 0.9239 - val_loss: 0.2424 - val_accuracy: 0.9140\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2062 - accuracy: 0.9244 - val_loss: 0.1970 - val_accuracy: 0.9278\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9239 - val_loss: 0.1954 - val_accuracy: 0.9288\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9230 - val_loss: 0.1959 - val_accuracy: 0.9313\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9236 - val_loss: 0.1960 - val_accuracy: 0.9308\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9258 - val_loss: 0.2129 - val_accuracy: 0.9258\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9232 - val_loss: 0.1943 - val_accuracy: 0.9317\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.9231 - val_loss: 0.2056 - val_accuracy: 0.9290\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9260 - val_loss: 0.1997 - val_accuracy: 0.9265\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 3ms/step - loss: 0.2056 - accuracy: 0.9256 - val_loss: 0.1985 - val_accuracy: 0.9264\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2027 - accuracy: 0.9235 - val_loss: 0.1929 - val_accuracy: 0.9327\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.9234 - val_loss: 0.1941 - val_accuracy: 0.9329\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9230 - val_loss: 0.1999 - val_accuracy: 0.9309\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9240 - val_loss: 0.1946 - val_accuracy: 0.9267\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1993 - accuracy: 0.9268 - val_loss: 0.1876 - val_accuracy: 0.9334\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1998 - accuracy: 0.9257 - val_loss: 0.1986 - val_accuracy: 0.9250\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9267 - val_loss: 0.1927 - val_accuracy: 0.9341\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9273 - val_loss: 0.2042 - val_accuracy: 0.9223\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9282 - val_loss: 0.1960 - val_accuracy: 0.9299\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1988 - accuracy: 0.9253 - val_loss: 0.1901 - val_accuracy: 0.9327\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1944 - accuracy: 0.9286 - val_loss: 0.1839 - val_accuracy: 0.9324\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9278 - val_loss: 0.1857 - val_accuracy: 0.9359\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9274 - val_loss: 0.1805 - val_accuracy: 0.9359\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9292 - val_loss: 0.1844 - val_accuracy: 0.9362\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9287 - val_loss: 0.1896 - val_accuracy: 0.9325\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.9311 - val_loss: 0.1763 - val_accuracy: 0.9362\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.9316 - val_loss: 0.2522 - val_accuracy: 0.9100\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9317 - val_loss: 0.1793 - val_accuracy: 0.9362\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.9305 - val_loss: 0.1800 - val_accuracy: 0.9361\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9311 - val_loss: 0.1782 - val_accuracy: 0.9424\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9304 - val_loss: 0.1980 - val_accuracy: 0.9280\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9324 - val_loss: 0.1688 - val_accuracy: 0.9373\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.9345 - val_loss: 0.1657 - val_accuracy: 0.9389\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.9335 - val_loss: 0.1849 - val_accuracy: 0.9366\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.9334 - val_loss: 0.1746 - val_accuracy: 0.9339\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.9352 - val_loss: 0.1621 - val_accuracy: 0.9387\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1720 - accuracy: 0.9363 - val_loss: 0.1805 - val_accuracy: 0.9420\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.9364 - val_loss: 0.1542 - val_accuracy: 0.9436\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1699 - accuracy: 0.9358 - val_loss: 0.1689 - val_accuracy: 0.9565\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9368 - val_loss: 0.1890 - val_accuracy: 0.9302\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9403 - val_loss: 0.1662 - val_accuracy: 0.9339\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1619 - accuracy: 0.9405 - val_loss: 0.2600 - val_accuracy: 0.8998\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1599 - accuracy: 0.9424 - val_loss: 0.1485 - val_accuracy: 0.9567\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1620 - accuracy: 0.9402 - val_loss: 0.1429 - val_accuracy: 0.9475\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1580 - accuracy: 0.9430 - val_loss: 0.1421 - val_accuracy: 0.9472\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9426 - val_loss: 0.1392 - val_accuracy: 0.9510\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9414 - val_loss: 0.1351 - val_accuracy: 0.9575\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9470 - val_loss: 0.1457 - val_accuracy: 0.9449\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1477 - accuracy: 0.9472 - val_loss: 0.1324 - val_accuracy: 0.9602\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9437 - val_loss: 0.2215 - val_accuracy: 0.8991\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9453 - val_loss: 0.1309 - val_accuracy: 0.9620\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1426 - accuracy: 0.9496 - val_loss: 0.1395 - val_accuracy: 0.9586\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1438 - accuracy: 0.9477 - val_loss: 0.1329 - val_accuracy: 0.9556\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9459 - val_loss: 0.1856 - val_accuracy: 0.9325\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1413 - accuracy: 0.9492 - val_loss: 0.1254 - val_accuracy: 0.9556\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9461 - val_loss: 0.1247 - val_accuracy: 0.9570\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1368 - accuracy: 0.9518 - val_loss: 0.1767 - val_accuracy: 0.9378\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9510 - val_loss: 0.1443 - val_accuracy: 0.9526\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1389 - accuracy: 0.9530 - val_loss: 0.1417 - val_accuracy: 0.9516\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9453 - val_loss: 0.1996 - val_accuracy: 0.9265\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1418 - accuracy: 0.9501 - val_loss: 0.1260 - val_accuracy: 0.9572\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9518 - val_loss: 0.1500 - val_accuracy: 0.9489\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.9520 - val_loss: 0.1342 - val_accuracy: 0.9583\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9489 - val_loss: 0.1188 - val_accuracy: 0.9605\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1399 - accuracy: 0.9515 - val_loss: 0.1881 - val_accuracy: 0.9324\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1394 - accuracy: 0.9516 - val_loss: 0.1234 - val_accuracy: 0.9611\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1311 - accuracy: 0.9548 - val_loss: 0.1186 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9525 - val_loss: 0.1680 - val_accuracy: 0.9436\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1335 - accuracy: 0.9524 - val_loss: 0.1262 - val_accuracy: 0.9595\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1350 - accuracy: 0.9538 - val_loss: 0.1153 - val_accuracy: 0.9627\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9608\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6792 - accuracy: 0.5916 - val_loss: 0.6719 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6748 - accuracy: 0.5916 - val_loss: 0.6701 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6724 - accuracy: 0.5916 - val_loss: 0.6665 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6639 - accuracy: 0.5916 - val_loss: 0.6438 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.6831 - val_loss: 0.4982 - val_accuracy: 0.8591\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4197 - accuracy: 0.8514 - val_loss: 0.3583 - val_accuracy: 0.8792\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8763 - val_loss: 0.3084 - val_accuracy: 0.9063\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2916 - accuracy: 0.8891 - val_loss: 0.2708 - val_accuracy: 0.8906\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.8962 - val_loss: 0.2661 - val_accuracy: 0.9190\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9005 - val_loss: 0.2580 - val_accuracy: 0.8873\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.9041 - val_loss: 0.2511 - val_accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2452 - accuracy: 0.9071 - val_loss: 0.2364 - val_accuracy: 0.9047\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2425 - accuracy: 0.9090 - val_loss: 0.2461 - val_accuracy: 0.9232\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.9096 - val_loss: 0.2431 - val_accuracy: 0.9237\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.9107 - val_loss: 0.2258 - val_accuracy: 0.9218\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2361 - accuracy: 0.9102 - val_loss: 0.2206 - val_accuracy: 0.9218\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2330 - accuracy: 0.9129 - val_loss: 0.2439 - val_accuracy: 0.8984\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2310 - accuracy: 0.9141 - val_loss: 0.2195 - val_accuracy: 0.9147\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9150 - val_loss: 0.2146 - val_accuracy: 0.9200\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.9141 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9174 - val_loss: 0.2112 - val_accuracy: 0.9236\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2240 - accuracy: 0.9179 - val_loss: 0.2139 - val_accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9168 - val_loss: 0.2089 - val_accuracy: 0.9241\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.9177 - val_loss: 0.2126 - val_accuracy: 0.9207\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2216 - accuracy: 0.9186 - val_loss: 0.2092 - val_accuracy: 0.9250\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2203 - accuracy: 0.9179 - val_loss: 0.2175 - val_accuracy: 0.9260\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9179 - val_loss: 0.2072 - val_accuracy: 0.9250\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2190 - accuracy: 0.9197 - val_loss: 0.2054 - val_accuracy: 0.9244\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2206 - accuracy: 0.9177 - val_loss: 0.2057 - val_accuracy: 0.9258\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9203 - val_loss: 0.2077 - val_accuracy: 0.9234\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9192 - val_loss: 0.2107 - val_accuracy: 0.9281\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2177 - accuracy: 0.9203 - val_loss: 0.2032 - val_accuracy: 0.9267\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9191 - val_loss: 0.2027 - val_accuracy: 0.9276\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2173 - accuracy: 0.9201 - val_loss: 0.2027 - val_accuracy: 0.9257\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2191 - accuracy: 0.9203 - val_loss: 0.2146 - val_accuracy: 0.9195\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2170 - accuracy: 0.9208 - val_loss: 0.2027 - val_accuracy: 0.9290\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2160 - accuracy: 0.9213 - val_loss: 0.2022 - val_accuracy: 0.9267\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2148 - accuracy: 0.9210 - val_loss: 0.2020 - val_accuracy: 0.9273\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9213 - val_loss: 0.2097 - val_accuracy: 0.9220\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9228 - val_loss: 0.2017 - val_accuracy: 0.9276\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2126 - accuracy: 0.9230 - val_loss: 0.2256 - val_accuracy: 0.9135\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.9221 - val_loss: 0.2024 - val_accuracy: 0.9276\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.9231 - val_loss: 0.2018 - val_accuracy: 0.9278\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9217 - val_loss: 0.1970 - val_accuracy: 0.9280\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.9227 - val_loss: 0.1981 - val_accuracy: 0.9302\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9223 - val_loss: 0.2064 - val_accuracy: 0.9276\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.9235 - val_loss: 0.1961 - val_accuracy: 0.9318\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2080 - accuracy: 0.9243 - val_loss: 0.2164 - val_accuracy: 0.9179\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9225 - val_loss: 0.2033 - val_accuracy: 0.9258\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9223 - val_loss: 0.1973 - val_accuracy: 0.9292\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9231 - val_loss: 0.1938 - val_accuracy: 0.9292\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9250 - val_loss: 0.2228 - val_accuracy: 0.9202\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9240 - val_loss: 0.2248 - val_accuracy: 0.9193\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9239 - val_loss: 0.1952 - val_accuracy: 0.9294\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9251 - val_loss: 0.1991 - val_accuracy: 0.9297\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2056 - accuracy: 0.9249 - val_loss: 0.1918 - val_accuracy: 0.9308\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9255 - val_loss: 0.2238 - val_accuracy: 0.9181\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2092 - accuracy: 0.9243 - val_loss: 0.2231 - val_accuracy: 0.9200\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2053 - accuracy: 0.9258 - val_loss: 0.1901 - val_accuracy: 0.9343\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9258 - val_loss: 0.2101 - val_accuracy: 0.9221\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9254 - val_loss: 0.1921 - val_accuracy: 0.9331\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2042 - accuracy: 0.9251 - val_loss: 0.1898 - val_accuracy: 0.9327\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.9239 - val_loss: 0.1997 - val_accuracy: 0.9285\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.9269 - val_loss: 0.1886 - val_accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9273 - val_loss: 0.1876 - val_accuracy: 0.9355\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2007 - accuracy: 0.9283 - val_loss: 0.1910 - val_accuracy: 0.9341\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2010 - accuracy: 0.9265 - val_loss: 0.2079 - val_accuracy: 0.9232\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9272 - val_loss: 0.1864 - val_accuracy: 0.9352\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2023 - accuracy: 0.9278 - val_loss: 0.1865 - val_accuracy: 0.9354\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9291 - val_loss: 0.1880 - val_accuracy: 0.9322\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9285 - val_loss: 0.1847 - val_accuracy: 0.9366\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9294 - val_loss: 0.1848 - val_accuracy: 0.9357\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9272 - val_loss: 0.1838 - val_accuracy: 0.9373\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2020 - accuracy: 0.9264 - val_loss: 0.1861 - val_accuracy: 0.9357\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9291 - val_loss: 0.1880 - val_accuracy: 0.9355\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9300 - val_loss: 0.1833 - val_accuracy: 0.9359\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9295 - val_loss: 0.1829 - val_accuracy: 0.9366\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9295 - val_loss: 0.1845 - val_accuracy: 0.9380\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9285 - val_loss: 0.1846 - val_accuracy: 0.9341\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9291 - val_loss: 0.1826 - val_accuracy: 0.9380\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1953 - accuracy: 0.9296 - val_loss: 0.1884 - val_accuracy: 0.9329\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1949 - accuracy: 0.9313 - val_loss: 0.2037 - val_accuracy: 0.9262\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9294 - val_loss: 0.2132 - val_accuracy: 0.9207\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1943 - accuracy: 0.9309 - val_loss: 0.1791 - val_accuracy: 0.9376\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9303 - val_loss: 0.2065 - val_accuracy: 0.9250\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9293 - val_loss: 0.1785 - val_accuracy: 0.9394\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9308 - val_loss: 0.1791 - val_accuracy: 0.9383\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9318 - val_loss: 0.1870 - val_accuracy: 0.9371\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.9316 - val_loss: 0.1766 - val_accuracy: 0.9387\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9308 - val_loss: 0.1797 - val_accuracy: 0.9366\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1931 - accuracy: 0.9294 - val_loss: 0.1760 - val_accuracy: 0.9392\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9307 - val_loss: 0.1925 - val_accuracy: 0.9295\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9314 - val_loss: 0.1823 - val_accuracy: 0.9352\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.9296 - val_loss: 0.1813 - val_accuracy: 0.9354\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1907 - accuracy: 0.9321 - val_loss: 0.1845 - val_accuracy: 0.9357\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9319 - val_loss: 0.1948 - val_accuracy: 0.9318\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9305 - val_loss: 0.1839 - val_accuracy: 0.9350\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.9324 - val_loss: 0.1734 - val_accuracy: 0.9410\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1947 - accuracy: 0.9309 - val_loss: 0.1753 - val_accuracy: 0.9392\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.9326 - val_loss: 0.1868 - val_accuracy: 0.9343\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9303\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6239 - val_loss: 0.6130 - val_accuracy: 0.6392\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.7022 - val_loss: 0.5751 - val_accuracy: 0.7486\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5595 - accuracy: 0.7379 - val_loss: 0.5413 - val_accuracy: 0.7405\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7599 - val_loss: 0.5176 - val_accuracy: 0.7384\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7766 - val_loss: 0.4980 - val_accuracy: 0.8082\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7893 - val_loss: 0.4803 - val_accuracy: 0.8194\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.8010 - val_loss: 0.4635 - val_accuracy: 0.7851\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8103 - val_loss: 0.4504 - val_accuracy: 0.8291\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8168 - val_loss: 0.4375 - val_accuracy: 0.8101\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.8257 - val_loss: 0.4271 - val_accuracy: 0.8122\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4215 - accuracy: 0.8293 - val_loss: 0.4186 - val_accuracy: 0.8101\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4123 - accuracy: 0.8349 - val_loss: 0.4114 - val_accuracy: 0.8085\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4043 - accuracy: 0.8383 - val_loss: 0.4006 - val_accuracy: 0.8432\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8423 - val_loss: 0.3954 - val_accuracy: 0.8612\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3895 - accuracy: 0.8439 - val_loss: 0.3882 - val_accuracy: 0.8614\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8484 - val_loss: 0.3806 - val_accuracy: 0.8504\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.8514 - val_loss: 0.3772 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8523 - val_loss: 0.3697 - val_accuracy: 0.8501\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3659 - accuracy: 0.8548 - val_loss: 0.3650 - val_accuracy: 0.8624\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8567 - val_loss: 0.3608 - val_accuracy: 0.8665\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8609 - val_loss: 0.3562 - val_accuracy: 0.8631\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8605 - val_loss: 0.3523 - val_accuracy: 0.8654\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8621 - val_loss: 0.3490 - val_accuracy: 0.8598\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8643 - val_loss: 0.3465 - val_accuracy: 0.8541\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8654 - val_loss: 0.3598 - val_accuracy: 0.9086\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8688 - val_loss: 0.3435 - val_accuracy: 0.8478\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8696 - val_loss: 0.3531 - val_accuracy: 0.8300\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8692 - val_loss: 0.3350 - val_accuracy: 0.8855\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8735 - val_loss: 0.3305 - val_accuracy: 0.8674\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8722 - val_loss: 0.3335 - val_accuracy: 0.8964\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8729 - val_loss: 0.3260 - val_accuracy: 0.8674\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8729 - val_loss: 0.3234 - val_accuracy: 0.8704\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8758 - val_loss: 0.3332 - val_accuracy: 0.8468\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.8753 - val_loss: 0.3194 - val_accuracy: 0.8704\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8761 - val_loss: 0.3168 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8775 - val_loss: 0.3264 - val_accuracy: 0.9095\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.8781 - val_loss: 0.3132 - val_accuracy: 0.8844\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3098 - accuracy: 0.8789 - val_loss: 0.3161 - val_accuracy: 0.9015\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8796 - val_loss: 0.3122 - val_accuracy: 0.8970\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8793 - val_loss: 0.3078 - val_accuracy: 0.8844\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8814 - val_loss: 0.3093 - val_accuracy: 0.8996\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8819 - val_loss: 0.3078 - val_accuracy: 0.8691\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8804 - val_loss: 0.3068 - val_accuracy: 0.9022\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8842 - val_loss: 0.3022 - val_accuracy: 0.8924\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2999 - accuracy: 0.8843 - val_loss: 0.3027 - val_accuracy: 0.8733\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8834 - val_loss: 0.3000 - val_accuracy: 0.8781\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2961 - accuracy: 0.8842 - val_loss: 0.2994 - val_accuracy: 0.8760\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2946 - accuracy: 0.8851 - val_loss: 0.2971 - val_accuracy: 0.8948\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2942 - accuracy: 0.8867 - val_loss: 0.2996 - val_accuracy: 0.8716\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8874 - val_loss: 0.2941 - val_accuracy: 0.8924\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2910 - accuracy: 0.8868 - val_loss: 0.2933 - val_accuracy: 0.8959\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8871 - val_loss: 0.2925 - val_accuracy: 0.8820\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.8871 - val_loss: 0.2909 - val_accuracy: 0.8860\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.8876 - val_loss: 0.2898 - val_accuracy: 0.8866\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8876 - val_loss: 0.2885 - val_accuracy: 0.8933\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8900 - val_loss: 0.2878 - val_accuracy: 0.8876\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.8896 - val_loss: 0.2888 - val_accuracy: 0.9054\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.8905 - val_loss: 0.2888 - val_accuracy: 0.8783\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8895 - val_loss: 0.2914 - val_accuracy: 0.9125\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.8900 - val_loss: 0.2848 - val_accuracy: 0.9029\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.8904 - val_loss: 0.2849 - val_accuracy: 0.9056\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.8912 - val_loss: 0.2827 - val_accuracy: 0.8881\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8917 - val_loss: 0.2814 - val_accuracy: 0.9012\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8933 - val_loss: 0.2803 - val_accuracy: 0.8934\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.8932 - val_loss: 0.2826 - val_accuracy: 0.8816\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8939 - val_loss: 0.2786 - val_accuracy: 0.8973\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.8935 - val_loss: 0.2779 - val_accuracy: 0.8955\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.8939 - val_loss: 0.2791 - val_accuracy: 0.9077\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8946 - val_loss: 0.2767 - val_accuracy: 0.8933\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.8931 - val_loss: 0.2854 - val_accuracy: 0.8737\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8944 - val_loss: 0.2753 - val_accuracy: 0.8933\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.8936 - val_loss: 0.2743 - val_accuracy: 0.9019\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.8936 - val_loss: 0.2735 - val_accuracy: 0.9019\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.8951 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.8952 - val_loss: 0.2722 - val_accuracy: 0.9021\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.8964 - val_loss: 0.2844 - val_accuracy: 0.8725\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8964 - val_loss: 0.2726 - val_accuracy: 0.8896\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.8956 - val_loss: 0.2703 - val_accuracy: 0.8994\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.8971 - val_loss: 0.2712 - val_accuracy: 0.9096\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.8975 - val_loss: 0.2704 - val_accuracy: 0.9095\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.8965 - val_loss: 0.2730 - val_accuracy: 0.9146\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.8982 - val_loss: 0.2701 - val_accuracy: 0.8901\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.8972 - val_loss: 0.2734 - val_accuracy: 0.9174\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.8984 - val_loss: 0.2688 - val_accuracy: 0.8910\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.8981 - val_loss: 0.2667 - val_accuracy: 0.9084\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.8992 - val_loss: 0.2721 - val_accuracy: 0.8827\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.9000 - val_loss: 0.2666 - val_accuracy: 0.8938\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2638 - accuracy: 0.8990 - val_loss: 0.2652 - val_accuracy: 0.8977\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.8998 - val_loss: 0.2686 - val_accuracy: 0.9163\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8996 - val_loss: 0.2652 - val_accuracy: 0.8941\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2624 - accuracy: 0.9000 - val_loss: 0.2633 - val_accuracy: 0.9012\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.8998 - val_loss: 0.2634 - val_accuracy: 0.9116\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9014 - val_loss: 0.2627 - val_accuracy: 0.9107\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.9003 - val_loss: 0.2614 - val_accuracy: 0.9058\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2606 - accuracy: 0.9002 - val_loss: 0.2611 - val_accuracy: 0.9045\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.9008 - val_loss: 0.2650 - val_accuracy: 0.8894\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.9017 - val_loss: 0.2610 - val_accuracy: 0.9126\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.9015 - val_loss: 0.2627 - val_accuracy: 0.8927\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2592 - accuracy: 0.9002 - val_loss: 0.2600 - val_accuracy: 0.9128\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9017 - val_loss: 0.2587 - val_accuracy: 0.9051\n",
      "277/277 [==============================] - 0s 926us/step - loss: 0.2491 - accuracy: 0.9049\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6572 - accuracy: 0.6083 - val_loss: 0.6271 - val_accuracy: 0.6747\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6062 - accuracy: 0.6823 - val_loss: 0.5831 - val_accuracy: 0.6775\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7281 - val_loss: 0.5505 - val_accuracy: 0.7546\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7536 - val_loss: 0.5244 - val_accuracy: 0.7897\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.7762 - val_loss: 0.5032 - val_accuracy: 0.8103\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.7945 - val_loss: 0.4818 - val_accuracy: 0.7895\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.8019 - val_loss: 0.4656 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4560 - accuracy: 0.8141 - val_loss: 0.4537 - val_accuracy: 0.8369\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.8197 - val_loss: 0.4394 - val_accuracy: 0.8237\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4297 - accuracy: 0.8265 - val_loss: 0.4359 - val_accuracy: 0.7810\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.8344 - val_loss: 0.4184 - val_accuracy: 0.8214\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4086 - accuracy: 0.8370 - val_loss: 0.4109 - val_accuracy: 0.8147\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8431 - val_loss: 0.4013 - val_accuracy: 0.8446\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3918 - accuracy: 0.8464 - val_loss: 0.3984 - val_accuracy: 0.8705\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8501 - val_loss: 0.3881 - val_accuracy: 0.8364\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3771 - accuracy: 0.8531 - val_loss: 0.3818 - val_accuracy: 0.8401\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3712 - accuracy: 0.8555 - val_loss: 0.3752 - val_accuracy: 0.8487\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8587 - val_loss: 0.3728 - val_accuracy: 0.8367\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8607 - val_loss: 0.3651 - val_accuracy: 0.8497\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8624 - val_loss: 0.3602 - val_accuracy: 0.8566\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8627 - val_loss: 0.3594 - val_accuracy: 0.8822\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8668 - val_loss: 0.3532 - val_accuracy: 0.8503\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8668 - val_loss: 0.3506 - val_accuracy: 0.8820\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8693 - val_loss: 0.3444 - val_accuracy: 0.8684\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8705 - val_loss: 0.3447 - val_accuracy: 0.8490\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8713 - val_loss: 0.3430 - val_accuracy: 0.8915\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8716 - val_loss: 0.3350 - val_accuracy: 0.8654\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8753 - val_loss: 0.3319 - val_accuracy: 0.8725\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.8759 - val_loss: 0.3312 - val_accuracy: 0.8608\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8768 - val_loss: 0.3270 - val_accuracy: 0.8679\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8777 - val_loss: 0.3241 - val_accuracy: 0.8741\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8780 - val_loss: 0.3267 - val_accuracy: 0.8578\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8799 - val_loss: 0.3200 - val_accuracy: 0.8848\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3088 - accuracy: 0.8810 - val_loss: 0.3173 - val_accuracy: 0.8807\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.8810 - val_loss: 0.3161 - val_accuracy: 0.8878\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8837 - val_loss: 0.3133 - val_accuracy: 0.8813\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.8828 - val_loss: 0.3160 - val_accuracy: 0.9007\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8828 - val_loss: 0.3126 - val_accuracy: 0.8674\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.8841 - val_loss: 0.3090 - val_accuracy: 0.8917\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8871 - val_loss: 0.3070 - val_accuracy: 0.8915\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8882 - val_loss: 0.3054 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.8857 - val_loss: 0.3096 - val_accuracy: 0.9058\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2920 - accuracy: 0.8868 - val_loss: 0.3033 - val_accuracy: 0.8748\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.8870 - val_loss: 0.3001 - val_accuracy: 0.8859\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8876 - val_loss: 0.3002 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.8884 - val_loss: 0.2997 - val_accuracy: 0.9008\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.8902 - val_loss: 0.2981 - val_accuracy: 0.8762\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8908 - val_loss: 0.3006 - val_accuracy: 0.8693\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.8906 - val_loss: 0.2959 - val_accuracy: 0.8765\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.8907 - val_loss: 0.2929 - val_accuracy: 0.8957\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.8909 - val_loss: 0.2913 - val_accuracy: 0.8888\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.8923 - val_loss: 0.2903 - val_accuracy: 0.8934\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.8916 - val_loss: 0.2920 - val_accuracy: 0.8774\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.8929 - val_loss: 0.2901 - val_accuracy: 0.8804\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8930 - val_loss: 0.2900 - val_accuracy: 0.9063\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.8938 - val_loss: 0.2861 - val_accuracy: 0.8911\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.8946 - val_loss: 0.2851 - val_accuracy: 0.8913\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8948 - val_loss: 0.2841 - val_accuracy: 0.8934\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.8952 - val_loss: 0.2843 - val_accuracy: 0.8857\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.8954 - val_loss: 0.2888 - val_accuracy: 0.8744\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2708 - accuracy: 0.8951 - val_loss: 0.2887 - val_accuracy: 0.9149\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8960 - val_loss: 0.2868 - val_accuracy: 0.9125\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8956 - val_loss: 0.2950 - val_accuracy: 0.9207\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2679 - accuracy: 0.8977 - val_loss: 0.2790 - val_accuracy: 0.8973\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.8959 - val_loss: 0.2782 - val_accuracy: 0.8978\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.8968 - val_loss: 0.2775 - val_accuracy: 0.9003\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.8968 - val_loss: 0.2815 - val_accuracy: 0.8800\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.8979 - val_loss: 0.2804 - val_accuracy: 0.9117\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.8983 - val_loss: 0.2767 - val_accuracy: 0.9068\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.8975 - val_loss: 0.2762 - val_accuracy: 0.8881\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.8986 - val_loss: 0.2738 - val_accuracy: 0.8982\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.8983 - val_loss: 0.2737 - val_accuracy: 0.8933\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2609 - accuracy: 0.9003 - val_loss: 0.2734 - val_accuracy: 0.8917\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.8996 - val_loss: 0.2725 - val_accuracy: 0.9061\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9009 - val_loss: 0.2713 - val_accuracy: 0.8992\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.8988 - val_loss: 0.2705 - val_accuracy: 0.9017\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.8997 - val_loss: 0.2721 - val_accuracy: 0.9112\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9003 - val_loss: 0.2700 - val_accuracy: 0.8952\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.9008 - val_loss: 0.2691 - val_accuracy: 0.8973\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.9012 - val_loss: 0.2682 - val_accuracy: 0.9019\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2566 - accuracy: 0.9007 - val_loss: 0.2678 - val_accuracy: 0.9005\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9009 - val_loss: 0.2726 - val_accuracy: 0.8848\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9008 - val_loss: 0.2667 - val_accuracy: 0.9061\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9022 - val_loss: 0.2663 - val_accuracy: 0.8998\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.9016 - val_loss: 0.2689 - val_accuracy: 0.8885\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9024 - val_loss: 0.2690 - val_accuracy: 0.9165\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9037 - val_loss: 0.2644 - val_accuracy: 0.9052\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9037 - val_loss: 0.2678 - val_accuracy: 0.9165\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9025 - val_loss: 0.2642 - val_accuracy: 0.8980\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9032 - val_loss: 0.2635 - val_accuracy: 0.8987\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.9028 - val_loss: 0.2645 - val_accuracy: 0.9133\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9022 - val_loss: 0.2633 - val_accuracy: 0.9128\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.9038 - val_loss: 0.2696 - val_accuracy: 0.9221\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9047 - val_loss: 0.2613 - val_accuracy: 0.9014\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.9050 - val_loss: 0.2645 - val_accuracy: 0.8901\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9042 - val_loss: 0.2637 - val_accuracy: 0.8908\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9036 - val_loss: 0.2602 - val_accuracy: 0.9007\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.9046 - val_loss: 0.2614 - val_accuracy: 0.8948\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9050 - val_loss: 0.2623 - val_accuracy: 0.9170\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9054 - val_loss: 0.2615 - val_accuracy: 0.9169\n",
      "277/277 [==============================] - 0s 910us/step - loss: 0.2731 - accuracy: 0.9124\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6442 - accuracy: 0.6239 - val_loss: 0.6159 - val_accuracy: 0.7166\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6945 - val_loss: 0.5740 - val_accuracy: 0.6778\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5613 - accuracy: 0.7344 - val_loss: 0.5403 - val_accuracy: 0.7460\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7545 - val_loss: 0.5164 - val_accuracy: 0.7428\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5101 - accuracy: 0.7753 - val_loss: 0.4951 - val_accuracy: 0.7717\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7906 - val_loss: 0.4777 - val_accuracy: 0.7888\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.8031 - val_loss: 0.4637 - val_accuracy: 0.7777\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.8088 - val_loss: 0.4527 - val_accuracy: 0.7763\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.8162 - val_loss: 0.4380 - val_accuracy: 0.7992\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8242 - val_loss: 0.4347 - val_accuracy: 0.8700\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4258 - accuracy: 0.8315 - val_loss: 0.4249 - val_accuracy: 0.7874\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8342 - val_loss: 0.4112 - val_accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.8377 - val_loss: 0.4009 - val_accuracy: 0.8482\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8427 - val_loss: 0.3934 - val_accuracy: 0.8460\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8462 - val_loss: 0.3902 - val_accuracy: 0.8695\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3862 - accuracy: 0.8506 - val_loss: 0.3881 - val_accuracy: 0.8832\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3802 - accuracy: 0.8531 - val_loss: 0.3799 - val_accuracy: 0.8260\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3756 - accuracy: 0.8525 - val_loss: 0.3698 - val_accuracy: 0.8490\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8579 - val_loss: 0.3661 - val_accuracy: 0.8455\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8586 - val_loss: 0.3610 - val_accuracy: 0.8682\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8594 - val_loss: 0.3569 - val_accuracy: 0.8704\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3561 - accuracy: 0.8622 - val_loss: 0.3536 - val_accuracy: 0.8485\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8628 - val_loss: 0.3549 - val_accuracy: 0.8906\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8655 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8662 - val_loss: 0.3422 - val_accuracy: 0.8575\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8666 - val_loss: 0.3396 - val_accuracy: 0.8807\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8680 - val_loss: 0.3361 - val_accuracy: 0.8600\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8695 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8718 - val_loss: 0.3360 - val_accuracy: 0.8982\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8739 - val_loss: 0.3284 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8738 - val_loss: 0.3242 - val_accuracy: 0.8725\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8757 - val_loss: 0.3218 - val_accuracy: 0.8730\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8767 - val_loss: 0.3231 - val_accuracy: 0.8594\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8765 - val_loss: 0.3176 - val_accuracy: 0.8822\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.8784 - val_loss: 0.3223 - val_accuracy: 0.9019\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8792 - val_loss: 0.3131 - val_accuracy: 0.8779\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3141 - accuracy: 0.8806 - val_loss: 0.3127 - val_accuracy: 0.8688\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3128 - accuracy: 0.8807 - val_loss: 0.3097 - val_accuracy: 0.8744\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8808 - val_loss: 0.3076 - val_accuracy: 0.8832\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8836 - val_loss: 0.3057 - val_accuracy: 0.8799\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3073 - accuracy: 0.8828 - val_loss: 0.3061 - val_accuracy: 0.8961\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3054 - accuracy: 0.8840 - val_loss: 0.3036 - val_accuracy: 0.8929\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8850 - val_loss: 0.3008 - val_accuracy: 0.8871\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8854 - val_loss: 0.2999 - val_accuracy: 0.8765\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3010 - accuracy: 0.8854 - val_loss: 0.2977 - val_accuracy: 0.8890\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2994 - accuracy: 0.8867 - val_loss: 0.2963 - val_accuracy: 0.8894\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8869 - val_loss: 0.2951 - val_accuracy: 0.8911\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8871 - val_loss: 0.2952 - val_accuracy: 0.9001\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8874 - val_loss: 0.2928 - val_accuracy: 0.8938\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8889 - val_loss: 0.2910 - val_accuracy: 0.8887\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.8882 - val_loss: 0.2917 - val_accuracy: 0.9007\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8887 - val_loss: 0.2891 - val_accuracy: 0.8968\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.8897 - val_loss: 0.2899 - val_accuracy: 0.9040\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8912 - val_loss: 0.2864 - val_accuracy: 0.8871\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8902 - val_loss: 0.2910 - val_accuracy: 0.9105\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2870 - accuracy: 0.8905 - val_loss: 0.2843 - val_accuracy: 0.8878\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2866 - accuracy: 0.8923 - val_loss: 0.2874 - val_accuracy: 0.8746\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2859 - accuracy: 0.8912 - val_loss: 0.2821 - val_accuracy: 0.8920\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.8923 - val_loss: 0.2811 - val_accuracy: 0.8952\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8927 - val_loss: 0.2821 - val_accuracy: 0.9058\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8933 - val_loss: 0.2794 - val_accuracy: 0.8885\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2813 - accuracy: 0.8936 - val_loss: 0.2823 - val_accuracy: 0.9096\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.8942 - val_loss: 0.2792 - val_accuracy: 0.8823\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.8939 - val_loss: 0.2807 - val_accuracy: 0.8778\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8951 - val_loss: 0.2756 - val_accuracy: 0.8915\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.8948 - val_loss: 0.2764 - val_accuracy: 0.9066\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.8949 - val_loss: 0.2742 - val_accuracy: 0.8910\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8962 - val_loss: 0.2729 - val_accuracy: 0.8968\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8965 - val_loss: 0.2722 - val_accuracy: 0.9005\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8960 - val_loss: 0.2715 - val_accuracy: 0.8938\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.8959 - val_loss: 0.2728 - val_accuracy: 0.8853\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8966 - val_loss: 0.2770 - val_accuracy: 0.8772\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2726 - accuracy: 0.8970 - val_loss: 0.2692 - val_accuracy: 0.9012\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.8979 - val_loss: 0.2692 - val_accuracy: 0.9063\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2714 - accuracy: 0.8968 - val_loss: 0.2776 - val_accuracy: 0.9202\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2709 - accuracy: 0.8977 - val_loss: 0.2669 - val_accuracy: 0.9005\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2705 - accuracy: 0.8976 - val_loss: 0.2662 - val_accuracy: 0.9005\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2698 - accuracy: 0.8986 - val_loss: 0.2655 - val_accuracy: 0.9003\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.8980 - val_loss: 0.2653 - val_accuracy: 0.8941\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.8977 - val_loss: 0.2651 - val_accuracy: 0.8933\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2681 - accuracy: 0.8994 - val_loss: 0.2722 - val_accuracy: 0.8779\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.8996 - val_loss: 0.2743 - val_accuracy: 0.9221\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.8996 - val_loss: 0.2627 - val_accuracy: 0.8966\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2661 - accuracy: 0.8984 - val_loss: 0.2670 - val_accuracy: 0.8829\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.9009 - val_loss: 0.2626 - val_accuracy: 0.8929\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.8999 - val_loss: 0.2609 - val_accuracy: 0.9068\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2649 - accuracy: 0.9004 - val_loss: 0.2621 - val_accuracy: 0.8913\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.8998 - val_loss: 0.2608 - val_accuracy: 0.9114\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.9005 - val_loss: 0.2624 - val_accuracy: 0.9154\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8999 - val_loss: 0.2590 - val_accuracy: 0.9107\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9019 - val_loss: 0.2581 - val_accuracy: 0.9001\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2618 - accuracy: 0.9012 - val_loss: 0.2575 - val_accuracy: 0.9015\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.9021 - val_loss: 0.2568 - val_accuracy: 0.9036\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9024 - val_loss: 0.2563 - val_accuracy: 0.9054\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.9020 - val_loss: 0.2591 - val_accuracy: 0.8908\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.9035 - val_loss: 0.2554 - val_accuracy: 0.9040\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.9036 - val_loss: 0.2602 - val_accuracy: 0.9190\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9026 - val_loss: 0.2572 - val_accuracy: 0.8931\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2584 - accuracy: 0.9034 - val_loss: 0.2592 - val_accuracy: 0.8883\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.9028 - val_loss: 0.2540 - val_accuracy: 0.9123\n",
      "277/277 [==============================] - 0s 917us/step - loss: 0.2463 - accuracy: 0.9090\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6330 - accuracy: 0.6445 - val_loss: 0.5327 - val_accuracy: 0.7055\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8415 - val_loss: 0.2974 - val_accuracy: 0.8860\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2853 - accuracy: 0.8891 - val_loss: 0.2513 - val_accuracy: 0.9031\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2634 - accuracy: 0.9000 - val_loss: 0.2411 - val_accuracy: 0.9190\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2510 - accuracy: 0.9036 - val_loss: 0.2636 - val_accuracy: 0.9211\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.9080 - val_loss: 0.2266 - val_accuracy: 0.9096\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.9090 - val_loss: 0.2134 - val_accuracy: 0.9227\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2368 - accuracy: 0.9104 - val_loss: 0.2468 - val_accuracy: 0.9220\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2333 - accuracy: 0.9108 - val_loss: 0.2130 - val_accuracy: 0.9287\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2319 - accuracy: 0.9133 - val_loss: 0.2405 - val_accuracy: 0.9193\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9166 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2241 - accuracy: 0.9164 - val_loss: 0.2318 - val_accuracy: 0.9088\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.9159 - val_loss: 0.2214 - val_accuracy: 0.9128\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2199 - accuracy: 0.9165 - val_loss: 0.2704 - val_accuracy: 0.8952\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2171 - accuracy: 0.9185 - val_loss: 0.2234 - val_accuracy: 0.9146\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2172 - accuracy: 0.9187 - val_loss: 0.2007 - val_accuracy: 0.9234\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9178 - val_loss: 0.1886 - val_accuracy: 0.9297\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2076 - accuracy: 0.9218 - val_loss: 0.1830 - val_accuracy: 0.9338\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2050 - accuracy: 0.9227 - val_loss: 0.1799 - val_accuracy: 0.9376\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2028 - accuracy: 0.9231 - val_loss: 0.2347 - val_accuracy: 0.9042\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2051 - accuracy: 0.9229 - val_loss: 0.1767 - val_accuracy: 0.9354\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9261 - val_loss: 0.1704 - val_accuracy: 0.9403\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9282 - val_loss: 0.1888 - val_accuracy: 0.9345\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.9270 - val_loss: 0.1693 - val_accuracy: 0.9389\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.9301 - val_loss: 0.1595 - val_accuracy: 0.9468\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.9324 - val_loss: 0.1556 - val_accuracy: 0.9479\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.9326 - val_loss: 0.1507 - val_accuracy: 0.9493\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.9363 - val_loss: 0.1457 - val_accuracy: 0.9510\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.9362 - val_loss: 0.1419 - val_accuracy: 0.9498\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1662 - accuracy: 0.9381 - val_loss: 0.1501 - val_accuracy: 0.9591\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1668 - accuracy: 0.9406 - val_loss: 0.1698 - val_accuracy: 0.9389\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9370 - val_loss: 0.1964 - val_accuracy: 0.9271\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9395 - val_loss: 0.1974 - val_accuracy: 0.9260\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1640 - accuracy: 0.9414 - val_loss: 0.1298 - val_accuracy: 0.9609\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1524 - accuracy: 0.9446 - val_loss: 0.1319 - val_accuracy: 0.9551\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1516 - accuracy: 0.9456 - val_loss: 0.8160 - val_accuracy: 0.5313\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1695 - accuracy: 0.9388 - val_loss: 0.1578 - val_accuracy: 0.9424\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9455 - val_loss: 0.1310 - val_accuracy: 0.9556\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.9465 - val_loss: 0.2203 - val_accuracy: 0.9221\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9484 - val_loss: 0.1210 - val_accuracy: 0.9598\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9487 - val_loss: 0.1201 - val_accuracy: 0.9627\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9512 - val_loss: 0.2102 - val_accuracy: 0.9253\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1602 - accuracy: 0.9432 - val_loss: 0.1445 - val_accuracy: 0.9484\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9451 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9447 - val_loss: 0.1262 - val_accuracy: 0.9579\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1485 - accuracy: 0.9480 - val_loss: 0.1374 - val_accuracy: 0.9577\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9511 - val_loss: 0.1148 - val_accuracy: 0.9628\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1552 - accuracy: 0.9447 - val_loss: 0.1362 - val_accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9498 - val_loss: 0.1426 - val_accuracy: 0.9501\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9491 - val_loss: 0.1625 - val_accuracy: 0.9459\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9492 - val_loss: 0.1239 - val_accuracy: 0.9595\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1536 - accuracy: 0.9455 - val_loss: 0.1972 - val_accuracy: 0.9174\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9494 - val_loss: 0.2133 - val_accuracy: 0.9267\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1407 - accuracy: 0.9505 - val_loss: 0.1285 - val_accuracy: 0.9553\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.9521 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9506 - val_loss: 0.1383 - val_accuracy: 0.9526\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.9534 - val_loss: 0.1132 - val_accuracy: 0.9635\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9514 - val_loss: 0.1357 - val_accuracy: 0.9524\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9485 - val_loss: 0.1264 - val_accuracy: 0.9563\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1340 - accuracy: 0.9531 - val_loss: 0.1451 - val_accuracy: 0.9482\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.9544 - val_loss: 0.1144 - val_accuracy: 0.9605\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1360 - accuracy: 0.9526 - val_loss: 0.1140 - val_accuracy: 0.9635\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9521 - val_loss: 0.1331 - val_accuracy: 0.9547\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9498 - val_loss: 0.1109 - val_accuracy: 0.9660\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1308 - accuracy: 0.9549 - val_loss: 0.1196 - val_accuracy: 0.9588\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1363 - accuracy: 0.9522 - val_loss: 0.1418 - val_accuracy: 0.9523\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1316 - accuracy: 0.9537 - val_loss: 0.1464 - val_accuracy: 0.9491\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1359 - accuracy: 0.9521 - val_loss: 0.1092 - val_accuracy: 0.9655\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9546 - val_loss: 0.1135 - val_accuracy: 0.9618\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9551 - val_loss: 0.1060 - val_accuracy: 0.9667\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9547 - val_loss: 0.1118 - val_accuracy: 0.9628\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.9541 - val_loss: 0.1177 - val_accuracy: 0.9611\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9585 - val_loss: 0.1094 - val_accuracy: 0.9639\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1318 - accuracy: 0.9548 - val_loss: 0.1217 - val_accuracy: 0.9590\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9558 - val_loss: 0.1200 - val_accuracy: 0.9581\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1235 - accuracy: 0.9586 - val_loss: 0.4309 - val_accuracy: 0.8723\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9529 - val_loss: 0.1622 - val_accuracy: 0.9417\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9541 - val_loss: 0.1225 - val_accuracy: 0.9581\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1266 - accuracy: 0.9557 - val_loss: 0.1100 - val_accuracy: 0.9648\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1272 - accuracy: 0.9557 - val_loss: 0.1335 - val_accuracy: 0.9531\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9516\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.6621 - val_loss: 0.5504 - val_accuracy: 0.6981\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8631 - val_loss: 0.2759 - val_accuracy: 0.8885\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.8979 - val_loss: 0.2490 - val_accuracy: 0.9176\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9041 - val_loss: 0.2409 - val_accuracy: 0.9019\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.9085 - val_loss: 0.3186 - val_accuracy: 0.9035\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2329 - accuracy: 0.9109 - val_loss: 0.2245 - val_accuracy: 0.9276\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2286 - accuracy: 0.9147 - val_loss: 0.2183 - val_accuracy: 0.9290\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2240 - accuracy: 0.9145 - val_loss: 0.2179 - val_accuracy: 0.9285\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2183 - accuracy: 0.9182 - val_loss: 0.2067 - val_accuracy: 0.9306\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9178 - val_loss: 0.2113 - val_accuracy: 0.9169\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9189 - val_loss: 0.1959 - val_accuracy: 0.9290\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9195 - val_loss: 0.1950 - val_accuracy: 0.9260\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2148 - accuracy: 0.9195 - val_loss: 0.1919 - val_accuracy: 0.9290\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2075 - accuracy: 0.9229 - val_loss: 0.1908 - val_accuracy: 0.9331\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2049 - accuracy: 0.9237 - val_loss: 0.1868 - val_accuracy: 0.9343\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9238 - val_loss: 0.1890 - val_accuracy: 0.9281\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.9235 - val_loss: 0.2304 - val_accuracy: 0.9133\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2004 - accuracy: 0.9260 - val_loss: 0.1839 - val_accuracy: 0.9302\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1988 - accuracy: 0.9263 - val_loss: 0.2098 - val_accuracy: 0.9274\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9269 - val_loss: 0.1847 - val_accuracy: 0.9297\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9271 - val_loss: 0.1855 - val_accuracy: 0.9369\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9290 - val_loss: 0.1816 - val_accuracy: 0.9391\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9277 - val_loss: 0.1707 - val_accuracy: 0.9394\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9284 - val_loss: 0.1689 - val_accuracy: 0.9413\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9306 - val_loss: 0.1710 - val_accuracy: 0.9369\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1927 - accuracy: 0.9307 - val_loss: 0.1698 - val_accuracy: 0.9406\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.9354 - val_loss: 0.1755 - val_accuracy: 0.9355\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.9357 - val_loss: 0.2015 - val_accuracy: 0.9285\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.9353 - val_loss: 0.1533 - val_accuracy: 0.9466\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9385 - val_loss: 0.1464 - val_accuracy: 0.9501\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9381 - val_loss: 0.1462 - val_accuracy: 0.9491\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1728 - accuracy: 0.9371 - val_loss: 0.1650 - val_accuracy: 0.9408\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1574 - accuracy: 0.9442 - val_loss: 0.1463 - val_accuracy: 0.9472\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1539 - accuracy: 0.9442 - val_loss: 0.1656 - val_accuracy: 0.9413\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1565 - accuracy: 0.9430 - val_loss: 0.1510 - val_accuracy: 0.9489\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9433 - val_loss: 0.1296 - val_accuracy: 0.9542\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.9470 - val_loss: 0.1875 - val_accuracy: 0.9369\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9444 - val_loss: 0.1365 - val_accuracy: 0.9510\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9459 - val_loss: 0.1267 - val_accuracy: 0.9546\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9466 - val_loss: 0.1501 - val_accuracy: 0.9465\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1400 - accuracy: 0.9519 - val_loss: 0.1910 - val_accuracy: 0.9308\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1404 - accuracy: 0.9497 - val_loss: 0.1296 - val_accuracy: 0.9533\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1403 - accuracy: 0.9505 - val_loss: 0.2022 - val_accuracy: 0.9285\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1380 - accuracy: 0.9521 - val_loss: 0.1160 - val_accuracy: 0.9625\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9499 - val_loss: 0.1707 - val_accuracy: 0.9392\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1411 - accuracy: 0.9526 - val_loss: 0.1381 - val_accuracy: 0.9540\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1445 - accuracy: 0.9496 - val_loss: 0.1386 - val_accuracy: 0.9530\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9520 - val_loss: 0.1141 - val_accuracy: 0.9612\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9557 - val_loss: 0.1511 - val_accuracy: 0.9461\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1442 - accuracy: 0.9506 - val_loss: 0.1841 - val_accuracy: 0.9385\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1448 - accuracy: 0.9510 - val_loss: 0.1264 - val_accuracy: 0.9583\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9543 - val_loss: 0.1202 - val_accuracy: 0.9586\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1424 - accuracy: 0.9515 - val_loss: 0.1149 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1342 - accuracy: 0.9530 - val_loss: 0.1526 - val_accuracy: 0.9461\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1363 - accuracy: 0.9523 - val_loss: 0.1141 - val_accuracy: 0.9623\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9553 - val_loss: 0.3176 - val_accuracy: 0.8792\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9492 - val_loss: 0.1509 - val_accuracy: 0.9459\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1333 - accuracy: 0.9542 - val_loss: 0.2433 - val_accuracy: 0.9125\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1383 - accuracy: 0.9520 - val_loss: 0.1456 - val_accuracy: 0.9507\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1424 - accuracy: 0.9518 - val_loss: 0.1154 - val_accuracy: 0.9616\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9568 - val_loss: 0.1132 - val_accuracy: 0.9614\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1325 - accuracy: 0.9540 - val_loss: 0.1168 - val_accuracy: 0.9628\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1317 - accuracy: 0.9544 - val_loss: 0.1363 - val_accuracy: 0.9535\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9523 - val_loss: 0.1095 - val_accuracy: 0.9649\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1416 - accuracy: 0.9503 - val_loss: 0.1124 - val_accuracy: 0.9644\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1249 - accuracy: 0.9562 - val_loss: 0.1405 - val_accuracy: 0.9528\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1360 - accuracy: 0.9526 - val_loss: 0.1387 - val_accuracy: 0.9538\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1268 - accuracy: 0.9571 - val_loss: 0.1052 - val_accuracy: 0.9658\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9547 - val_loss: 0.1403 - val_accuracy: 0.9535\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9569 - val_loss: 0.1830 - val_accuracy: 0.9350\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9572 - val_loss: 0.1237 - val_accuracy: 0.9575\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1284 - accuracy: 0.9562 - val_loss: 0.1131 - val_accuracy: 0.9623\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1227 - accuracy: 0.9584 - val_loss: 0.1176 - val_accuracy: 0.9602\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9518 - val_loss: 0.1131 - val_accuracy: 0.9625\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.9586 - val_loss: 0.2207 - val_accuracy: 0.9232\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9536 - val_loss: 0.1118 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1352 - accuracy: 0.9540 - val_loss: 0.1222 - val_accuracy: 0.9579\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9593 - val_loss: 0.1020 - val_accuracy: 0.9685\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9521 - val_loss: 0.1047 - val_accuracy: 0.9657\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1260 - accuracy: 0.9574 - val_loss: 0.1326 - val_accuracy: 0.9563\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1219 - accuracy: 0.9591 - val_loss: 0.1057 - val_accuracy: 0.9649\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9551 - val_loss: 0.1098 - val_accuracy: 0.9635\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1281 - accuracy: 0.9570 - val_loss: 0.1087 - val_accuracy: 0.9644\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1288 - accuracy: 0.9559 - val_loss: 0.1020 - val_accuracy: 0.9701\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9560 - val_loss: 0.1096 - val_accuracy: 0.9646\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9521 - val_loss: 0.2058 - val_accuracy: 0.9304\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9577 - val_loss: 0.1037 - val_accuracy: 0.9688\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1296 - accuracy: 0.9553 - val_loss: 0.1988 - val_accuracy: 0.9301\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9586 - val_loss: 0.1108 - val_accuracy: 0.9637\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1200 - accuracy: 0.9595 - val_loss: 0.1066 - val_accuracy: 0.9676\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1194 - accuracy: 0.9590 - val_loss: 0.1015 - val_accuracy: 0.9685\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1263 - accuracy: 0.9575 - val_loss: 0.1304 - val_accuracy: 0.9567\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1226 - accuracy: 0.9585 - val_loss: 0.1652 - val_accuracy: 0.9431\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1269 - accuracy: 0.9573 - val_loss: 0.1244 - val_accuracy: 0.9593\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1162 - accuracy: 0.9617 - val_loss: 0.1097 - val_accuracy: 0.9641\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1244 - accuracy: 0.9582 - val_loss: 0.1909 - val_accuracy: 0.9362\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1175 - accuracy: 0.9608 - val_loss: 0.1354 - val_accuracy: 0.9549\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1220 - accuracy: 0.9585 - val_loss: 0.1134 - val_accuracy: 0.9620\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9578 - val_loss: 0.2542 - val_accuracy: 0.8903\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1264 - accuracy: 0.9576 - val_loss: 0.1028 - val_accuracy: 0.9672\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9660\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6386 - accuracy: 0.6340 - val_loss: 0.5499 - val_accuracy: 0.6928\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4001 - accuracy: 0.8430 - val_loss: 0.3474 - val_accuracy: 0.8295\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.8917 - val_loss: 0.3171 - val_accuracy: 0.8564\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9033 - val_loss: 0.2376 - val_accuracy: 0.9244\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9089 - val_loss: 0.2411 - val_accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.9122 - val_loss: 0.2155 - val_accuracy: 0.9280\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2316 - accuracy: 0.9144 - val_loss: 0.2315 - val_accuracy: 0.9044\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2298 - accuracy: 0.9165 - val_loss: 0.2006 - val_accuracy: 0.9253\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2203 - accuracy: 0.9197 - val_loss: 0.3729 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9193 - val_loss: 0.2338 - val_accuracy: 0.9059\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2150 - accuracy: 0.9221 - val_loss: 0.2212 - val_accuracy: 0.9133\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2227 - accuracy: 0.9182 - val_loss: 0.2145 - val_accuracy: 0.9281\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2159 - accuracy: 0.9215 - val_loss: 0.1975 - val_accuracy: 0.9331\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9258 - val_loss: 0.3483 - val_accuracy: 0.8682\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2104 - accuracy: 0.9248 - val_loss: 0.1835 - val_accuracy: 0.9320\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9253 - val_loss: 0.2580 - val_accuracy: 0.8927\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9245 - val_loss: 0.1954 - val_accuracy: 0.9258\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9270 - val_loss: 0.1905 - val_accuracy: 0.9288\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9259 - val_loss: 0.1943 - val_accuracy: 0.9288\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2024 - accuracy: 0.9245 - val_loss: 0.1719 - val_accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9281 - val_loss: 0.1905 - val_accuracy: 0.9387\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9337 - val_loss: 0.1830 - val_accuracy: 0.9399\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9289 - val_loss: 0.2493 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9343 - val_loss: 0.1606 - val_accuracy: 0.9475\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.9338 - val_loss: 0.1574 - val_accuracy: 0.9493\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9356 - val_loss: 0.1725 - val_accuracy: 0.9352\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.9363 - val_loss: 0.1472 - val_accuracy: 0.9523\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1693 - accuracy: 0.9390 - val_loss: 0.1557 - val_accuracy: 0.9450\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.9386 - val_loss: 0.1670 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1612 - accuracy: 0.9412 - val_loss: 0.1387 - val_accuracy: 0.9517\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1525 - accuracy: 0.9461 - val_loss: 0.2371 - val_accuracy: 0.9133\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9452 - val_loss: 0.2119 - val_accuracy: 0.9271\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9479 - val_loss: 0.1369 - val_accuracy: 0.9524\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1502 - accuracy: 0.9460 - val_loss: 0.2503 - val_accuracy: 0.9065\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9445 - val_loss: 0.1282 - val_accuracy: 0.9570\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9492 - val_loss: 0.1542 - val_accuracy: 0.9420\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1409 - accuracy: 0.9510 - val_loss: 0.1179 - val_accuracy: 0.9639\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1441 - accuracy: 0.9498 - val_loss: 0.1430 - val_accuracy: 0.9479\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1508 - accuracy: 0.9470 - val_loss: 0.2419 - val_accuracy: 0.9165\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1520 - accuracy: 0.9483 - val_loss: 0.2507 - val_accuracy: 0.9109\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1398 - accuracy: 0.9529 - val_loss: 0.1209 - val_accuracy: 0.9600\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9495 - val_loss: 0.1464 - val_accuracy: 0.9477\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1420 - accuracy: 0.9510 - val_loss: 0.2061 - val_accuracy: 0.9153\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1435 - accuracy: 0.9506 - val_loss: 0.1150 - val_accuracy: 0.9627\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9544 - val_loss: 0.1196 - val_accuracy: 0.9614\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1379 - accuracy: 0.9531 - val_loss: 0.1558 - val_accuracy: 0.9494\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9512 - val_loss: 0.1113 - val_accuracy: 0.9651\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1399 - accuracy: 0.9515 - val_loss: 0.2089 - val_accuracy: 0.9285\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9530 - val_loss: 0.1104 - val_accuracy: 0.9664\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9475 - val_loss: 0.1298 - val_accuracy: 0.9556\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1386 - accuracy: 0.9521 - val_loss: 0.1226 - val_accuracy: 0.9611\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9510 - val_loss: 0.1298 - val_accuracy: 0.9567\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9542 - val_loss: 0.1137 - val_accuracy: 0.9646\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9553 - val_loss: 0.2652 - val_accuracy: 0.9079\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9518 - val_loss: 0.1206 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1540 - accuracy: 0.9454 - val_loss: 0.1196 - val_accuracy: 0.9642\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1375 - accuracy: 0.9530 - val_loss: 0.1172 - val_accuracy: 0.9628\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1368 - accuracy: 0.9525 - val_loss: 0.1209 - val_accuracy: 0.9611\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1392 - accuracy: 0.9512 - val_loss: 0.1357 - val_accuracy: 0.9533\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9508\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6604 - accuracy: 0.5975 - val_loss: 0.6362 - val_accuracy: 0.6174\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6257 - accuracy: 0.6461 - val_loss: 0.6087 - val_accuracy: 0.6459\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6865 - val_loss: 0.5838 - val_accuracy: 0.6951\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5768 - accuracy: 0.7133 - val_loss: 0.5632 - val_accuracy: 0.7069\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5565 - accuracy: 0.7351 - val_loss: 0.5484 - val_accuracy: 0.7777\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7497 - val_loss: 0.5313 - val_accuracy: 0.7812\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7642 - val_loss: 0.5155 - val_accuracy: 0.7731\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5107 - accuracy: 0.7733 - val_loss: 0.5029 - val_accuracy: 0.7603\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4984 - accuracy: 0.7842 - val_loss: 0.4923 - val_accuracy: 0.7988\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7902 - val_loss: 0.4809 - val_accuracy: 0.7853\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7983 - val_loss: 0.4721 - val_accuracy: 0.7763\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.8037 - val_loss: 0.4629 - val_accuracy: 0.7856\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.8085 - val_loss: 0.4541 - val_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.8158 - val_loss: 0.4467 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.8179 - val_loss: 0.4431 - val_accuracy: 0.8492\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8217 - val_loss: 0.4332 - val_accuracy: 0.8092\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4290 - accuracy: 0.8233 - val_loss: 0.4300 - val_accuracy: 0.8526\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8288 - val_loss: 0.4212 - val_accuracy: 0.8344\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4180 - accuracy: 0.8323 - val_loss: 0.4161 - val_accuracy: 0.8386\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8337 - val_loss: 0.4116 - val_accuracy: 0.8468\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8375 - val_loss: 0.4064 - val_accuracy: 0.8448\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4030 - accuracy: 0.8381 - val_loss: 0.4019 - val_accuracy: 0.8469\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3984 - accuracy: 0.8391 - val_loss: 0.3978 - val_accuracy: 0.8339\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8415 - val_loss: 0.3943 - val_accuracy: 0.8564\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8434 - val_loss: 0.3915 - val_accuracy: 0.8279\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3862 - accuracy: 0.8453 - val_loss: 0.3857 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3826 - accuracy: 0.8472 - val_loss: 0.3862 - val_accuracy: 0.8254\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3787 - accuracy: 0.8490 - val_loss: 0.3801 - val_accuracy: 0.8383\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3754 - accuracy: 0.8517 - val_loss: 0.3855 - val_accuracy: 0.8138\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3723 - accuracy: 0.8517 - val_loss: 0.3810 - val_accuracy: 0.8173\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8538 - val_loss: 0.3698 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3657 - accuracy: 0.8553 - val_loss: 0.3668 - val_accuracy: 0.8619\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8573 - val_loss: 0.3671 - val_accuracy: 0.8395\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8575 - val_loss: 0.3616 - val_accuracy: 0.8651\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8586 - val_loss: 0.3611 - val_accuracy: 0.8765\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.8600 - val_loss: 0.3594 - val_accuracy: 0.8793\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8610 - val_loss: 0.3542 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8619 - val_loss: 0.3523 - val_accuracy: 0.8688\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8630 - val_loss: 0.3506 - val_accuracy: 0.8735\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8630 - val_loss: 0.3492 - val_accuracy: 0.8772\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8641 - val_loss: 0.3459 - val_accuracy: 0.8624\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8669 - val_loss: 0.3476 - val_accuracy: 0.8482\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8652 - val_loss: 0.3422 - val_accuracy: 0.8633\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8682 - val_loss: 0.3419 - val_accuracy: 0.8823\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.8685 - val_loss: 0.3393 - val_accuracy: 0.8783\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8688 - val_loss: 0.3382 - val_accuracy: 0.8593\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8701 - val_loss: 0.3352 - val_accuracy: 0.8739\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8707 - val_loss: 0.3335 - val_accuracy: 0.8695\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8703 - val_loss: 0.3321 - val_accuracy: 0.8762\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8713 - val_loss: 0.3306 - val_accuracy: 0.8769\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8713 - val_loss: 0.3294 - val_accuracy: 0.8809\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8734 - val_loss: 0.3291 - val_accuracy: 0.8623\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8734 - val_loss: 0.3262 - val_accuracy: 0.8799\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8735 - val_loss: 0.3247 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8742 - val_loss: 0.3276 - val_accuracy: 0.8962\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8756 - val_loss: 0.3229 - val_accuracy: 0.8672\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8770 - val_loss: 0.3206 - val_accuracy: 0.8797\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3179 - accuracy: 0.8765 - val_loss: 0.3222 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8758 - val_loss: 0.3195 - val_accuracy: 0.8892\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8772 - val_loss: 0.3179 - val_accuracy: 0.8881\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8771 - val_loss: 0.3166 - val_accuracy: 0.8871\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8787 - val_loss: 0.3153 - val_accuracy: 0.8866\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.8789 - val_loss: 0.3145 - val_accuracy: 0.8887\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3104 - accuracy: 0.8785 - val_loss: 0.3143 - val_accuracy: 0.8924\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3099 - accuracy: 0.8802 - val_loss: 0.3122 - val_accuracy: 0.8739\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.8788 - val_loss: 0.3126 - val_accuracy: 0.8940\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8805 - val_loss: 0.3111 - val_accuracy: 0.8927\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3063 - accuracy: 0.8800 - val_loss: 0.3086 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3057 - accuracy: 0.8803 - val_loss: 0.3077 - val_accuracy: 0.8807\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3051 - accuracy: 0.8806 - val_loss: 0.3074 - val_accuracy: 0.8908\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8814 - val_loss: 0.3058 - val_accuracy: 0.8822\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3028 - accuracy: 0.8818 - val_loss: 0.3051 - val_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3020 - accuracy: 0.8816 - val_loss: 0.3041 - val_accuracy: 0.8862\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3011 - accuracy: 0.8824 - val_loss: 0.3043 - val_accuracy: 0.8756\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3003 - accuracy: 0.8828 - val_loss: 0.3040 - val_accuracy: 0.8739\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8831 - val_loss: 0.3015 - val_accuracy: 0.8874\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2987 - accuracy: 0.8845 - val_loss: 0.3059 - val_accuracy: 0.9058\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2981 - accuracy: 0.8827 - val_loss: 0.3001 - val_accuracy: 0.8818\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2970 - accuracy: 0.8842 - val_loss: 0.3012 - val_accuracy: 0.8741\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2957 - accuracy: 0.8838 - val_loss: 0.2985 - val_accuracy: 0.8832\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.8843 - val_loss: 0.2977 - val_accuracy: 0.8904\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.8845 - val_loss: 0.2968 - val_accuracy: 0.8864\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8858 - val_loss: 0.2978 - val_accuracy: 0.8769\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.8851 - val_loss: 0.2957 - val_accuracy: 0.8829\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8851 - val_loss: 0.2947 - val_accuracy: 0.8918\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2920 - accuracy: 0.8861 - val_loss: 0.2941 - val_accuracy: 0.8931\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8870 - val_loss: 0.2941 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8870 - val_loss: 0.2964 - val_accuracy: 0.8742\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.8871 - val_loss: 0.2921 - val_accuracy: 0.8864\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8879 - val_loss: 0.2914 - val_accuracy: 0.8938\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.8876 - val_loss: 0.2916 - val_accuracy: 0.8823\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8881 - val_loss: 0.2922 - val_accuracy: 0.9036\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8885 - val_loss: 0.2897 - val_accuracy: 0.8962\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.8894 - val_loss: 0.2889 - val_accuracy: 0.8896\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2860 - accuracy: 0.8887 - val_loss: 0.2935 - val_accuracy: 0.8742\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2853 - accuracy: 0.8898 - val_loss: 0.2880 - val_accuracy: 0.8978\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.8889 - val_loss: 0.2879 - val_accuracy: 0.8843\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.8897 - val_loss: 0.2866 - val_accuracy: 0.8908\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.8894 - val_loss: 0.2864 - val_accuracy: 0.8881\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.8902 - val_loss: 0.2859 - val_accuracy: 0.8881\n",
      "277/277 [==============================] - 0s 912us/step - loss: 0.2767 - accuracy: 0.8903\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6582 - accuracy: 0.6018 - val_loss: 0.6378 - val_accuracy: 0.6097\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.6469 - val_loss: 0.6079 - val_accuracy: 0.6512\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6875 - val_loss: 0.5844 - val_accuracy: 0.7205\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5738 - accuracy: 0.7134 - val_loss: 0.5620 - val_accuracy: 0.7129\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.7339 - val_loss: 0.5434 - val_accuracy: 0.7397\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7529 - val_loss: 0.5289 - val_accuracy: 0.7277\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5195 - accuracy: 0.7643 - val_loss: 0.5133 - val_accuracy: 0.7685\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.7796 - val_loss: 0.5008 - val_accuracy: 0.7842\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4933 - accuracy: 0.7874 - val_loss: 0.4927 - val_accuracy: 0.7481\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.7946 - val_loss: 0.4794 - val_accuracy: 0.8076\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4705 - accuracy: 0.8016 - val_loss: 0.4800 - val_accuracy: 0.8638\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8100 - val_loss: 0.4604 - val_accuracy: 0.7890\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.8142 - val_loss: 0.4521 - val_accuracy: 0.8091\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8178 - val_loss: 0.4456 - val_accuracy: 0.8307\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.8229 - val_loss: 0.4382 - val_accuracy: 0.8297\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8266 - val_loss: 0.4313 - val_accuracy: 0.8261\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4239 - accuracy: 0.8321 - val_loss: 0.4260 - val_accuracy: 0.8087\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4179 - accuracy: 0.8345 - val_loss: 0.4199 - val_accuracy: 0.8191\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8378 - val_loss: 0.4172 - val_accuracy: 0.8066\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8395 - val_loss: 0.4095 - val_accuracy: 0.8420\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8411 - val_loss: 0.4047 - val_accuracy: 0.8314\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3963 - accuracy: 0.8436 - val_loss: 0.4016 - val_accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3914 - accuracy: 0.8470 - val_loss: 0.3958 - val_accuracy: 0.8490\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8480 - val_loss: 0.3915 - val_accuracy: 0.8496\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8515 - val_loss: 0.3938 - val_accuracy: 0.8772\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.8520 - val_loss: 0.3839 - val_accuracy: 0.8540\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3750 - accuracy: 0.8539 - val_loss: 0.3806 - val_accuracy: 0.8434\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8551 - val_loss: 0.3769 - val_accuracy: 0.8476\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8561 - val_loss: 0.3736 - val_accuracy: 0.8594\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8584 - val_loss: 0.3705 - val_accuracy: 0.8496\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8587 - val_loss: 0.3673 - val_accuracy: 0.8556\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3579 - accuracy: 0.8613 - val_loss: 0.3645 - val_accuracy: 0.8557\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.8624 - val_loss: 0.3619 - val_accuracy: 0.8533\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8625 - val_loss: 0.3614 - val_accuracy: 0.8448\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8629 - val_loss: 0.3575 - val_accuracy: 0.8503\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8649 - val_loss: 0.3547 - val_accuracy: 0.8559\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8652 - val_loss: 0.3521 - val_accuracy: 0.8665\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8684 - val_loss: 0.3517 - val_accuracy: 0.8497\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8678 - val_loss: 0.3495 - val_accuracy: 0.8501\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.8677 - val_loss: 0.3456 - val_accuracy: 0.8698\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8705 - val_loss: 0.3458 - val_accuracy: 0.8827\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8707 - val_loss: 0.3428 - val_accuracy: 0.8793\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8725 - val_loss: 0.3441 - val_accuracy: 0.8482\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8721 - val_loss: 0.3379 - val_accuracy: 0.8652\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8732 - val_loss: 0.3419 - val_accuracy: 0.8940\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8740 - val_loss: 0.3341 - val_accuracy: 0.8709\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8741 - val_loss: 0.3329 - val_accuracy: 0.8783\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.8749 - val_loss: 0.3342 - val_accuracy: 0.8559\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3205 - accuracy: 0.8758 - val_loss: 0.3293 - val_accuracy: 0.8707\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8758 - val_loss: 0.3283 - val_accuracy: 0.8807\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8774 - val_loss: 0.3263 - val_accuracy: 0.8714\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3155 - accuracy: 0.8767 - val_loss: 0.3248 - val_accuracy: 0.8744\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.8779 - val_loss: 0.3235 - val_accuracy: 0.8718\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.8795 - val_loss: 0.3227 - val_accuracy: 0.8841\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8787 - val_loss: 0.3252 - val_accuracy: 0.8587\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3098 - accuracy: 0.8802 - val_loss: 0.3194 - val_accuracy: 0.8744\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.8790 - val_loss: 0.3193 - val_accuracy: 0.8888\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8808 - val_loss: 0.3184 - val_accuracy: 0.8904\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.8816 - val_loss: 0.3163 - val_accuracy: 0.8864\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.8807 - val_loss: 0.3151 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.8822 - val_loss: 0.3164 - val_accuracy: 0.8658\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8822 - val_loss: 0.3123 - val_accuracy: 0.8807\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3012 - accuracy: 0.8832 - val_loss: 0.3143 - val_accuracy: 0.8661\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.8832 - val_loss: 0.3105 - val_accuracy: 0.8862\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.8833 - val_loss: 0.3097 - val_accuracy: 0.8885\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2978 - accuracy: 0.8844 - val_loss: 0.3088 - val_accuracy: 0.8749\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8836 - val_loss: 0.3086 - val_accuracy: 0.8920\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2959 - accuracy: 0.8859 - val_loss: 0.3064 - val_accuracy: 0.8869\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2952 - accuracy: 0.8869 - val_loss: 0.3057 - val_accuracy: 0.8892\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2939 - accuracy: 0.8860 - val_loss: 0.3045 - val_accuracy: 0.8866\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2930 - accuracy: 0.8876 - val_loss: 0.3042 - val_accuracy: 0.8917\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8864 - val_loss: 0.3027 - val_accuracy: 0.8852\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2913 - accuracy: 0.8872 - val_loss: 0.3018 - val_accuracy: 0.8866\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8864 - val_loss: 0.3059 - val_accuracy: 0.8670\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.8888 - val_loss: 0.3006 - val_accuracy: 0.8804\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2886 - accuracy: 0.8874 - val_loss: 0.3032 - val_accuracy: 0.9031\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.8897 - val_loss: 0.2988 - val_accuracy: 0.8910\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.8884 - val_loss: 0.2978 - val_accuracy: 0.8874\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8895 - val_loss: 0.2973 - val_accuracy: 0.8911\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8897 - val_loss: 0.2987 - val_accuracy: 0.9008\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.8902 - val_loss: 0.2969 - val_accuracy: 0.8991\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.8892 - val_loss: 0.2949 - val_accuracy: 0.8906\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8902 - val_loss: 0.2977 - val_accuracy: 0.9045\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8906 - val_loss: 0.2956 - val_accuracy: 0.9019\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.8910 - val_loss: 0.2942 - val_accuracy: 0.8800\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2812 - accuracy: 0.8914 - val_loss: 0.2922 - val_accuracy: 0.8873\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.8899 - val_loss: 0.2917 - val_accuracy: 0.8860\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8914 - val_loss: 0.2908 - val_accuracy: 0.8892\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8915 - val_loss: 0.2915 - val_accuracy: 0.9008\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.8915 - val_loss: 0.2898 - val_accuracy: 0.8959\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2776 - accuracy: 0.8937 - val_loss: 0.2903 - val_accuracy: 0.9015\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8914 - val_loss: 0.2897 - val_accuracy: 0.9015\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.8944 - val_loss: 0.2881 - val_accuracy: 0.8869\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2756 - accuracy: 0.8925 - val_loss: 0.2872 - val_accuracy: 0.8954\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8936 - val_loss: 0.2945 - val_accuracy: 0.9135\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8939 - val_loss: 0.2859 - val_accuracy: 0.8920\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.8941 - val_loss: 0.2878 - val_accuracy: 0.9056\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.8961 - val_loss: 0.2853 - val_accuracy: 0.8878\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8938 - val_loss: 0.2844 - val_accuracy: 0.8910\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.8941 - val_loss: 0.2838 - val_accuracy: 0.8913\n",
      "277/277 [==============================] - 0s 887us/step - loss: 0.2935 - accuracy: 0.8845\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6645 - accuracy: 0.5939 - val_loss: 0.6445 - val_accuracy: 0.6051\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.6335 - val_loss: 0.6137 - val_accuracy: 0.6481\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.6762 - val_loss: 0.5942 - val_accuracy: 0.7513\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5830 - accuracy: 0.7042 - val_loss: 0.5724 - val_accuracy: 0.7714\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5635 - accuracy: 0.7311 - val_loss: 0.5500 - val_accuracy: 0.7492\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7432 - val_loss: 0.5336 - val_accuracy: 0.7317\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7557 - val_loss: 0.5223 - val_accuracy: 0.8015\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7682 - val_loss: 0.5071 - val_accuracy: 0.7465\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7789 - val_loss: 0.4940 - val_accuracy: 0.7680\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7875 - val_loss: 0.4846 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4827 - accuracy: 0.7926 - val_loss: 0.4742 - val_accuracy: 0.8078\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7990 - val_loss: 0.4654 - val_accuracy: 0.8149\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.8070 - val_loss: 0.4564 - val_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.8109 - val_loss: 0.4505 - val_accuracy: 0.8362\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.8165 - val_loss: 0.4414 - val_accuracy: 0.8124\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8198 - val_loss: 0.4349 - val_accuracy: 0.8274\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4345 - accuracy: 0.8224 - val_loss: 0.4316 - val_accuracy: 0.8504\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.8283 - val_loss: 0.4230 - val_accuracy: 0.8131\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8303 - val_loss: 0.4172 - val_accuracy: 0.8388\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4172 - accuracy: 0.8325 - val_loss: 0.4125 - val_accuracy: 0.8194\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4120 - accuracy: 0.8365 - val_loss: 0.4072 - val_accuracy: 0.8434\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8388 - val_loss: 0.4024 - val_accuracy: 0.8418\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8396 - val_loss: 0.4011 - val_accuracy: 0.8631\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3980 - accuracy: 0.8430 - val_loss: 0.3955 - val_accuracy: 0.8242\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8464 - val_loss: 0.3902 - val_accuracy: 0.8376\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8476 - val_loss: 0.3860 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8476 - val_loss: 0.3849 - val_accuracy: 0.8665\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8494 - val_loss: 0.3790 - val_accuracy: 0.8483\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3797 - accuracy: 0.8512 - val_loss: 0.3758 - val_accuracy: 0.8510\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3762 - accuracy: 0.8520 - val_loss: 0.3727 - val_accuracy: 0.8564\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3730 - accuracy: 0.8564 - val_loss: 0.3711 - val_accuracy: 0.8672\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8558 - val_loss: 0.3667 - val_accuracy: 0.8587\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3673 - accuracy: 0.8565 - val_loss: 0.3638 - val_accuracy: 0.8570\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8593 - val_loss: 0.3615 - val_accuracy: 0.8508\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8601 - val_loss: 0.3586 - val_accuracy: 0.8623\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3591 - accuracy: 0.8595 - val_loss: 0.3560 - val_accuracy: 0.8623\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3566 - accuracy: 0.8612 - val_loss: 0.3538 - val_accuracy: 0.8665\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8637 - val_loss: 0.3517 - val_accuracy: 0.8547\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8636 - val_loss: 0.3533 - val_accuracy: 0.8855\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8651 - val_loss: 0.3470 - val_accuracy: 0.8603\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8660 - val_loss: 0.3463 - val_accuracy: 0.8772\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8662 - val_loss: 0.3430 - val_accuracy: 0.8700\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8674 - val_loss: 0.3408 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8675 - val_loss: 0.3392 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3401 - accuracy: 0.8694 - val_loss: 0.3412 - val_accuracy: 0.8887\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8691 - val_loss: 0.3360 - val_accuracy: 0.8760\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8702 - val_loss: 0.3338 - val_accuracy: 0.8733\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8709 - val_loss: 0.3331 - val_accuracy: 0.8815\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8722 - val_loss: 0.3345 - val_accuracy: 0.8526\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8734 - val_loss: 0.3298 - val_accuracy: 0.8623\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8735 - val_loss: 0.3299 - val_accuracy: 0.8878\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8735 - val_loss: 0.3262 - val_accuracy: 0.8792\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3266 - accuracy: 0.8737 - val_loss: 0.3284 - val_accuracy: 0.8924\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3254 - accuracy: 0.8745 - val_loss: 0.3248 - val_accuracy: 0.8869\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8754 - val_loss: 0.3224 - val_accuracy: 0.8852\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8764 - val_loss: 0.3201 - val_accuracy: 0.8725\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8763 - val_loss: 0.3252 - val_accuracy: 0.9010\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8787 - val_loss: 0.3175 - val_accuracy: 0.8776\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8777 - val_loss: 0.3237 - val_accuracy: 0.8543\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3175 - accuracy: 0.8785 - val_loss: 0.3165 - val_accuracy: 0.8878\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8801 - val_loss: 0.3140 - val_accuracy: 0.8811\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8787 - val_loss: 0.3129 - val_accuracy: 0.8822\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3142 - accuracy: 0.8805 - val_loss: 0.3130 - val_accuracy: 0.8689\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8794 - val_loss: 0.3106 - val_accuracy: 0.8765\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3117 - accuracy: 0.8806 - val_loss: 0.3145 - val_accuracy: 0.9014\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3103 - accuracy: 0.8827 - val_loss: 0.3085 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.8810 - val_loss: 0.3079 - val_accuracy: 0.8876\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3092 - accuracy: 0.8818 - val_loss: 0.3064 - val_accuracy: 0.8853\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.8830 - val_loss: 0.3070 - val_accuracy: 0.8929\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3068 - accuracy: 0.8827 - val_loss: 0.3053 - val_accuracy: 0.8730\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.8825 - val_loss: 0.3034 - val_accuracy: 0.8829\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8834 - val_loss: 0.3025 - val_accuracy: 0.8830\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8825 - val_loss: 0.3017 - val_accuracy: 0.8790\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.8845 - val_loss: 0.3044 - val_accuracy: 0.8675\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.8848 - val_loss: 0.3007 - val_accuracy: 0.8760\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8849 - val_loss: 0.2990 - val_accuracy: 0.8818\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3009 - accuracy: 0.8859 - val_loss: 0.2982 - val_accuracy: 0.8880\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.8867 - val_loss: 0.2978 - val_accuracy: 0.8913\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8859 - val_loss: 0.2998 - val_accuracy: 0.8702\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2982 - accuracy: 0.8856 - val_loss: 0.2961 - val_accuracy: 0.8792\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.8874 - val_loss: 0.2955 - val_accuracy: 0.8929\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2963 - accuracy: 0.8870 - val_loss: 0.2941 - val_accuracy: 0.8871\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.8877 - val_loss: 0.2933 - val_accuracy: 0.8883\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8864 - val_loss: 0.3038 - val_accuracy: 0.9147\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8880 - val_loss: 0.2926 - val_accuracy: 0.8793\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8876 - val_loss: 0.2918 - val_accuracy: 0.8961\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8881 - val_loss: 0.2906 - val_accuracy: 0.8915\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2919 - accuracy: 0.8889 - val_loss: 0.2897 - val_accuracy: 0.8892\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2914 - accuracy: 0.8887 - val_loss: 0.2891 - val_accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2908 - accuracy: 0.8902 - val_loss: 0.2894 - val_accuracy: 0.8802\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2905 - accuracy: 0.8897 - val_loss: 0.2876 - val_accuracy: 0.8896\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8893 - val_loss: 0.2877 - val_accuracy: 0.8825\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.8895 - val_loss: 0.2867 - val_accuracy: 0.8859\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8900 - val_loss: 0.2862 - val_accuracy: 0.8850\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.8899 - val_loss: 0.2875 - val_accuracy: 0.9051\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8904 - val_loss: 0.2893 - val_accuracy: 0.9084\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8913 - val_loss: 0.2910 - val_accuracy: 0.9121\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.8925 - val_loss: 0.2835 - val_accuracy: 0.8874\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.8912 - val_loss: 0.2826 - val_accuracy: 0.8913\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8917 - val_loss: 0.2830 - val_accuracy: 0.8844\n",
      "277/277 [==============================] - 0s 875us/step - loss: 0.2723 - accuracy: 0.8859\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6738 - accuracy: 0.5903 - val_loss: 0.6662 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6666 - accuracy: 0.5914 - val_loss: 0.6604 - val_accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6601 - accuracy: 0.5921 - val_loss: 0.6535 - val_accuracy: 0.6049\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6534 - accuracy: 0.5981 - val_loss: 0.6471 - val_accuracy: 0.6051\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6472 - accuracy: 0.6049 - val_loss: 0.6407 - val_accuracy: 0.6171\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6412 - accuracy: 0.6146 - val_loss: 0.6351 - val_accuracy: 0.6299\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6353 - accuracy: 0.6247 - val_loss: 0.6290 - val_accuracy: 0.6278\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6295 - accuracy: 0.6325 - val_loss: 0.6250 - val_accuracy: 0.6623\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6240 - accuracy: 0.6450 - val_loss: 0.6181 - val_accuracy: 0.6449\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6187 - accuracy: 0.6504 - val_loss: 0.6130 - val_accuracy: 0.6516\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6136 - accuracy: 0.6585 - val_loss: 0.6093 - val_accuracy: 0.6857\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6088 - accuracy: 0.6669 - val_loss: 0.6038 - val_accuracy: 0.6838\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.6747 - val_loss: 0.5992 - val_accuracy: 0.6896\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6819 - val_loss: 0.5943 - val_accuracy: 0.6697\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6851 - val_loss: 0.5903 - val_accuracy: 0.7057\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6923 - val_loss: 0.5852 - val_accuracy: 0.6968\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5855 - accuracy: 0.6970 - val_loss: 0.5834 - val_accuracy: 0.7349\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5813 - accuracy: 0.7077 - val_loss: 0.5770 - val_accuracy: 0.6924\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5773 - accuracy: 0.7075 - val_loss: 0.5729 - val_accuracy: 0.7079\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5731 - accuracy: 0.7127 - val_loss: 0.5690 - val_accuracy: 0.7120\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.7167 - val_loss: 0.5654 - val_accuracy: 0.7065\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7201 - val_loss: 0.5622 - val_accuracy: 0.7375\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5617 - accuracy: 0.7258 - val_loss: 0.5580 - val_accuracy: 0.7261\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7301 - val_loss: 0.5545 - val_accuracy: 0.7226\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5546 - accuracy: 0.7320 - val_loss: 0.5512 - val_accuracy: 0.7215\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7372 - val_loss: 0.5478 - val_accuracy: 0.7333\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7402 - val_loss: 0.5447 - val_accuracy: 0.7284\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7430 - val_loss: 0.5415 - val_accuracy: 0.7426\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7476 - val_loss: 0.5384 - val_accuracy: 0.7367\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7482 - val_loss: 0.5355 - val_accuracy: 0.7354\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7497 - val_loss: 0.5334 - val_accuracy: 0.7666\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7553 - val_loss: 0.5298 - val_accuracy: 0.7573\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7578\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7610 - val_loss: 0.5241 - val_accuracy: 0.7544\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7620 - val_loss: 0.5216 - val_accuracy: 0.7638\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5210 - accuracy: 0.7638 - val_loss: 0.5190 - val_accuracy: 0.7643\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7672 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7680 - val_loss: 0.5138 - val_accuracy: 0.7594\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7702 - val_loss: 0.5117 - val_accuracy: 0.7735\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7730 - val_loss: 0.5094 - val_accuracy: 0.7782\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7732 - val_loss: 0.5072 - val_accuracy: 0.7837\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7765 - val_loss: 0.5042 - val_accuracy: 0.7724\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7724\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.7813 - val_loss: 0.5004 - val_accuracy: 0.7553\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4989 - accuracy: 0.7820 - val_loss: 0.4975 - val_accuracy: 0.7687\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4967 - accuracy: 0.7821 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.7855 - val_loss: 0.4931 - val_accuracy: 0.7761\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4925 - accuracy: 0.7850 - val_loss: 0.4912 - val_accuracy: 0.7735\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7860 - val_loss: 0.4898 - val_accuracy: 0.7953\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.7878 - val_loss: 0.4873 - val_accuracy: 0.7881\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7886 - val_loss: 0.4862 - val_accuracy: 0.8022\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7908 - val_loss: 0.4852 - val_accuracy: 0.8124\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4823 - accuracy: 0.7921 - val_loss: 0.4816 - val_accuracy: 0.7798\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7935 - val_loss: 0.4797 - val_accuracy: 0.7823\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.7963 - val_loss: 0.4790 - val_accuracy: 0.7694\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7951 - val_loss: 0.4761 - val_accuracy: 0.7951\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7982 - val_loss: 0.4742 - val_accuracy: 0.7883\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4731 - accuracy: 0.7972 - val_loss: 0.4727 - val_accuracy: 0.8017\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.7995 - val_loss: 0.4713 - val_accuracy: 0.8075\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4695 - accuracy: 0.8017 - val_loss: 0.4692 - val_accuracy: 0.8022\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4679 - accuracy: 0.8017 - val_loss: 0.4685 - val_accuracy: 0.8159\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4663 - accuracy: 0.8038 - val_loss: 0.4661 - val_accuracy: 0.8075\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.8034 - val_loss: 0.4642 - val_accuracy: 0.8018\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8053 - val_loss: 0.4627 - val_accuracy: 0.7951\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.8050 - val_loss: 0.4611 - val_accuracy: 0.7957\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.8062 - val_loss: 0.4598 - val_accuracy: 0.7918\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4583 - accuracy: 0.8068 - val_loss: 0.4583 - val_accuracy: 0.8108\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8094 - val_loss: 0.4566 - val_accuracy: 0.8047\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8082 - val_loss: 0.4552 - val_accuracy: 0.8096\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.8110 - val_loss: 0.4537 - val_accuracy: 0.8092\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.8104 - val_loss: 0.4528 - val_accuracy: 0.8212\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.8122 - val_loss: 0.4508 - val_accuracy: 0.8039\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4491 - accuracy: 0.8130 - val_loss: 0.4495 - val_accuracy: 0.8154\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4477 - accuracy: 0.8157 - val_loss: 0.4480 - val_accuracy: 0.8096\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8156 - val_loss: 0.4467 - val_accuracy: 0.8047\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.8163 - val_loss: 0.4453 - val_accuracy: 0.8073\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8156 - val_loss: 0.4441 - val_accuracy: 0.8165\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8171 - val_loss: 0.4427 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8181 - val_loss: 0.4418 - val_accuracy: 0.8251\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4397 - accuracy: 0.8184 - val_loss: 0.4403 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8188 - val_loss: 0.4393 - val_accuracy: 0.8279\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8217 - val_loss: 0.4379 - val_accuracy: 0.8254\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4359 - accuracy: 0.8208 - val_loss: 0.4369 - val_accuracy: 0.8305\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8207 - val_loss: 0.4353 - val_accuracy: 0.8205\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4333 - accuracy: 0.8226 - val_loss: 0.4343 - val_accuracy: 0.8110\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4322 - accuracy: 0.8225 - val_loss: 0.4329 - val_accuracy: 0.8202\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4309 - accuracy: 0.8225 - val_loss: 0.4320 - val_accuracy: 0.8302\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4298 - accuracy: 0.8243 - val_loss: 0.4306 - val_accuracy: 0.8202\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.8242 - val_loss: 0.4296 - val_accuracy: 0.8311\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4271 - accuracy: 0.8253 - val_loss: 0.4284 - val_accuracy: 0.8305\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4263 - accuracy: 0.8269 - val_loss: 0.4272 - val_accuracy: 0.8165\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8266 - val_loss: 0.4260 - val_accuracy: 0.8247\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4240 - accuracy: 0.8267 - val_loss: 0.4251 - val_accuracy: 0.8184\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4227 - accuracy: 0.8280 - val_loss: 0.4239 - val_accuracy: 0.8205\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4218 - accuracy: 0.8280 - val_loss: 0.4228 - val_accuracy: 0.8297\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4207 - accuracy: 0.8296 - val_loss: 0.4220 - val_accuracy: 0.8194\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4196 - accuracy: 0.8301 - val_loss: 0.4208 - val_accuracy: 0.8288\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4186 - accuracy: 0.8296 - val_loss: 0.4197 - val_accuracy: 0.8295\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8306 - val_loss: 0.4190 - val_accuracy: 0.8209\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4166 - accuracy: 0.8302 - val_loss: 0.4178 - val_accuracy: 0.8288\n",
      "277/277 [==============================] - 0s 882us/step - loss: 0.4147 - accuracy: 0.8329\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6721 - accuracy: 0.5942 - val_loss: 0.6663 - val_accuracy: 0.6005\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6650 - accuracy: 0.5947 - val_loss: 0.6593 - val_accuracy: 0.6005\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6583 - accuracy: 0.5955 - val_loss: 0.6533 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6516 - accuracy: 0.6000 - val_loss: 0.6463 - val_accuracy: 0.6081\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6454 - accuracy: 0.6087 - val_loss: 0.6401 - val_accuracy: 0.6139\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6393 - accuracy: 0.6154 - val_loss: 0.6343 - val_accuracy: 0.6241\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6332 - accuracy: 0.6274 - val_loss: 0.6292 - val_accuracy: 0.6218\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6275 - accuracy: 0.6338 - val_loss: 0.6250 - val_accuracy: 0.6651\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.6445 - val_loss: 0.6178 - val_accuracy: 0.6449\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6167 - accuracy: 0.6517 - val_loss: 0.6127 - val_accuracy: 0.6577\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6115 - accuracy: 0.6600 - val_loss: 0.6101 - val_accuracy: 0.7005\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6065 - accuracy: 0.6688 - val_loss: 0.6037 - val_accuracy: 0.6896\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6015 - accuracy: 0.6770 - val_loss: 0.5982 - val_accuracy: 0.6813\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6802 - val_loss: 0.5937 - val_accuracy: 0.6893\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6894 - val_loss: 0.5892 - val_accuracy: 0.6939\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5876 - accuracy: 0.6938 - val_loss: 0.5848 - val_accuracy: 0.6919\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7004 - val_loss: 0.5806 - val_accuracy: 0.6970\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5788 - accuracy: 0.7058 - val_loss: 0.5772 - val_accuracy: 0.6870\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7079 - val_loss: 0.5746 - val_accuracy: 0.7421\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5707 - accuracy: 0.7173 - val_loss: 0.5690 - val_accuracy: 0.6972\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7185 - val_loss: 0.5665 - val_accuracy: 0.7470\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7246 - val_loss: 0.5615 - val_accuracy: 0.7368\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5587 - accuracy: 0.7284 - val_loss: 0.5573 - val_accuracy: 0.7252\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5548 - accuracy: 0.7298 - val_loss: 0.5548 - val_accuracy: 0.7483\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5512 - accuracy: 0.7373 - val_loss: 0.5503 - val_accuracy: 0.7231\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7375 - val_loss: 0.5470 - val_accuracy: 0.7407\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7435 - val_loss: 0.5440 - val_accuracy: 0.7231\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7442 - val_loss: 0.5411 - val_accuracy: 0.7227\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7471 - val_loss: 0.5376 - val_accuracy: 0.7511\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7522 - val_loss: 0.5344 - val_accuracy: 0.7389\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7515 - val_loss: 0.5318 - val_accuracy: 0.7603\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7571 - val_loss: 0.5286 - val_accuracy: 0.7546\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7586 - val_loss: 0.5257 - val_accuracy: 0.7472\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5225 - accuracy: 0.7610 - val_loss: 0.5229 - val_accuracy: 0.7509\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7639 - val_loss: 0.5209 - val_accuracy: 0.7411\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7659 - val_loss: 0.5175 - val_accuracy: 0.7613\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.7680 - val_loss: 0.5150 - val_accuracy: 0.7548\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5116 - accuracy: 0.7710 - val_loss: 0.5127 - val_accuracy: 0.7745\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5088 - accuracy: 0.7739 - val_loss: 0.5099 - val_accuracy: 0.7622\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.7734 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7775 - val_loss: 0.5053 - val_accuracy: 0.7758\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5014 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7844\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.7798 - val_loss: 0.5005 - val_accuracy: 0.7742\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7819 - val_loss: 0.4983 - val_accuracy: 0.7721\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4944 - accuracy: 0.7843 - val_loss: 0.4962 - val_accuracy: 0.7823\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4921 - accuracy: 0.7859 - val_loss: 0.4951 - val_accuracy: 0.7999\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4900 - accuracy: 0.7910 - val_loss: 0.4920 - val_accuracy: 0.7692\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.7888 - val_loss: 0.4898 - val_accuracy: 0.7869\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.7920 - val_loss: 0.4886 - val_accuracy: 0.7636\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.7903 - val_loss: 0.4857 - val_accuracy: 0.7888\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4813 - accuracy: 0.7948 - val_loss: 0.4838 - val_accuracy: 0.7759\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.7948 - val_loss: 0.4817 - val_accuracy: 0.7890\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7957 - val_loss: 0.4806 - val_accuracy: 0.8059\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.7999 - val_loss: 0.4779 - val_accuracy: 0.7860\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.7988 - val_loss: 0.4761 - val_accuracy: 0.7950\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.8018 - val_loss: 0.4743 - val_accuracy: 0.7826\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.8023 - val_loss: 0.4724 - val_accuracy: 0.7987\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.8036 - val_loss: 0.4705 - val_accuracy: 0.7965\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4658 - accuracy: 0.8055 - val_loss: 0.4688 - val_accuracy: 0.7930\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4639 - accuracy: 0.8057 - val_loss: 0.4671 - val_accuracy: 0.8018\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4622 - accuracy: 0.8066 - val_loss: 0.4653 - val_accuracy: 0.7962\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4603 - accuracy: 0.8082 - val_loss: 0.4641 - val_accuracy: 0.8119\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.8105 - val_loss: 0.4624 - val_accuracy: 0.8119\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4568 - accuracy: 0.8103 - val_loss: 0.4607 - val_accuracy: 0.8122\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8124 - val_loss: 0.4587 - val_accuracy: 0.8015\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.8139 - val_loss: 0.4572 - val_accuracy: 0.7978\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4518 - accuracy: 0.8141 - val_loss: 0.4558 - val_accuracy: 0.7951\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8137 - val_loss: 0.4542 - val_accuracy: 0.8018\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4486 - accuracy: 0.8150 - val_loss: 0.4528 - val_accuracy: 0.7992\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4472 - accuracy: 0.8163 - val_loss: 0.4512 - val_accuracy: 0.8047\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4456 - accuracy: 0.8191 - val_loss: 0.4509 - val_accuracy: 0.7899\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8180 - val_loss: 0.4483 - val_accuracy: 0.8061\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.8200 - val_loss: 0.4471 - val_accuracy: 0.8022\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4412 - accuracy: 0.8193 - val_loss: 0.4456 - val_accuracy: 0.8163\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8202 - val_loss: 0.4445 - val_accuracy: 0.8242\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.8242 - val_loss: 0.4428 - val_accuracy: 0.8120\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4369 - accuracy: 0.8220 - val_loss: 0.4415 - val_accuracy: 0.8180\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4355 - accuracy: 0.8247 - val_loss: 0.4403 - val_accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.8248 - val_loss: 0.4393 - val_accuracy: 0.8286\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8263 - val_loss: 0.4377 - val_accuracy: 0.8112\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.8263 - val_loss: 0.4365 - val_accuracy: 0.8105\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8263 - val_loss: 0.4351 - val_accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.8270 - val_loss: 0.4339 - val_accuracy: 0.8193\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4277 - accuracy: 0.8273 - val_loss: 0.4331 - val_accuracy: 0.8087\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.8270 - val_loss: 0.4316 - val_accuracy: 0.8293\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4249 - accuracy: 0.8293 - val_loss: 0.4306 - val_accuracy: 0.8341\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4238 - accuracy: 0.8291 - val_loss: 0.4291 - val_accuracy: 0.8279\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4285 - val_accuracy: 0.8105\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4214 - accuracy: 0.8314 - val_loss: 0.4268 - val_accuracy: 0.8291\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4203 - accuracy: 0.8328 - val_loss: 0.4257 - val_accuracy: 0.8184\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4191 - accuracy: 0.8322 - val_loss: 0.4247 - val_accuracy: 0.8365\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4176 - accuracy: 0.8343 - val_loss: 0.4238 - val_accuracy: 0.8143\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4168 - accuracy: 0.8334 - val_loss: 0.4224 - val_accuracy: 0.8355\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4154 - accuracy: 0.8352 - val_loss: 0.4215 - val_accuracy: 0.8175\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.8349 - val_loss: 0.4203 - val_accuracy: 0.8210\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4133 - accuracy: 0.8343 - val_loss: 0.4193 - val_accuracy: 0.8371\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8346 - val_loss: 0.4185 - val_accuracy: 0.8408\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.8379 - val_loss: 0.4171 - val_accuracy: 0.8297\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8377 - val_loss: 0.4162 - val_accuracy: 0.8381\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8382 - val_loss: 0.4153 - val_accuracy: 0.8244\n",
      "277/277 [==============================] - 0s 850us/step - loss: 0.4216 - accuracy: 0.8151\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6808 - accuracy: 0.5699 - val_loss: 0.6626 - val_accuracy: 0.6003\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.5919 - val_loss: 0.6569 - val_accuracy: 0.6024\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6582 - accuracy: 0.5939 - val_loss: 0.6515 - val_accuracy: 0.6089\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6523 - accuracy: 0.6000 - val_loss: 0.6453 - val_accuracy: 0.6153\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6464 - accuracy: 0.6076 - val_loss: 0.6393 - val_accuracy: 0.6197\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6159 - val_loss: 0.6337 - val_accuracy: 0.6220\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6353 - accuracy: 0.6258 - val_loss: 0.6288 - val_accuracy: 0.6243\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6307 - val_loss: 0.6230 - val_accuracy: 0.6401\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.6412 - val_loss: 0.6188 - val_accuracy: 0.6646\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.6491 - val_loss: 0.6139 - val_accuracy: 0.6766\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6148 - accuracy: 0.6587 - val_loss: 0.6100 - val_accuracy: 0.6961\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6102 - accuracy: 0.6658 - val_loss: 0.6034 - val_accuracy: 0.6634\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6056 - accuracy: 0.6722 - val_loss: 0.5987 - val_accuracy: 0.6752\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6784 - val_loss: 0.5943 - val_accuracy: 0.6748\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5967 - accuracy: 0.6832 - val_loss: 0.5902 - val_accuracy: 0.6806\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5925 - accuracy: 0.6891 - val_loss: 0.5861 - val_accuracy: 0.6930\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6932 - val_loss: 0.5825 - val_accuracy: 0.7085\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5844 - accuracy: 0.6962 - val_loss: 0.5804 - val_accuracy: 0.7361\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7116\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.7086 - val_loss: 0.5705 - val_accuracy: 0.7180\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5729 - accuracy: 0.7125 - val_loss: 0.5667 - val_accuracy: 0.7226\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7152 - val_loss: 0.5641 - val_accuracy: 0.7395\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7242 - val_loss: 0.5596 - val_accuracy: 0.7120\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5619 - accuracy: 0.7220 - val_loss: 0.5568 - val_accuracy: 0.7430\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7307 - val_loss: 0.5526 - val_accuracy: 0.7330\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7327 - val_loss: 0.5502 - val_accuracy: 0.7486\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5518 - accuracy: 0.7374 - val_loss: 0.5463 - val_accuracy: 0.7375\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7393 - val_loss: 0.5432 - val_accuracy: 0.7340\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7413 - val_loss: 0.5412 - val_accuracy: 0.7611\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7453 - val_loss: 0.5379 - val_accuracy: 0.7596\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7476 - val_loss: 0.5348 - val_accuracy: 0.7597\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7522 - val_loss: 0.5315 - val_accuracy: 0.7509\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7518 - val_loss: 0.5301 - val_accuracy: 0.7745\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7545 - val_loss: 0.5259 - val_accuracy: 0.7516\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7566 - val_loss: 0.5242 - val_accuracy: 0.7733\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5254 - accuracy: 0.7601 - val_loss: 0.5210 - val_accuracy: 0.7675\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.7618 - val_loss: 0.5181 - val_accuracy: 0.7557\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5204 - accuracy: 0.7630 - val_loss: 0.5161 - val_accuracy: 0.7736\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7659 - val_loss: 0.5136 - val_accuracy: 0.7744\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7692 - val_loss: 0.5116 - val_accuracy: 0.7825\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.7702 - val_loss: 0.5100 - val_accuracy: 0.7916\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5106 - accuracy: 0.7734 - val_loss: 0.5062 - val_accuracy: 0.7752\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7821\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7757 - val_loss: 0.5015 - val_accuracy: 0.7766\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7777 - val_loss: 0.4998 - val_accuracy: 0.7870\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5013 - accuracy: 0.7781 - val_loss: 0.4970 - val_accuracy: 0.7751\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7799 - val_loss: 0.4953 - val_accuracy: 0.7872\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4969 - accuracy: 0.7823 - val_loss: 0.4934 - val_accuracy: 0.7928\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7844 - val_loss: 0.4906 - val_accuracy: 0.7768\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7844 - val_loss: 0.4891 - val_accuracy: 0.7918\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4908 - accuracy: 0.7867 - val_loss: 0.4867 - val_accuracy: 0.7830\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.7882 - val_loss: 0.4849 - val_accuracy: 0.7879\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4868 - accuracy: 0.7896 - val_loss: 0.4832 - val_accuracy: 0.7928\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7929 - val_loss: 0.4812 - val_accuracy: 0.7782\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4831 - accuracy: 0.7920 - val_loss: 0.4792 - val_accuracy: 0.7858\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.7924 - val_loss: 0.4779 - val_accuracy: 0.8015\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4793 - accuracy: 0.7958 - val_loss: 0.4757 - val_accuracy: 0.7856\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4776 - accuracy: 0.7956 - val_loss: 0.4739 - val_accuracy: 0.7897\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7982 - val_loss: 0.4721 - val_accuracy: 0.7907\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4740 - accuracy: 0.7981 - val_loss: 0.4704 - val_accuracy: 0.7953\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4721 - accuracy: 0.8009 - val_loss: 0.4686 - val_accuracy: 0.7914\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.8012 - val_loss: 0.4672 - val_accuracy: 0.8059\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4687 - accuracy: 0.8006 - val_loss: 0.4657 - val_accuracy: 0.8082\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.8016 - val_loss: 0.4655 - val_accuracy: 0.8267\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.8047 - val_loss: 0.4621 - val_accuracy: 0.8054\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8053 - val_loss: 0.4606 - val_accuracy: 0.7911\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.8047 - val_loss: 0.4591 - val_accuracy: 0.8087\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4605 - accuracy: 0.8062 - val_loss: 0.4582 - val_accuracy: 0.8196\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4591 - accuracy: 0.8078 - val_loss: 0.4559 - val_accuracy: 0.8069\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.8073 - val_loss: 0.4561 - val_accuracy: 0.8323\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4561 - accuracy: 0.8092 - val_loss: 0.4536 - val_accuracy: 0.8202\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4547 - accuracy: 0.8120 - val_loss: 0.4516 - val_accuracy: 0.8089\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8106 - val_loss: 0.4504 - val_accuracy: 0.8154\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4519 - accuracy: 0.8121 - val_loss: 0.4495 - val_accuracy: 0.8249\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.8145 - val_loss: 0.4474 - val_accuracy: 0.8069\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4490 - accuracy: 0.8143 - val_loss: 0.4461 - val_accuracy: 0.8083\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.8146 - val_loss: 0.4452 - val_accuracy: 0.8254\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4462 - accuracy: 0.8159 - val_loss: 0.4438 - val_accuracy: 0.8246\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.8162 - val_loss: 0.4423 - val_accuracy: 0.8205\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8189 - val_loss: 0.4410 - val_accuracy: 0.8076\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.8171 - val_loss: 0.4400 - val_accuracy: 0.8263\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4411 - accuracy: 0.8188 - val_loss: 0.4384 - val_accuracy: 0.8124\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8185 - val_loss: 0.4374 - val_accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8222 - val_loss: 0.4360 - val_accuracy: 0.8177\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8214 - val_loss: 0.4348 - val_accuracy: 0.8173\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8216 - val_loss: 0.4343 - val_accuracy: 0.8355\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8226 - val_loss: 0.4329 - val_accuracy: 0.8325\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.8235 - val_loss: 0.4319 - val_accuracy: 0.8362\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4329 - accuracy: 0.8257 - val_loss: 0.4304 - val_accuracy: 0.8126\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8247 - val_loss: 0.4291 - val_accuracy: 0.8231\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.8262 - val_loss: 0.4284 - val_accuracy: 0.8346\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8256 - val_loss: 0.4278 - val_accuracy: 0.8408\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4284 - accuracy: 0.8286 - val_loss: 0.4259 - val_accuracy: 0.8274\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4273 - accuracy: 0.8275 - val_loss: 0.4251 - val_accuracy: 0.8362\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4260 - accuracy: 0.8285 - val_loss: 0.4245 - val_accuracy: 0.8413\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8288 - val_loss: 0.4250 - val_accuracy: 0.8494\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4241 - accuracy: 0.8302 - val_loss: 0.4218 - val_accuracy: 0.8360\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8317 - val_loss: 0.4212 - val_accuracy: 0.8143\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4220 - accuracy: 0.8293 - val_loss: 0.4197 - val_accuracy: 0.8323\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4209 - accuracy: 0.8312 - val_loss: 0.4187 - val_accuracy: 0.8263\n",
      "277/277 [==============================] - 0s 863us/step - loss: 0.4096 - accuracy: 0.8330\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6408 - accuracy: 0.6440 - val_loss: 0.6492 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.6914 - val_loss: 0.4105 - val_accuracy: 0.8848\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3683 - accuracy: 0.8499 - val_loss: 0.4837 - val_accuracy: 0.8284\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8881 - val_loss: 1.2219 - val_accuracy: 0.3995\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8709 - val_loss: 0.2268 - val_accuracy: 0.9110\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8915 - val_loss: 0.2480 - val_accuracy: 0.9232\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.8976 - val_loss: 0.4190 - val_accuracy: 0.8379\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2700 - accuracy: 0.8973 - val_loss: 0.2274 - val_accuracy: 0.9257\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9062 - val_loss: 0.4164 - val_accuracy: 0.8712\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9048 - val_loss: 0.2234 - val_accuracy: 0.9154\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2700 - accuracy: 0.8986 - val_loss: 0.1966 - val_accuracy: 0.9352\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2593 - accuracy: 0.9044 - val_loss: 0.2092 - val_accuracy: 0.9297\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.9110 - val_loss: 0.1935 - val_accuracy: 0.9339\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2552 - accuracy: 0.9054 - val_loss: 0.2375 - val_accuracy: 0.9066\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9115 - val_loss: 0.2397 - val_accuracy: 0.9047\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.9125 - val_loss: 0.4916 - val_accuracy: 0.7129\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.9011 - val_loss: 0.1832 - val_accuracy: 0.9348\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2302 - accuracy: 0.9159 - val_loss: 0.1975 - val_accuracy: 0.9267\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.9115 - val_loss: 0.1877 - val_accuracy: 0.9327\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2317 - accuracy: 0.9171 - val_loss: 0.3127 - val_accuracy: 0.8732\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9211 - val_loss: 0.2588 - val_accuracy: 0.9028\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2118 - accuracy: 0.9227 - val_loss: 0.7392 - val_accuracy: 0.4696\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2198 - accuracy: 0.9230 - val_loss: 0.4134 - val_accuracy: 0.8138\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2270 - accuracy: 0.9174 - val_loss: 0.1753 - val_accuracy: 0.9405\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.9236 - val_loss: 0.2886 - val_accuracy: 0.9112\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2141 - accuracy: 0.9227 - val_loss: 0.1730 - val_accuracy: 0.9376\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2228 - accuracy: 0.9196 - val_loss: 0.2487 - val_accuracy: 0.9003\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2076 - accuracy: 0.9243 - val_loss: 0.1776 - val_accuracy: 0.9368\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9246 - val_loss: 0.1699 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2064 - accuracy: 0.9252 - val_loss: 0.1966 - val_accuracy: 0.9339\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2048 - accuracy: 0.9269 - val_loss: 0.4174 - val_accuracy: 0.8718\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9250 - val_loss: 0.3182 - val_accuracy: 0.8818\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.9230 - val_loss: 0.2017 - val_accuracy: 0.9243\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2026 - accuracy: 0.9277 - val_loss: 0.1996 - val_accuracy: 0.9297\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9265 - val_loss: 0.1617 - val_accuracy: 0.9457\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.9279 - val_loss: 0.1770 - val_accuracy: 0.9357\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9306 - val_loss: 0.1628 - val_accuracy: 0.9454\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9305 - val_loss: 0.1602 - val_accuracy: 0.9452\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9323 - val_loss: 0.1715 - val_accuracy: 0.9440\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9338 - val_loss: 0.1546 - val_accuracy: 0.9487\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9341 - val_loss: 0.1993 - val_accuracy: 0.9318\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9290 - val_loss: 0.1768 - val_accuracy: 0.9389\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1912 - accuracy: 0.9322 - val_loss: 0.1811 - val_accuracy: 0.9345\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.9352 - val_loss: 0.1713 - val_accuracy: 0.9394\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9321 - val_loss: 0.1793 - val_accuracy: 0.9369\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.9388 - val_loss: 0.5573 - val_accuracy: 0.8508\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9320 - val_loss: 0.1767 - val_accuracy: 0.9389\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1852 - accuracy: 0.9362 - val_loss: 0.1475 - val_accuracy: 0.9526\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9342 - val_loss: 0.1615 - val_accuracy: 0.9470\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1945 - accuracy: 0.9317 - val_loss: 0.1687 - val_accuracy: 0.9419\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.9363 - val_loss: 0.1455 - val_accuracy: 0.9523\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.9398 - val_loss: 0.1562 - val_accuracy: 0.9480\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.9376 - val_loss: 0.1436 - val_accuracy: 0.9533\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9387 - val_loss: 0.1509 - val_accuracy: 0.9510\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.9376 - val_loss: 0.1687 - val_accuracy: 0.9447\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9391 - val_loss: 0.1401 - val_accuracy: 0.9542\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.9386 - val_loss: 0.1474 - val_accuracy: 0.9509\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1709 - accuracy: 0.9410 - val_loss: 0.2826 - val_accuracy: 0.9019\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9425 - val_loss: 0.1682 - val_accuracy: 0.9514\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.9410 - val_loss: 0.1745 - val_accuracy: 0.9454\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9369 - val_loss: 0.1501 - val_accuracy: 0.9489\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.9375 - val_loss: 0.1373 - val_accuracy: 0.9577\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9454 - val_loss: 0.1950 - val_accuracy: 0.9294\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1717 - accuracy: 0.9424 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1670 - accuracy: 0.9433 - val_loss: 0.2103 - val_accuracy: 0.9466\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9402 - val_loss: 0.2242 - val_accuracy: 0.9260\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.9416 - val_loss: 0.1389 - val_accuracy: 0.9553\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9415 - val_loss: 0.1408 - val_accuracy: 0.9505\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1712 - accuracy: 0.9412 - val_loss: 0.1456 - val_accuracy: 0.9509\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1495 - accuracy: 0.9503 - val_loss: 0.1339 - val_accuracy: 0.9584\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1681 - accuracy: 0.9439 - val_loss: 0.1883 - val_accuracy: 0.9309\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1695 - accuracy: 0.9434 - val_loss: 0.1502 - val_accuracy: 0.9521\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1602 - accuracy: 0.9453 - val_loss: 0.1304 - val_accuracy: 0.9590\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1636 - accuracy: 0.9446 - val_loss: 0.1450 - val_accuracy: 0.9517\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1697 - accuracy: 0.9444 - val_loss: 0.7122 - val_accuracy: 0.5094\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1645 - accuracy: 0.9444 - val_loss: 0.1932 - val_accuracy: 0.9324\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9465 - val_loss: 0.2458 - val_accuracy: 0.9169\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9433 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1585 - accuracy: 0.9473 - val_loss: 0.1377 - val_accuracy: 0.9542\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1691 - accuracy: 0.9432 - val_loss: 0.1311 - val_accuracy: 0.9593\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1594 - accuracy: 0.9462 - val_loss: 0.1717 - val_accuracy: 0.9428\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1513 - accuracy: 0.9489 - val_loss: 0.1696 - val_accuracy: 0.9431\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1736 - accuracy: 0.9411 - val_loss: 0.2917 - val_accuracy: 0.8955\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8906\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6621 - accuracy: 0.6105 - val_loss: 0.6386 - val_accuracy: 0.6465\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4170 - accuracy: 0.8193 - val_loss: 0.2279 - val_accuracy: 0.9128\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3030 - accuracy: 0.8836 - val_loss: 0.2794 - val_accuracy: 0.9100\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3064 - accuracy: 0.8848 - val_loss: 0.2300 - val_accuracy: 0.9114\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9014 - val_loss: 0.2688 - val_accuracy: 0.8964\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.8983 - val_loss: 0.2200 - val_accuracy: 0.9213\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2653 - accuracy: 0.9000 - val_loss: 0.3272 - val_accuracy: 0.8610\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9016 - val_loss: 0.2291 - val_accuracy: 0.9285\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9104 - val_loss: 0.2002 - val_accuracy: 0.9299\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9061 - val_loss: 0.2880 - val_accuracy: 0.8802\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.9089 - val_loss: 0.2152 - val_accuracy: 0.9246\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9061 - val_loss: 0.1973 - val_accuracy: 0.9317\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.9095 - val_loss: 0.2243 - val_accuracy: 0.9133\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2384 - accuracy: 0.9105 - val_loss: 0.2078 - val_accuracy: 0.9278\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2358 - accuracy: 0.9128 - val_loss: 0.2052 - val_accuracy: 0.9223\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9141 - val_loss: 0.2742 - val_accuracy: 0.8998\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2350 - accuracy: 0.9143 - val_loss: 0.2203 - val_accuracy: 0.9142\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2265 - accuracy: 0.9165 - val_loss: 0.1827 - val_accuracy: 0.9387\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.9141 - val_loss: 0.3089 - val_accuracy: 0.8645\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.9216 - val_loss: 0.2320 - val_accuracy: 0.9214\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.9218 - val_loss: 0.2049 - val_accuracy: 0.9239\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.9217 - val_loss: 0.6014 - val_accuracy: 0.8358\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2225 - accuracy: 0.9178 - val_loss: 0.1720 - val_accuracy: 0.9408\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2207 - accuracy: 0.9211 - val_loss: 0.1771 - val_accuracy: 0.9412\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9236 - val_loss: 0.2249 - val_accuracy: 0.9089\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.9266 - val_loss: 0.1978 - val_accuracy: 0.9251\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9238 - val_loss: 0.2363 - val_accuracy: 0.9105\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9232 - val_loss: 0.1964 - val_accuracy: 0.9309\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9259 - val_loss: 0.1736 - val_accuracy: 0.9436\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2022 - accuracy: 0.9269 - val_loss: 0.2709 - val_accuracy: 0.8952\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9230 - val_loss: 0.2702 - val_accuracy: 0.9228\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1989 - accuracy: 0.9286 - val_loss: 0.1705 - val_accuracy: 0.9422\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2027 - accuracy: 0.9292 - val_loss: 0.1652 - val_accuracy: 0.9452\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9290 - val_loss: 0.1690 - val_accuracy: 0.9445\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9224 - val_loss: 0.3213 - val_accuracy: 0.8809\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9311 - val_loss: 0.1616 - val_accuracy: 0.9459\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9298 - val_loss: 0.1650 - val_accuracy: 0.9454\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9307 - val_loss: 0.1737 - val_accuracy: 0.9389\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9310 - val_loss: 0.1867 - val_accuracy: 0.9308\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9344 - val_loss: 0.1656 - val_accuracy: 0.9413\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.9314 - val_loss: 0.1591 - val_accuracy: 0.9449\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9326 - val_loss: 0.2269 - val_accuracy: 0.9084\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.9339 - val_loss: 0.1742 - val_accuracy: 0.9410\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9317 - val_loss: 0.2070 - val_accuracy: 0.9228\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9363 - val_loss: 0.2803 - val_accuracy: 0.9022\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.9379 - val_loss: 0.2348 - val_accuracy: 0.9095\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1945 - accuracy: 0.9306 - val_loss: 0.2094 - val_accuracy: 0.9258\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9341 - val_loss: 0.1776 - val_accuracy: 0.9383\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9357 - val_loss: 0.2320 - val_accuracy: 0.9132\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.9342 - val_loss: 0.2091 - val_accuracy: 0.9177\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.9364 - val_loss: 0.2103 - val_accuracy: 0.9251\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9206\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5804 - accuracy: 0.7112 - val_loss: 0.6838 - val_accuracy: 0.6491\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6886 - val_loss: 0.5969 - val_accuracy: 0.6436\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.8080 - val_loss: 0.3290 - val_accuracy: 0.8864\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8863 - val_loss: 0.2221 - val_accuracy: 0.9179\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.8997 - val_loss: 0.3160 - val_accuracy: 0.8712\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.8952 - val_loss: 0.4119 - val_accuracy: 0.8473\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.9027 - val_loss: 0.4433 - val_accuracy: 0.8476\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.9070 - val_loss: 0.2716 - val_accuracy: 0.9007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9106 - val_loss: 0.2235 - val_accuracy: 0.9135\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.9118 - val_loss: 0.2025 - val_accuracy: 0.9290\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.9105 - val_loss: 0.1966 - val_accuracy: 0.9339\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2404 - accuracy: 0.9154 - val_loss: 0.2094 - val_accuracy: 0.9243\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.9126 - val_loss: 0.2375 - val_accuracy: 0.9089\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9100 - val_loss: 0.2175 - val_accuracy: 0.9186\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.9088 - val_loss: 0.2443 - val_accuracy: 0.9112\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2238 - accuracy: 0.9184 - val_loss: 0.4007 - val_accuracy: 0.8686\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2321 - accuracy: 0.9144 - val_loss: 0.2846 - val_accuracy: 0.9073\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.9115 - val_loss: 0.2094 - val_accuracy: 0.9237\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2328 - accuracy: 0.9166 - val_loss: 0.1877 - val_accuracy: 0.9378\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2291 - accuracy: 0.9166 - val_loss: 0.2178 - val_accuracy: 0.9158\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2249 - accuracy: 0.9196 - val_loss: 0.2083 - val_accuracy: 0.9230\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2225 - accuracy: 0.9192 - val_loss: 0.9636 - val_accuracy: 0.3997\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9042 - val_loss: 0.2211 - val_accuracy: 0.9230\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.9214 - val_loss: 0.2782 - val_accuracy: 0.8933\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2171 - accuracy: 0.9201 - val_loss: 0.2126 - val_accuracy: 0.9223\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2156 - accuracy: 0.9219 - val_loss: 0.2217 - val_accuracy: 0.9239\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9260 - val_loss: 0.1805 - val_accuracy: 0.9394\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9270 - val_loss: 0.1696 - val_accuracy: 0.9420\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.9278 - val_loss: 0.3083 - val_accuracy: 0.8973\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2143 - accuracy: 0.9228 - val_loss: 0.2044 - val_accuracy: 0.9239\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9246 - val_loss: 0.1832 - val_accuracy: 0.9336\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9268 - val_loss: 0.1980 - val_accuracy: 0.9369\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9279 - val_loss: 0.1631 - val_accuracy: 0.9435\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9312 - val_loss: 0.1605 - val_accuracy: 0.9461\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9285 - val_loss: 0.1914 - val_accuracy: 0.9280\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.9326 - val_loss: 0.3869 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2025 - accuracy: 0.9255 - val_loss: 0.1906 - val_accuracy: 0.9258\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.9340 - val_loss: 0.1600 - val_accuracy: 0.9440\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9352 - val_loss: 0.2175 - val_accuracy: 0.9181\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1928 - accuracy: 0.9311 - val_loss: 0.3344 - val_accuracy: 0.8802\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9332 - val_loss: 0.1488 - val_accuracy: 0.9482\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.9360 - val_loss: 0.1998 - val_accuracy: 0.9299\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.9366 - val_loss: 0.2388 - val_accuracy: 0.8962\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.9385 - val_loss: 0.1437 - val_accuracy: 0.9561\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1628 - accuracy: 0.9428 - val_loss: 0.1380 - val_accuracy: 0.9523\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.9380 - val_loss: 0.1375 - val_accuracy: 0.9609\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1915 - accuracy: 0.9344 - val_loss: 0.1676 - val_accuracy: 0.9375\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.9388 - val_loss: 0.1755 - val_accuracy: 0.9346\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.9410 - val_loss: 0.3600 - val_accuracy: 0.8790\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.9392 - val_loss: 0.1531 - val_accuracy: 0.9473\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.9415 - val_loss: 0.1339 - val_accuracy: 0.9577\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1618 - accuracy: 0.9460 - val_loss: 0.2296 - val_accuracy: 0.9230\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.9415 - val_loss: 0.1707 - val_accuracy: 0.9417\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1667 - accuracy: 0.9428 - val_loss: 0.1300 - val_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1599 - accuracy: 0.9450 - val_loss: 0.1450 - val_accuracy: 0.9533\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9392 - val_loss: 0.2399 - val_accuracy: 0.9035\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.9378 - val_loss: 0.1799 - val_accuracy: 0.9503\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9445 - val_loss: 0.2760 - val_accuracy: 0.9070\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1668 - accuracy: 0.9440 - val_loss: 0.1393 - val_accuracy: 0.9618\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.9405 - val_loss: 0.1354 - val_accuracy: 0.9575\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1591 - accuracy: 0.9478 - val_loss: 0.1367 - val_accuracy: 0.9547\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1628 - accuracy: 0.9463 - val_loss: 0.1470 - val_accuracy: 0.9494\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.9441 - val_loss: 0.1396 - val_accuracy: 0.9618\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9450 - val_loss: 0.2426 - val_accuracy: 0.9265\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.9188\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6903 - val_loss: 0.4356 - val_accuracy: 0.7835\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8684 - val_loss: 0.3166 - val_accuracy: 0.9251\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.8939 - val_loss: 0.2508 - val_accuracy: 0.8896\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9044 - val_loss: 0.2907 - val_accuracy: 0.8737\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.9070 - val_loss: 0.2627 - val_accuracy: 0.8869\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2333 - accuracy: 0.9101 - val_loss: 0.2153 - val_accuracy: 0.9139\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2304 - accuracy: 0.9129 - val_loss: 0.6316 - val_accuracy: 0.6701\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2318 - accuracy: 0.9131 - val_loss: 0.1970 - val_accuracy: 0.9317\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9175 - val_loss: 0.3991 - val_accuracy: 0.8459\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9104 - val_loss: 0.2295 - val_accuracy: 0.9260\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9188 - val_loss: 0.2173 - val_accuracy: 0.9144\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2130 - accuracy: 0.9198 - val_loss: 0.4391 - val_accuracy: 0.8159\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9197 - val_loss: 0.1876 - val_accuracy: 0.9299\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2114 - accuracy: 0.9209 - val_loss: 0.2102 - val_accuracy: 0.9281\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2038 - accuracy: 0.9240 - val_loss: 0.2305 - val_accuracy: 0.9036\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9238 - val_loss: 0.1829 - val_accuracy: 0.9392\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9219 - val_loss: 0.1764 - val_accuracy: 0.9392\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9283 - val_loss: 0.1992 - val_accuracy: 0.9304\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1934 - accuracy: 0.9268 - val_loss: 0.1667 - val_accuracy: 0.9401\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9259 - val_loss: 0.1603 - val_accuracy: 0.9422\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1923 - accuracy: 0.9282 - val_loss: 0.1920 - val_accuracy: 0.9295\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.9311 - val_loss: 0.1584 - val_accuracy: 0.9415\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.9287 - val_loss: 0.1603 - val_accuracy: 0.9440\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.9329 - val_loss: 0.1740 - val_accuracy: 0.9355\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9302 - val_loss: 0.2413 - val_accuracy: 0.9029\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.9354 - val_loss: 0.1945 - val_accuracy: 0.9264\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.9341 - val_loss: 0.1451 - val_accuracy: 0.9486\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9418 - val_loss: 0.1301 - val_accuracy: 0.9553\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1647 - accuracy: 0.9405 - val_loss: 0.1560 - val_accuracy: 0.9443\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.9393 - val_loss: 0.1472 - val_accuracy: 0.9486\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9420 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1593 - accuracy: 0.9442 - val_loss: 0.1444 - val_accuracy: 0.9472\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1431 - accuracy: 0.9493 - val_loss: 0.1224 - val_accuracy: 0.9597\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1529 - accuracy: 0.9443 - val_loss: 0.1293 - val_accuracy: 0.9540\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9466 - val_loss: 0.1462 - val_accuracy: 0.9482\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9492 - val_loss: 0.1161 - val_accuracy: 0.9627\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1459 - accuracy: 0.9488 - val_loss: 0.5809 - val_accuracy: 0.7506\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1524 - accuracy: 0.9470 - val_loss: 0.1455 - val_accuracy: 0.9501\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1660 - accuracy: 0.9414 - val_loss: 0.1235 - val_accuracy: 0.9591\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1465 - accuracy: 0.9494 - val_loss: 0.1684 - val_accuracy: 0.9346\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1412 - accuracy: 0.9495 - val_loss: 0.1684 - val_accuracy: 0.9394\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9500 - val_loss: 0.1549 - val_accuracy: 0.9472\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1473 - accuracy: 0.9488 - val_loss: 0.1150 - val_accuracy: 0.9639\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1580 - accuracy: 0.9439 - val_loss: 0.2789 - val_accuracy: 0.8832\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.9517 - val_loss: 0.1364 - val_accuracy: 0.9549\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9491 - val_loss: 0.1808 - val_accuracy: 0.9361\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1423 - accuracy: 0.9512 - val_loss: 0.1661 - val_accuracy: 0.9369\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1386 - accuracy: 0.9511 - val_loss: 0.1098 - val_accuracy: 0.9653\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1466 - accuracy: 0.9487 - val_loss: 0.3799 - val_accuracy: 0.8816\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9505 - val_loss: 0.1919 - val_accuracy: 0.9336\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1379 - accuracy: 0.9523 - val_loss: 0.2974 - val_accuracy: 0.9040\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9514 - val_loss: 0.1115 - val_accuracy: 0.9634\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1388 - accuracy: 0.9514 - val_loss: 0.1967 - val_accuracy: 0.9315\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1375 - accuracy: 0.9529 - val_loss: 0.1423 - val_accuracy: 0.9507\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1361 - accuracy: 0.9545 - val_loss: 0.2282 - val_accuracy: 0.9088\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1462 - accuracy: 0.9491 - val_loss: 0.1127 - val_accuracy: 0.9646\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9495 - val_loss: 0.1642 - val_accuracy: 0.9435\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9536 - val_loss: 0.1135 - val_accuracy: 0.9657\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9648\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.6924 - val_loss: 0.4146 - val_accuracy: 0.8714\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8750 - val_loss: 0.2673 - val_accuracy: 0.8881\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.8954 - val_loss: 0.2483 - val_accuracy: 0.9232\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.9060 - val_loss: 0.2519 - val_accuracy: 0.9255\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2324 - accuracy: 0.9127 - val_loss: 0.2173 - val_accuracy: 0.9274\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2300 - accuracy: 0.9128 - val_loss: 0.2270 - val_accuracy: 0.9079\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2325 - accuracy: 0.9124 - val_loss: 0.3434 - val_accuracy: 0.8660\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9159 - val_loss: 0.1990 - val_accuracy: 0.9295\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9198 - val_loss: 0.2158 - val_accuracy: 0.9144\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2214 - accuracy: 0.9175 - val_loss: 0.2020 - val_accuracy: 0.9214\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2074 - accuracy: 0.9254 - val_loss: 0.1886 - val_accuracy: 0.9315\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9227 - val_loss: 0.1893 - val_accuracy: 0.9304\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2033 - accuracy: 0.9249 - val_loss: 0.2678 - val_accuracy: 0.8982\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2040 - accuracy: 0.9253 - val_loss: 0.1819 - val_accuracy: 0.9339\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2004 - accuracy: 0.9253 - val_loss: 0.1913 - val_accuracy: 0.9355\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9259 - val_loss: 0.1843 - val_accuracy: 0.9362\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9275 - val_loss: 0.2220 - val_accuracy: 0.9223\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2080 - accuracy: 0.9239 - val_loss: 0.2028 - val_accuracy: 0.9288\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9285 - val_loss: 0.2068 - val_accuracy: 0.9225\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9266 - val_loss: 0.1721 - val_accuracy: 0.9373\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9297 - val_loss: 0.2285 - val_accuracy: 0.9197\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9302 - val_loss: 0.1664 - val_accuracy: 0.9401\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9303 - val_loss: 0.1981 - val_accuracy: 0.9376\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.9309 - val_loss: 0.1825 - val_accuracy: 0.9350\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9328 - val_loss: 0.2085 - val_accuracy: 0.9251\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9358 - val_loss: 0.2051 - val_accuracy: 0.9199\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9352 - val_loss: 0.1816 - val_accuracy: 0.9324\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9383 - val_loss: 0.1482 - val_accuracy: 0.9491\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9337 - val_loss: 0.1543 - val_accuracy: 0.9436\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9363 - val_loss: 0.2052 - val_accuracy: 0.9221\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9394 - val_loss: 0.1468 - val_accuracy: 0.9517\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1665 - accuracy: 0.9418 - val_loss: 0.1451 - val_accuracy: 0.9542\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9403 - val_loss: 0.1492 - val_accuracy: 0.9463\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1546 - accuracy: 0.9454 - val_loss: 0.2205 - val_accuracy: 0.9234\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1670 - accuracy: 0.9395 - val_loss: 0.1393 - val_accuracy: 0.9533\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1533 - accuracy: 0.9470 - val_loss: 0.1512 - val_accuracy: 0.9470\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1630 - accuracy: 0.9405 - val_loss: 0.1616 - val_accuracy: 0.9456\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1502 - accuracy: 0.9468 - val_loss: 0.1535 - val_accuracy: 0.9496\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1489 - accuracy: 0.9480 - val_loss: 0.1289 - val_accuracy: 0.9547\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1564 - accuracy: 0.9448 - val_loss: 0.1463 - val_accuracy: 0.9484\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9499 - val_loss: 0.1443 - val_accuracy: 0.9494\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9442 - val_loss: 0.1280 - val_accuracy: 0.9551\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9479 - val_loss: 0.1507 - val_accuracy: 0.9480\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9468 - val_loss: 0.1219 - val_accuracy: 0.9591\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9510 - val_loss: 0.1196 - val_accuracy: 0.9612\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9508 - val_loss: 0.1841 - val_accuracy: 0.9341\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1444 - accuracy: 0.9513 - val_loss: 0.1208 - val_accuracy: 0.9616\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1523 - accuracy: 0.9463 - val_loss: 0.2125 - val_accuracy: 0.9341\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9474 - val_loss: 0.1557 - val_accuracy: 0.9433\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1546 - accuracy: 0.9469 - val_loss: 0.1831 - val_accuracy: 0.9338\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1556 - accuracy: 0.9462 - val_loss: 0.1753 - val_accuracy: 0.9424\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.9490 - val_loss: 0.1311 - val_accuracy: 0.9560\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1405 - accuracy: 0.9512 - val_loss: 0.1183 - val_accuracy: 0.9616\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9519 - val_loss: 0.1363 - val_accuracy: 0.9538\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1391 - accuracy: 0.9515 - val_loss: 0.1599 - val_accuracy: 0.9461\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9509 - val_loss: 0.1127 - val_accuracy: 0.9637\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1429 - accuracy: 0.9519 - val_loss: 0.1909 - val_accuracy: 0.9218\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.9518 - val_loss: 0.1367 - val_accuracy: 0.9537\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1319 - accuracy: 0.9552 - val_loss: 0.1287 - val_accuracy: 0.9563\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1376 - accuracy: 0.9527 - val_loss: 0.1132 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1391 - accuracy: 0.9518 - val_loss: 0.1318 - val_accuracy: 0.9637\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1316 - accuracy: 0.9552 - val_loss: 0.1173 - val_accuracy: 0.9628\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9553 - val_loss: 0.1160 - val_accuracy: 0.9632\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9512 - val_loss: 0.3334 - val_accuracy: 0.8684\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1370 - accuracy: 0.9528 - val_loss: 0.1319 - val_accuracy: 0.9570\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1345 - accuracy: 0.9545 - val_loss: 0.2119 - val_accuracy: 0.9246\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9210\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.6606 - val_loss: 0.4920 - val_accuracy: 0.8140\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3855 - accuracy: 0.8511 - val_loss: 0.3038 - val_accuracy: 0.8596\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.8923 - val_loss: 0.3401 - val_accuracy: 0.9054\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.9023 - val_loss: 0.2388 - val_accuracy: 0.8999\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.9084 - val_loss: 0.2222 - val_accuracy: 0.9260\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.9099 - val_loss: 0.2248 - val_accuracy: 0.9265\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2321 - accuracy: 0.9128 - val_loss: 0.2097 - val_accuracy: 0.9280\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2317 - accuracy: 0.9135 - val_loss: 0.7143 - val_accuracy: 0.5799\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.9058 - val_loss: 0.2253 - val_accuracy: 0.9269\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2206 - accuracy: 0.9180 - val_loss: 0.2148 - val_accuracy: 0.9283\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2172 - accuracy: 0.9191 - val_loss: 0.2070 - val_accuracy: 0.9177\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2217 - accuracy: 0.9183 - val_loss: 0.1945 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.9210 - val_loss: 0.1983 - val_accuracy: 0.9239\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.9200 - val_loss: 0.2022 - val_accuracy: 0.9311\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2115 - accuracy: 0.9227 - val_loss: 0.2227 - val_accuracy: 0.9158\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2167 - accuracy: 0.9211 - val_loss: 0.1833 - val_accuracy: 0.9338\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2169 - accuracy: 0.9206 - val_loss: 0.1838 - val_accuracy: 0.9331\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9235 - val_loss: 0.1855 - val_accuracy: 0.9313\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9234 - val_loss: 0.1807 - val_accuracy: 0.9336\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2044 - accuracy: 0.9259 - val_loss: 0.7799 - val_accuracy: 0.4696\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2133 - accuracy: 0.9192 - val_loss: 0.1873 - val_accuracy: 0.9292\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9256 - val_loss: 0.1722 - val_accuracy: 0.9380\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9291 - val_loss: 0.1741 - val_accuracy: 0.9369\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1993 - accuracy: 0.9265 - val_loss: 0.2982 - val_accuracy: 0.8908\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1927 - accuracy: 0.9298 - val_loss: 0.1889 - val_accuracy: 0.9318\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9273 - val_loss: 0.2329 - val_accuracy: 0.9112\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9290 - val_loss: 0.1767 - val_accuracy: 0.9376\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9291 - val_loss: 0.1777 - val_accuracy: 0.9357\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9261 - val_loss: 0.1555 - val_accuracy: 0.9461\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.9334 - val_loss: 0.3359 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.9332 - val_loss: 0.2358 - val_accuracy: 0.9119\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1727 - accuracy: 0.9371 - val_loss: 0.1487 - val_accuracy: 0.9470\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1687 - accuracy: 0.9385 - val_loss: 0.1429 - val_accuracy: 0.9477\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.9349 - val_loss: 0.1904 - val_accuracy: 0.9334\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1662 - accuracy: 0.9404 - val_loss: 0.1360 - val_accuracy: 0.9560\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9411 - val_loss: 0.1307 - val_accuracy: 0.9565\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1625 - accuracy: 0.9407 - val_loss: 0.1476 - val_accuracy: 0.9503\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9445 - val_loss: 0.2330 - val_accuracy: 0.9153\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9433 - val_loss: 0.2453 - val_accuracy: 0.9081\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9469 - val_loss: 0.1998 - val_accuracy: 0.9184\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1606 - accuracy: 0.9419 - val_loss: 0.1216 - val_accuracy: 0.9611\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9477 - val_loss: 0.2789 - val_accuracy: 0.9040\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1569 - accuracy: 0.9448 - val_loss: 0.1747 - val_accuracy: 0.9373\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1596 - accuracy: 0.9445 - val_loss: 0.1204 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9515 - val_loss: 0.1272 - val_accuracy: 0.9561\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9484 - val_loss: 0.4208 - val_accuracy: 0.8765\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1515 - accuracy: 0.9466 - val_loss: 0.1314 - val_accuracy: 0.9546\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1472 - accuracy: 0.9490 - val_loss: 0.1633 - val_accuracy: 0.9410\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1538 - accuracy: 0.9467 - val_loss: 0.2403 - val_accuracy: 0.9121\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9429 - val_loss: 0.1667 - val_accuracy: 0.9383\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9497 - val_loss: 0.1242 - val_accuracy: 0.9634\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9488 - val_loss: 0.7029 - val_accuracy: 0.6044\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1477 - accuracy: 0.9498 - val_loss: 0.6583 - val_accuracy: 0.6775\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1435 - accuracy: 0.9523 - val_loss: 0.2020 - val_accuracy: 0.9228\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9256\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5886 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6775 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6736 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5949\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5937 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6760 - accuracy: 0.5946 - val_loss: 0.6725 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6745 - accuracy: 0.5946 - val_loss: 0.6702 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6744 - accuracy: 0.5946 - val_loss: 0.6716 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6759 - accuracy: 0.5946 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6737 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5884\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5888 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5916 - val_loss: 0.6742 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6763 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6763 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5942\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6806 - accuracy: 0.5899 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6771 - accuracy: 0.5913 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6735 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5949\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5935 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6756 - accuracy: 0.5946 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6757 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6755 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5884\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.5897 - val_loss: 0.6737 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5916 - val_loss: 0.6739 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5916 - val_loss: 0.6739 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5942\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.5597 - val_loss: 0.6758 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6771 - accuracy: 0.5914 - val_loss: 0.6706 - val_accuracy: 0.6005\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6714 - accuracy: 0.5914 - val_loss: 0.6647 - val_accuracy: 0.6005\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6658 - accuracy: 0.5916 - val_loss: 0.6598 - val_accuracy: 0.6023\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6603 - accuracy: 0.5934 - val_loss: 0.6541 - val_accuracy: 0.6049\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.5975 - val_loss: 0.6485 - val_accuracy: 0.6072\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6497 - accuracy: 0.6032 - val_loss: 0.6435 - val_accuracy: 0.6130\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6104 - val_loss: 0.6385 - val_accuracy: 0.6158\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6393 - accuracy: 0.6170 - val_loss: 0.6347 - val_accuracy: 0.6408\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6346 - accuracy: 0.6263 - val_loss: 0.6289 - val_accuracy: 0.6283\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6297 - accuracy: 0.6322 - val_loss: 0.6245 - val_accuracy: 0.6468\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.6411 - val_loss: 0.6203 - val_accuracy: 0.6584\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6204 - accuracy: 0.6483 - val_loss: 0.6162 - val_accuracy: 0.6715\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6157 - accuracy: 0.6573 - val_loss: 0.6107 - val_accuracy: 0.6539\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6114 - accuracy: 0.6622 - val_loss: 0.6064 - val_accuracy: 0.6614\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6069 - accuracy: 0.6691 - val_loss: 0.6024 - val_accuracy: 0.6748\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6028 - accuracy: 0.6745 - val_loss: 0.5988 - val_accuracy: 0.6937\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5988 - accuracy: 0.6826 - val_loss: 0.5944 - val_accuracy: 0.6699\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5948 - accuracy: 0.6867 - val_loss: 0.5913 - val_accuracy: 0.6662\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6894 - val_loss: 0.5868 - val_accuracy: 0.6995\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6972 - val_loss: 0.5829 - val_accuracy: 0.6914\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5834 - accuracy: 0.7012 - val_loss: 0.5794 - val_accuracy: 0.7046\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5797 - accuracy: 0.7064 - val_loss: 0.5759 - val_accuracy: 0.7094\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5759 - accuracy: 0.7117 - val_loss: 0.5726 - val_accuracy: 0.6970\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7142 - val_loss: 0.5691 - val_accuracy: 0.7192\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.7162 - val_loss: 0.5664 - val_accuracy: 0.7338\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5659 - accuracy: 0.7208 - val_loss: 0.5627 - val_accuracy: 0.7284\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7244 - val_loss: 0.5595 - val_accuracy: 0.7291\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5594 - accuracy: 0.7291 - val_loss: 0.5565 - val_accuracy: 0.7331\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.7293 - val_loss: 0.5540 - val_accuracy: 0.7423\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5534 - accuracy: 0.7336 - val_loss: 0.5513 - val_accuracy: 0.7486\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7372 - val_loss: 0.5479 - val_accuracy: 0.7305\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.7390 - val_loss: 0.5451 - val_accuracy: 0.7323\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7408 - val_loss: 0.5425 - val_accuracy: 0.7463\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7461 - val_loss: 0.5404 - val_accuracy: 0.7564\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7490 - val_loss: 0.5380 - val_accuracy: 0.7631\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7496 - val_loss: 0.5346 - val_accuracy: 0.7532\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7522 - val_loss: 0.5336 - val_accuracy: 0.7751\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7538 - val_loss: 0.5300 - val_accuracy: 0.7641\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7575 - val_loss: 0.5276 - val_accuracy: 0.7655\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7585 - val_loss: 0.5247 - val_accuracy: 0.7534\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7603 - val_loss: 0.5226 - val_accuracy: 0.7648\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5217 - accuracy: 0.7636 - val_loss: 0.5202 - val_accuracy: 0.7645\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5194 - accuracy: 0.7663 - val_loss: 0.5179 - val_accuracy: 0.7509\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7653 - val_loss: 0.5155 - val_accuracy: 0.7566\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7687 - val_loss: 0.5135 - val_accuracy: 0.7707\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5126 - accuracy: 0.7711 - val_loss: 0.5113 - val_accuracy: 0.7722\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5103 - accuracy: 0.7727 - val_loss: 0.5091 - val_accuracy: 0.7699\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7739 - val_loss: 0.5082 - val_accuracy: 0.7897\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5061 - accuracy: 0.7770 - val_loss: 0.5049 - val_accuracy: 0.7715\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7757 - val_loss: 0.5048 - val_accuracy: 0.7999\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7808 - val_loss: 0.5014 - val_accuracy: 0.7855\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7881\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4981 - accuracy: 0.7822 - val_loss: 0.4975 - val_accuracy: 0.7645\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4962 - accuracy: 0.7840 - val_loss: 0.4957 - val_accuracy: 0.7863\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7846 - val_loss: 0.4937 - val_accuracy: 0.7705\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4925 - accuracy: 0.7841 - val_loss: 0.4925 - val_accuracy: 0.7946\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7863 - val_loss: 0.4902 - val_accuracy: 0.7881\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.7895 - val_loss: 0.4884 - val_accuracy: 0.7759\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7872 - val_loss: 0.4871 - val_accuracy: 0.7964\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7904 - val_loss: 0.4864 - val_accuracy: 0.8094\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7938 - val_loss: 0.4835 - val_accuracy: 0.7932\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4820 - accuracy: 0.7941 - val_loss: 0.4816 - val_accuracy: 0.7823\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4805 - accuracy: 0.7932 - val_loss: 0.4800 - val_accuracy: 0.7890\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7950 - val_loss: 0.4793 - val_accuracy: 0.8078\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4769 - accuracy: 0.7962 - val_loss: 0.4769 - val_accuracy: 0.7818\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7969 - val_loss: 0.4753 - val_accuracy: 0.7948\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4738 - accuracy: 0.7985 - val_loss: 0.4737 - val_accuracy: 0.7976\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4723 - accuracy: 0.7999 - val_loss: 0.4722 - val_accuracy: 0.7855\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.7992 - val_loss: 0.4708 - val_accuracy: 0.8025\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4692 - accuracy: 0.8010 - val_loss: 0.4693 - val_accuracy: 0.8032\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.8030 - val_loss: 0.4683 - val_accuracy: 0.8120\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.8037 - val_loss: 0.4669 - val_accuracy: 0.8119\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.8044 - val_loss: 0.4649 - val_accuracy: 0.7955\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4634 - accuracy: 0.8034 - val_loss: 0.4636 - val_accuracy: 0.8048\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8048 - val_loss: 0.4627 - val_accuracy: 0.8143\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.8073 - val_loss: 0.4612 - val_accuracy: 0.8117\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.8071 - val_loss: 0.4598 - val_accuracy: 0.8122\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8091 - val_loss: 0.4585 - val_accuracy: 0.7932\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.8088 - val_loss: 0.4569 - val_accuracy: 0.8015\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4552 - accuracy: 0.8084 - val_loss: 0.4559 - val_accuracy: 0.8145\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4539 - accuracy: 0.8101 - val_loss: 0.4543 - val_accuracy: 0.8057\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8120 - val_loss: 0.4531 - val_accuracy: 0.8091\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4513 - accuracy: 0.8118 - val_loss: 0.4526 - val_accuracy: 0.8249\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8130 - val_loss: 0.4507 - val_accuracy: 0.8091\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.8134 - val_loss: 0.4496 - val_accuracy: 0.8136\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8143 - val_loss: 0.4483 - val_accuracy: 0.8129\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4464 - accuracy: 0.8145 - val_loss: 0.4472 - val_accuracy: 0.8142\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4453 - accuracy: 0.8143 - val_loss: 0.4460 - val_accuracy: 0.8126\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4440 - accuracy: 0.8156 - val_loss: 0.4449 - val_accuracy: 0.8122\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4429 - accuracy: 0.8168 - val_loss: 0.4438 - val_accuracy: 0.8180\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4418 - accuracy: 0.8179 - val_loss: 0.4428 - val_accuracy: 0.8230\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4405 - accuracy: 0.8195 - val_loss: 0.4415 - val_accuracy: 0.8165\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4394 - accuracy: 0.8194 - val_loss: 0.4404 - val_accuracy: 0.8126\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.8197 - val_loss: 0.4393 - val_accuracy: 0.8142\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4372 - accuracy: 0.8199 - val_loss: 0.4386 - val_accuracy: 0.8288\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8215 - val_loss: 0.4372 - val_accuracy: 0.8145\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8202 - val_loss: 0.4361 - val_accuracy: 0.8226\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4338 - accuracy: 0.8210 - val_loss: 0.4355 - val_accuracy: 0.8323\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8221 - val_loss: 0.4340 - val_accuracy: 0.8198\n",
      "277/277 [==============================] - 0s 905us/step - loss: 0.4315 - accuracy: 0.8254\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6826 - accuracy: 0.5811 - val_loss: 0.6740 - val_accuracy: 0.6008\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6739 - accuracy: 0.5946 - val_loss: 0.6683 - val_accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6679 - accuracy: 0.5947 - val_loss: 0.6625 - val_accuracy: 0.6008\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6624 - accuracy: 0.5951 - val_loss: 0.6571 - val_accuracy: 0.6047\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6565 - accuracy: 0.5980 - val_loss: 0.6512 - val_accuracy: 0.6054\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6510 - accuracy: 0.6020 - val_loss: 0.6458 - val_accuracy: 0.6095\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6454 - accuracy: 0.6088 - val_loss: 0.6421 - val_accuracy: 0.6324\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6403 - accuracy: 0.6166 - val_loss: 0.6354 - val_accuracy: 0.6264\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6349 - accuracy: 0.6247 - val_loss: 0.6311 - val_accuracy: 0.6392\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6301 - accuracy: 0.6299 - val_loss: 0.6265 - val_accuracy: 0.6503\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.6399 - val_loss: 0.6210 - val_accuracy: 0.6373\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6205 - accuracy: 0.6461 - val_loss: 0.6164 - val_accuracy: 0.6525\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6160 - accuracy: 0.6535 - val_loss: 0.6125 - val_accuracy: 0.6699\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6114 - accuracy: 0.6611 - val_loss: 0.6076 - val_accuracy: 0.6586\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6069 - accuracy: 0.6672 - val_loss: 0.6034 - val_accuracy: 0.6641\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6027 - accuracy: 0.6726 - val_loss: 0.5994 - val_accuracy: 0.6799\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5983 - accuracy: 0.6788 - val_loss: 0.5959 - val_accuracy: 0.6963\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6856 - val_loss: 0.5916 - val_accuracy: 0.6946\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5902 - accuracy: 0.6907 - val_loss: 0.5885 - val_accuracy: 0.7111\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5865 - accuracy: 0.6993 - val_loss: 0.5841 - val_accuracy: 0.6833\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5826 - accuracy: 0.7003 - val_loss: 0.5803 - val_accuracy: 0.6910\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5789 - accuracy: 0.7034 - val_loss: 0.5767 - val_accuracy: 0.7062\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5755 - accuracy: 0.7092 - val_loss: 0.5732 - val_accuracy: 0.7078\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7110 - val_loss: 0.5702 - val_accuracy: 0.7227\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7156 - val_loss: 0.5677 - val_accuracy: 0.7381\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7206 - val_loss: 0.5633 - val_accuracy: 0.7256\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5615 - accuracy: 0.7249 - val_loss: 0.5601 - val_accuracy: 0.7108\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.7275 - val_loss: 0.5568 - val_accuracy: 0.7305\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5548 - accuracy: 0.7312 - val_loss: 0.5539 - val_accuracy: 0.7171\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7322 - val_loss: 0.5512 - val_accuracy: 0.7402\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7378 - val_loss: 0.5484 - val_accuracy: 0.7456\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7426 - val_loss: 0.5450 - val_accuracy: 0.7358\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7433 - val_loss: 0.5424 - val_accuracy: 0.7305\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7449 - val_loss: 0.5395 - val_accuracy: 0.7386\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7493 - val_loss: 0.5369 - val_accuracy: 0.7416\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7490 - val_loss: 0.5344 - val_accuracy: 0.7395\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7516 - val_loss: 0.5326 - val_accuracy: 0.7645\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5293 - accuracy: 0.7578 - val_loss: 0.5301 - val_accuracy: 0.7340\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5270 - accuracy: 0.7562 - val_loss: 0.5274 - val_accuracy: 0.7648\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7609 - val_loss: 0.5248 - val_accuracy: 0.7416\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5218 - accuracy: 0.7600 - val_loss: 0.5224 - val_accuracy: 0.7652\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5192 - accuracy: 0.7627 - val_loss: 0.5198 - val_accuracy: 0.7571\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5169 - accuracy: 0.7658 - val_loss: 0.5175 - val_accuracy: 0.7650\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7691 - val_loss: 0.5161 - val_accuracy: 0.7414\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5123 - accuracy: 0.7675 - val_loss: 0.5130 - val_accuracy: 0.7675\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5098 - accuracy: 0.7718 - val_loss: 0.5110 - val_accuracy: 0.7721\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5076 - accuracy: 0.7744 - val_loss: 0.5086 - val_accuracy: 0.7685\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5052 - accuracy: 0.7756 - val_loss: 0.5072 - val_accuracy: 0.7842\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5010 - accuracy: 0.7793 - val_loss: 0.5025 - val_accuracy: 0.7648\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4990 - accuracy: 0.7804 - val_loss: 0.5005 - val_accuracy: 0.7652\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4969 - accuracy: 0.7811 - val_loss: 0.4988 - val_accuracy: 0.7846\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4948 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7687\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4928 - accuracy: 0.7846 - val_loss: 0.4946 - val_accuracy: 0.7770\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4907 - accuracy: 0.7864 - val_loss: 0.4927 - val_accuracy: 0.7749\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4889 - accuracy: 0.7891 - val_loss: 0.4913 - val_accuracy: 0.7670\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7875 - val_loss: 0.4891 - val_accuracy: 0.7800\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4852 - accuracy: 0.7909 - val_loss: 0.4873 - val_accuracy: 0.7839\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4834 - accuracy: 0.7925 - val_loss: 0.4858 - val_accuracy: 0.7909\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4815 - accuracy: 0.7942 - val_loss: 0.4839 - val_accuracy: 0.7789\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4798 - accuracy: 0.7940 - val_loss: 0.4839 - val_accuracy: 0.8113\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4782 - accuracy: 0.7976 - val_loss: 0.4806 - val_accuracy: 0.7913\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7971 - val_loss: 0.4789 - val_accuracy: 0.7876\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4747 - accuracy: 0.7983 - val_loss: 0.4778 - val_accuracy: 0.8034\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4729 - accuracy: 0.8005 - val_loss: 0.4757 - val_accuracy: 0.7862\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4715 - accuracy: 0.8017 - val_loss: 0.4743 - val_accuracy: 0.7839\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.8008 - val_loss: 0.4728 - val_accuracy: 0.7830\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8017 - val_loss: 0.4723 - val_accuracy: 0.8142\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4666 - accuracy: 0.8045 - val_loss: 0.4695 - val_accuracy: 0.7913\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.8057 - val_loss: 0.4681 - val_accuracy: 0.7899\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4635 - accuracy: 0.8059 - val_loss: 0.4666 - val_accuracy: 0.7930\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4617 - accuracy: 0.8082 - val_loss: 0.4655 - val_accuracy: 0.7865\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.8073 - val_loss: 0.4639 - val_accuracy: 0.8076\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4588 - accuracy: 0.8101 - val_loss: 0.4624 - val_accuracy: 0.7916\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4575 - accuracy: 0.8107 - val_loss: 0.4611 - val_accuracy: 0.7911\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4560 - accuracy: 0.8110 - val_loss: 0.4595 - val_accuracy: 0.8069\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4544 - accuracy: 0.8120 - val_loss: 0.4582 - val_accuracy: 0.7946\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8103 - val_loss: 0.4570 - val_accuracy: 0.8128\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.8137 - val_loss: 0.4555 - val_accuracy: 0.8099\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8145 - val_loss: 0.4541 - val_accuracy: 0.8015\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4489 - accuracy: 0.8150 - val_loss: 0.4530 - val_accuracy: 0.7976\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8145 - val_loss: 0.4516 - val_accuracy: 0.8098\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4461 - accuracy: 0.8177 - val_loss: 0.4503 - val_accuracy: 0.8085\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.8178 - val_loss: 0.4491 - val_accuracy: 0.8017\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.8182 - val_loss: 0.4478 - val_accuracy: 0.8076\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4424 - accuracy: 0.8191 - val_loss: 0.4466 - val_accuracy: 0.8133\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4458 - val_accuracy: 0.8219\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4398 - accuracy: 0.8207 - val_loss: 0.4455 - val_accuracy: 0.8355\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8219 - val_loss: 0.4430 - val_accuracy: 0.8112\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4374 - accuracy: 0.8228 - val_loss: 0.4419 - val_accuracy: 0.8140\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4362 - accuracy: 0.8223 - val_loss: 0.4407 - val_accuracy: 0.8138\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4350 - accuracy: 0.8236 - val_loss: 0.4397 - val_accuracy: 0.8203\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4338 - accuracy: 0.8241 - val_loss: 0.4384 - val_accuracy: 0.8140\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4326 - accuracy: 0.8248 - val_loss: 0.4373 - val_accuracy: 0.8122\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4315 - accuracy: 0.8253 - val_loss: 0.4362 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4303 - accuracy: 0.8262 - val_loss: 0.4351 - val_accuracy: 0.8165\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.8280 - val_loss: 0.4340 - val_accuracy: 0.8165\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.8267 - val_loss: 0.4333 - val_accuracy: 0.8309\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4269 - accuracy: 0.8284 - val_loss: 0.4319 - val_accuracy: 0.8200\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4259 - accuracy: 0.8287 - val_loss: 0.4312 - val_accuracy: 0.8112\n",
      "277/277 [==============================] - 0s 833us/step - loss: 0.4376 - accuracy: 0.8035\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6774 - accuracy: 0.5844 - val_loss: 0.6693 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6702 - accuracy: 0.5916 - val_loss: 0.6646 - val_accuracy: 0.6012\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6645 - accuracy: 0.5921 - val_loss: 0.6588 - val_accuracy: 0.6035\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.5941 - val_loss: 0.6525 - val_accuracy: 0.6044\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6541 - accuracy: 0.5976 - val_loss: 0.6475 - val_accuracy: 0.6105\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6488 - accuracy: 0.6043 - val_loss: 0.6424 - val_accuracy: 0.6179\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6436 - accuracy: 0.6116 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6388 - accuracy: 0.6182 - val_loss: 0.6325 - val_accuracy: 0.6333\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6340 - accuracy: 0.6256 - val_loss: 0.6277 - val_accuracy: 0.6385\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6294 - accuracy: 0.6328 - val_loss: 0.6229 - val_accuracy: 0.6366\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6247 - accuracy: 0.6396 - val_loss: 0.6198 - val_accuracy: 0.6729\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6203 - accuracy: 0.6499 - val_loss: 0.6138 - val_accuracy: 0.6549\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6158 - accuracy: 0.6556 - val_loss: 0.6094 - val_accuracy: 0.6634\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6114 - accuracy: 0.6631 - val_loss: 0.6052 - val_accuracy: 0.6685\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6074 - accuracy: 0.6683 - val_loss: 0.6022 - val_accuracy: 0.6983\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.6742 - val_loss: 0.5975 - val_accuracy: 0.6949\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6819 - val_loss: 0.5933 - val_accuracy: 0.6935\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5955 - accuracy: 0.6836 - val_loss: 0.5894 - val_accuracy: 0.6902\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5916 - accuracy: 0.6890 - val_loss: 0.5865 - val_accuracy: 0.7120\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5881 - accuracy: 0.6951 - val_loss: 0.5821 - val_accuracy: 0.6946\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5843 - accuracy: 0.6983 - val_loss: 0.5799 - val_accuracy: 0.7264\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5810 - accuracy: 0.7045 - val_loss: 0.5756 - val_accuracy: 0.7159\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7057 - val_loss: 0.5725 - val_accuracy: 0.7257\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5744 - accuracy: 0.7077 - val_loss: 0.5690 - val_accuracy: 0.7249\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7152 - val_loss: 0.5655 - val_accuracy: 0.7162\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7171 - val_loss: 0.5631 - val_accuracy: 0.7379\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7219 - val_loss: 0.5597 - val_accuracy: 0.7361\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5618 - accuracy: 0.7273 - val_loss: 0.5568 - val_accuracy: 0.7379\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5589 - accuracy: 0.7271 - val_loss: 0.5542 - val_accuracy: 0.7474\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5558 - accuracy: 0.7322 - val_loss: 0.5504 - val_accuracy: 0.7293\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.7344 - val_loss: 0.5475 - val_accuracy: 0.7296\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7354 - val_loss: 0.5455 - val_accuracy: 0.7534\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7395 - val_loss: 0.5420 - val_accuracy: 0.7492\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7434 - val_loss: 0.5398 - val_accuracy: 0.7566\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7456 - val_loss: 0.5372 - val_accuracy: 0.7622\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7476 - val_loss: 0.5345 - val_accuracy: 0.7622\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7494 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7525 - val_loss: 0.5290 - val_accuracy: 0.7530\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7533 - val_loss: 0.5265 - val_accuracy: 0.7523\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5288 - accuracy: 0.7577 - val_loss: 0.5243 - val_accuracy: 0.7596\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5265 - accuracy: 0.7606 - val_loss: 0.5219 - val_accuracy: 0.7525\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7593 - val_loss: 0.5202 - val_accuracy: 0.7703\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5223 - accuracy: 0.7628 - val_loss: 0.5181 - val_accuracy: 0.7736\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7661 - val_loss: 0.5155 - val_accuracy: 0.7675\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5176 - accuracy: 0.7679 - val_loss: 0.5134 - val_accuracy: 0.7525\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7659 - val_loss: 0.5113 - val_accuracy: 0.7717\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5134 - accuracy: 0.7713 - val_loss: 0.5092 - val_accuracy: 0.7735\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5113 - accuracy: 0.7729 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5093 - accuracy: 0.7729 - val_loss: 0.5049 - val_accuracy: 0.7729\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5073 - accuracy: 0.7733 - val_loss: 0.5029 - val_accuracy: 0.7699\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5051 - accuracy: 0.7763 - val_loss: 0.5011 - val_accuracy: 0.7802\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7803 - val_loss: 0.4990 - val_accuracy: 0.7714\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5014 - accuracy: 0.7786 - val_loss: 0.4972 - val_accuracy: 0.7754\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4993 - accuracy: 0.7806 - val_loss: 0.4959 - val_accuracy: 0.7900\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4976 - accuracy: 0.7820 - val_loss: 0.4935 - val_accuracy: 0.7715\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4957 - accuracy: 0.7839 - val_loss: 0.4920 - val_accuracy: 0.7883\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4940 - accuracy: 0.7856 - val_loss: 0.4901 - val_accuracy: 0.7842\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4921 - accuracy: 0.7881 - val_loss: 0.4884 - val_accuracy: 0.7712\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4905 - accuracy: 0.7866 - val_loss: 0.4868 - val_accuracy: 0.7906\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4887 - accuracy: 0.7894 - val_loss: 0.4850 - val_accuracy: 0.7897\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7905 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7894 - val_loss: 0.4821 - val_accuracy: 0.7999\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4836 - accuracy: 0.7931 - val_loss: 0.4816 - val_accuracy: 0.8124\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4820 - accuracy: 0.7953 - val_loss: 0.4787 - val_accuracy: 0.7957\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4804 - accuracy: 0.7942 - val_loss: 0.4770 - val_accuracy: 0.7951\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4787 - accuracy: 0.7953 - val_loss: 0.4760 - val_accuracy: 0.8064\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.7969 - val_loss: 0.4738 - val_accuracy: 0.7869\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.7973 - val_loss: 0.4726 - val_accuracy: 0.8024\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4743 - accuracy: 0.7981 - val_loss: 0.4708 - val_accuracy: 0.7950\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.7988 - val_loss: 0.4702 - val_accuracy: 0.8129\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4712 - accuracy: 0.8006 - val_loss: 0.4682 - val_accuracy: 0.8068\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.8026 - val_loss: 0.4671 - val_accuracy: 0.8122\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4684 - accuracy: 0.8018 - val_loss: 0.4656 - val_accuracy: 0.8117\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8038 - val_loss: 0.4637 - val_accuracy: 0.8020\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4656 - accuracy: 0.8045 - val_loss: 0.4623 - val_accuracy: 0.8038\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4641 - accuracy: 0.8038 - val_loss: 0.4626 - val_accuracy: 0.8265\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4629 - accuracy: 0.8058 - val_loss: 0.4597 - val_accuracy: 0.8066\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4613 - accuracy: 0.8070 - val_loss: 0.4587 - val_accuracy: 0.8138\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.8068 - val_loss: 0.4577 - val_accuracy: 0.8186\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4587 - accuracy: 0.8090 - val_loss: 0.4559 - val_accuracy: 0.7941\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4574 - accuracy: 0.8083 - val_loss: 0.4549 - val_accuracy: 0.8179\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4562 - accuracy: 0.8108 - val_loss: 0.4532 - val_accuracy: 0.8018\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4550 - accuracy: 0.8103 - val_loss: 0.4525 - val_accuracy: 0.8194\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4537 - accuracy: 0.8124 - val_loss: 0.4510 - val_accuracy: 0.8170\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4525 - accuracy: 0.8113 - val_loss: 0.4496 - val_accuracy: 0.8135\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4510 - accuracy: 0.8119 - val_loss: 0.4491 - val_accuracy: 0.8277\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4500 - accuracy: 0.8139 - val_loss: 0.4475 - val_accuracy: 0.8191\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4488 - accuracy: 0.8151 - val_loss: 0.4464 - val_accuracy: 0.8230\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8159 - val_loss: 0.4450 - val_accuracy: 0.8193\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4466 - accuracy: 0.8164 - val_loss: 0.4438 - val_accuracy: 0.8186\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4454 - accuracy: 0.8159 - val_loss: 0.4429 - val_accuracy: 0.8223\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4440 - accuracy: 0.8172 - val_loss: 0.4421 - val_accuracy: 0.8291\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8192 - val_loss: 0.4408 - val_accuracy: 0.8272\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4420 - accuracy: 0.8188 - val_loss: 0.4393 - val_accuracy: 0.8124\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4409 - accuracy: 0.8191 - val_loss: 0.4385 - val_accuracy: 0.8247\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4399 - accuracy: 0.8203 - val_loss: 0.4372 - val_accuracy: 0.8165\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8202 - val_loss: 0.4367 - val_accuracy: 0.8316\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4376 - accuracy: 0.8226 - val_loss: 0.4351 - val_accuracy: 0.8173\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4367 - accuracy: 0.8217 - val_loss: 0.4341 - val_accuracy: 0.8138\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4356 - accuracy: 0.8216 - val_loss: 0.4339 - val_accuracy: 0.8379\n",
      "277/277 [==============================] - 0s 848us/step - loss: 0.4254 - accuracy: 0.8411\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f61df81c100>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-beb0a2675d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m rnd_search_cv.fit(X_train, y_train, epochs = 100, \n\u001b[0m\u001b[1;32m      9\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f61df81c100>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3,4,5,6],\n",
    "    \"n_neurons\": np.arange(1,600),\n",
    "    \"learning_rate\": reciprocal(1e-5,0.01),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs = 100, \n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.2062939642434896e-05, 'n_hidden': 6, 'n_neurons': 426}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12700140476226807"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b8ba0c4ba001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run this line of code if you are sure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# run this line of code if you are sure \n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=32,\n",
    "                                        max_value=512,\n",
    "                                        step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=list(np.linspace(start=1e-5, stop=10, num=500)))),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [1e-05, 0.020050060120240482, 0.04009012024048097, 0.06013018036072145, 0.08017024048096193, 0.10021030060120241, 0.12025036072144289, 0.1402904208416834, 0.16033048096192387, 0.18037054108216435, 0.20041060120240484, 0.22045066132264532, 0.2404907214428858, 0.2605307815631263, 0.28057084168336677, 0.3006109018036072, 0.32065096192384773, 0.34069102204408824, 0.3607310821643287, 0.38077114228456915, 0.40081120240480966, 0.4208512625250502, 0.44089132264529063, 0.4609313827655311, 0.4809714428857716, 0.501011503006012, 0.5210515631262526, 0.541091623246493, 0.5611316833667335, 0.581171743486974, 0.6012118036072144, 0.6212518637274549, 0.6412919238476954, 0.6613319839679359, 0.6813720440881764, 0.7014121042084168, 0.7214521643286573, 0.7414922244488978, 0.7615322845691382, 0.7815723446893788, 0.8016124048096193, 0.8216524649298598, 0.8416925250501003, 0.8617325851703407, 0.8817726452905812, 0.9018127054108217, 0.9218527655310621, 0.9418928256513026, 0.9619328857715431, 0.9819729458917836, 1.0020130060120243, 1.0220530661322647, 1.0420931262525053, 1.0621331863727457, 1.082173246492986, 1.1022133066132267, 1.122253366733467, 1.1422934268537075, 1.1623334869739481, 1.1823735470941885, 1.202413607214429, 1.2224536673346695, 1.24249372745491, 1.2625337875751506, 1.282573847695391, 1.3026139078156314, 1.322653967935872, 1.3426940280561124, 1.362734088176353, 1.3827741482965934, 1.4028142084168338, 1.4228542685370744, 1.4428943286573148, 1.4629343887775552, 1.4829744488977958, 1.5030145090180362, 1.5230545691382766, 1.5430946292585173, 1.5631346893787577, 1.5831747494989983, 1.6032148096192387, 1.623254869739479, 1.6432949298597197, 1.66333498997996, 1.6833750501002007, 1.7034151102204411, 1.7234551703406815, 1.7434952304609221, 1.7635352905811625, 1.783575350701403, 1.8036154108216436, 1.823655470941884, 1.8436955310621244, 1.863735591182365, 1.8837756513026054, 1.903815711422846, 1.9238557715430864, 1.9438958316633268, 1.9639358917835674, 1.9839759519038078, 2.0040160120240484, 2.0240560721442886, 2.0440961322645292, 2.06413619238477, 2.0841762525050105, 2.1042163126252507, 2.1242563727454913, 2.144296432865732, 2.164336492985972, 2.1843765531062127, 2.2044166132264533, 2.2244566733466935, 2.244496733466934, 2.2645367935871747, 2.284576853707415, 2.3046169138276555, 2.324656973947896, 2.3446970340681363, 2.364737094188377, 2.3847771543086176, 2.4048172144288578, 2.4248572745490984, 2.444897334669339, 2.4649373947895796, 2.48497745490982, 2.5050175150300604, 2.525057575150301, 2.5450976352705412, 2.565137695390782, 2.5851777555110225, 2.6052178156312626, 2.6252578757515033, 2.645297935871744, 2.665337995991984, 2.6853780561122247, 2.7054181162324653, 2.725458176352706, 2.745498236472946, 2.7655382965931867, 2.7855783567134274, 2.8056184168336675, 2.825658476953908, 2.8456985370741488, 2.865738597194389, 2.8857786573146296, 2.90581871743487, 2.9258587775551104, 2.945898837675351, 2.9659388977955916, 2.985978957915832, 3.0060190180360724, 3.026059078156313, 3.046099138276553, 3.066139198396794, 3.0861792585170345, 3.106219318637275, 3.1262593787575153, 3.146299438877756, 3.1663394989979965, 3.1863795591182367, 3.2064196192384773, 3.226459679358718, 3.246499739478958, 3.2665397995991987, 3.2865798597194393, 3.3066199198396795, 3.32665997995992, 3.3467000400801608, 3.3667401002004014, 3.3867801603206416, 3.406820220440882, 3.426860280561123, 3.446900340681363, 3.4669404008016036, 3.486980460921844, 3.5070205210420844, 3.527060581162325, 3.5471006412825656, 3.567140701402806, 3.5871807615230464, 3.607220821643287, 3.6272608817635272, 3.647300941883768, 3.6673410020040085, 3.6873810621242487, 3.7074211222444893, 3.72746118236473, 3.7475012424849705, 3.7675413026052107, 3.7875813627254513, 3.807621422845692, 3.827661482965932, 3.8477015430861727, 3.8677416032064134, 3.8877816633266535, 3.907821723446894, 3.927861783567135, 3.947901843687375, 3.9679419038076156, 3.987981963927856, 4.008022024048096, 4.0280620841683366, 4.048102144288577, 4.068142204408818, 4.088182264529058, 4.108222324649298, 4.128262384769539, 4.148302444889779, 4.1683425050100205, 4.188382565130261, 4.208422625250501, 4.228462685370742, 4.248502745490982, 4.268542805611222, 4.288582865731463, 4.3086229258517035, 4.328662985971944, 4.348703046092185, 4.368743106212425, 4.388783166332665, 4.408823226452906, 4.428863286573146, 4.4489033466933865, 4.468943406813628, 4.488983466933868, 4.509023527054108, 4.529063587174349, 4.549103647294589, 4.569143707414829, 4.58918376753507, 4.609223827655311, 4.629263887775551, 4.649303947895792, 4.669344008016032, 4.689384068136272, 4.709424128256513, 4.729464188376753, 4.749504248496994, 4.769544308617235, 4.789584368737475, 4.809624428857715, 4.829664488977956, 4.849704549098196, 4.869744609218437, 4.8897846693386775, 4.909824729458918, 4.929864789579159, 4.949904849699399, 4.969944909819639, 4.98998496993988, 5.01002503006012, 5.0300650901803605, 5.050105150300602, 5.070145210420842, 5.090185270541082, 5.110225330661323, 5.130265390781563, 5.150305450901803, 5.170345511022044, 5.190385571142285, 5.210425631262525, 5.230465691382766, 5.250505751503006, 5.270545811623246, 5.290585871743487, 5.3106259318637274, 5.330665991983968, 5.350706052104209, 5.370746112224449, 5.390786172344689, 5.41082623246493, 5.43086629258517, 5.450906352705411, 5.4709464128256515, 5.490986472945892, 5.511026533066133, 5.531066593186373, 5.551106653306613, 5.571146713426854, 5.591186773547094, 5.6112268336673345, 5.631266893787576, 5.651306953907816, 5.671347014028056, 5.691387074148297, 5.711427134268537, 5.731467194388777, 5.7515072545090185, 5.771547314629259, 5.791587374749499, 5.81162743486974, 5.83166749498998, 5.85170755511022, 5.871747615230461, 5.8917876753507015, 5.911827735470942, 5.931867795591183, 5.951907855711423, 5.971947915831663, 5.991987975951904, 6.012028036072144, 6.0320680961923845, 6.0521081563126256, 6.072148216432866, 6.092188276553106, 6.112228336673347, 6.132268396793587, 6.152308456913828, 6.172348517034068, 6.192388577154309, 6.21242863727455, 6.23246869739479, 6.25250875751503, 6.272548817635271, 6.292588877755511, 6.312628937875751, 6.3326689979959925, 6.352709058116233, 6.372749118236473, 6.392789178356714, 6.412829238476954, 6.432869298597194, 6.452909358717435, 6.4729494188376755, 6.492989478957916, 6.513029539078157, 6.533069599198397, 6.553109659318637, 6.573149719438878, 6.593189779559118, 6.6132298396793585, 6.6332698997996, 6.65330995991984, 6.67335002004008, 6.693390080160321, 6.713430140280561, 6.733470200400802, 6.753510260521042, 6.773550320641283, 6.793590380761524, 6.813630440881764, 6.833670501002004, 6.853710561122245, 6.873750621242485, 6.893790681362725, 6.9138307414829665, 6.933870801603207, 6.953910861723447, 6.973950921843688, 6.993990981963928, 7.014031042084168, 7.034071102204409, 7.0541111623246495, 7.07415122244489, 7.094191282565131, 7.114231342685371, 7.134271402805611, 7.154311462925852, 7.174351523046092, 7.1943915831663325, 7.214431643286574, 7.234471703406814, 7.254511763527054, 7.274551823647295, 7.294591883767535, 7.314631943887775, 7.334672004008016, 7.354712064128257, 7.374752124248497, 7.394792184368738, 7.414832244488978, 7.434872304609219, 7.454912364729459, 7.4749524248496995, 7.4949924849699405, 7.515032545090181, 7.535072605210421, 7.555112665330662, 7.575152725450902, 7.595192785571142, 7.615232845691383, 7.6352729058116235, 7.655312965931864, 7.675353026052105, 7.695393086172345, 7.715433146292585, 7.735473206412826, 7.755513266533066, 7.775553326653307, 7.795593386773548, 7.815633446893788, 7.835673507014028, 7.855713567134269, 7.875753627254509, 7.895793687374749, 7.9158337474949905, 7.935873807615231, 7.955913867735471, 7.975953927855712, 7.995993987975952, 8.016034048096193, 8.036074108216432, 8.056114168336673, 8.076154228456915, 8.096194288577154, 8.116234348697395, 8.136274408817636, 8.156314468937875, 8.176354529058116, 8.196394589178357, 8.216434649298597, 8.236474709418838, 8.256514769539079, 8.276554829659318, 8.29659488977956, 8.3166349498998, 8.336675010020041, 8.35671507014028, 8.376755130260522, 8.396795190380763, 8.416835250501002, 8.436875310621243, 8.456915370741484, 8.476955430861723, 8.496995490981964, 8.517035551102206, 8.537075611222445, 8.557115671342686, 8.577155731462927, 8.597195791583166, 8.617235851703407, 8.637275911823648, 8.657315971943888, 8.677356032064129, 8.69739609218437, 8.717436152304609, 8.73747621242485, 8.757516272545091, 8.77755633266533, 8.797596392785572, 8.817636452905813, 8.837676513026052, 8.857716573146293, 8.877756633266534, 8.897796693386773, 8.917836753507014, 8.937876813627256, 8.957916873747495, 8.977956933867736, 8.997996993987977, 9.018037054108216, 9.038077114228457, 9.058117174348698, 9.078157234468938, 9.098197294589179, 9.11823735470942, 9.138277414829659, 9.1583174749499, 9.178357535070141, 9.19839759519038, 9.218437655310622, 9.238477715430863, 9.258517775551102, 9.278557835671343, 9.298597895791584, 9.318637955911823, 9.338678016032064, 9.358718076152305, 9.378758136272545, 9.398798196392786, 9.418838256513027, 9.438878316633266, 9.458918376753507, 9.478958436873748, 9.498998496993988, 9.519038557114229, 9.53907861723447, 9.559118677354709, 9.57915873747495, 9.599198797595191, 9.61923885771543, 9.639278917835671, 9.659318977955913, 9.679359038076154, 9.699399098196393, 9.719439158316634, 9.739479218436875, 9.759519278557114, 9.779559338677355, 9.799599398797596, 9.819639458917836, 9.839679519038077, 9.859719579158318, 9.879759639278557, 9.899799699398798, 9.91983975951904, 9.939879819639279, 9.95991987975952, 9.97995993987976, 10.0]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.68 - ETA: 1s - loss: 259.0526 - accuracy: 0.52 - ETA: 1s - loss: 129.8933 - accuracy: 0.52 - ETA: 0s - loss: 89.1579 - accuracy: 0.5355 - ETA: 0s - loss: 68.9138 - accuracy: 0.529 - ETA: 0s - loss: 55.2876 - accuracy: 0.527 - ETA: 0s - loss: 46.2012 - accuracy: 0.529 - ETA: 0s - loss: 39.5601 - accuracy: 0.531 - ETA: 0s - loss: 34.9650 - accuracy: 0.534 - ETA: 0s - loss: 31.2495 - accuracy: 0.531 - ETA: 0s - loss: 28.1542 - accuracy: 0.534 - ETA: 0s - loss: 25.7879 - accuracy: 0.530 - ETA: 0s - loss: 23.6893 - accuracy: 0.530 - ETA: 0s - loss: 22.0484 - accuracy: 0.532 - ETA: 0s - loss: 20.5900 - accuracy: 0.532 - ETA: 0s - loss: 19.1786 - accuracy: 0.533 - ETA: 0s - loss: 18.0146 - accuracy: 0.532 - ETA: 0s - loss: 17.0464 - accuracy: 0.531 - ETA: 0s - loss: 16.1302 - accuracy: 0.531 - ETA: 0s - loss: 15.3555 - accuracy: 0.531 - ETA: 0s - loss: 14.6364 - accuracy: 0.530 - ETA: 0s - loss: 13.9350 - accuracy: 0.530 - ETA: 0s - loss: 13.3468 - accuracy: 0.529 - ETA: 0s - loss: 12.9143 - accuracy: 0.530 - 1s 2ms/step - loss: 12.7670 - accuracy: 0.5298 - val_loss: 0.7122 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.65 - ETA: 1s - loss: 1.7838 - accuracy: 0.54 - ETA: 1s - loss: 1.2569 - accuracy: 0.54 - ETA: 1s - loss: 1.1267 - accuracy: 0.52 - ETA: 0s - loss: 1.0363 - accuracy: 0.52 - ETA: 0s - loss: 0.9892 - accuracy: 0.52 - ETA: 0s - loss: 0.9589 - accuracy: 0.52 - ETA: 0s - loss: 0.9468 - accuracy: 0.52 - ETA: 0s - loss: 0.9268 - accuracy: 0.52 - ETA: 0s - loss: 0.9047 - accuracy: 0.52 - ETA: 0s - loss: 0.8918 - accuracy: 0.52 - ETA: 0s - loss: 0.8851 - accuracy: 0.52 - ETA: 0s - loss: 0.8736 - accuracy: 0.52 - ETA: 0s - loss: 0.8655 - accuracy: 0.52 - ETA: 0s - loss: 0.8548 - accuracy: 0.53 - ETA: 0s - loss: 0.8493 - accuracy: 0.53 - ETA: 0s - loss: 0.8501 - accuracy: 0.52 - ETA: 0s - loss: 0.8497 - accuracy: 0.52 - ETA: 0s - loss: 0.8437 - accuracy: 0.52 - ETA: 0s - loss: 0.8377 - accuracy: 0.52 - ETA: 0s - loss: 0.8318 - accuracy: 0.53 - ETA: 0s - loss: 0.8280 - accuracy: 0.53 - ETA: 0s - loss: 0.8233 - accuracy: 0.53 - ETA: 0s - loss: 0.8221 - accuracy: 0.53 - ETA: 0s - loss: 0.8198 - accuracy: 0.53 - 1s 2ms/step - loss: 0.8196 - accuracy: 0.5311 - val_loss: 1.1006 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.1784 - accuracy: 0.34 - ETA: 1s - loss: 0.8403 - accuracy: 0.50 - ETA: 1s - loss: 0.8231 - accuracy: 0.52 - ETA: 1s - loss: 0.7898 - accuracy: 0.52 - ETA: 0s - loss: 0.7960 - accuracy: 0.52 - ETA: 0s - loss: 0.7839 - accuracy: 0.53 - ETA: 0s - loss: 0.7751 - accuracy: 0.53 - ETA: 0s - loss: 0.7744 - accuracy: 0.53 - ETA: 0s - loss: 0.7825 - accuracy: 0.53 - ETA: 0s - loss: 0.7756 - accuracy: 0.53 - ETA: 0s - loss: 0.7718 - accuracy: 0.53 - ETA: 0s - loss: 0.7749 - accuracy: 0.53 - ETA: 0s - loss: 0.7762 - accuracy: 0.52 - ETA: 0s - loss: 0.7724 - accuracy: 0.53 - ETA: 0s - loss: 0.7712 - accuracy: 0.53 - ETA: 0s - loss: 0.7699 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - ETA: 0s - loss: 0.7688 - accuracy: 0.53 - ETA: 0s - loss: 0.7716 - accuracy: 0.53 - ETA: 0s - loss: 0.7711 - accuracy: 0.53 - ETA: 0s - loss: 0.7677 - accuracy: 0.53 - ETA: 0s - loss: 0.7687 - accuracy: 0.53 - ETA: 0s - loss: 0.7685 - accuracy: 0.53 - ETA: 0s - loss: 0.7669 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7669 - accuracy: 0.5318 - val_loss: 0.7113 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7191 - accuracy: 0.34 - ETA: 1s - loss: 0.7945 - accuracy: 0.51 - ETA: 1s - loss: 0.7875 - accuracy: 0.50 - ETA: 1s - loss: 0.7869 - accuracy: 0.51 - ETA: 1s - loss: 0.7848 - accuracy: 0.51 - ETA: 0s - loss: 0.7750 - accuracy: 0.53 - ETA: 0s - loss: 0.7750 - accuracy: 0.53 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7742 - accuracy: 0.52 - ETA: 0s - loss: 0.7735 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7734 - accuracy: 0.52 - ETA: 0s - loss: 0.7773 - accuracy: 0.52 - ETA: 0s - loss: 0.7712 - accuracy: 0.52 - ETA: 0s - loss: 0.7768 - accuracy: 0.52 - ETA: 0s - loss: 0.7739 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7757 - accuracy: 0.52 - ETA: 0s - loss: 0.7735 - accuracy: 0.52 - ETA: 0s - loss: 0.7732 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.52 - ETA: 0s - loss: 0.7692 - accuracy: 0.52 - ETA: 0s - loss: 0.7683 - accuracy: 0.52 - ETA: 0s - loss: 0.7676 - accuracy: 0.52 - ETA: 0s - loss: 0.7680 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - 2s 2ms/step - loss: 0.7695 - accuracy: 0.5263 - val_loss: 0.7045 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.62 - ETA: 1s - loss: 0.7684 - accuracy: 0.50 - ETA: 1s - loss: 0.7439 - accuracy: 0.52 - ETA: 1s - loss: 0.7397 - accuracy: 0.52 - ETA: 1s - loss: 0.7430 - accuracy: 0.52 - ETA: 0s - loss: 0.7359 - accuracy: 0.53 - ETA: 0s - loss: 0.7559 - accuracy: 0.52 - ETA: 0s - loss: 0.7558 - accuracy: 0.52 - ETA: 0s - loss: 0.7547 - accuracy: 0.53 - ETA: 0s - loss: 0.7484 - accuracy: 0.53 - ETA: 0s - loss: 0.7527 - accuracy: 0.53 - ETA: 0s - loss: 0.7565 - accuracy: 0.53 - ETA: 0s - loss: 0.7535 - accuracy: 0.53 - ETA: 0s - loss: 0.7529 - accuracy: 0.53 - ETA: 0s - loss: 0.7583 - accuracy: 0.52 - ETA: 0s - loss: 0.7580 - accuracy: 0.52 - ETA: 0s - loss: 0.7582 - accuracy: 0.53 - ETA: 0s - loss: 0.7563 - accuracy: 0.53 - ETA: 0s - loss: 0.7589 - accuracy: 0.53 - ETA: 0s - loss: 0.7610 - accuracy: 0.53 - ETA: 0s - loss: 0.7587 - accuracy: 0.53 - ETA: 0s - loss: 0.7627 - accuracy: 0.53 - ETA: 0s - loss: 0.7626 - accuracy: 0.53 - ETA: 0s - loss: 0.7667 - accuracy: 0.52 - ETA: 0s - loss: 0.7656 - accuracy: 0.52 - 1s 2ms/step - loss: 0.7671 - accuracy: 0.5280 - val_loss: 0.9081 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6027 - accuracy: 0.75 - ETA: 1s - loss: 35.2568 - accuracy: 0.570 - ETA: 1s - loss: 19.3793 - accuracy: 0.561 - ETA: 1s - loss: 13.3368 - accuracy: 0.559 - ETA: 1s - loss: 10.3226 - accuracy: 0.559 - ETA: 0s - loss: 8.5132 - accuracy: 0.559 - ETA: 0s - loss: 7.2012 - accuracy: 0.54 - ETA: 0s - loss: 6.4227 - accuracy: 0.55 - ETA: 0s - loss: 5.7323 - accuracy: 0.55 - ETA: 0s - loss: 5.2025 - accuracy: 0.54 - ETA: 0s - loss: 4.7622 - accuracy: 0.54 - ETA: 0s - loss: 4.3730 - accuracy: 0.54 - ETA: 0s - loss: 4.0788 - accuracy: 0.54 - ETA: 0s - loss: 3.8141 - accuracy: 0.54 - ETA: 0s - loss: 3.5919 - accuracy: 0.54 - ETA: 0s - loss: 3.3992 - accuracy: 0.54 - ETA: 0s - loss: 3.2466 - accuracy: 0.54 - ETA: 0s - loss: 3.0937 - accuracy: 0.54 - ETA: 0s - loss: 2.9621 - accuracy: 0.54 - ETA: 0s - loss: 2.8468 - accuracy: 0.54 - ETA: 0s - loss: 2.7410 - accuracy: 0.54 - ETA: 0s - loss: 2.6550 - accuracy: 0.54 - ETA: 0s - loss: 2.5684 - accuracy: 0.54 - ETA: 0s - loss: 2.4857 - accuracy: 0.53 - ETA: 0s - loss: 2.4169 - accuracy: 0.53 - 1s 2ms/step - loss: 2.3683 - accuracy: 0.5357 - val_loss: 1.8196 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.4375 - accuracy: 0.68 - ETA: 1s - loss: 0.7785 - accuracy: 0.52 - ETA: 1s - loss: 0.7969 - accuracy: 0.51 - ETA: 1s - loss: 0.7795 - accuracy: 0.52 - ETA: 1s - loss: 0.7789 - accuracy: 0.52 - ETA: 1s - loss: 0.7670 - accuracy: 0.52 - ETA: 1s - loss: 0.7650 - accuracy: 0.53 - ETA: 1s - loss: 0.7647 - accuracy: 0.53 - ETA: 0s - loss: 0.7637 - accuracy: 0.53 - ETA: 0s - loss: 0.7654 - accuracy: 0.53 - ETA: 0s - loss: 0.7648 - accuracy: 0.53 - ETA: 0s - loss: 0.7665 - accuracy: 0.53 - ETA: 0s - loss: 0.7661 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7680 - accuracy: 0.53 - ETA: 0s - loss: 0.7700 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7644 - accuracy: 0.53 - ETA: 0s - loss: 0.7631 - accuracy: 0.53 - ETA: 0s - loss: 0.7941 - accuracy: 0.53 - ETA: 0s - loss: 0.7937 - accuracy: 0.53 - ETA: 0s - loss: 0.7939 - accuracy: 0.53 - ETA: 0s - loss: 0.7918 - accuracy: 0.53 - ETA: 0s - loss: 0.7914 - accuracy: 0.53 - ETA: 0s - loss: 0.7947 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7932 - accuracy: 0.5316 - val_loss: 0.7286 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.65 - ETA: 1s - loss: 0.8165 - accuracy: 0.53 - ETA: 1s - loss: 0.7916 - accuracy: 0.53 - ETA: 1s - loss: 0.8005 - accuracy: 0.52 - ETA: 1s - loss: 0.7966 - accuracy: 0.52 - ETA: 1s - loss: 0.7912 - accuracy: 0.52 - ETA: 0s - loss: 0.7811 - accuracy: 0.52 - ETA: 0s - loss: 0.7804 - accuracy: 0.52 - ETA: 0s - loss: 0.7844 - accuracy: 0.52 - ETA: 0s - loss: 0.7856 - accuracy: 0.52 - ETA: 0s - loss: 0.7802 - accuracy: 0.52 - ETA: 0s - loss: 0.7758 - accuracy: 0.52 - ETA: 0s - loss: 0.7747 - accuracy: 0.52 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7735 - accuracy: 0.53 - ETA: 0s - loss: 0.7750 - accuracy: 0.52 - ETA: 0s - loss: 0.7732 - accuracy: 0.52 - ETA: 0s - loss: 0.7751 - accuracy: 0.52 - ETA: 0s - loss: 0.7748 - accuracy: 0.52 - ETA: 0s - loss: 0.7761 - accuracy: 0.52 - ETA: 0s - loss: 0.7753 - accuracy: 0.52 - ETA: 0s - loss: 0.7762 - accuracy: 0.52 - ETA: 0s - loss: 0.7734 - accuracy: 0.52 - ETA: 0s - loss: 0.7722 - accuracy: 0.52 - ETA: 0s - loss: 0.7713 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7695 - accuracy: 0.5304 - val_loss: 1.1560 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.4429 - accuracy: 0.50 - ETA: 1s - loss: 0.7752 - accuracy: 0.52 - ETA: 1s - loss: 0.7651 - accuracy: 0.53 - ETA: 1s - loss: 0.7557 - accuracy: 0.53 - ETA: 0s - loss: 0.7595 - accuracy: 0.53 - ETA: 0s - loss: 0.7617 - accuracy: 0.52 - ETA: 0s - loss: 0.7713 - accuracy: 0.52 - ETA: 0s - loss: 0.7749 - accuracy: 0.52 - ETA: 0s - loss: 0.7795 - accuracy: 0.52 - ETA: 0s - loss: 0.7823 - accuracy: 0.52 - ETA: 0s - loss: 0.7755 - accuracy: 0.53 - ETA: 0s - loss: 0.7721 - accuracy: 0.53 - ETA: 0s - loss: 0.7728 - accuracy: 0.53 - ETA: 0s - loss: 0.7721 - accuracy: 0.53 - ETA: 0s - loss: 0.7727 - accuracy: 0.53 - ETA: 0s - loss: 0.7748 - accuracy: 0.53 - ETA: 0s - loss: 0.7756 - accuracy: 0.53 - ETA: 0s - loss: 0.7732 - accuracy: 0.53 - ETA: 0s - loss: 0.7726 - accuracy: 0.53 - ETA: 0s - loss: 0.7740 - accuracy: 0.53 - ETA: 0s - loss: 0.7729 - accuracy: 0.53 - ETA: 0s - loss: 0.7745 - accuracy: 0.53 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7751 - accuracy: 0.53 - ETA: 0s - loss: 0.7738 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7757 - accuracy: 0.5329 - val_loss: 0.7497 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.53 - ETA: 1s - loss: 0.8154 - accuracy: 0.50 - ETA: 1s - loss: 0.7759 - accuracy: 0.53 - ETA: 1s - loss: 0.7929 - accuracy: 0.51 - ETA: 1s - loss: 0.7880 - accuracy: 0.51 - ETA: 1s - loss: 0.7811 - accuracy: 0.52 - ETA: 0s - loss: 0.7747 - accuracy: 0.51 - ETA: 0s - loss: 0.7697 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7731 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.52 - ETA: 0s - loss: 0.7658 - accuracy: 0.52 - ETA: 0s - loss: 0.7678 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - ETA: 0s - loss: 0.7655 - accuracy: 0.53 - ETA: 0s - loss: 0.7641 - accuracy: 0.53 - ETA: 0s - loss: 0.7677 - accuracy: 0.53 - ETA: 0s - loss: 0.7701 - accuracy: 0.52 - ETA: 0s - loss: 0.7671 - accuracy: 0.53 - ETA: 0s - loss: 0.7646 - accuracy: 0.53 - ETA: 0s - loss: 0.7635 - accuracy: 0.53 - ETA: 0s - loss: 0.7675 - accuracy: 0.53 - ETA: 0s - loss: 0.7658 - accuracy: 0.53 - ETA: 0s - loss: 0.7680 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7679 - accuracy: 0.5331 - val_loss: 0.7551 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8811 - accuracy: 0.31 - ETA: 1s - loss: 77.9600 - accuracy: 0.500 - ETA: 1s - loss: 40.9788 - accuracy: 0.516 - ETA: 1s - loss: 26.9634 - accuracy: 0.519 - ETA: 0s - loss: 20.5983 - accuracy: 0.526 - ETA: 0s - loss: 16.7157 - accuracy: 0.526 - ETA: 0s - loss: 14.1277 - accuracy: 0.523 - ETA: 0s - loss: 12.3521 - accuracy: 0.527 - ETA: 0s - loss: 10.8843 - accuracy: 0.529 - ETA: 0s - loss: 9.8877 - accuracy: 0.530 - ETA: 0s - loss: 8.9790 - accuracy: 0.53 - ETA: 0s - loss: 8.2521 - accuracy: 0.53 - ETA: 0s - loss: 7.6584 - accuracy: 0.53 - ETA: 0s - loss: 7.1279 - accuracy: 0.52 - ETA: 0s - loss: 6.6953 - accuracy: 0.52 - ETA: 0s - loss: 6.2746 - accuracy: 0.52 - ETA: 0s - loss: 5.9560 - accuracy: 0.52 - ETA: 0s - loss: 5.6224 - accuracy: 0.52 - ETA: 0s - loss: 5.6493 - accuracy: 0.52 - ETA: 0s - loss: 5.3782 - accuracy: 0.52 - ETA: 0s - loss: 5.1446 - accuracy: 0.52 - ETA: 0s - loss: 4.9735 - accuracy: 0.52 - ETA: 0s - loss: 4.7923 - accuracy: 0.52 - ETA: 0s - loss: 4.5904 - accuracy: 0.52 - 1s 2ms/step - loss: 4.5202 - accuracy: 0.5280 - val_loss: 0.7238 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.62 - ETA: 1s - loss: 0.7918 - accuracy: 0.53 - ETA: 1s - loss: 0.7431 - accuracy: 0.55 - ETA: 1s - loss: 0.7387 - accuracy: 0.55 - ETA: 0s - loss: 0.7358 - accuracy: 0.55 - ETA: 0s - loss: 0.7386 - accuracy: 0.55 - ETA: 0s - loss: 0.8012 - accuracy: 0.54 - ETA: 0s - loss: 0.7932 - accuracy: 0.54 - ETA: 0s - loss: 0.7961 - accuracy: 0.53 - ETA: 0s - loss: 0.7966 - accuracy: 0.53 - ETA: 0s - loss: 0.7923 - accuracy: 0.53 - ETA: 0s - loss: 0.7909 - accuracy: 0.53 - ETA: 0s - loss: 0.7884 - accuracy: 0.53 - ETA: 0s - loss: 0.7865 - accuracy: 0.52 - ETA: 0s - loss: 0.7882 - accuracy: 0.52 - ETA: 0s - loss: 0.7869 - accuracy: 0.52 - ETA: 0s - loss: 0.7840 - accuracy: 0.52 - ETA: 0s - loss: 0.7796 - accuracy: 0.52 - ETA: 0s - loss: 0.7762 - accuracy: 0.53 - ETA: 0s - loss: 0.7752 - accuracy: 0.53 - ETA: 0s - loss: 0.7715 - accuracy: 0.53 - ETA: 0s - loss: 0.7710 - accuracy: 0.53 - ETA: 0s - loss: 0.7754 - accuracy: 0.53 - ETA: 0s - loss: 0.7738 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7738 - accuracy: 0.5322 - val_loss: 1.8063 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.5049 - accuracy: 0.50 - ETA: 1s - loss: 0.7232 - accuracy: 0.56 - ETA: 1s - loss: 0.7415 - accuracy: 0.55 - ETA: 1s - loss: 0.7582 - accuracy: 0.54 - ETA: 1s - loss: 0.7876 - accuracy: 0.53 - ETA: 0s - loss: 0.7829 - accuracy: 0.52 - ETA: 0s - loss: 0.7726 - accuracy: 0.53 - ETA: 0s - loss: 0.7757 - accuracy: 0.53 - ETA: 0s - loss: 0.7725 - accuracy: 0.53 - ETA: 0s - loss: 0.7740 - accuracy: 0.53 - ETA: 0s - loss: 0.7731 - accuracy: 0.52 - ETA: 0s - loss: 0.7698 - accuracy: 0.52 - ETA: 0s - loss: 0.8014 - accuracy: 0.52 - ETA: 0s - loss: 0.7961 - accuracy: 0.53 - ETA: 0s - loss: 0.7948 - accuracy: 0.52 - ETA: 0s - loss: 0.7943 - accuracy: 0.52 - ETA: 0s - loss: 0.7960 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7910 - accuracy: 0.53 - ETA: 0s - loss: 0.7908 - accuracy: 0.53 - ETA: 0s - loss: 0.7926 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7939 - accuracy: 0.52 - ETA: 0s - loss: 0.7931 - accuracy: 0.52 - 1s 2ms/step - loss: 0.7926 - accuracy: 0.5257 - val_loss: 1.5704 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.6226 - accuracy: 0.37 - ETA: 1s - loss: 0.7855 - accuracy: 0.52 - ETA: 1s - loss: 0.7673 - accuracy: 0.52 - ETA: 1s - loss: 0.7626 - accuracy: 0.52 - ETA: 1s - loss: 0.7669 - accuracy: 0.52 - ETA: 0s - loss: 0.7653 - accuracy: 0.52 - ETA: 0s - loss: 0.7646 - accuracy: 0.53 - ETA: 0s - loss: 0.7616 - accuracy: 0.53 - ETA: 0s - loss: 0.7559 - accuracy: 0.53 - ETA: 0s - loss: 0.7524 - accuracy: 0.53 - ETA: 0s - loss: 0.7494 - accuracy: 0.53 - ETA: 0s - loss: 0.7479 - accuracy: 0.54 - ETA: 0s - loss: 0.7471 - accuracy: 0.53 - ETA: 0s - loss: 0.7463 - accuracy: 0.53 - ETA: 0s - loss: 0.7488 - accuracy: 0.53 - ETA: 0s - loss: 0.7511 - accuracy: 0.53 - ETA: 0s - loss: 0.7558 - accuracy: 0.53 - ETA: 0s - loss: 0.7567 - accuracy: 0.53 - ETA: 0s - loss: 0.7562 - accuracy: 0.53 - ETA: 0s - loss: 0.7544 - accuracy: 0.53 - ETA: 0s - loss: 0.7572 - accuracy: 0.53 - ETA: 0s - loss: 0.7563 - accuracy: 0.53 - ETA: 0s - loss: 0.7538 - accuracy: 0.53 - ETA: 0s - loss: 0.7532 - accuracy: 0.53 - ETA: 0s - loss: 0.7549 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7551 - accuracy: 0.5334 - val_loss: 1.3215 - val_accuracy: 0.3962\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9317 - accuracy: 0.59 - ETA: 1s - loss: 0.7485 - accuracy: 0.55 - ETA: 1s - loss: 0.7574 - accuracy: 0.54 - ETA: 0s - loss: 0.7621 - accuracy: 0.53 - ETA: 0s - loss: 0.7554 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7634 - accuracy: 0.53 - ETA: 0s - loss: 0.7681 - accuracy: 0.53 - ETA: 0s - loss: 0.7598 - accuracy: 0.53 - ETA: 0s - loss: 0.7595 - accuracy: 0.53 - ETA: 0s - loss: 0.7547 - accuracy: 0.53 - ETA: 0s - loss: 0.7554 - accuracy: 0.53 - ETA: 0s - loss: 0.7566 - accuracy: 0.53 - ETA: 0s - loss: 0.7578 - accuracy: 0.53 - ETA: 0s - loss: 0.7542 - accuracy: 0.53 - ETA: 0s - loss: 0.7567 - accuracy: 0.53 - ETA: 0s - loss: 0.7578 - accuracy: 0.53 - ETA: 0s - loss: 0.7580 - accuracy: 0.53 - ETA: 0s - loss: 0.7568 - accuracy: 0.53 - ETA: 0s - loss: 0.7574 - accuracy: 0.53 - ETA: 0s - loss: 0.7556 - accuracy: 0.53 - ETA: 0s - loss: 0.7618 - accuracy: 0.53 - ETA: 0s - loss: 0.7619 - accuracy: 0.53 - ETA: 0s - loss: 0.7613 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7628 - accuracy: 0.5344 - val_loss: 0.7190 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3d3482d6602d7d2b7ef8e3c0e62f8297</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 7.835673507014028</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.56 - ETA: 1s - loss: 4.8114 - accuracy: 0.50 - ETA: 1s - loss: 2.8769 - accuracy: 0.55 - ETA: 1s - loss: 2.1776 - accuracy: 0.55 - ETA: 1s - loss: 1.8237 - accuracy: 0.55 - ETA: 0s - loss: 1.5811 - accuracy: 0.55 - ETA: 0s - loss: 1.4249 - accuracy: 0.55 - ETA: 0s - loss: 1.3253 - accuracy: 0.55 - ETA: 0s - loss: 1.2472 - accuracy: 0.55 - ETA: 0s - loss: 1.1999 - accuracy: 0.55 - ETA: 0s - loss: 1.1489 - accuracy: 0.55 - ETA: 0s - loss: 1.1038 - accuracy: 0.55 - ETA: 0s - loss: 1.0672 - accuracy: 0.55 - ETA: 0s - loss: 1.0354 - accuracy: 0.56 - ETA: 0s - loss: 1.0131 - accuracy: 0.55 - ETA: 0s - loss: 0.9907 - accuracy: 0.55 - ETA: 0s - loss: 0.9709 - accuracy: 0.56 - ETA: 0s - loss: 0.9621 - accuracy: 0.56 - ETA: 0s - loss: 0.9480 - accuracy: 0.56 - ETA: 0s - loss: 0.9342 - accuracy: 0.56 - ETA: 0s - loss: 0.9216 - accuracy: 0.56 - ETA: 0s - loss: 0.9113 - accuracy: 0.56 - ETA: 0s - loss: 0.9016 - accuracy: 0.56 - ETA: 0s - loss: 0.8926 - accuracy: 0.56 - 1s 2ms/step - loss: 0.8912 - accuracy: 0.5696 - val_loss: 0.7124 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.68 - ETA: 1s - loss: 0.6681 - accuracy: 0.61 - ETA: 1s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6828 - accuracy: 0.58 - ETA: 0s - loss: 0.6802 - accuracy: 0.58 - ETA: 0s - loss: 0.6803 - accuracy: 0.58 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5677 - val_loss: 0.7112 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8482 - accuracy: 0.46 - ETA: 1s - loss: 0.6850 - accuracy: 0.58 - ETA: 1s - loss: 0.6894 - accuracy: 0.57 - ETA: 1s - loss: 0.6932 - accuracy: 0.56 - ETA: 0s - loss: 0.6932 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5711 - val_loss: 0.6902 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.62 - ETA: 1s - loss: 0.6848 - accuracy: 0.60 - ETA: 1s - loss: 0.6864 - accuracy: 0.58 - ETA: 1s - loss: 0.6873 - accuracy: 0.57 - ETA: 1s - loss: 0.6882 - accuracy: 0.56 - ETA: 0s - loss: 0.6884 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5658 - val_loss: 0.7106 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7838 - accuracy: 0.53 - ETA: 1s - loss: 0.6780 - accuracy: 0.60 - ETA: 1s - loss: 0.6853 - accuracy: 0.58 - ETA: 1s - loss: 0.6834 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5719 - val_loss: 0.7107 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.28 - ETA: 1s - loss: 6.6690 - accuracy: 0.55 - ETA: 1s - loss: 3.7156 - accuracy: 0.57 - ETA: 1s - loss: 2.7373 - accuracy: 0.56 - ETA: 1s - loss: 2.2593 - accuracy: 0.56 - ETA: 0s - loss: 1.9611 - accuracy: 0.56 - ETA: 0s - loss: 1.7587 - accuracy: 0.56 - ETA: 0s - loss: 1.6052 - accuracy: 0.56 - ETA: 0s - loss: 1.4864 - accuracy: 0.56 - ETA: 0s - loss: 1.4002 - accuracy: 0.56 - ETA: 0s - loss: 1.3329 - accuracy: 0.56 - ETA: 0s - loss: 1.2759 - accuracy: 0.56 - ETA: 0s - loss: 1.2267 - accuracy: 0.56 - ETA: 0s - loss: 1.1870 - accuracy: 0.56 - ETA: 0s - loss: 1.1510 - accuracy: 0.56 - ETA: 0s - loss: 1.1200 - accuracy: 0.56 - ETA: 0s - loss: 1.0922 - accuracy: 0.56 - ETA: 0s - loss: 1.0685 - accuracy: 0.56 - ETA: 0s - loss: 1.0454 - accuracy: 0.56 - ETA: 0s - loss: 1.0260 - accuracy: 0.56 - ETA: 0s - loss: 1.0085 - accuracy: 0.56 - ETA: 0s - loss: 0.9964 - accuracy: 0.56 - ETA: 0s - loss: 0.9819 - accuracy: 0.56 - ETA: 0s - loss: 0.9693 - accuracy: 0.56 - ETA: 0s - loss: 0.9571 - accuracy: 0.56 - 1s 2ms/step - loss: 0.9508 - accuracy: 0.5661 - val_loss: 0.9137 - val_accuracy: 0.3962\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9347 - accuracy: 0.37 - ETA: 1s - loss: 0.6879 - accuracy: 0.58 - ETA: 1s - loss: 0.6889 - accuracy: 0.56 - ETA: 1s - loss: 0.6862 - accuracy: 0.57 - ETA: 1s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6898 - accuracy: 0.5693 - val_loss: 0.9197 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9725 - accuracy: 0.34 - ETA: 1s - loss: 0.7012 - accuracy: 0.56 - ETA: 1s - loss: 0.6983 - accuracy: 0.55 - ETA: 1s - loss: 0.6945 - accuracy: 0.56 - ETA: 1s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6912 - accuracy: 0.57 - ETA: 0s - loss: 0.6912 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5682 - val_loss: 0.6924 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.68 - ETA: 1s - loss: 0.6798 - accuracy: 0.58 - ETA: 1s - loss: 0.6803 - accuracy: 0.57 - ETA: 1s - loss: 0.6865 - accuracy: 0.57 - ETA: 1s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6906 - accuracy: 0.5715 - val_loss: 0.6932 - val_accuracy: 0.3962\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.46 - ETA: 1s - loss: 0.6846 - accuracy: 0.59 - ETA: 1s - loss: 0.6907 - accuracy: 0.57 - ETA: 1s - loss: 0.6938 - accuracy: 0.56 - ETA: 1s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5677 - val_loss: 0.7104 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.1146 - accuracy: 0.40 - ETA: 1s - loss: 11.9880 - accuracy: 0.568 - ETA: 1s - loss: 6.1816 - accuracy: 0.549 - ETA: 1s - loss: 4.4995 - accuracy: 0.55 - ETA: 1s - loss: 3.4777 - accuracy: 0.56 - ETA: 0s - loss: 2.9398 - accuracy: 0.56 - ETA: 0s - loss: 2.5856 - accuracy: 0.56 - ETA: 0s - loss: 2.3085 - accuracy: 0.56 - ETA: 0s - loss: 2.1021 - accuracy: 0.56 - ETA: 0s - loss: 1.9556 - accuracy: 0.55 - ETA: 0s - loss: 1.8339 - accuracy: 0.55 - ETA: 0s - loss: 1.7267 - accuracy: 0.55 - ETA: 0s - loss: 1.6351 - accuracy: 0.55 - ETA: 0s - loss: 1.5604 - accuracy: 0.55 - ETA: 0s - loss: 1.5018 - accuracy: 0.55 - ETA: 0s - loss: 1.4465 - accuracy: 0.55 - ETA: 0s - loss: 1.4033 - accuracy: 0.55 - ETA: 0s - loss: 1.3595 - accuracy: 0.56 - ETA: 0s - loss: 1.3228 - accuracy: 0.56 - ETA: 0s - loss: 1.2894 - accuracy: 0.56 - ETA: 0s - loss: 1.2610 - accuracy: 0.56 - ETA: 0s - loss: 1.2322 - accuracy: 0.56 - ETA: 0s - loss: 1.2078 - accuracy: 0.56 - ETA: 0s - loss: 1.1851 - accuracy: 0.56 - ETA: 0s - loss: 1.1641 - accuracy: 0.56 - 1s 2ms/step - loss: 1.1565 - accuracy: 0.5652 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.59 - ETA: 1s - loss: 0.6878 - accuracy: 0.56 - ETA: 1s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6935 - accuracy: 0.55 - ETA: 0s - loss: 0.6923 - accuracy: 0.55 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5679 - val_loss: 0.6902 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.62 - ETA: 1s - loss: 0.6767 - accuracy: 0.59 - ETA: 1s - loss: 0.6840 - accuracy: 0.59 - ETA: 1s - loss: 0.6856 - accuracy: 0.58 - ETA: 1s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.56 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5689 - val_loss: 0.7106 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8153 - accuracy: 0.50 - ETA: 1s - loss: 0.6871 - accuracy: 0.58 - ETA: 1s - loss: 0.6923 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5699 - val_loss: 0.7127 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8833 - accuracy: 0.43 - ETA: 1s - loss: 0.6951 - accuracy: 0.56 - ETA: 1s - loss: 0.6925 - accuracy: 0.57 - ETA: 1s - loss: 0.6893 - accuracy: 0.58 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5667 - val_loss: 0.6933 - val_accuracy: 0.3960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3e68b6d2d15e304a028985d2cd653aa1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 4.0280620841683366</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.59 - ETA: 0s - loss: 0.7494 - accuracy: 0.57 - ETA: 0s - loss: 0.7132 - accuracy: 0.58 - ETA: 0s - loss: 0.7015 - accuracy: 0.59 - ETA: 0s - loss: 0.6927 - accuracy: 0.59 - ETA: 0s - loss: 0.6912 - accuracy: 0.59 - ETA: 0s - loss: 0.6899 - accuracy: 0.58 - ETA: 0s - loss: 0.6882 - accuracy: 0.59 - ETA: 0s - loss: 0.6868 - accuracy: 0.59 - ETA: 0s - loss: 0.6854 - accuracy: 0.59 - ETA: 0s - loss: 0.6843 - accuracy: 0.59 - ETA: 0s - loss: 0.6835 - accuracy: 0.59 - ETA: 0s - loss: 0.6831 - accuracy: 0.59 - ETA: 0s - loss: 0.6832 - accuracy: 0.59 - ETA: 0s - loss: 0.6827 - accuracy: 0.59 - ETA: 0s - loss: 0.6824 - accuracy: 0.59 - ETA: 0s - loss: 0.6820 - accuracy: 0.59 - ETA: 0s - loss: 0.6819 - accuracy: 0.59 - ETA: 0s - loss: 0.6818 - accuracy: 0.59 - ETA: 0s - loss: 0.6815 - accuracy: 0.59 - ETA: 0s - loss: 0.6812 - accuracy: 0.59 - ETA: 0s - loss: 0.6813 - accuracy: 0.59 - ETA: 0s - loss: 0.6809 - accuracy: 0.59 - ETA: 0s - loss: 0.6807 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6807 - accuracy: 0.5924 - val_loss: 0.6799 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.68 - ETA: 1s - loss: 0.6729 - accuracy: 0.60 - ETA: 1s - loss: 0.6739 - accuracy: 0.60 - ETA: 1s - loss: 0.6780 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6741 - accuracy: 0.60 - ETA: 0s - loss: 0.6736 - accuracy: 0.60 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6744 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6743 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6748 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6751 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6816 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.75 - ETA: 1s - loss: 0.6759 - accuracy: 0.60 - ETA: 1s - loss: 0.6786 - accuracy: 0.59 - ETA: 1s - loss: 0.6801 - accuracy: 0.58 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 0s - loss: 0.6796 - accuracy: 0.58 - ETA: 0s - loss: 0.6793 - accuracy: 0.58 - ETA: 0s - loss: 0.6790 - accuracy: 0.58 - ETA: 0s - loss: 0.6789 - accuracy: 0.58 - ETA: 0s - loss: 0.6781 - accuracy: 0.59 - ETA: 0s - loss: 0.6785 - accuracy: 0.58 - ETA: 0s - loss: 0.6785 - accuracy: 0.58 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6771 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7033 - accuracy: 0.53 - ETA: 1s - loss: 0.6757 - accuracy: 0.59 - ETA: 1s - loss: 0.6777 - accuracy: 0.58 - ETA: 1s - loss: 0.6783 - accuracy: 0.58 - ETA: 1s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6779 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6786 - accuracy: 0.58 - ETA: 0s - loss: 0.6784 - accuracy: 0.58 - ETA: 0s - loss: 0.6782 - accuracy: 0.58 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.78 - ETA: 1s - loss: 0.6654 - accuracy: 0.62 - ETA: 1s - loss: 0.6750 - accuracy: 0.59 - ETA: 1s - loss: 0.6736 - accuracy: 0.60 - ETA: 1s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7609 - accuracy: 0.43 - ETA: 1s - loss: 0.8527 - accuracy: 0.58 - ETA: 1s - loss: 0.7676 - accuracy: 0.59 - ETA: 1s - loss: 0.7395 - accuracy: 0.58 - ETA: 0s - loss: 0.7233 - accuracy: 0.59 - ETA: 0s - loss: 0.7147 - accuracy: 0.58 - ETA: 0s - loss: 0.7060 - accuracy: 0.59 - ETA: 0s - loss: 0.7028 - accuracy: 0.59 - ETA: 0s - loss: 0.6998 - accuracy: 0.59 - ETA: 0s - loss: 0.6977 - accuracy: 0.59 - ETA: 0s - loss: 0.6955 - accuracy: 0.59 - ETA: 0s - loss: 0.6944 - accuracy: 0.59 - ETA: 0s - loss: 0.6924 - accuracy: 0.59 - ETA: 0s - loss: 0.6907 - accuracy: 0.59 - ETA: 0s - loss: 0.6896 - accuracy: 0.59 - ETA: 0s - loss: 0.6891 - accuracy: 0.59 - ETA: 0s - loss: 0.6884 - accuracy: 0.59 - ETA: 0s - loss: 0.6883 - accuracy: 0.59 - ETA: 0s - loss: 0.6875 - accuracy: 0.59 - ETA: 0s - loss: 0.6870 - accuracy: 0.59 - ETA: 0s - loss: 0.6860 - accuracy: 0.59 - ETA: 0s - loss: 0.6862 - accuracy: 0.59 - ETA: 0s - loss: 0.6860 - accuracy: 0.59 - ETA: 0s - loss: 0.6855 - accuracy: 0.59 - ETA: 0s - loss: 0.6850 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5924 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.50 - ETA: 1s - loss: 0.6802 - accuracy: 0.58 - ETA: 1s - loss: 0.6766 - accuracy: 0.59 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 1s - loss: 0.6783 - accuracy: 0.58 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6757 - accuracy: 0.59 - ETA: 0s - loss: 0.6751 - accuracy: 0.59 - ETA: 0s - loss: 0.6753 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6716 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 1s - loss: 0.6682 - accuracy: 0.61 - ETA: 1s - loss: 0.6775 - accuracy: 0.58 - ETA: 1s - loss: 0.6778 - accuracy: 0.58 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6749 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.68 - ETA: 1s - loss: 0.6679 - accuracy: 0.61 - ETA: 1s - loss: 0.6752 - accuracy: 0.59 - ETA: 1s - loss: 0.6751 - accuracy: 0.59 - ETA: 1s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.75 - ETA: 1s - loss: 0.6788 - accuracy: 0.59 - ETA: 1s - loss: 0.6804 - accuracy: 0.58 - ETA: 1s - loss: 0.6788 - accuracy: 0.58 - ETA: 1s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6737 - accuracy: 0.59 - ETA: 0s - loss: 0.6742 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6754 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6719 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.62 - ETA: 1s - loss: 0.9888 - accuracy: 0.57 - ETA: 1s - loss: 0.8353 - accuracy: 0.58 - ETA: 0s - loss: 0.7834 - accuracy: 0.58 - ETA: 0s - loss: 0.7597 - accuracy: 0.58 - ETA: 0s - loss: 0.7451 - accuracy: 0.58 - ETA: 0s - loss: 0.7345 - accuracy: 0.58 - ETA: 0s - loss: 0.7265 - accuracy: 0.58 - ETA: 0s - loss: 0.7209 - accuracy: 0.58 - ETA: 0s - loss: 0.7169 - accuracy: 0.58 - ETA: 0s - loss: 0.7131 - accuracy: 0.58 - ETA: 0s - loss: 0.7096 - accuracy: 0.58 - ETA: 0s - loss: 0.7068 - accuracy: 0.58 - ETA: 0s - loss: 0.7047 - accuracy: 0.58 - ETA: 0s - loss: 0.7029 - accuracy: 0.58 - ETA: 0s - loss: 0.7008 - accuracy: 0.58 - ETA: 0s - loss: 0.6989 - accuracy: 0.59 - ETA: 0s - loss: 0.6982 - accuracy: 0.58 - ETA: 0s - loss: 0.6976 - accuracy: 0.58 - ETA: 0s - loss: 0.6959 - accuracy: 0.58 - ETA: 0s - loss: 0.6944 - accuracy: 0.59 - ETA: 0s - loss: 0.6935 - accuracy: 0.59 - ETA: 0s - loss: 0.6926 - accuracy: 0.59 - ETA: 0s - loss: 0.6918 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5921 - val_loss: 0.6727 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6288 - accuracy: 0.68 - ETA: 1s - loss: 0.6813 - accuracy: 0.58 - ETA: 1s - loss: 0.6717 - accuracy: 0.60 - ETA: 1s - loss: 0.6721 - accuracy: 0.60 - ETA: 0s - loss: 0.6733 - accuracy: 0.60 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6756 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5927 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.56 - ETA: 1s - loss: 0.6836 - accuracy: 0.57 - ETA: 1s - loss: 0.6814 - accuracy: 0.58 - ETA: 1s - loss: 0.6799 - accuracy: 0.58 - ETA: 1s - loss: 0.6789 - accuracy: 0.58 - ETA: 0s - loss: 0.6802 - accuracy: 0.58 - ETA: 0s - loss: 0.6793 - accuracy: 0.58 - ETA: 0s - loss: 0.6784 - accuracy: 0.59 - ETA: 0s - loss: 0.6782 - accuracy: 0.59 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6753 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5929 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.71 - ETA: 1s - loss: 0.6766 - accuracy: 0.59 - ETA: 1s - loss: 0.6794 - accuracy: 0.58 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 1s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6757 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7509 - accuracy: 0.40 - ETA: 1s - loss: 0.6796 - accuracy: 0.58 - ETA: 1s - loss: 0.6781 - accuracy: 0.59 - ETA: 1s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6754 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6731 - accuracy: 0.60 - ETA: 0s - loss: 0.6735 - accuracy: 0.60 - ETA: 0s - loss: 0.6741 - accuracy: 0.60 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6749 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6733 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2e718f4b3965c573b66000c6c8ae9e7c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.5210515631262526</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.53 - ETA: 1s - loss: 129.4386 - accuracy: 0.58 - ETA: 1s - loss: 69.5942 - accuracy: 0.5814 - ETA: 1s - loss: 46.4181 - accuracy: 0.563 - ETA: 0s - loss: 34.6711 - accuracy: 0.564 - ETA: 0s - loss: 28.1818 - accuracy: 0.563 - ETA: 0s - loss: 23.6628 - accuracy: 0.568 - ETA: 0s - loss: 20.5813 - accuracy: 0.570 - ETA: 0s - loss: 17.9823 - accuracy: 0.570 - ETA: 0s - loss: 16.0805 - accuracy: 0.565 - ETA: 0s - loss: 14.5153 - accuracy: 0.565 - ETA: 0s - loss: 13.2129 - accuracy: 0.568 - ETA: 0s - loss: 12.1573 - accuracy: 0.566 - ETA: 0s - loss: 11.2890 - accuracy: 0.565 - ETA: 0s - loss: 10.6224 - accuracy: 0.566 - ETA: 0s - loss: 9.9314 - accuracy: 0.565 - ETA: 0s - loss: 9.4058 - accuracy: 0.56 - ETA: 0s - loss: 8.8949 - accuracy: 0.56 - ETA: 0s - loss: 8.4532 - accuracy: 0.56 - ETA: 0s - loss: 8.0570 - accuracy: 0.56 - ETA: 0s - loss: 7.6990 - accuracy: 0.56 - ETA: 0s - loss: 7.3558 - accuracy: 0.56 - ETA: 0s - loss: 7.0612 - accuracy: 0.56 - ETA: 0s - loss: 6.7840 - accuracy: 0.56 - 1s 2ms/step - loss: 6.6060 - accuracy: 0.5632 - val_loss: 0.7306 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7783 - accuracy: 0.56 - ETA: 1s - loss: 0.6951 - accuracy: 0.55 - ETA: 1s - loss: 0.6912 - accuracy: 0.56 - ETA: 1s - loss: 0.6947 - accuracy: 0.56 - ETA: 1s - loss: 0.6972 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6950 - accuracy: 0.55 - ETA: 0s - loss: 0.6957 - accuracy: 0.55 - ETA: 0s - loss: 0.6966 - accuracy: 0.55 - ETA: 0s - loss: 0.6954 - accuracy: 0.55 - ETA: 0s - loss: 0.6963 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6951 - accuracy: 0.55 - ETA: 0s - loss: 0.6952 - accuracy: 0.55 - ETA: 0s - loss: 0.6970 - accuracy: 0.55 - ETA: 0s - loss: 0.6972 - accuracy: 0.55 - ETA: 0s - loss: 0.6969 - accuracy: 0.55 - ETA: 0s - loss: 0.6965 - accuracy: 0.55 - ETA: 0s - loss: 0.6956 - accuracy: 0.55 - ETA: 0s - loss: 0.6955 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6950 - accuracy: 0.55 - 1s 2ms/step - loss: 0.6954 - accuracy: 0.5572 - val_loss: 0.6923 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 1s - loss: 0.6972 - accuracy: 0.56 - ETA: 1s - loss: 0.6950 - accuracy: 0.56 - ETA: 1s - loss: 0.6926 - accuracy: 0.56 - ETA: 1s - loss: 0.6945 - accuracy: 0.55 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.7020 - accuracy: 0.55 - ETA: 0s - loss: 0.7008 - accuracy: 0.55 - ETA: 0s - loss: 0.6998 - accuracy: 0.55 - ETA: 0s - loss: 0.6974 - accuracy: 0.56 - ETA: 0s - loss: 0.6953 - accuracy: 0.56 - ETA: 0s - loss: 0.6958 - accuracy: 0.56 - ETA: 0s - loss: 0.6951 - accuracy: 0.56 - ETA: 0s - loss: 0.6942 - accuracy: 0.56 - ETA: 0s - loss: 0.6941 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6942 - accuracy: 0.56 - ETA: 0s - loss: 0.6943 - accuracy: 0.56 - ETA: 0s - loss: 0.6939 - accuracy: 0.56 - ETA: 0s - loss: 0.6940 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5624 - val_loss: 0.6940 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.37 - ETA: 1s - loss: 0.6873 - accuracy: 0.58 - ETA: 1s - loss: 0.6858 - accuracy: 0.57 - ETA: 1s - loss: 0.6881 - accuracy: 0.57 - ETA: 1s - loss: 0.6915 - accuracy: 0.55 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.56 - ETA: 0s - loss: 0.6879 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.56 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6894 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5672 - val_loss: 33.8894 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 37.4407 - accuracy: 0.562 - ETA: 1s - loss: 1.7389 - accuracy: 0.565 - ETA: 1s - loss: 1.1906 - accuracy: 0.57 - ETA: 1s - loss: 1.0311 - accuracy: 0.55 - ETA: 0s - loss: 0.9494 - accuracy: 0.56 - ETA: 0s - loss: 0.9012 - accuracy: 0.56 - ETA: 0s - loss: 0.8674 - accuracy: 0.56 - ETA: 0s - loss: 0.8414 - accuracy: 0.57 - ETA: 0s - loss: 0.8227 - accuracy: 0.57 - ETA: 0s - loss: 0.8077 - accuracy: 0.57 - ETA: 0s - loss: 0.7972 - accuracy: 0.56 - ETA: 0s - loss: 0.7869 - accuracy: 0.57 - ETA: 0s - loss: 0.7792 - accuracy: 0.57 - ETA: 0s - loss: 0.7719 - accuracy: 0.57 - ETA: 0s - loss: 0.7668 - accuracy: 0.56 - ETA: 0s - loss: 0.7618 - accuracy: 0.57 - ETA: 0s - loss: 0.7578 - accuracy: 0.56 - ETA: 0s - loss: 0.7541 - accuracy: 0.56 - ETA: 0s - loss: 0.7508 - accuracy: 0.56 - ETA: 0s - loss: 0.7483 - accuracy: 0.56 - ETA: 0s - loss: 0.7455 - accuracy: 0.56 - ETA: 0s - loss: 0.7430 - accuracy: 0.56 - ETA: 0s - loss: 0.7402 - accuracy: 0.56 - ETA: 0s - loss: 0.7381 - accuracy: 0.56 - ETA: 0s - loss: 0.7359 - accuracy: 0.56 - 1s 2ms/step - loss: 0.7355 - accuracy: 0.5683 - val_loss: 0.9401 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8039 - accuracy: 0.50 - ETA: 1s - loss: 37.2861 - accuracy: 0.546 - ETA: 1s - loss: 19.2907 - accuracy: 0.563 - ETA: 1s - loss: 13.0343 - accuracy: 0.569 - ETA: 1s - loss: 10.1326 - accuracy: 0.562 - ETA: 1s - loss: 8.3341 - accuracy: 0.560 - ETA: 0s - loss: 7.1106 - accuracy: 0.56 - ETA: 0s - loss: 6.1782 - accuracy: 0.56 - ETA: 0s - loss: 5.4649 - accuracy: 0.56 - ETA: 0s - loss: 4.9149 - accuracy: 0.56 - ETA: 0s - loss: 4.4793 - accuracy: 0.56 - ETA: 0s - loss: 4.1242 - accuracy: 0.56 - ETA: 0s - loss: 3.8317 - accuracy: 0.56 - ETA: 0s - loss: 3.5976 - accuracy: 0.56 - ETA: 0s - loss: 3.3895 - accuracy: 0.56 - ETA: 0s - loss: 3.2082 - accuracy: 0.56 - ETA: 0s - loss: 3.0507 - accuracy: 0.56 - ETA: 0s - loss: 2.9156 - accuracy: 0.57 - ETA: 0s - loss: 2.7751 - accuracy: 0.56 - ETA: 0s - loss: 2.6694 - accuracy: 0.56 - ETA: 0s - loss: 2.5739 - accuracy: 0.56 - ETA: 0s - loss: 2.4922 - accuracy: 0.56 - ETA: 0s - loss: 2.4149 - accuracy: 0.56 - ETA: 0s - loss: 2.3334 - accuracy: 0.56 - ETA: 0s - loss: 2.2674 - accuracy: 0.56 - 1s 2ms/step - loss: 2.2446 - accuracy: 0.5667 - val_loss: 0.7157 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.65 - ETA: 1s - loss: 0.6795 - accuracy: 0.59 - ETA: 1s - loss: 0.6875 - accuracy: 0.57 - ETA: 1s - loss: 0.6866 - accuracy: 0.57 - ETA: 1s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.58 - ETA: 0s - loss: 0.6866 - accuracy: 0.58 - ETA: 0s - loss: 0.6864 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6891 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5672 - val_loss: 0.7225 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8706 - accuracy: 0.46 - ETA: 1s - loss: 0.6806 - accuracy: 0.60 - ETA: 1s - loss: 0.6890 - accuracy: 0.56 - ETA: 1s - loss: 0.6925 - accuracy: 0.56 - ETA: 1s - loss: 0.6907 - accuracy: 0.57 - ETA: 1s - loss: 0.6880 - accuracy: 0.58 - ETA: 0s - loss: 0.6876 - accuracy: 0.58 - ETA: 0s - loss: 0.6871 - accuracy: 0.58 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6863 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.56 - ETA: 0s - loss: 0.6889 - accuracy: 0.56 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5698 - val_loss: 0.9378 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.0878 - accuracy: 0.53 - ETA: 1s - loss: 0.7048 - accuracy: 0.54 - ETA: 1s - loss: 0.6998 - accuracy: 0.55 - ETA: 1s - loss: 0.6995 - accuracy: 0.54 - ETA: 1s - loss: 0.6983 - accuracy: 0.54 - ETA: 1s - loss: 0.6960 - accuracy: 0.54 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6912 - accuracy: 0.55 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6899 - accuracy: 0.56 - ETA: 0s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5624 - val_loss: 0.9374 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8292 - accuracy: 0.65 - ETA: 1s - loss: 0.6958 - accuracy: 0.57 - ETA: 1s - loss: 0.6919 - accuracy: 0.57 - ETA: 1s - loss: 0.6918 - accuracy: 0.57 - ETA: 1s - loss: 0.6919 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6926 - accuracy: 0.55 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6923 - accuracy: 0.55 - ETA: 0s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6934 - accuracy: 0.55 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6935 - accuracy: 0.55 - ETA: 0s - loss: 0.6947 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6943 - accuracy: 0.55 - ETA: 0s - loss: 0.6941 - accuracy: 0.55 - ETA: 0s - loss: 0.6931 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5627 - val_loss: 0.7132 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7317 - accuracy: 0.50 - ETA: 1s - loss: 11.3495 - accuracy: 0.536 - ETA: 1s - loss: 6.3984 - accuracy: 0.537 - ETA: 1s - loss: 4.4460 - accuracy: 0.54 - ETA: 0s - loss: 3.5711 - accuracy: 0.53 - ETA: 0s - loss: 3.0405 - accuracy: 0.54 - ETA: 0s - loss: 2.6855 - accuracy: 0.54 - ETA: 0s - loss: 2.3903 - accuracy: 0.54 - ETA: 0s - loss: 2.1854 - accuracy: 0.54 - ETA: 0s - loss: 2.0291 - accuracy: 0.55 - ETA: 0s - loss: 1.8990 - accuracy: 0.55 - ETA: 0s - loss: 1.7863 - accuracy: 0.55 - ETA: 0s - loss: 1.6947 - accuracy: 0.55 - ETA: 0s - loss: 1.6185 - accuracy: 0.55 - ETA: 0s - loss: 1.5546 - accuracy: 0.55 - ETA: 0s - loss: 1.4956 - accuracy: 0.55 - ETA: 0s - loss: 1.4487 - accuracy: 0.55 - ETA: 0s - loss: 1.4043 - accuracy: 0.56 - ETA: 0s - loss: 1.3641 - accuracy: 0.55 - ETA: 0s - loss: 1.3282 - accuracy: 0.56 - ETA: 0s - loss: 1.2976 - accuracy: 0.55 - ETA: 0s - loss: 1.2693 - accuracy: 0.56 - ETA: 0s - loss: 1.2406 - accuracy: 0.56 - ETA: 0s - loss: 1.2176 - accuracy: 0.56 - ETA: 0s - loss: 1.1968 - accuracy: 0.56 - 1s 2ms/step - loss: 1.1900 - accuracy: 0.5611 - val_loss: 0.9374 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.62 - ETA: 1s - loss: 0.6998 - accuracy: 0.54 - ETA: 1s - loss: 0.6911 - accuracy: 0.56 - ETA: 1s - loss: 0.6904 - accuracy: 0.57 - ETA: 1s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6967 - accuracy: 0.55 - ETA: 0s - loss: 0.6974 - accuracy: 0.55 - ETA: 0s - loss: 0.6953 - accuracy: 0.55 - ETA: 0s - loss: 0.6939 - accuracy: 0.56 - ETA: 0s - loss: 0.6933 - accuracy: 0.56 - ETA: 0s - loss: 0.6931 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6936 - accuracy: 0.55 - ETA: 0s - loss: 0.6930 - accuracy: 0.56 - ETA: 0s - loss: 0.6945 - accuracy: 0.55 - ETA: 0s - loss: 0.6938 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6933 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6947 - accuracy: 0.55 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5594 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.65 - ETA: 1s - loss: 0.6855 - accuracy: 0.57 - ETA: 1s - loss: 0.6848 - accuracy: 0.57 - ETA: 1s - loss: 0.6935 - accuracy: 0.56 - ETA: 1s - loss: 0.6950 - accuracy: 0.56 - ETA: 0s - loss: 0.6961 - accuracy: 0.55 - ETA: 0s - loss: 0.6973 - accuracy: 0.55 - ETA: 0s - loss: 0.6978 - accuracy: 0.55 - ETA: 0s - loss: 0.6955 - accuracy: 0.55 - ETA: 0s - loss: 0.7112 - accuracy: 0.55 - ETA: 0s - loss: 0.7077 - accuracy: 0.56 - ETA: 0s - loss: 0.7068 - accuracy: 0.56 - ETA: 0s - loss: 0.7047 - accuracy: 0.56 - ETA: 0s - loss: 0.7042 - accuracy: 0.56 - ETA: 0s - loss: 0.7024 - accuracy: 0.56 - ETA: 0s - loss: 0.7014 - accuracy: 0.56 - ETA: 0s - loss: 0.7013 - accuracy: 0.56 - ETA: 0s - loss: 0.7015 - accuracy: 0.56 - ETA: 0s - loss: 0.7017 - accuracy: 0.56 - ETA: 0s - loss: 0.7015 - accuracy: 0.56 - ETA: 0s - loss: 0.7007 - accuracy: 0.56 - ETA: 0s - loss: 0.7004 - accuracy: 0.56 - ETA: 0s - loss: 0.6995 - accuracy: 0.56 - ETA: 0s - loss: 0.6985 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6989 - accuracy: 0.5648 - val_loss: 0.7132 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.62 - ETA: 1s - loss: 0.7035 - accuracy: 0.55 - ETA: 1s - loss: 0.6968 - accuracy: 0.56 - ETA: 1s - loss: 0.6979 - accuracy: 0.55 - ETA: 0s - loss: 0.6973 - accuracy: 0.54 - ETA: 0s - loss: 0.6930 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6938 - accuracy: 0.55 - ETA: 0s - loss: 0.6930 - accuracy: 0.55 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5626 - val_loss: 0.6941 - val_accuracy: 0.3960\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.46 - ETA: 1s - loss: 0.6964 - accuracy: 0.55 - ETA: 1s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5632 - val_loss: 0.6934 - val_accuracy: 0.3960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 37fbbe9491e17456b0a25398cfd9a2ef</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 4.148302444889779</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.59 - ETA: 1s - loss: 3.4077 - accuracy: 0.56 - ETA: 1s - loss: 2.1770 - accuracy: 0.56 - ETA: 1s - loss: 1.6833 - accuracy: 0.57 - ETA: 0s - loss: 1.4409 - accuracy: 0.57 - ETA: 0s - loss: 1.2902 - accuracy: 0.57 - ETA: 0s - loss: 1.1853 - accuracy: 0.57 - ETA: 0s - loss: 1.1163 - accuracy: 0.57 - ETA: 0s - loss: 1.0637 - accuracy: 0.57 - ETA: 0s - loss: 1.0239 - accuracy: 0.57 - ETA: 0s - loss: 0.9904 - accuracy: 0.57 - ETA: 0s - loss: 0.9643 - accuracy: 0.57 - ETA: 0s - loss: 0.9409 - accuracy: 0.57 - ETA: 0s - loss: 0.9223 - accuracy: 0.56 - ETA: 0s - loss: 0.9046 - accuracy: 0.56 - ETA: 0s - loss: 0.8909 - accuracy: 0.56 - ETA: 0s - loss: 0.8793 - accuracy: 0.56 - ETA: 0s - loss: 0.8692 - accuracy: 0.56 - ETA: 0s - loss: 0.8584 - accuracy: 0.57 - ETA: 0s - loss: 0.8498 - accuracy: 0.57 - ETA: 0s - loss: 0.8417 - accuracy: 0.57 - ETA: 0s - loss: 0.8353 - accuracy: 0.57 - ETA: 0s - loss: 0.8281 - accuracy: 0.57 - ETA: 0s - loss: 0.8221 - accuracy: 0.57 - 1s 2ms/step - loss: 0.8213 - accuracy: 0.5730 - val_loss: 0.6909 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.53 - ETA: 1s - loss: 0.6785 - accuracy: 0.59 - ETA: 1s - loss: 0.6838 - accuracy: 0.58 - ETA: 1s - loss: 0.6843 - accuracy: 0.58 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.56 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6941 - accuracy: 0.56 - ETA: 0s - loss: 0.6949 - accuracy: 0.56 - ETA: 0s - loss: 0.6943 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5711 - val_loss: 0.6873 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.65 - ETA: 1s - loss: 0.6892 - accuracy: 0.59 - ETA: 1s - loss: 0.6902 - accuracy: 0.57 - ETA: 1s - loss: 0.6902 - accuracy: 0.56 - ETA: 1s - loss: 0.6887 - accuracy: 0.56 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5748 - val_loss: 0.6850 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6723 - accuracy: 0.75 - ETA: 1s - loss: 0.6894 - accuracy: 0.57 - ETA: 1s - loss: 0.6892 - accuracy: 0.57 - ETA: 1s - loss: 0.6889 - accuracy: 0.57 - ETA: 1s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6846 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6856 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5755 - val_loss: 0.6941 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.62 - ETA: 1s - loss: 0.6961 - accuracy: 0.57 - ETA: 1s - loss: 0.6892 - accuracy: 0.57 - ETA: 1s - loss: 0.6863 - accuracy: 0.58 - ETA: 1s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5740 - val_loss: 0.8312 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.68 - ETA: 1s - loss: 4.6411 - accuracy: 0.54 - ETA: 1s - loss: 2.8259 - accuracy: 0.55 - ETA: 0s - loss: 2.1241 - accuracy: 0.56 - ETA: 0s - loss: 1.7918 - accuracy: 0.56 - ETA: 0s - loss: 1.5689 - accuracy: 0.57 - ETA: 0s - loss: 1.4481 - accuracy: 0.57 - ETA: 0s - loss: 1.3416 - accuracy: 0.56 - ETA: 0s - loss: 1.2630 - accuracy: 0.57 - ETA: 0s - loss: 1.2078 - accuracy: 0.57 - ETA: 0s - loss: 1.1601 - accuracy: 0.57 - ETA: 0s - loss: 1.1196 - accuracy: 0.57 - ETA: 0s - loss: 1.0856 - accuracy: 0.57 - ETA: 0s - loss: 1.0573 - accuracy: 0.57 - ETA: 0s - loss: 1.0320 - accuracy: 0.57 - ETA: 0s - loss: 1.0099 - accuracy: 0.57 - ETA: 0s - loss: 0.9914 - accuracy: 0.57 - ETA: 0s - loss: 0.9747 - accuracy: 0.57 - ETA: 0s - loss: 0.9585 - accuracy: 0.57 - ETA: 0s - loss: 0.9448 - accuracy: 0.57 - ETA: 0s - loss: 0.9316 - accuracy: 0.57 - ETA: 0s - loss: 0.9204 - accuracy: 0.57 - ETA: 0s - loss: 0.9099 - accuracy: 0.57 - ETA: 0s - loss: 0.9001 - accuracy: 0.57 - ETA: 0s - loss: 0.8920 - accuracy: 0.57 - 1s 2ms/step - loss: 0.8918 - accuracy: 0.5758 - val_loss: 0.6846 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.68 - ETA: 1s - loss: 0.6881 - accuracy: 0.56 - ETA: 1s - loss: 0.6819 - accuracy: 0.58 - ETA: 1s - loss: 0.6827 - accuracy: 0.58 - ETA: 1s - loss: 0.6823 - accuracy: 0.59 - ETA: 0s - loss: 0.6844 - accuracy: 0.58 - ETA: 0s - loss: 0.6854 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.58 - ETA: 0s - loss: 0.6847 - accuracy: 0.58 - ETA: 0s - loss: 0.6854 - accuracy: 0.58 - ETA: 0s - loss: 0.6864 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6858 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.58 - ETA: 0s - loss: 0.6855 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5769 - val_loss: 0.7061 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7463 - accuracy: 0.56 - ETA: 1s - loss: 0.6901 - accuracy: 0.55 - ETA: 1s - loss: 0.6842 - accuracy: 0.57 - ETA: 1s - loss: 0.6816 - accuracy: 0.58 - ETA: 1s - loss: 0.6815 - accuracy: 0.58 - ETA: 0s - loss: 0.6841 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.56 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6844 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6843 - accuracy: 0.57 - ETA: 0s - loss: 0.6840 - accuracy: 0.57 - ETA: 0s - loss: 0.6846 - accuracy: 0.57 - ETA: 0s - loss: 0.6851 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5726 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.62 - ETA: 1s - loss: 0.6888 - accuracy: 0.55 - ETA: 1s - loss: 0.6869 - accuracy: 0.55 - ETA: 1s - loss: 0.6825 - accuracy: 0.56 - ETA: 1s - loss: 0.6854 - accuracy: 0.56 - ETA: 1s - loss: 0.6869 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6871 - accuracy: 0.56 - ETA: 0s - loss: 0.6881 - accuracy: 0.56 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.56 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6881 - accuracy: 0.56 - ETA: 0s - loss: 0.6872 - accuracy: 0.56 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5729 - val_loss: 0.8403 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8574 - accuracy: 0.59 - ETA: 1s - loss: 0.6780 - accuracy: 0.59 - ETA: 1s - loss: 0.6806 - accuracy: 0.59 - ETA: 1s - loss: 0.6813 - accuracy: 0.59 - ETA: 0s - loss: 0.6833 - accuracy: 0.59 - ETA: 0s - loss: 0.6818 - accuracy: 0.59 - ETA: 0s - loss: 0.6815 - accuracy: 0.59 - ETA: 0s - loss: 0.6838 - accuracy: 0.58 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6851 - accuracy: 0.58 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5733 - val_loss: 0.7059 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.46 - ETA: 1s - loss: 3.2013 - accuracy: 0.53 - ETA: 1s - loss: 1.9756 - accuracy: 0.55 - ETA: 1s - loss: 1.5774 - accuracy: 0.56 - ETA: 1s - loss: 1.3652 - accuracy: 0.55 - ETA: 0s - loss: 1.2262 - accuracy: 0.55 - ETA: 0s - loss: 1.1312 - accuracy: 0.56 - ETA: 0s - loss: 1.0752 - accuracy: 0.57 - ETA: 0s - loss: 1.0232 - accuracy: 0.57 - ETA: 0s - loss: 0.9827 - accuracy: 0.57 - ETA: 0s - loss: 0.9544 - accuracy: 0.57 - ETA: 0s - loss: 0.9305 - accuracy: 0.57 - ETA: 0s - loss: 0.9101 - accuracy: 0.57 - ETA: 0s - loss: 0.8929 - accuracy: 0.57 - ETA: 0s - loss: 0.8782 - accuracy: 0.57 - ETA: 0s - loss: 0.8650 - accuracy: 0.57 - ETA: 0s - loss: 0.8538 - accuracy: 0.57 - ETA: 0s - loss: 0.8440 - accuracy: 0.57 - ETA: 0s - loss: 0.8350 - accuracy: 0.57 - ETA: 0s - loss: 0.8261 - accuracy: 0.57 - ETA: 0s - loss: 0.8195 - accuracy: 0.57 - ETA: 0s - loss: 0.8131 - accuracy: 0.57 - ETA: 0s - loss: 0.8070 - accuracy: 0.57 - ETA: 0s - loss: 0.8024 - accuracy: 0.57 - 1s 2ms/step - loss: 0.7988 - accuracy: 0.5757 - val_loss: 0.6941 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.62 - ETA: 1s - loss: 0.6828 - accuracy: 0.59 - ETA: 1s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.56 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5771 - val_loss: 0.6946 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.62 - ETA: 1s - loss: 0.6731 - accuracy: 0.61 - ETA: 1s - loss: 0.6824 - accuracy: 0.58 - ETA: 1s - loss: 0.6814 - accuracy: 0.58 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6847 - accuracy: 0.57 - ETA: 0s - loss: 0.6845 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6851 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6863 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5723 - val_loss: 0.6897 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.75 - ETA: 1s - loss: 0.6821 - accuracy: 0.56 - ETA: 1s - loss: 0.6852 - accuracy: 0.56 - ETA: 1s - loss: 0.6867 - accuracy: 0.56 - ETA: 1s - loss: 0.6867 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6854 - accuracy: 0.57 - ETA: 0s - loss: 0.6844 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6848 - accuracy: 0.57 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6916 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5774 - val_loss: 0.7030 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7422 - accuracy: 0.56 - ETA: 1s - loss: 0.7002 - accuracy: 0.56 - ETA: 1s - loss: 0.6956 - accuracy: 0.57 - ETA: 1s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.58 - ETA: 0s - loss: 0.6861 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6948 - accuracy: 0.57 - ETA: 0s - loss: 0.6951 - accuracy: 0.57 - ETA: 0s - loss: 0.6954 - accuracy: 0.57 - ETA: 0s - loss: 0.6953 - accuracy: 0.57 - ETA: 0s - loss: 0.6952 - accuracy: 0.57 - ETA: 0s - loss: 0.6949 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5723 - val_loss: 0.6916 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d4210bc23e147226bbbf82e487a3a8f3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 3.32665997995992</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1074dcd520>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f1074dcd880>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(keras.Sequential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units = 303, input_shape = (769,), activation = 'relu'),\n",
    "    keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 64, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 32, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 16, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 1, activation = 'sigmoid') # here the units must be 1 in order for binary classifications to work\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 303)               233310    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               77824     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 354,911\n",
      "Trainable params: 354,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(lr=0.001, beta_1 = 0.9, beta_2=0.999), # you can tune the learning rate here. Default lr = 0.01\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.4575 - accuracy: 0.7809 - val_loss: 0.2514 - val_accuracy: 0.9021\n",
      "Epoch 2/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.3318 - accuracy: 0.8703 - val_loss: 0.3140 - val_accuracy: 0.8716\n",
      "Epoch 3/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2670 - accuracy: 0.9005 - val_loss: 0.2260 - val_accuracy: 0.9169\n",
      "Epoch 4/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2735 - accuracy: 0.8985 - val_loss: 0.2091 - val_accuracy: 0.9264\n",
      "Epoch 5/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2977 - accuracy: 0.8900 - val_loss: 0.2364 - val_accuracy: 0.9042\n",
      "Epoch 6/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2584 - accuracy: 0.9025 - val_loss: 0.3783 - val_accuracy: 0.8628\n",
      "Epoch 7/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2520 - accuracy: 0.9074 - val_loss: 0.2048 - val_accuracy: 0.9280\n",
      "Epoch 8/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2480 - accuracy: 0.9082 - val_loss: 0.2118 - val_accuracy: 0.9304\n",
      "Epoch 9/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2491 - accuracy: 0.9115 - val_loss: 0.2035 - val_accuracy: 0.9304\n",
      "Epoch 10/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2336 - accuracy: 0.9160 - val_loss: 0.2281 - val_accuracy: 0.9181\n",
      "Epoch 11/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2474 - accuracy: 0.9100 - val_loss: 0.2475 - val_accuracy: 0.9068\n",
      "Epoch 12/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2267 - accuracy: 0.9192 - val_loss: 0.4076 - val_accuracy: 0.8311\n",
      "Epoch 13/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2440 - accuracy: 0.9104 - val_loss: 0.2663 - val_accuracy: 0.8860\n",
      "Epoch 14/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2229 - accuracy: 0.9186 - val_loss: 0.2205 - val_accuracy: 0.9142\n",
      "Epoch 15/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2200 - accuracy: 0.9205 - val_loss: 0.3121 - val_accuracy: 0.8769\n",
      "Epoch 16/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2212 - accuracy: 0.9202 - val_loss: 0.3572 - val_accuracy: 0.8628\n",
      "Epoch 17/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2168 - accuracy: 0.9224 - val_loss: 0.2238 - val_accuracy: 0.9199\n",
      "Epoch 18/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2208 - accuracy: 0.9213 - val_loss: 0.1949 - val_accuracy: 0.9295\n",
      "Epoch 19/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2168 - accuracy: 0.9218 - val_loss: 0.1910 - val_accuracy: 0.9324\n",
      "Epoch 20/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2167 - accuracy: 0.9216 - val_loss: 0.1934 - val_accuracy: 0.9325\n",
      "Epoch 21/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2132 - accuracy: 0.9249 - val_loss: 0.1836 - val_accuracy: 0.9389\n",
      "Epoch 22/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2079 - accuracy: 0.9274 - val_loss: 0.1826 - val_accuracy: 0.9373\n",
      "Epoch 23/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2132 - accuracy: 0.9266 - val_loss: 0.2193 - val_accuracy: 0.9225\n",
      "Epoch 24/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2013 - accuracy: 0.9278 - val_loss: 0.1923 - val_accuracy: 0.9287\n",
      "Epoch 25/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1956 - accuracy: 0.9320 - val_loss: 0.1667 - val_accuracy: 0.9420\n",
      "Epoch 26/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1948 - accuracy: 0.9287 - val_loss: 0.1700 - val_accuracy: 0.9438\n",
      "Epoch 27/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1945 - accuracy: 0.9313 - val_loss: 0.3085 - val_accuracy: 0.8860\n",
      "Epoch 28/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1909 - accuracy: 0.9312 - val_loss: 0.1628 - val_accuracy: 0.9447\n",
      "Epoch 29/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1888 - accuracy: 0.9324 - val_loss: 0.1675 - val_accuracy: 0.9459\n",
      "Epoch 30/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1894 - accuracy: 0.9322 - val_loss: 0.1551 - val_accuracy: 0.9472\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 30, \n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid = True\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14300668239593506, 0.9518433809280396]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world Test (r/shortscarystories and r/self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_creepy = \"\"\"\n",
    "Irene (not her real name) was my first non-bot tinder match in three months. Things moved pretty fastwe chatted, I offered to cook dinner (Spaghetti puttanesca), then we hooked up.\n",
    "\n",
    "Irene was super hot but SUPER weird. She had a thick accent but insisted she grew up nearby, said it was a good night to make love because her goddess cycle was aligned with the moons, and totally starfished during sex.\n",
    "\n",
    "I figured - no big deal, Ill just do the adult thing and ghost her.\n",
    "\n",
    "Well that pissed Irene off. She messaged calling me a fuckboy and said, youll be sorry. I blocked her number, but the messages didnt stop. Eventually she baited me into replying:\n",
    "\n",
    "Her: Since youre alone tonight how about we have a little fun? \n",
    "\n",
    "Me: Im not alone. My housemates here. (I was lying.)\n",
    "\n",
    "Her: Surrrrrreeeeee.\n",
    "\n",
    "My bedroom door creaked open. From behind it something whispered, JJJJJJJJJJTTTTTTTBBBBBBBBBB6666666888888885555555.\n",
    "\n",
    "I thought maybe my housemate had come back and went to check it out. A dark figure almost as tall as the ceiling was creeping through the hall. I closed my bedroom door and locked it.\n",
    "\n",
    "My phone dinged.\n",
    "\n",
    "Her: I see youve met the other man in my life \n",
    "\n",
    "I thought, no big dealjust my imagination, or maybe a nightmare. Ill stay here and everythingll be alright in the morning.\n",
    "\n",
    "But I really needed to pee. Rather than wander through the empty house, I climbed out the window and urinated in the garden.\n",
    "\n",
    "When I returned, my phone dinged again.\n",
    "\n",
    "Her: Whats wrong? Afraid to go to the bathroom by yourself?\n",
    "\n",
    "Her: Look out the window. Hes outside. \n",
    "\n",
    "The figure appeared out of nowhere. Whatever it was, it wasnt human. This is the only way I can describe it: picture a living shadow with pale eyes and a tongue that doesnt fit in its mouth.\n",
    "\n",
    "It licked the window; I staggered back. The window opened (I dont know how - it doesnt unlock from the outside) and the figure poked its grinning head past the frame and into the room. I messaged Irene.\n",
    "\n",
    "Me: Im sorry. Please make it stop. Ill do ANYTHING.\n",
    "\n",
    "Her: I wish I could, but he hates seeing me upset.  If only something cheered me upOh well\n",
    "\n",
    "The figure climbed through the window and crawled along the floor, dragging its grotesque tongue across the carpet. It stood, leaned over me, then rocked its head like a seesaw.\n",
    "\n",
    "Me: Free tomorrow evening?\n",
    "\n",
    "Immediately the shadow turned and climbed back out the window.\n",
    "\n",
    "Her: Pick me up at eight. And we better have a magical timeOr else. X.\n",
    "\n",
    "So now were meeting tonight, and I have no idea what to do. I absolutely DO NOT want to date a girl who summons demons and probably gives shitty blowjobs.\n",
    "\n",
    "I need to figure out a way to make her both enjoy the date and never want to see me again.\n",
    "\n",
    "If anyone has any suggestions, Id really really appreciate it\n",
    "\"\"\"\n",
    "\n",
    "text_non_creepy = \"\"\"\n",
    "a few years ago my grandfather died and grandma was left to deal with finances for the first time in her life. mentally she was always sharp but in the months after his death she was so vulnerable. during this time some phone scammers managed to get her locked into a contract so she had to pay an extra $500/mo for electricity. i was royally pissed to say the least. worst of all, i couldn't do anything about it. eventually she was able to get out of the contract but not before she paid them thousands of dollars.\n",
    "\n",
    "as revenge, when someone tries to scam me i waste as much of their time as possible. i figure if i can slow them down for just 10-20 min it might be saving some other poor old lady from being taken advantage of. when i first started it wasn't easy. i could only keep them on the line for a few min before i broke down and started swearing at them. then i learned to keep my cool but they have ways of figuring out who is legit so i could only keep them on the line for 5 min before they would hang up. it sort of became a game where i would slowly figure out what they wanted to hear. with each call i get a little better. today i managed to keep them for 30+ min before they got frustrated and hung up.\n",
    "\n",
    "if everyone did this it would slow them down a lot. many old ladies would be saved.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.17855311,  0.99887389, -0.1818566 , ..., -0.11338365,\n",
       "         0.32053056, -0.53172892],\n",
       "       [ 7.03615729,  0.28519672, -0.21132576, ...,  0.2008417 ,\n",
       "        -0.19763832, -0.22631331]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creepy_vec = np.concatenate(([np.log(1310+1+0.01)],sbert_model.encode(text_creepy)))\n",
    "non_creepy_vec = np.concatenate(([np.log(1136+1+0.01)],sbert_model.encode(text_non_creepy)))\n",
    "vecs = np.array([creepy_vec, non_creepy_vec])\n",
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_vecs = scaler.fit_transform(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=100)\n",
    "scaled_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00936089],\n",
       "       [0.99898547]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fbe95a0ef40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepyvenv",
   "language": "python",
   "name": "creepyvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
