{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] github-afr-neural-folkales\n",
    "- [ ] Folklore and Mythology Electronic Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folklore and Mythology Electronic Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_stories(url, directory = \"Download/Folktales and Myths/raw data/Folklore and Mythology Electronic Texts\"):\n",
    "    import os\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    \n",
    "    try:\n",
    "        PATH = os.path.join(directory, soup.find('h1').get_text().strip())\n",
    "    except AttributeError:\n",
    "        PATH = os.path.join(directory, soup.find('h2').get_text().strip())\n",
    "    \n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    sections = str(soup).split('<hr/>')\n",
    "    titles = [a.get_text().replace('\\n',' ').strip() for a in soup.find_all('a',attrs={'name': True}) if a.get_text() != \"Contents\"]\n",
    "\n",
    "    count = 0\n",
    "    for section in sections:\n",
    "        soup2 = BeautifulSoup(section)\n",
    "        possible_title = [a.get_text().replace('\\n',' ').strip() for a in soup2.find_all('a', attrs={'name':True})]\n",
    "        if len(possible_title) == 1 and possible_title[0] in titles:\n",
    "            text = soup2.get_text()\n",
    "            file = os.path.join(PATH, possible_title[0])\n",
    "            n = 1\n",
    "            while os.path.isfile(file+\".txt\"):\n",
    "                file = os.path.join(PATH, possible_title[0] + f\"({n})\")\n",
    "                n+=1\n",
    "                \n",
    "            file = os.path.split(file)\n",
    "            try:\n",
    "                with open((file[0] + '/' +file[1].replace('/','')+\".txt\"), 'w') as f:\n",
    "                    f.write(text)\n",
    "                    count += 1\n",
    "            except:\n",
    "                pass\n",
    "        elif len(possible_title) != 0:\n",
    "            print(possible_title)\n",
    "\n",
    "    try:\n",
    "        if count == len(titles):\n",
    "            print(\"Successfully scrapped\", count, \"stories in\", soup.find('h1').get_text().strip())\n",
    "        else:\n",
    "            print(\"Successfully scrapped\", count, \"stories in\", soup.find('h1').get_text().strip(), \"but\", len(titles)-count,\"does/do not get scrapped\")\n",
    "    except:\n",
    "        if count == len(titles):\n",
    "            print(\"Successfully scrapped\", count, \"stories in\", soup.find('h2').get_text().strip())\n",
    "        else:\n",
    "            print(\"Successfully scrapped\", count, \"stories in\", soup.find('h2').get_text().strip(), \"but\", len(titles)-count,\"does/do not get scrapped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://www.pitt.edu/~dash/folktexts2.html\"\n",
    "\n",
    "res1 = requests.get(url1)\n",
    "soup1 = BeautifulSoup(res1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Contents']\n",
      "Successfully scrapped 23 stories in The Name of the Helper\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in The Master \n",
      "Who Gave Strange Names \n",
      "to Things in His House\n",
      "['Contents']\n",
      "Successfully scrapped 25 stories in Nasreddin Hodja\n",
      "['Contents']\n",
      "Successfully scrapped 12 stories in The Three Nephites\n",
      "Successfully scrapped 0 stories in The Nibelungenlied\n",
      "[\"Otter's Wergild\", 'Sigurd Slays Fafnir', 'Sigurd and Brynhild', 'Atli Marries Gudrun']\n",
      "Successfully scrapped 2 stories in The Treasure of the Niflungs but 4 does/do not get scrapped\n",
      "Successfully scrapped 0 stories in The Disobedient Daughter\n",
      "Who Married a Skull\n",
      "Successfully scrapped 0 stories in The Hippopotamus\n",
      "and the Tortoise\n",
      "['Contents']\n",
      "Successfully scrapped 19 stories in Human Sacrifice in Legends and Myths\n",
      "['Contents']\n",
      "Successfully scrapped 12 stories in The Singing Bone\n",
      "['Contents']\n",
      "Successfully scrapped 13 stories in Cat and Mouse\n",
      "Successfully scrapped 0 stories in Why Dead People Are Buried\n",
      "Successfully scrapped 15 stories in Night-Mares\n",
      "Successfully scrapped 0 stories in The Njugl\n",
      "Successfully scrapped 0 stories in The Norse Creation Myth\n",
      "Successfully scrapped 0 stories in Oisin in Tir na n-Og\n",
      "Successfully scrapped 6 stories in Old Dogs Learn New Tricks\n",
      "['Contents']\n",
      "Successfully scrapped 13 stories in The Bremen Town Musicians\n",
      "['Contents']\n",
      "Successfully scrapped 9 stories in Old, Older, and Oldest\n",
      "['Contents']\n",
      "Successfully scrapped 20 stories in Old Grandfathers\n",
      "and\n",
      "Their Grandsons\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in Old Parents and Their Ungrateful Children\n",
      "Successfully scrapped 14 stories in Killing of Old People\n",
      "['Contents']\n",
      "Successfully scrapped 11 stories in Ungrateful Heirs\n",
      "['Contents']\n",
      "Successfully scrapped 7 stories in Open Sesame!\n",
      "['Contents']\n",
      "Successfully scrapped 9 stories in The Origin of Underground People\n",
      "Successfully scrapped 0 stories in The Osenberg Dwarfs\n",
      "['Contents']\n",
      "Successfully scrapped 5 stories in The Education of an Ox\n",
      "['Contents']\n",
      "Successfully scrapped 13 stories in The Panchatantra\n",
      "['Contents']\n",
      "Successfully scrapped 19 stories in A Visitor from Paradise\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in The Parrot That Talked Too Much\n",
      "['Contents']\n",
      "Successfully scrapped 5 stories in Hear No Evil\n",
      "See No Evil\n",
      "Speak No Evil\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in The Parrot and the Adulterous Woman\n",
      "['Contents']\n",
      "Successfully scrapped 10 stories in Peacock Plumes\n",
      "['Contents']\n",
      "Successfully scrapped 9 stories in The Enchanted Pear Tree\n",
      "Successfully scrapped 0 stories in Charles Perrault's Mother Goose Tales\n",
      "Successfully scrapped 6 stories in Folktales from the Philippines\n",
      "['Contents']\n",
      "Successfully scrapped 30 stories in The Pied Piper of Hameln\n",
      "['Contents']\n",
      "Successfully scrapped 28 stories in Plague Legends\n",
      "['Contents']\n",
      "Successfully scrapped 8 stories in Playing Dead\n",
      "Successfully scrapped 0 stories in The Plaisham\n",
      "['Contents']\n",
      "Successfully scrapped 11 stories in Dishonest Surveyor and Plowman Legends\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in The Pot That Died\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in The Princess on the Pea\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in Puss in Boots\n",
      "['Contents']\n",
      "Successfully scrapped 17 stories in Puss in Boots\n",
      "['Contents']\n",
      "Successfully scrapped 2 stories in Rain or Sunshine?\n",
      "['Contents']\n",
      "Successfully scrapped 8 stories in The Rabbit Herd\n",
      "['Contents']\n",
      "Successfully scrapped 8 stories in Rapunzel\n",
      "['C', 'Chain tales']\n",
      "['G', 'The Girl without Hands']\n",
      "['M', 'Mouse, Mice.']\n",
      "Successfully scrapped 10 stories in Folklore and Mythology\n",
      "Electronic Texts but 6 does/do not get scrapped\n",
      "Successfully scrapped 8 stories in Little Red Riding Hood\n",
      "['Contents']\n",
      "Successfully scrapped 7 stories in Revived from Apparent Death\n",
      "by a Grave-Robber\n",
      "Successfully scrapped 0 stories in Rígsþula: The Lay of Rig\n",
      "['Contents']\n",
      "Successfully scrapped 14 stories in The Robber Bridegroom\n",
      "Successfully scrapped 0 stories in Rübezahl Is Entertained by Musicians\n",
      "['Contents']\n",
      "Successfully scrapped 14 stories in The Runaway Pancake\n",
      "Successfully scrapped 2 stories in Saint George and the Dragon\n",
      "Successfully scrapped 0 stories in The Legend of Saint George\n",
      "Successfully scrapped 0 stories in The Legend of Saint George\n",
      "['Contents']\n",
      "Successfully scrapped 2 stories in Saint George\n",
      "['Contents']\n",
      "Successfully scrapped 16 stories in Saint George Legends  \n",
      "from Northern Europe\n",
      "['Contents']\n",
      "Successfully scrapped 12 stories in Love Like Salt\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in Why the Sea Is Salty\n",
      "Successfully scrapped 0 stories in Scandinavia, Finland, and Estonia\n",
      "Successfully scrapped 1 stories in Folklore, Folktales, and Fairy Tales\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in The Scorpion and the Tortoise\n",
      "['Contents']\n",
      "Successfully scrapped 10 stories in Self Did It\n",
      "['Contents']\n",
      "Successfully scrapped 27 stories in The Shoemaker and the Elves\n",
      "['Contents']\n",
      "Successfully scrapped 11 stories in The Shoes That Were Danced to Pieces\n",
      "['Contents']\n",
      "Successfully scrapped 14 stories in The Silence Wager\n",
      "['Contents']\n",
      "Successfully scrapped 12 stories in The Singing Bone\n",
      "['Contents']\n",
      "Successfully scrapped 5 stories in Singing Thieves\n",
      "Successfully scrapped 1 stories in Slavic and Other Eastern European Folk and Fairy Tales\n",
      "['Contents']\n",
      "Successfully scrapped 4 stories in Sleeping Beauty\n",
      "['Contents']\n",
      "Successfully scrapped 28 stories in Sleeping Hero Legends\n",
      "Successfully scrapped 16 stories in Snake and Serpent Husbands\n",
      "['Contents']\n",
      "Successfully scrapped 7 stories in The Snow Child\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in The Snow Maiden\n",
      "Successfully scrapped 0 stories in The Snow, the Crow, and the Blood\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in Snow-White\n",
      "['Contents']\n",
      "Successfully scrapped 9 stories in The Sorcerer's Apprentice\n",
      "['Contents']\n",
      "Successfully scrapped 10 stories in Specter Bridegrooms\n",
      "['Contents']\n",
      "Successfully scrapped 7 stories in Stages of Life\n",
      "['Contents']\n",
      "Successfully scrapped 25 stories in Stone Monument Legends\n",
      "Successfully scrapped 0 stories in Dolmens in Denmark\n",
      "['Contents']\n",
      "Successfully scrapped 25 stories in Stone Monument Legends\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in Stone Soup\n",
      "['Contents']\n",
      "Successfully scrapped 5 stories in Straightening a Curly Hair\n",
      "['Contents']\n",
      "Successfully scrapped 5 stories in Straw, Coal, and Bean\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in The Strong Boy\n",
      "['Contents']\n",
      "Successfully scrapped 2 stories in The Entrapped Suitors\n",
      "['Contents']\n",
      "Successfully scrapped 1 stories in Sun, Moon, and Star Legends\n",
      "['Contents']\n",
      "['Aging and Death', 'The vulgar superstition']\n",
      "['All German superstitions were taken from Jacob Grimm', \"K. M'Gonigle,\", 'Ethel H. Rudkin,', 'Eliza Gutch and Mabel Peacock,', 'The Denham Tracts.', 'Robert Hunt,', \"Hunt's source: John Gay\", 'Francis Grose,']\n",
      "Successfully scrapped 12 stories in Superstitions from Europe but 10 does/do not get scrapped\n",
      "['Contents']\n",
      "Successfully scrapped 8 stories in Swan Maidens\n",
      "['Contents']\n",
      "Successfully scrapped 11 stories in The Tail-Fisher\n",
      "['Contents']\n",
      "Successfully scrapped 4 stories in The Tailor in Heaven\n",
      "Successfully scrapped 9 stories in Taming a Shrewish Wife\n",
      "Successfully scrapped 1 stories in Tannhäuser\n",
      "['Contents']\n",
      "Successfully scrapped 15 stories in The Tar-Baby\n",
      "Successfully scrapped 0 stories in Tatterhood\n",
      "Successfully scrapped 0 stories in Thangbrand the Priest Goes to Iceland\n",
      "Successfully scrapped 0 stories in THOR and the MIDGARD SERPENT\n",
      "Successfully scrapped 0 stories in Thor's Hammer in the Alps\n",
      "['Contents']\n",
      "Successfully scrapped 4 stories in Three Billy Goats Gruff\n",
      "['Contents']\n",
      "Successfully scrapped 10 stories in Three Little Pigs\n",
      "['Contents']\n",
      "Successfully scrapped 7 stories in Three Magic Gifts\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in The Three-Ring Parable\n",
      "Successfully scrapped 0 stories in The Lay of Thrym\n",
      "Successfully scrapped 0 stories in Thunderbolts\n",
      "Successfully scrapped 0 stories in Tikki Tikki Tembo\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in The Tongue-Cut Sparrow\n",
      "['Contents']\n",
      "Successfully scrapped 9 stories in The Tortoise That Wanted to Fly\n",
      "['Contents']\n",
      "Successfully scrapped 33 stories in The Tortoise and the Hare\n",
      "['Contents']\n",
      "Successfully scrapped 4 stories in Trading Away One's Fortune\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in Trading Places\n",
      "['Contents']\n",
      "Successfully scrapped 4 stories in Trading Up (1)\n",
      "['Contents']\n",
      "Successfully scrapped 8 stories in Trading Up (2)\n",
      "['Contents']\n",
      "Successfully scrapped 11 stories in Folktales for Travelers\n",
      "Successfully scrapped 9 stories in Treasure Finders\n",
      "Murder One Another\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in Trickster Wives and Maids\n",
      "Successfully scrapped 0 stories in Tristan and Isolde\n",
      "['Contents']\n",
      "Successfully scrapped 2 stories in Twigmuntus, Cowbelliantus, Perchnosius\n",
      "['Contents']\n",
      "Successfully scrapped 13 stories in The Two Travelers: Truth and Falsehood\n",
      "['Contents']\n",
      "Successfully scrapped 11 stories in Underground People Disturbed\n",
      "by Farm or Household Waste\n",
      "['Contents']\n",
      "Successfully scrapped 14 stories in Unfinished and Endless Stories\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in Vampire and Ghost Stories\n",
      "from Russia\n",
      "Successfully scrapped 0 stories in The Saga of the Volsungs\n",
      "Successfully scrapped 0 stories in Folklore, Folktales, and Fairy Tales\n",
      "['Contents']\n",
      "Successfully scrapped 18 stories in The Wandering Jew\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in War between Wild Animals and Domestic Animals\n",
      "['Contents']\n",
      "Successfully scrapped 9 stories in Water Spirit Legends 1\n",
      "['Contents']\n",
      "Successfully scrapped 9 stories in Water Spirit Legends 2\n",
      "The Hour Is Come but the Man Is Not\n",
      "Successfully scrapped 3 stories in Weather and Climate Legends\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in The Women of Weinsberg\n",
      "['Contents']\n",
      "Successfully scrapped 30 stories in \n",
      "['Contents']\n",
      "Successfully scrapped 11 stories in Animal Brides\n",
      "Successfully scrapped 2 stories in The Werewolf's Daughter\n",
      "['Contents']\n",
      "Successfully scrapped 11 stories in What Should I Have Said (or Done)?\n",
      "['Contents']\n",
      "Successfully scrapped 5 stories in Folklore Ballads\n",
      "of\n",
      "John Greenleaf Whittier\n",
      "['Contents']\n",
      "Successfully scrapped 14 stories in Widows\n",
      "['Contents']\n",
      "Successfully scrapped 5 stories in An Adulterous Wife Locks Her Husband Out of Doors\n",
      "['Contents']\n",
      "Successfully scrapped 13 stories in The Contrary Wife\n",
      "Successfully scrapped 0 stories in The Falsely Accused Wife\n",
      "['Contents']\n",
      "Successfully scrapped 6 stories in The Wife Who Could Not Keep a Secret\n",
      "Successfully scrapped 0 stories in Of Women, Who Not Only Betray Secrets, but Lie\n",
      "Fearfully\n",
      "['Contents']\n",
      "Successfully scrapped 17 stories in Wild Huntsman Legends\n",
      "['Contents']\n",
      "Successfully scrapped 10 stories in The Wild Man As Helper\n",
      "['Contents']\n",
      "Successfully scrapped 15 stories in Will-o'-the-Wisp\n",
      "Jack-o'-Lantern\n",
      "['Contents']\n",
      "Successfully scrapped 5 stories in Wind and Sun\n",
      "Successfully scrapped 30 stories in The Witch That Was Hurt\n",
      "['Contents']\n",
      "Successfully scrapped 10 stories in Witchcraft Legends\n",
      "Successfully scrapped 0 stories in Wolves in Aesop's Fables\n",
      "['Contents']\n",
      "Successfully scrapped 3 stories in An Old Woman as the Devil's Helper\n",
      "['Contents']\n",
      "Successfully scrapped 7 stories in The Woman Who Did Not Know Herself\n",
      "Successfully scrapped 0 stories in Yggdrasil\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for link in soup1.select(\"h1+ ul a\"):\n",
    "    if link.get('href'):\n",
    "        if not link.get('href').startswith(\"http\"):\n",
    "            scrap_stories(os.path.join(\"https://www.pitt.edu/~dash\", link.get('href')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Contents']\n",
      "Successfully scrapped 8 stories in Folktales from China\n"
     ]
    }
   ],
   "source": [
    "scrap_stories(\"https://web.archive.org/web/20090224073548/http://www.pitt.edu/~dash/china.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The King James Version of the Bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 28\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "PATH = \"Download/Folktales and Myths/raw data/The King James Version of the Bible\"\n",
    "\n",
    "CHAPTERS1 = [\n",
    "    \"The First Book of Moses: Called Genesis\",\n",
    "    \"The Second Book of Moses: Called Exodus\",\n",
    "    \"The Third Book of Moses: Called Leviticus\",\n",
    "    \"The Fourth Book of Moses: Called Numbers\",\n",
    "    \"The Fifth Book of Moses: Called Deuteronomy\",\n",
    "    \"The Book of Joshua\",\n",
    "    \"The Book of Judges\",\n",
    "    \"The Book of Ruth\",\n",
    "    \"The First Book of Samuel\",\n",
    "    \"The Second Book of Samuel\",\n",
    "    \"The First Book of the Kings\",\n",
    "    \"The Second Book of the Kings\",\n",
    "    \"The First Book of the Chronicles\",\n",
    "    \"The Second Book of the Chronicles\",\n",
    "    \"Ezra\",\n",
    "    \"The Book of Nehemiah\",\n",
    "    \"The Book of Esther\",\n",
    "    \"The Book of Job\",\n",
    "    \"The Book of Psalms\",\n",
    "    \"The Proverbs\",\n",
    "    \"Ecclesiastes\",\n",
    "    \"The Song of Solomon\",\n",
    "    \"The Book of the Prophet Isaiah\",\n",
    "    \"The Book of the Prophet Jeremiah\",\n",
    "    \"The Lamentations of Jeremiah\",\n",
    "    \"The Book of the Prophet Ezekiel\",\n",
    "    \"The Book of Daniel\",\n",
    "    \"Hosea\",\n",
    "    \"Joel\",\n",
    "    \"Amos\",\n",
    "    \"Obadiah\",\n",
    "    \"Jonah\",\n",
    "    \"Micah\",\n",
    "    \"Nahum\",\n",
    "    \"Habakkuk\",\n",
    "    \"Zephaniah\",\n",
    "    \"Haggai\",\n",
    "    \"Zechariah\",\n",
    "    \"Malachi\"]\n",
    "\n",
    "CHAPTERS2 = [\n",
    "    \"The Gospel According to Saint Matthew\",\n",
    "    \"The Gospel According to Saint Mark\",\n",
    "    \"The Gospel According to Saint Luke\",\n",
    "    \"The Gospel According to Saint John\",\n",
    "    \"The Acts of the Apostles\",\n",
    "    \"The Epistle of Paul the Apostle to the Romans\",\n",
    "    \"The First Epistle of Paul the Apostle to the Corinthians\",\n",
    "    \"The Second Epistle of Paul the Apostle to the Corinthians\",\n",
    "    \"The Epistle of Paul the Apostle to the Galatians\",\n",
    "    \"The Epistle of Paul the Apostle to the Ephesians\",\n",
    "    \"The Epistle of Paul the Apostle to the Philippians\",\n",
    "    \"The Epistle of Paul the Apostle to the Colossians\",\n",
    "    \"The First Epistle of Paul the Apostle to the Thessalonians\",\n",
    "    \"The Second Epistle of Paul the Apostle to the Thessalonians\",\n",
    "    \"The First Epistle of Paul the Apostle to Timothy\",\n",
    "    \"The Second Epistle of Paul the Apostle to Timothy\",\n",
    "    \"The Epistle of Paul the Apostle to Titus\",\n",
    "    \"The Epistle of Paul the Apostle to Philemon\",\n",
    "    \"The Epistle of Paul the Apostle to the Hebrews\",\n",
    "    \"The General Epistle of James\",\n",
    "    \"The First Epistle General of Peter\",\n",
    "    \"The Second General Epistle of Peter\",\n",
    "    \"The First Epistle General of John\",\n",
    "    \"The Second Epistle General of John\",\n",
    "    \"The Third Epistle General of John\",\n",
    "    \"The General Epistle of Jude\",\n",
    "    \"The Revelation of Saint John the Devine\"\n",
    "]\n",
    "with open(os.path.join(PATH, 'The New Testament of the King James Bible/The New Testament.txt'), 'r') as f:\n",
    "    allText = f.read()\n",
    "    \n",
    "    parts = re.split('|'.join(CHAPTERS2), allText)\n",
    "    print(len(CHAPTERS2),len(parts))\n",
    "    \n",
    "    for t, p in zip(CHAPTERS2, parts[1:]):\n",
    "        text = t + p\n",
    "        with open(os.path.join(PATH, 'The New Testament of the King James Bible/splitted by chapters', t+'.txt'), 'w') as f1:\n",
    "            f1.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "PATH = \"Download/Folktales and Myths/raw data/The King James Version of the Bible\"\n",
    "\n",
    "CHAPTERS1 = [\n",
    "    \"The First Book of Moses: Called Genesis\",\n",
    "    \"The Second Book of Moses: Called Exodus\",\n",
    "    \"The Third Book of Moses: Called Leviticus\",\n",
    "    \"The Fourth Book of Moses: Called Numbers\",\n",
    "    \"The Fifth Book of Moses: Called Deuteronomy\",\n",
    "    \"The Book of Joshua\",\n",
    "    \"The Book of Judges\",\n",
    "    \"The Book of Ruth\",\n",
    "    \"The First Book of Samuel\",\n",
    "    \"The Second Book of Samuel\",\n",
    "    \"The First Book of the Kings\",\n",
    "    \"The Second Book of the Kings\",\n",
    "    \"The First Book of the Chronicles\",\n",
    "    \"The Second Book of the Chronicles\",\n",
    "    \"Ezra\",\n",
    "    \"The Book of Nehemiah\",\n",
    "    \"The Book of Esther\",\n",
    "    \"The Book of Job\",\n",
    "    \"The Book of Psalms\",\n",
    "    \"The Proverbs\",\n",
    "    \"Ecclesiastes\",\n",
    "    \"The Song of Solomon\",\n",
    "    \"The Book of the Prophet Isaiah\",\n",
    "    \"The Book of the Prophet Jeremiah\",\n",
    "    \"The Lamentations of Jeremiah\",\n",
    "    \"The Book of the Prophet Ezekiel\",\n",
    "    \"The Book of Daniel\",\n",
    "    \"Hosea\",\n",
    "    \"Joel\",\n",
    "    \"Amos\",\n",
    "    \"Obadiah\",\n",
    "    \"Jonah\",\n",
    "    \"Micah\",\n",
    "    \"Nahum\",\n",
    "    \"Habakkuk\",\n",
    "    \"Zephaniah\",\n",
    "    \"Haggai\",\n",
    "    \"Zechariah\",\n",
    "    \"Malachi\"]\n",
    "\n",
    "CHAPTERS2 = [\n",
    "    \"The Gospel According to Saint Matthew\",\n",
    "    \"The Gospel According to Saint Mark\",\n",
    "    \"The Gospel According to Saint Luke\",\n",
    "    \"The Gospel According to Saint John\",\n",
    "    \"The Acts of the Apostles\",\n",
    "    \"The Epistle of Paul the Apostle to the Romans\",\n",
    "    \"The First Epistle of Paul the Apostle to the Corinthians\",\n",
    "    \"The Second Epistle of Paul the Apostle to the Corinthians\",\n",
    "    \"The Epistle of Paul the Apostle to the Galatians\",\n",
    "    \"The Epistle of Paul the Apostle to the Ephesians\",\n",
    "    \"The Epistle of Paul the Apostle to the Philippians\",\n",
    "    \"The Epistle of Paul the Apostle to the Colossians\",\n",
    "    \"The First Epistle of Paul the Apostle to the Thessalonians\",\n",
    "    \"The Second Epistle of Paul the Apostle to the Thessalonians\",\n",
    "    \"The First Epistle of Paul the Apostle to Timothy\",\n",
    "    \"The Second Epistle of Paul the Apostle to Timothy\",\n",
    "    \"The Epistle of Paul the Apostle to Titus\",\n",
    "    \"The Epistle of Paul the Apostle to Philemon\",\n",
    "    \"The Epistle of Paul the Apostle to the Hebrews\",\n",
    "    \"The General Epistle of James\",\n",
    "    \"The First Epistle General of Peter\",\n",
    "    \"The Second General Epistle of Peter\",\n",
    "    \"The First Epistle General of John\",\n",
    "    \"The Second Epistle General of John\",\n",
    "    \"The Third Epistle General of John\",\n",
    "    \"The General Epistle of Jude\",\n",
    "    \"The Revelation of Saint John the Devine\"\n",
    "]\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/10/10-h/10-h.htm\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chapter in soup.find_all('div', attrs={'class':'chapter'})[1:]:\n",
    "    name = chapter.h2.get_text().replace('  ',' ')\n",
    "    nowChap = name.strip()\n",
    "    if name.strip() in CHAPTERS1:\n",
    "        with open(os.path.join(PATH, 'The Old Testament of the King James Version of the Bible/splitted by chapters', nowChap + '.txt'), 'a+') as f:\n",
    "            f.write(name + '\\n')\n",
    "            for p in [p.get_text() for p in chapter.find_all('p')]:\n",
    "                f.write(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'The Old Testament of the King James Version of the Bible/The Old Testament.txt'), 'r') as f:\n",
    "    nowChap = ''\n",
    "    for line in f:\n",
    "        if line.strip() in CHAPTERS1:\n",
    "            with open(os.path.join(PATH, 'The Old Testament of the King James Version of the Bible/splitted by chapters', line.strip() + '.txt'), 'a+') as f:\n",
    "                f.write(line)\n",
    "                nowChap = line.strip()\n",
    "        else:\n",
    "            with open(os.path.join(PATH, 'The Old Testament of the King James Version of the Bible/splitted by chapters', nowChap+ '.txt'), 'a+') as f:\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Epic of Atraḥasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://www.livius.org/sources/content/anet/104-106-the-epic-of-atrahasis/\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text)\n",
    "PATH = \"Download/Folktales and Myths/raw data/The Epic of Atraḥasis\"\n",
    "CHAPTERS = [a.get_text() for a in soup.select(\"#content h4 , p~ p+ h3 , h3+ h3\")]\n",
    "len(CHAPTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>The Epic of Atraḥasis</h1>\n"
     ]
    }
   ],
   "source": [
    "for article in soup.find_all(id=\"content\"):\n",
    "    print(article.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 tablets of creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"http://www.gutenberg.org/files/21765/21765-h/files/Met_I-III.html\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text)\n",
    "\n",
    "PATH = \"Download/Folktales and Myths/raw data/THE METAMORPHOSES.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOOK THE FIRST.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-268-d0c358a2484a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'span'\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hr'\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pagenum mckay'\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'linnum mckay'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Research-Mapping-Uncanny-Valley-DSc8QBrC/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\n\u001b[1;32m   1405\u001b[0m         and throws an exception if it's not there.\"\"\"\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "for content in soup.find_all('span', attrs={'class':'pagenum mckay'}):\n",
    "    currentBOOK = None\n",
    "    while content.next_sibling:\n",
    "#         print(content.find_next())\n",
    "        content = content.next_sibling\n",
    "        \n",
    "        if isinstance(content, NavigableString):\n",
    "            continue\n",
    "        if isinstance(content, Tag):\n",
    "            if content.name == 'span' or \\\n",
    "                content.name == 'hr' or \\\n",
    "                content['class'] in ['pagenum mckay', 'linnum mckay', 'pagenum bell', 'linenum bell'] :\n",
    "                continue\n",
    "            \n",
    "            elif content.name == 'h4':\n",
    "                print(content.get_text())\n",
    "                currentBOOK = content.get_text().strip()\n",
    "                directory = os.path.join(PATH, currentBOOK)\n",
    "                if not os.path.exists(directory):\n",
    "                    os.makedirs(directory)\n",
    "            elif content.name == 'h5':\n",
    "                currentFILE = content.get_text().strip()\n",
    "                open(os.path.join(directory, currentFILE + \"txt\"), 'a').close()\n",
    "            else:\n",
    "                if content.name == 'span' or \\\n",
    "                    content.name == 'hr' or \\\n",
    "                    content['class'] in ['pagenum mckay', 'linnum mckay', 'pagenum bell', 'linenum bell'] :\n",
    "                \n",
    "                with open(os.path.join(directory, currentFILE + \"txt\"), 'a+') as f:\n",
    "                    f.write(content.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(os.path.join(PATH, 'splitted by books'))\n",
    "with open(os.path.join(PATH, \"Hesiod, The Homeric Hymns, and Homerica.txt\"), 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        if fname.startswith('.'):\n",
    "            continue\n",
    "        with open(os.path.join(PATH, 'splitted by books',fname)) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOOK XX.txt',\n",
       " 'BOOK XVI.txt',\n",
       " 'BOOK IV.txt',\n",
       " 'BOOK XXIV.txt',\n",
       " 'BOOK XII.txt',\n",
       " 'BOOK XV.txt',\n",
       " 'BOOK XIX.txt',\n",
       " 'BOOK XVII.txt',\n",
       " 'BOOK III.txt',\n",
       " 'BOOK VI.txt',\n",
       " 'BOOK XXII.txt',\n",
       " 'BOOK XIII.txt',\n",
       " 'BOOK V.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'BOOK XIV.txt',\n",
       " 'BOOK IX.txt',\n",
       " 'BOOK VII.txt',\n",
       " 'BOOK X.txt',\n",
       " 'BOOK VIII.txt',\n",
       " 'BOOK XI.txt',\n",
       " 'BOOK XXIII.txt',\n",
       " 'BOOK II.txt',\n",
       " 'BOOK XVIII.txt',\n",
       " 'BOOK I.txt',\n",
       " 'BOOK XXI.txt']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(PATH, 'splitted by books'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Download/Folktales and Myths/raw data/github-afr-neural-folktales/input_eur.txt', 'r') as f:\n",
    "    stories = f.read().split('\\n\\n')\n",
    "    for i,story in enumerate(stories):\n",
    "        with open(f'Download/Folktales and Myths/raw data/github-afr-neural-folktales/splitted eur/{i}.txt', 'w') as f1:\n",
    "            f1.write(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepy-venv",
   "language": "python",
   "name": "creepy-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
