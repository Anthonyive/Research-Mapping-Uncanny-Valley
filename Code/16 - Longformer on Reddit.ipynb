{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at allenai/longformer-base-4096.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TFLongformerModel, LongformerTokenizerFast, LongformerConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "config = LongformerConfig.from_pretrained('allenai/longformer-base-4096')\n",
    "# choose the attention mode 'n2', 'tvm' or 'sliding_chunks'\n",
    "# 'n2': for regular n2 attantion\n",
    "# 'tvm': a custom CUDA kernel implementation of our sliding window attention\n",
    "# 'sliding_chunks': a PyTorch implementation of our sliding window attention\n",
    "config.attention_mode = 'sliding_chunks'\n",
    "\n",
    "model = TFLongformerModel.from_pretrained('allenai/longformer-base-4096', config = config)\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096')\n",
    "tokenizer.model_max_length = model.config.max_position_embeddings\n",
    "\n",
    "def LFencode(row):\n",
    "    SAMPLE_TEXT = row['selftext']\n",
    "    input_ids = tf.expand_dims(tf.convert_to_tensor(tokenizer.encode(SAMPLE_TEXT)), 0) # batch of size 1\n",
    "\n",
    "    # model = model.cuda(); input_ids = input_ids.cuda()\n",
    "\n",
    "    # Attention mask values -- 0: no attention, 1: local attention, 2: global attention\n",
    "    attention_mask = tf.ones(input_ids.shape, dtype=tf.int32) # initialize to local attention\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = outputs.pooler_output\n",
    "    return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4002])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "nosleepDf = pd.read_csv('Download/Cleaned Data/NoSleep.csv')\n",
    "selfDf = pd.read_csv('Download/Cleaned Data/Self.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nosleepDfShort = nosleepDf[:2000].copy()\n",
    "selfDfShort = selfDf[:2000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c63350588a64c9b86593a98459d3979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0bc39c39a84cca858b7a6b30f357af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "selfDfShort['LF pooler output']= selfDfShort.progress_apply(LFencode, axis=1)\n",
    "nosleepDfShort['LF pooler output']= nosleepDfShort.progress_apply(LFencode, axis=1)\n",
    "\n",
    "selfDfShort.to_pickle('Download/Cleaned Data with Longformer/selfDfShort.pkl')\n",
    "nosleepDfShort.to_pickle('Download/Cleaned Data with Longformer/nosleepDfShort.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "nosleepDfShort = pd.read_pickle('Download/Cleaned Data with Longformer/nosleepDfShort.pkl')\n",
    "selfDfShort = pd.read_pickle('Download/Cleaned Data with Longformer/selfDfShort.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nosleepLF = tf.stack(nosleepDfShort.loc[:,'LF pooler output'].to_list())\n",
    "selfLF = tf.stack(selfDfShort.loc[:,'LF pooler output'].to_list())\n",
    "\n",
    "nosleepLF = tf.reshape(nosleepLF, nosleepLF.shape[::2])\n",
    "selfLF = tf.reshape(selfLF, selfLF.shape[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_embedded_nosleep = TSNE(perplexity=30, learning_rate=50, n_components=3, n_iter=5000).fit_transform(nosleepLF)\n",
    "X_embedded_self = TSNE(perplexity=30, learning_rate=50, n_components=3, n_iter=2000).fit_transform(selfLF)\n",
    "\n",
    "df1 = pd.DataFrame(X_embedded_nosleep, columns=['x','y', 'z'])\n",
    "df1['subreddit'] = 'nosleep'\n",
    "df2 = pd.DataFrame(X_embedded_self, columns=['x','y', 'z'])\n",
    "df2['subreddit'] = 'self'\n",
    "\n",
    "df = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-36.957981</td>\n",
       "      <td>8.635462</td>\n",
       "      <td>4.994235</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.002152</td>\n",
       "      <td>-3.801722</td>\n",
       "      <td>-14.028380</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.685936</td>\n",
       "      <td>-12.819247</td>\n",
       "      <td>1.706671</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-36.276886</td>\n",
       "      <td>2.473907</td>\n",
       "      <td>8.568995</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.806938</td>\n",
       "      <td>-9.899336</td>\n",
       "      <td>-19.658789</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-13.722092</td>\n",
       "      <td>-11.108675</td>\n",
       "      <td>13.826125</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>18.899832</td>\n",
       "      <td>-7.848379</td>\n",
       "      <td>10.200396</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-0.305643</td>\n",
       "      <td>10.742041</td>\n",
       "      <td>16.996696</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>11.247368</td>\n",
       "      <td>15.277654</td>\n",
       "      <td>-23.854303</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-4.371283</td>\n",
       "      <td>-1.302812</td>\n",
       "      <td>29.049860</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y          z subreddit\n",
       "0    -36.957981   8.635462   4.994235   nosleep\n",
       "1      7.002152  -3.801722 -14.028380   nosleep\n",
       "2     35.685936 -12.819247   1.706671   nosleep\n",
       "3    -36.276886   2.473907   8.568995   nosleep\n",
       "4      6.806938  -9.899336 -19.658789   nosleep\n",
       "...         ...        ...        ...       ...\n",
       "1995 -13.722092 -11.108675  13.826125      self\n",
       "1996  18.899832  -7.848379  10.200396      self\n",
       "1997  -0.305643  10.742041  16.996696      self\n",
       "1998  11.247368  15.277654 -23.854303      self\n",
       "1999  -4.371283  -1.302812  29.049860      self\n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d7be19ccb94296a208f249e7b5c4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D,axes3d\n",
    "sns.set(style = \"darkgrid\")\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "\n",
    "ax.scatter(df[df['subreddit']=='nosleep']['x'], df[df['subreddit']=='nosleep']['y'], df[df['subreddit']=='nosleep']['z'], c='red', label='nosleep')\n",
    "ax.scatter(df[df['subreddit']=='self']['x'], df[df['subreddit']=='self']['y'], df[df['subreddit']=='self']['z'], c='blue', label='self')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nosleepLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 768), dtype=float32, numpy=\n",
       "array([[ 0.17356455, -0.28822845,  0.08040078, ..., -0.04949597,\n",
       "         0.17774035,  0.03145612],\n",
       "       [ 0.152154  , -0.3131358 ,  0.09661903, ..., -0.0544746 ,\n",
       "         0.20656316, -0.00459675],\n",
       "       [ 0.193991  , -0.3316983 ,  0.09307294, ..., -0.06202645,\n",
       "         0.20297652,  0.02324418],\n",
       "       ...,\n",
       "       [ 0.17017554, -0.34362826,  0.10915487, ..., -0.06822307,\n",
       "         0.20495556,  0.02520667],\n",
       "       [ 0.19672579, -0.34024084,  0.09063036, ..., -0.08465302,\n",
       "         0.18416663, -0.0188603 ],\n",
       "       [ 0.18555108, -0.3117493 ,  0.12184663, ..., -0.06562941,\n",
       "         0.18309756, -0.02888302]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creepy_features = nosleepLF\n",
    "creepy_labels = np.ones(len(creepy_features))\n",
    "creepy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 768), dtype=float32, numpy=\n",
       "array([[ 1.61632180e-01, -2.65369445e-01,  9.51929018e-02, ...,\n",
       "        -7.22304583e-02,  1.92816019e-01,  1.56589076e-02],\n",
       "       [ 1.28829047e-01, -2.89937794e-01,  7.89543763e-02, ...,\n",
       "        -4.83777523e-02,  1.91524208e-01,  6.91677677e-03],\n",
       "       [ 1.70354187e-01, -3.17211837e-01,  1.21957265e-01, ...,\n",
       "        -6.16075248e-02,  1.82307720e-01,  8.63182265e-03],\n",
       "       ...,\n",
       "       [ 1.67272553e-01, -2.53856778e-01,  9.05781314e-02, ...,\n",
       "        -7.19489008e-02,  1.67981252e-01,  2.79515982e-04],\n",
       "       [ 1.72974482e-01, -3.11384588e-01,  1.12448640e-01, ...,\n",
       "        -6.59727380e-02,  2.19963238e-01, -2.19200202e-03],\n",
       "       [ 1.66960493e-01, -2.52201796e-01,  1.04491428e-01, ...,\n",
       "        -8.50258991e-02,  1.67221159e-01,  2.78245900e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncreepy_features = selfLF\n",
    "noncreepy_labels = np.zeros(len(noncreepy_features))\n",
    "noncreepy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creepy_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7356455e-01 -2.8822845e-01  8.0400780e-02 ... -4.9495969e-02\n",
      "   1.7774035e-01  3.1456120e-02]\n",
      " [ 1.5215400e-01 -3.1313580e-01  9.6619032e-02 ... -5.4474600e-02\n",
      "   2.0656316e-01 -4.5967521e-03]\n",
      " [ 1.9399101e-01 -3.3169830e-01  9.3072943e-02 ... -6.2026449e-02\n",
      "   2.0297652e-01  2.3244182e-02]\n",
      " ...\n",
      " [ 1.6727255e-01 -2.5385678e-01  9.0578131e-02 ... -7.1948901e-02\n",
      "   1.6798125e-01  2.7951598e-04]\n",
      " [ 1.7297448e-01 -3.1138459e-01  1.1244864e-01 ... -6.5972738e-02\n",
      "   2.1996324e-01 -2.1920020e-03]\n",
      " [ 1.6696049e-01 -2.5220180e-01  1.0449143e-01 ... -8.5025899e-02\n",
      "   1.6722116e-01  2.7824590e-02]] [1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "features = np.concatenate((creepy_features, noncreepy_features))\n",
    "labels = np.concatenate((creepy_labels, noncreepy_labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 768) (4000,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16227037 -0.29918158  0.08713523 ... -0.07697824  0.17576697\n",
      "   0.04927548]\n",
      " [ 0.1869312  -0.27167854  0.07679233 ... -0.05150076  0.17872503\n",
      "   0.01457355]\n",
      " [ 0.18796471 -0.27861446  0.10946713 ... -0.0566155   0.17434561\n",
      "   0.00563797]\n",
      " ...\n",
      " [ 0.1626543  -0.26078555  0.09792019 ... -0.06696568  0.18959539\n",
      "  -0.02509238]\n",
      " [ 0.18691248 -0.2947923   0.08334965 ... -0.05329227  0.17755672\n",
      "  -0.03196963]\n",
      " [ 0.2021577  -0.3198302   0.09191491 ... -0.03372351  0.1764846\n",
      "   0.01798243]] [0. 0. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "features, labels = shuffle(features, labels)\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4052891  0.44818425 0.35995463 ... 0.4688404  0.37285864 0.77140045]\n",
      " [0.61858636 0.5985776  0.2686521  ... 0.6187166  0.3969139  0.54304516]\n",
      " [0.6275255  0.56065035 0.5570909  ... 0.5886282  0.3613     0.48424476]\n",
      " ...\n",
      " [0.4086098  0.65814316 0.45515952 ... 0.5277412  0.4853127  0.2820244 ]\n",
      " [0.6184245  0.47218597 0.32653728 ... 0.6081778  0.38741302 0.23676883]\n",
      " [0.750284   0.33527255 0.40214756 ... 0.7232948  0.37869442 0.56547725]] [0. 0. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "print(scaled_features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] 70% train, 15% val, 15% test\n",
    " - Train: 26500\n",
    " - Valid: 5677\n",
    " - Test: 5669\n",
    "- [x] 80% train, 10% val, 10% test\n",
    "- [ ] 60% train, 20% val, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4052891 , 0.61858636, 0.6275255 , ..., 0.4086098 , 0.6184245 ,\n",
       "       0.750284  ], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 768)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = scaled_features\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins import projector\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size,\n",
    "                            768,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "#     keras.layers.Dense(units = 303, input_shape = (769,), activation = 'relu'),\n",
    "#     keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units = 303, input_shape = (768,), activation = 'relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "#     keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 64, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 32, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 16, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 1, activation = 'sigmoid') # here the units must be 1 in order for binary classifications to work\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 303)               233007    \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 303)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               38912     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 282,800\n",
      "Trainable params: 282,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(lr=0.000959, beta_1 = 0.9, beta_2=0.999), # you can tune the learning rate here. Default lr = 0.01\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.5837 - accuracy: 0.6914 - val_loss: 0.3839 - val_accuracy: 0.8400\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8593 - val_loss: 0.3814 - val_accuracy: 0.8575\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8532 - val_loss: 0.4241 - val_accuracy: 0.8075\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8891 - val_loss: 0.4106 - val_accuracy: 0.8500\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9138 - val_loss: 0.2956 - val_accuracy: 0.8875\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9142 - val_loss: 0.3528 - val_accuracy: 0.8650\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.8949 - val_loss: 0.2809 - val_accuracy: 0.8925\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9042 - val_loss: 0.2925 - val_accuracy: 0.8750\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8921 - val_loss: 0.3037 - val_accuracy: 0.8925\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9162 - val_loss: 0.2726 - val_accuracy: 0.8825\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9043 - val_loss: 0.2825 - val_accuracy: 0.8950\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9155 - val_loss: 0.2980 - val_accuracy: 0.8875\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9093 - val_loss: 0.2751 - val_accuracy: 0.8850\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9287 - val_loss: 0.4305 - val_accuracy: 0.8525\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9149 - val_loss: 0.2715 - val_accuracy: 0.8800\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9175 - val_loss: 0.2917 - val_accuracy: 0.8775\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9262 - val_loss: 0.3138 - val_accuracy: 0.8925\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9321 - val_loss: 0.2924 - val_accuracy: 0.8925\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9320 - val_loss: 0.2695 - val_accuracy: 0.8875\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9251 - val_loss: 0.3128 - val_accuracy: 0.8800\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9142 - val_loss: 0.2839 - val_accuracy: 0.8775\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9295 - val_loss: 0.2569 - val_accuracy: 0.8950\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9257 - val_loss: 0.3042 - val_accuracy: 0.8825\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9226 - val_loss: 0.3363 - val_accuracy: 0.8800\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1988 - accuracy: 0.9253 - val_loss: 0.2836 - val_accuracy: 0.8900\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9233 - val_loss: 0.2691 - val_accuracy: 0.8725\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9136 - val_loss: 0.3334 - val_accuracy: 0.8750\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9244 - val_loss: 0.3497 - val_accuracy: 0.8650\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9428 - val_loss: 0.2592 - val_accuracy: 0.8825\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9177 - val_loss: 0.2782 - val_accuracy: 0.8800\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14502), started 0:06:52 ago. (Use '!kill 14502' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cf78319bf9209453\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cf78319bf9209453\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir,\"tensorboard_logs\", \"longformer\")\n",
    "\n",
    "def get_run_log_dir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_log_dir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 30, \n",
    "                   validation_data=(X_val, y_val),\n",
    "                   callbacks=[tensorboard_cb])\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tensorboard_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccd7655bc0a4eabb8d33b0978be3547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid = True\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepy-venv",
   "language": "python",
   "name": "creepy-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
