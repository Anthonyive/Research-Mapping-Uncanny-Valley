{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at allenai/longformer-base-4096.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TFLongformerModel, LongformerTokenizerFast, LongformerConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "config = LongformerConfig.from_pretrained('allenai/longformer-base-4096')\n",
    "# choose the attention mode 'n2', 'tvm' or 'sliding_chunks'\n",
    "# 'n2': for regular n2 attantion\n",
    "# 'tvm': a custom CUDA kernel implementation of our sliding window attention\n",
    "# 'sliding_chunks': a PyTorch implementation of our sliding window attention\n",
    "config.attention_mode = 'sliding_chunks'\n",
    "\n",
    "model = TFLongformerModel.from_pretrained('allenai/longformer-base-4096', config = config)\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096')\n",
    "tokenizer.model_max_length = model.config.max_position_embeddings\n",
    "\n",
    "def LFencode(row):\n",
    "    SAMPLE_TEXT = row['selftext']\n",
    "    input_ids = tf.expand_dims(tf.convert_to_tensor(tokenizer.encode(SAMPLE_TEXT)), 0) # batch of size 1\n",
    "\n",
    "    # model = model.cuda(); input_ids = input_ids.cuda()\n",
    "\n",
    "    # Attention mask values -- 0: no attention, 1: local attention, 2: global attention\n",
    "    attention_mask = tf.ones(input_ids.shape, dtype=tf.int32) # initialize to local attention\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = outputs.pooler_output\n",
    "    return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "nosleepDf = pd.read_csv('Download/Cleaned Data/NoSleep.csv')\n",
    "selfDf = pd.read_csv('Download/Cleaned Data/Self.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nosleepDfShort = nosleepDf[:2000].copy()\n",
    "selfDfShort = selfDf[:2000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c63350588a64c9b86593a98459d3979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0bc39c39a84cca858b7a6b30f357af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "selfDfShort['LF pooler output']= selfDfShort.progress_apply(LFencode, axis=1)\n",
    "nosleepDfShort['LF pooler output']= nosleepDfShort.progress_apply(LFencode, axis=1)\n",
    "\n",
    "selfDfShort.to_pickle('Download/Cleaned Data with Longformer/selfDfShort.pkl')\n",
    "nosleepDfShort.to_pickle('Download/Cleaned Data with Longformer/nosleepDfShort.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "nosleepDfShort = pd.read_pickle('Download/Cleaned Data with Longformer/nosleepDfShort.pkl')\n",
    "selfDfShort = pd.read_pickle('Download/Cleaned Data with Longformer/selfDfShort.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nosleepLF = tf.stack(nosleepDfShort.loc[:,'LF pooler output'].to_list())\n",
    "selfLF = tf.stack(selfDfShort.loc[:,'LF pooler output'].to_list())\n",
    "\n",
    "nosleepLF = tf.reshape(nosleepLF, nosleepLF.shape[::2])\n",
    "selfLF = tf.reshape(selfLF, selfLF.shape[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_embedded_nosleep = TSNE(perplexity=30, learning_rate=50, n_components=3, n_iter=5000).fit_transform(nosleepLF)\n",
    "X_embedded_self = TSNE(perplexity=30, learning_rate=50, n_components=3, n_iter=2000).fit_transform(selfLF)\n",
    "\n",
    "df1 = pd.DataFrame(X_embedded_nosleep, columns=['x','y', 'z'])\n",
    "df1['subreddit'] = 'nosleep'\n",
    "df2 = pd.DataFrame(X_embedded_self, columns=['x','y', 'z'])\n",
    "df2['subreddit'] = 'self'\n",
    "\n",
    "df = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.435028</td>\n",
       "      <td>-23.430191</td>\n",
       "      <td>27.846485</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.453467</td>\n",
       "      <td>13.920367</td>\n",
       "      <td>-1.642473</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.754526</td>\n",
       "      <td>26.287334</td>\n",
       "      <td>-27.450058</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.615822</td>\n",
       "      <td>-24.700964</td>\n",
       "      <td>24.934481</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.820519</td>\n",
       "      <td>22.547499</td>\n",
       "      <td>3.794347</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>6.502117</td>\n",
       "      <td>-14.733069</td>\n",
       "      <td>13.893977</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>3.216796</td>\n",
       "      <td>-5.083644</td>\n",
       "      <td>-8.147502</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-24.140860</td>\n",
       "      <td>2.374579</td>\n",
       "      <td>15.830630</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-5.080696</td>\n",
       "      <td>-0.582466</td>\n",
       "      <td>-19.006369</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-10.243524</td>\n",
       "      <td>-20.689852</td>\n",
       "      <td>21.245548</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y          z subreddit\n",
       "0      3.435028 -23.430191  27.846485   nosleep\n",
       "1     -0.453467  13.920367  -1.642473   nosleep\n",
       "2      9.754526  26.287334 -27.450058   nosleep\n",
       "3     -3.615822 -24.700964  24.934481   nosleep\n",
       "4     -1.820519  22.547499   3.794347   nosleep\n",
       "...         ...        ...        ...       ...\n",
       "1995   6.502117 -14.733069  13.893977      self\n",
       "1996   3.216796  -5.083644  -8.147502      self\n",
       "1997 -24.140860   2.374579  15.830630      self\n",
       "1998  -5.080696  -0.582466 -19.006369      self\n",
       "1999 -10.243524 -20.689852  21.245548      self\n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c727e44e5643e1a26ff8e9b24f29ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D,axes3d\n",
    "sns.set(style = \"darkgrid\")\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "\n",
    "ax.scatter(df[df['subreddit']=='nosleep']['x'], df[df['subreddit']=='nosleep']['y'], df[df['subreddit']=='nosleep']['z'], c='red', label='nosleep')\n",
    "ax.scatter(df[df['subreddit']=='self']['x'], df[df['subreddit']=='self']['y'], df[df['subreddit']=='self']['z'], c='blue', label='self')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nosleepLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 768), dtype=float32, numpy=\n",
       "array([[ 0.17356455, -0.28822845,  0.08040078, ..., -0.04949597,\n",
       "         0.17774035,  0.03145612],\n",
       "       [ 0.152154  , -0.3131358 ,  0.09661903, ..., -0.0544746 ,\n",
       "         0.20656316, -0.00459675],\n",
       "       [ 0.193991  , -0.3316983 ,  0.09307294, ..., -0.06202645,\n",
       "         0.20297652,  0.02324418],\n",
       "       ...,\n",
       "       [ 0.17017554, -0.34362826,  0.10915487, ..., -0.06822307,\n",
       "         0.20495556,  0.02520667],\n",
       "       [ 0.19672579, -0.34024084,  0.09063036, ..., -0.08465302,\n",
       "         0.18416663, -0.0188603 ],\n",
       "       [ 0.18555108, -0.3117493 ,  0.12184663, ..., -0.06562941,\n",
       "         0.18309756, -0.02888302]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creepy_features = nosleepLF\n",
    "creepy_labels = np.ones(len(creepy_features))\n",
    "creepy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 768), dtype=float32, numpy=\n",
       "array([[ 1.61632180e-01, -2.65369445e-01,  9.51929018e-02, ...,\n",
       "        -7.22304583e-02,  1.92816019e-01,  1.56589076e-02],\n",
       "       [ 1.28829047e-01, -2.89937794e-01,  7.89543763e-02, ...,\n",
       "        -4.83777523e-02,  1.91524208e-01,  6.91677677e-03],\n",
       "       [ 1.70354187e-01, -3.17211837e-01,  1.21957265e-01, ...,\n",
       "        -6.16075248e-02,  1.82307720e-01,  8.63182265e-03],\n",
       "       ...,\n",
       "       [ 1.67272553e-01, -2.53856778e-01,  9.05781314e-02, ...,\n",
       "        -7.19489008e-02,  1.67981252e-01,  2.79515982e-04],\n",
       "       [ 1.72974482e-01, -3.11384588e-01,  1.12448640e-01, ...,\n",
       "        -6.59727380e-02,  2.19963238e-01, -2.19200202e-03],\n",
       "       [ 1.66960493e-01, -2.52201796e-01,  1.04491428e-01, ...,\n",
       "        -8.50258991e-02,  1.67221159e-01,  2.78245900e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncreepy_features = selfLF\n",
    "noncreepy_labels = np.zeros(len(noncreepy_features))\n",
    "noncreepy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creepy_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7356455e-01 -2.8822845e-01  8.0400780e-02 ... -4.9495969e-02\n",
      "   1.7774035e-01  3.1456120e-02]\n",
      " [ 1.5215400e-01 -3.1313580e-01  9.6619032e-02 ... -5.4474600e-02\n",
      "   2.0656316e-01 -4.5967521e-03]\n",
      " [ 1.9399101e-01 -3.3169830e-01  9.3072943e-02 ... -6.2026449e-02\n",
      "   2.0297652e-01  2.3244182e-02]\n",
      " ...\n",
      " [ 1.6727255e-01 -2.5385678e-01  9.0578131e-02 ... -7.1948901e-02\n",
      "   1.6798125e-01  2.7951598e-04]\n",
      " [ 1.7297448e-01 -3.1138459e-01  1.1244864e-01 ... -6.5972738e-02\n",
      "   2.1996324e-01 -2.1920020e-03]\n",
      " [ 1.6696049e-01 -2.5220180e-01  1.0449143e-01 ... -8.5025899e-02\n",
      "   1.6722116e-01  2.7824590e-02]] [1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "features = np.concatenate((creepy_features, noncreepy_features))\n",
    "labels = np.concatenate((creepy_labels, noncreepy_labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 768) (4000,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17372166 -0.31675315  0.09627467 ... -0.06102977  0.19031945\n",
      "  -0.01382293]\n",
      " [ 0.18293348 -0.28995857  0.08175075 ... -0.0694469   0.18828677\n",
      "   0.00495734]\n",
      " [ 0.19889185 -0.34668326  0.08101564 ... -0.06365429  0.18032654\n",
      "   0.0013986 ]\n",
      " ...\n",
      " [ 0.19230823 -0.29125318  0.06716394 ... -0.06317285  0.17826806\n",
      "   0.03855895]\n",
      " [ 0.16728517 -0.2878742   0.09056299 ... -0.07442877  0.17100859\n",
      "  -0.02031929]\n",
      " [ 0.18101485 -0.3242344   0.09589295 ... -0.06436511  0.16940033\n",
      "  -0.00677954]] [0. 0. 1. ... 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "features, labels = shuffle(features, labels)\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50433403 0.3520987  0.44063362 ... 0.5626604  0.4912008  0.35618275]\n",
      " [0.58400923 0.498618   0.31242284 ... 0.51314497 0.4746709  0.47976592]\n",
      " [0.7220369  0.18843353 0.30593362 ... 0.5472211  0.4099375  0.45634773]\n",
      " ...\n",
      " [0.6650936  0.49153876 0.18365696 ... 0.55005324 0.39319777 0.7008805 ]\n",
      " [0.4486634  0.51001585 0.39021346 ... 0.48383814 0.33416295 0.31343365]\n",
      " [0.5674146  0.3111894  0.437264   ... 0.54303956 0.3210845  0.40253165]] [0. 0. 1. ... 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "print(scaled_features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] 70% train, 15% val, 15% test\n",
    " - Train: 26500\n",
    " - Valid: 5677\n",
    " - Test: 5669\n",
    "- [x] 80% train, 10% val, 10% test\n",
    "- [ ] 60% train, 20% val, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50433403, 0.58400923, 0.7220369 , ..., 0.6650936 , 0.4486634 ,\n",
       "       0.5674146 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = scaled_features\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins import projector\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-39dad67169ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m embedding_layer = Embedding(vocab_size,\n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             trainable=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(vocab_size,\n",
    "                            768,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTF = keras.Sequential([\n",
    "#     keras.layers.Dense(units = 303, input_shape = (769,), activation = 'relu'),\n",
    "#     keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units = 303, input_shape = (768,), activation = 'relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "#     keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 64, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 32, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 16, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 1, activation = 'sigmoid') # here the units must be 1 in order for binary classifications to work\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 303)               233007    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 303)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               38912     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 282,800\n",
      "Trainable params: 282,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelTF.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTF.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(lr=0.000959, beta_1 = 0.9, beta_2=0.999), # you can tune the learning rate here. Default lr = 0.01\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7158 - val_loss: 0.3894 - val_accuracy: 0.8250\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8536 - val_loss: 0.2440 - val_accuracy: 0.9025\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8852 - val_loss: 0.2365 - val_accuracy: 0.9125\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.8924 - val_loss: 0.1992 - val_accuracy: 0.9200\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.8925 - val_loss: 0.2098 - val_accuracy: 0.9200\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.9039 - val_loss: 0.2628 - val_accuracy: 0.9200\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9114 - val_loss: 0.1946 - val_accuracy: 0.9275\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9135 - val_loss: 0.2289 - val_accuracy: 0.9175\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9184 - val_loss: 0.2048 - val_accuracy: 0.9325\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.8922 - val_loss: 0.1770 - val_accuracy: 0.9350\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8763 - val_loss: 0.1780 - val_accuracy: 0.9325\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9139 - val_loss: 0.1810 - val_accuracy: 0.9325\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9241 - val_loss: 0.1827 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9147 - val_loss: 0.1874 - val_accuracy: 0.9200\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9122 - val_loss: 0.1881 - val_accuracy: 0.9325\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9125 - val_loss: 0.2139 - val_accuracy: 0.9200\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9197 - val_loss: 0.1987 - val_accuracy: 0.9225\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9037 - val_loss: 0.2069 - val_accuracy: 0.9200\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9185 - val_loss: 0.2098 - val_accuracy: 0.9350\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9049 - val_loss: 0.1753 - val_accuracy: 0.9350\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9249 - val_loss: 0.2385 - val_accuracy: 0.8825\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9182 - val_loss: 0.1711 - val_accuracy: 0.9375\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9229 - val_loss: 0.1777 - val_accuracy: 0.9325\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9296 - val_loss: 0.2062 - val_accuracy: 0.9125\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9203 - val_loss: 0.1789 - val_accuracy: 0.9300\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9280 - val_loss: 0.1936 - val_accuracy: 0.9275\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9270 - val_loss: 0.1733 - val_accuracy: 0.9350\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9330 - val_loss: 0.1882 - val_accuracy: 0.9225\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9179 - val_loss: 0.1991 - val_accuracy: 0.9150\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9197 - val_loss: 0.1700 - val_accuracy: 0.9350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12362), started 0:05:11 ago. (Use '!kill 12362' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ec726c35c29439ce\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ec726c35c29439ce\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir,\"tensorboard_logs\", \"longformer\")\n",
    "\n",
    "def get_run_log_dir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_log_dir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = modelTF.fit(X_train, y_train, epochs = 30, \n",
    "                   validation_data=(X_val, y_val),\n",
    "                   callbacks=[tensorboard_cb])\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tensorboard_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb14b3eb2aa941ebb3c18ed549a77ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid = True\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 966us/step - loss: 0.2477 - accuracy: 0.9025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24772435426712036, 0.9024999737739563]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTF.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rw_test(SAMPLE_TEXT):\n",
    "    input_ids = tf.expand_dims(tf.convert_to_tensor(tokenizer.encode(SAMPLE_TEXT)), 0) # batch of size 1\n",
    "\n",
    "    # model = model.cuda(); input_ids = input_ids.cuda()\n",
    "\n",
    "    # Attention mask values -- 0: no attention, 1: local attention, 2: global attention\n",
    "    attention_mask = tf.ones(input_ids.shape, dtype=tf.int32) # initialize to local attention\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = outputs.pooler_output\n",
    "    prediction = modelTF.predict(pooled_output)\n",
    "    return prediction\n",
    "#     print(np.argmax(prediction, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_TEXT1 = '''\n",
    "He's holding a knife behind me. He feels creepy to me.\n",
    "'''\n",
    "SAMPLE_TEXT2 = '''\n",
    "The leaves smell so good in the spring. That's why I like spring so much.\n",
    "'''\n",
    "SAMPLE_TEXT3 = '''\n",
    "He's holding a knife behind me. He feels creepy to me.\n",
    "The leaves smell so good in the spring. That's why I like spring so much.\n",
    "'''\n",
    "SAMPLE_TEXT4 = '''\n",
    "He's holding a knife behind me. He feels creepy to me.\n",
    "It's a little creepy to have someone like that around.\n",
    "Everything in this place screamed creepy order, which made her wonder what was wrong with the owner.\n",
    "'''\n",
    "SAMPLE_TEXT5 = '''\n",
    "He ran out of money, so he had to stop playing poker.\n",
    "If I don’t like something, I’ll stay away from it.\n",
    "I often see the time 11:11 or 12:34 on clocks.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE_TEXT1 [[0.62332803]]\n",
      "SAMPLE_TEXT2 [[0.5364992]]\n",
      "SAMPLE_TEXT3 [[0.6369032]]\n",
      "SAMPLE_TEXT4 [[0.7230916]]\n",
      "SAMPLE_TEXT5 [[0.5673562]]\n"
     ]
    }
   ],
   "source": [
    "print('SAMPLE_TEXT1', rw_test(SAMPLE_TEXT1))\n",
    "print('SAMPLE_TEXT2', rw_test(SAMPLE_TEXT2))\n",
    "print('SAMPLE_TEXT3', rw_test(SAMPLE_TEXT3))\n",
    "print('SAMPLE_TEXT4', rw_test(SAMPLE_TEXT4))\n",
    "print('SAMPLE_TEXT5', rw_test(SAMPLE_TEXT5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepyenv",
   "language": "python",
   "name": "creepyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
