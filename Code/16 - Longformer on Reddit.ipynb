{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at allenai/longformer-base-4096.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TFLongformerModel, LongformerTokenizerFast, LongformerConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "config = LongformerConfig.from_pretrained('allenai/longformer-base-4096')\n",
    "# choose the attention mode 'n2', 'tvm' or 'sliding_chunks'\n",
    "# 'n2': for regular n2 attantion\n",
    "# 'tvm': a custom CUDA kernel implementation of our sliding window attention\n",
    "# 'sliding_chunks': a PyTorch implementation of our sliding window attention\n",
    "config.attention_mode = 'sliding_chunks'\n",
    "\n",
    "model = TFLongformerModel.from_pretrained('allenai/longformer-base-4096', config = config)\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096')\n",
    "tokenizer.model_max_length = model.config.max_position_embeddings\n",
    "\n",
    "def LFencode(row):\n",
    "    SAMPLE_TEXT = row['selftext']\n",
    "    input_ids = tf.expand_dims(tf.convert_to_tensor(tokenizer.encode(SAMPLE_TEXT)), 0) # batch of size 1\n",
    "\n",
    "    # model = model.cuda(); input_ids = input_ids.cuda()\n",
    "\n",
    "    # Attention mask values -- 0: no attention, 1: local attention, 2: global attention\n",
    "    attention_mask = tf.ones(input_ids.shape, dtype=tf.int32) # initialize to local attention\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = outputs.pooler_output\n",
    "    return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4002])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "nosleepDf = pd.read_csv('Download/Cleaned Data/NoSleep.csv')\n",
    "selfDf = pd.read_csv('Download/Cleaned Data/Self.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nosleepDfShort = nosleepDf[:2000].copy()\n",
    "selfDfShort = selfDf[:2000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c63350588a64c9b86593a98459d3979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0bc39c39a84cca858b7a6b30f357af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "selfDfShort['LF pooler output']= selfDfShort.progress_apply(LFencode, axis=1)\n",
    "nosleepDfShort['LF pooler output']= nosleepDfShort.progress_apply(LFencode, axis=1)\n",
    "\n",
    "selfDfShort.to_pickle('Download/Cleaned Data with Longformer/selfDfShort.pkl')\n",
    "nosleepDfShort.to_pickle('Download/Cleaned Data with Longformer/nosleepDfShort.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "nosleepDfShort = pd.read_pickle('Download/Cleaned Data with Longformer/nosleepDfShort.pkl')\n",
    "selfDfShort = pd.read_pickle('Download/Cleaned Data with Longformer/selfDfShort.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nosleepLF = tf.stack(nosleepDfShort.loc[:,'LF pooler output'].to_list())\n",
    "selfLF = tf.stack(selfDfShort.loc[:,'LF pooler output'].to_list())\n",
    "\n",
    "nosleepLF = tf.reshape(nosleepLF, nosleepLF.shape[::2])\n",
    "selfLF = tf.reshape(selfLF, selfLF.shape[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_embedded_nosleep = TSNE(learning_rate=80, n_components=3).fit_transform(nosleepLF)\n",
    "X_embedded_self = TSNE(learning_rate=80, n_components=3).fit_transform(selfLF)\n",
    "\n",
    "df1 = pd.DataFrame(X_embedded_nosleep, columns=['x','y', 'z'])\n",
    "df1['subreddit'] = 'nosleep'\n",
    "df2 = pd.DataFrame(X_embedded_self, columns=['x','y', 'z'])\n",
    "df2['subreddit'] = 'self'\n",
    "\n",
    "df = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-38.624775</td>\n",
       "      <td>-2.294882</td>\n",
       "      <td>20.955492</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.792412</td>\n",
       "      <td>-15.289292</td>\n",
       "      <td>14.973711</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.421726</td>\n",
       "      <td>9.070208</td>\n",
       "      <td>7.038894</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-40.429996</td>\n",
       "      <td>-4.475523</td>\n",
       "      <td>14.154373</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.247477</td>\n",
       "      <td>-15.553728</td>\n",
       "      <td>0.569228</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>22.816322</td>\n",
       "      <td>-13.808095</td>\n",
       "      <td>1.618495</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-10.423856</td>\n",
       "      <td>22.686611</td>\n",
       "      <td>-3.754926</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>21.218271</td>\n",
       "      <td>17.061604</td>\n",
       "      <td>19.053509</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-9.011683</td>\n",
       "      <td>2.076463</td>\n",
       "      <td>-19.166342</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>47.524239</td>\n",
       "      <td>13.626618</td>\n",
       "      <td>12.902069</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y          z subreddit\n",
       "0    -38.624775  -2.294882  20.955492   nosleep\n",
       "1      0.792412 -15.289292  14.973711   nosleep\n",
       "2     40.421726   9.070208   7.038894   nosleep\n",
       "3    -40.429996  -4.475523  14.154373   nosleep\n",
       "4      0.247477 -15.553728   0.569228   nosleep\n",
       "...         ...        ...        ...       ...\n",
       "1995  22.816322 -13.808095   1.618495      self\n",
       "1996 -10.423856  22.686611  -3.754926      self\n",
       "1997  21.218271  17.061604  19.053509      self\n",
       "1998  -9.011683   2.076463 -19.166342      self\n",
       "1999  47.524239  13.626618  12.902069      self\n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c183291b8d294934888e98f29d731444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D,axes3d\n",
    "sns.set(style = \"darkgrid\")\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"z\")\n",
    "\n",
    "ax.scatter(df[df['subreddit']=='nosleep']['x'], df[df['subreddit']=='nosleep']['y'], df[df['subreddit']=='nosleep']['z'], c='red', label='nosleep')\n",
    "ax.scatter(df[df['subreddit']=='self']['x'], df[df['subreddit']=='self']['y'], df[df['subreddit']=='self']['z'], c='blue', label='self')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Z = axes3d.get_test_data(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -20.150057\n",
       "1      -12.655766\n",
       "2       -8.502742\n",
       "3      -14.510887\n",
       "4      -23.239290\n",
       "          ...    \n",
       "1995   -10.086859\n",
       "1996    32.394302\n",
       "1997     7.504486\n",
       "1998   -14.713305\n",
       "1999   -16.362164\n",
       "Name: z, Length: 2000, dtype: float32"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['subreddit']=='nosleep']['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00982064, -0.01319036, -0.01754004, ..., -0.023092  ,\n",
       "        -0.01754004, -0.01319036],\n",
       "       [-0.01319036, -0.01771632, -0.02355849, ..., -0.03101548,\n",
       "        -0.02355849, -0.01771632],\n",
       "       [-0.01754004, -0.02355849, -0.03132719, ..., -0.0412432 ,\n",
       "        -0.03132719, -0.02355849],\n",
       "       ...,\n",
       "       [-0.01373043, -0.01985735, -0.02800271, ...,  0.11812427,\n",
       "         0.11827665,  0.11591304],\n",
       "       [-0.01289122, -0.01801753, -0.02475215, ...,  0.04437913,\n",
       "         0.04788803,  0.04940405],\n",
       "       [-0.01097235, -0.01507265, -0.02042145, ...,  0.00983613,\n",
       "         0.01423619,  0.01709512]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepy-venv",
   "language": "python",
   "name": "creepy-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
