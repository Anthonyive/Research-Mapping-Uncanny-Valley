{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "df = pd.read_csv('Download/Cleaned Data/NoSleep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ''.join([''.join(i) for i in df.sample()['selftext']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 112 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import neuralcoref\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "\n",
    "def get_entity_pairs(text, coref=True):\n",
    "    # preprocess text\n",
    "    text = re.sub(r'\\n+', '.', text)  # replace multiple newlines with period\n",
    "    text = re.sub(r'\\[\\d+\\]', ' ', text)  # remove reference numbers\n",
    "    text = nlp(text)\n",
    "    if coref:\n",
    "        text = nlp(text._.coref_resolved)  # resolve coreference clusters\n",
    "\n",
    "    def refine_ent(ent, sent):\n",
    "        unwanted_tokens = (\n",
    "            'PRON',  # pronouns\n",
    "            'PART',  # particle\n",
    "            'DET',  # determiner\n",
    "            'SCONJ',  # subordinating conjunction\n",
    "            'PUNCT',  # punctuation\n",
    "            'SYM',  # symbol\n",
    "            'X',  # other\n",
    "        )\n",
    "        ent_type = ent.ent_type_  # get entity type\n",
    "        if ent_type == '':\n",
    "            ent_type = 'NOUN_CHUNK'\n",
    "            ent = ' '.join(str(t.text) for t in\n",
    "                           nlp(str(ent)) if t.pos_\n",
    "                           not in unwanted_tokens and t.is_stop == False)\n",
    "        elif ent_type in ('NOMINAL', 'CARDINAL', 'ORDINAL') and str(ent).find(' ') == -1:\n",
    "            refined = ''\n",
    "            for i in range(len(sent) - ent.i):\n",
    "                if ent.nbor(i).pos_ not in ('VERB', 'PUNCT'):\n",
    "                    refined += ' ' + str(ent.nbor(i))\n",
    "                else:\n",
    "                    ent = refined.strip()\n",
    "                    break\n",
    "\n",
    "        return ent, ent_type\n",
    "\n",
    "    sentences = [sent.string.strip() for sent in text.sents]  # split text into sentences\n",
    "    ent_pairs = []\n",
    "    for sent in sentences:\n",
    "        sent = nlp(sent)\n",
    "        spans = list(sent.ents) + list(sent.noun_chunks)  # collect nodes\n",
    "        spans = spacy.util.filter_spans(spans)\n",
    "        with sent.retokenize() as retokenizer:\n",
    "            [retokenizer.merge(span, attrs={'tag': span.root.tag,\n",
    "                                            'dep': span.root.dep}) for span in spans]\n",
    "        deps = [token.dep_ for token in sent]\n",
    "\n",
    "        # limit our example to simple sentences with one subject and object\n",
    "        if (deps.count('obj') + deps.count('dobj')) != 1\\\n",
    "                or (deps.count('subj') + deps.count('nsubj')) != 1:\n",
    "            continue\n",
    "\n",
    "        for token in sent:\n",
    "            if token.dep_ not in ('obj', 'dobj'):  # identify object nodes\n",
    "                continue\n",
    "            subject = [w for w in token.head.lefts if w.dep_\n",
    "                       in ('subj', 'nsubj')]  # identify subject nodes\n",
    "            if subject:\n",
    "                subject = subject[0]\n",
    "                # identify relationship by root dependency\n",
    "                relation = [w for w in token.ancestors if w.dep_ == 'ROOT']\n",
    "                if relation:\n",
    "                    relation = relation[0]\n",
    "                    # add adposition or particle to relationship\n",
    "                    if relation.nbor(1).pos_ in ('ADP', 'PART'):\n",
    "                        relation = ' '.join((str(relation), str(relation.nbor(1))))\n",
    "                else:\n",
    "                    relation = 'unknown'\n",
    "\n",
    "                subject, subject_type = refine_ent(subject, sent)\n",
    "                token, object_type = refine_ent(token, sent)\n",
    "\n",
    "                ent_pairs.append([str(subject), str(relation), str(token),\n",
    "                                  str(subject_type), str(object_type)])\n",
    "\n",
    "    ent_pairs = [sublist for sublist in ent_pairs\n",
    "                          if not any(str(ent) == '' for ent in sublist)]\n",
    "    pairs = pd.DataFrame(ent_pairs, columns=['subject', 'relation', 'object',\n",
    "                                             'subject_type', 'object_type'])\n",
    "    print('Entity pairs extracted:', str(len(ent_pairs)))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entity_pairs(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepy-venv",
   "language": "python",
   "name": "creepy-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
