{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] github-afr-neural-folkales\n",
    "- [ ] Folklore and Mythology Electronic Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folklore and Mythology Electronic Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_stories(url, directory = \"Download/Folktales and Myths/raw data/Folklore and Mythology Electronic Texts\"):\n",
    "    import os\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    \n",
    "    out = dict()\n",
    "    \n",
    "    try:\n",
    "        PATH = os.path.join(directory, soup.find('h1').get_text().strip())\n",
    "    except AttributeError:\n",
    "        PATH = os.path.join(directory, soup.find('h2').get_text().strip())\n",
    "    \n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    sections = str(soup).split('<hr/>')\n",
    "    titles = [a.get_text().replace('\\n',' ').strip() for a in soup.find_all('a',attrs={'name': True}) if a.get_text() != \"Contents\"]\n",
    "\n",
    "    count = 0\n",
    "    for section in sections:\n",
    "        soup2 = BeautifulSoup(section)\n",
    "        possible_title = [a.get_text().replace('\\n',' ').strip() for a in soup2.find_all('a', attrs={'name':True})]\n",
    "        if len(possible_title) == 1 and possible_title[0] in titles:\n",
    "            text = soup2.get_text()\n",
    "            file = os.path.join(PATH, possible_title[0])\n",
    "            n = 1\n",
    "            while os.path.isfile(file+\".txt\"):\n",
    "                file = os.path.join(PATH, possible_title[0] + f\"({n})\")\n",
    "                n+=1\n",
    "                \n",
    "            file = os.path.split(file)\n",
    "            try:\n",
    "                with open((file[0] + '/' +file[1].replace('/','')+\".txt\"), 'w') as f:\n",
    "                    f.write(text)\n",
    "                    count += 1\n",
    "            except:\n",
    "                pass\n",
    "        elif len(possible_title) != 0:\n",
    "            out['possible title'] = possible_title\n",
    "\n",
    "    try:\n",
    "        if count == len(titles):\n",
    "            out['title'] = soup.find('h1').get_text().strip()\n",
    "            out['stories'] = titles\n",
    "            out['number of stories'] = len(titles)\n",
    "            out['message'] = f\"Successfully scrapped {count} stories in {soup.find('h1').get_text().strip()}\"\n",
    "            out['url'] = res.url\n",
    "        else:\n",
    "            out['title'] = soup.find('h1').get_text().strip()\n",
    "            out['stories'] = titles\n",
    "            out['number of stories'] = len(titles)\n",
    "            out['message'] = f\"Successfully scrapped {count} stories in {soup.find('h1').get_text().strip()}, but {len(titles)-count} does/do not get scrapped\"\n",
    "            out['url'] = res.url\n",
    "    except:\n",
    "        if count == len(titles):\n",
    "            out['title'] = soup.find('h2').get_text().strip()\n",
    "            out['stories'] = titles\n",
    "            out['number of stories'] = len(titles)\n",
    "            out['message'] = f\"Successfully scrapped {count} stories in {soup.find('h2').get_text().strip()}\"\n",
    "            out['url'] = res.url\n",
    "        else:\n",
    "            out['title'] = soup.find('h2').get_text().strip()\n",
    "            out['stories'] = titles\n",
    "            out['number of stories'] = len(titles)\n",
    "            out['message'] = f\"Successfully scrapped {count} stories in {soup.find('h2').get_text().strip()}, but {len(titles)-count} does/do not get scrapped\"\n",
    "            out['url'] = res.url\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://www.pitt.edu/~dash/folktexts2.html\"\n",
    "\n",
    "res1 = requests.get(url1)\n",
    "soup1 = BeautifulSoup(res1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b19c64c25b49d3b0fd1fa01c5360f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, pprint,json\n",
    "from tqdm.notebook import tqdm\n",
    "pp=pprint.PrettyPrinter(indent=4)\n",
    "li = []\n",
    "for link in tqdm(soup1.select(\"h1+ ul a\")):\n",
    "    if link.get('href'):\n",
    "        if not link.get('href').startswith(\"http\"):\n",
    "            out = scrap_stories(os.path.join(\"https://www.pitt.edu/~dash\", link.get('href')))\n",
    "            li.append(out)\n",
    "with open('Download/Folktales and Myths/metadata/Folklore and Mythology Electronic Texts.json', 'w') as f:\n",
    "    json.dump(li, f)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = scrap_stories(\"https://web.archive.org/web/20090224073548/http://www.pitt.edu/~dash/china.html\")\n",
    "with open('Download/Folktales and Myths/metadata/Folktales from China.json', 'w') as f:\n",
    "    json.dump(out, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The King James Version of the Bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 28\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "PATH = \"Download/Folktales and Myths/raw data/The King James Version of the Bible\"\n",
    "\n",
    "CHAPTERS1 = [\n",
    "    \"The First Book of Moses: Called Genesis\",\n",
    "    \"The Second Book of Moses: Called Exodus\",\n",
    "    \"The Third Book of Moses: Called Leviticus\",\n",
    "    \"The Fourth Book of Moses: Called Numbers\",\n",
    "    \"The Fifth Book of Moses: Called Deuteronomy\",\n",
    "    \"The Book of Joshua\",\n",
    "    \"The Book of Judges\",\n",
    "    \"The Book of Ruth\",\n",
    "    \"The First Book of Samuel\",\n",
    "    \"The Second Book of Samuel\",\n",
    "    \"The First Book of the Kings\",\n",
    "    \"The Second Book of the Kings\",\n",
    "    \"The First Book of the Chronicles\",\n",
    "    \"The Second Book of the Chronicles\",\n",
    "    \"Ezra\",\n",
    "    \"The Book of Nehemiah\",\n",
    "    \"The Book of Esther\",\n",
    "    \"The Book of Job\",\n",
    "    \"The Book of Psalms\",\n",
    "    \"The Proverbs\",\n",
    "    \"Ecclesiastes\",\n",
    "    \"The Song of Solomon\",\n",
    "    \"The Book of the Prophet Isaiah\",\n",
    "    \"The Book of the Prophet Jeremiah\",\n",
    "    \"The Lamentations of Jeremiah\",\n",
    "    \"The Book of the Prophet Ezekiel\",\n",
    "    \"The Book of Daniel\",\n",
    "    \"Hosea\",\n",
    "    \"Joel\",\n",
    "    \"Amos\",\n",
    "    \"Obadiah\",\n",
    "    \"Jonah\",\n",
    "    \"Micah\",\n",
    "    \"Nahum\",\n",
    "    \"Habakkuk\",\n",
    "    \"Zephaniah\",\n",
    "    \"Haggai\",\n",
    "    \"Zechariah\",\n",
    "    \"Malachi\"]\n",
    "\n",
    "CHAPTERS2 = [\n",
    "    \"The Gospel According to Saint Matthew\",\n",
    "    \"The Gospel According to Saint Mark\",\n",
    "    \"The Gospel According to Saint Luke\",\n",
    "    \"The Gospel According to Saint John\",\n",
    "    \"The Acts of the Apostles\",\n",
    "    \"The Epistle of Paul the Apostle to the Romans\",\n",
    "    \"The First Epistle of Paul the Apostle to the Corinthians\",\n",
    "    \"The Second Epistle of Paul the Apostle to the Corinthians\",\n",
    "    \"The Epistle of Paul the Apostle to the Galatians\",\n",
    "    \"The Epistle of Paul the Apostle to the Ephesians\",\n",
    "    \"The Epistle of Paul the Apostle to the Philippians\",\n",
    "    \"The Epistle of Paul the Apostle to the Colossians\",\n",
    "    \"The First Epistle of Paul the Apostle to the Thessalonians\",\n",
    "    \"The Second Epistle of Paul the Apostle to the Thessalonians\",\n",
    "    \"The First Epistle of Paul the Apostle to Timothy\",\n",
    "    \"The Second Epistle of Paul the Apostle to Timothy\",\n",
    "    \"The Epistle of Paul the Apostle to Titus\",\n",
    "    \"The Epistle of Paul the Apostle to Philemon\",\n",
    "    \"The Epistle of Paul the Apostle to the Hebrews\",\n",
    "    \"The General Epistle of James\",\n",
    "    \"The First Epistle General of Peter\",\n",
    "    \"The Second General Epistle of Peter\",\n",
    "    \"The First Epistle General of John\",\n",
    "    \"The Second Epistle General of John\",\n",
    "    \"The Third Epistle General of John\",\n",
    "    \"The General Epistle of Jude\",\n",
    "    \"The Revelation of Saint John the Devine\"\n",
    "]\n",
    "with open(os.path.join(PATH, 'The New Testament of the King James Bible/The New Testament.txt'), 'r') as f:\n",
    "    allText = f.read()\n",
    "    \n",
    "    parts = re.split('|'.join(CHAPTERS2), allText)\n",
    "    print(len(CHAPTERS2),len(parts))\n",
    "    \n",
    "    for t, p in zip(CHAPTERS2, parts[1:]):\n",
    "        text = t + p\n",
    "        with open(os.path.join(PATH, 'The New Testament of the King James Bible/splitted by chapters', t+'.txt'), 'w') as f1:\n",
    "            f1.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "PATH = \"Download/Folktales and Myths/raw data/The King James Version of the Bible\"\n",
    "\n",
    "CHAPTERS1 = [\n",
    "    \"The First Book of Moses: Called Genesis\",\n",
    "    \"The Second Book of Moses: Called Exodus\",\n",
    "    \"The Third Book of Moses: Called Leviticus\",\n",
    "    \"The Fourth Book of Moses: Called Numbers\",\n",
    "    \"The Fifth Book of Moses: Called Deuteronomy\",\n",
    "    \"The Book of Joshua\",\n",
    "    \"The Book of Judges\",\n",
    "    \"The Book of Ruth\",\n",
    "    \"The First Book of Samuel\",\n",
    "    \"The Second Book of Samuel\",\n",
    "    \"The First Book of the Kings\",\n",
    "    \"The Second Book of the Kings\",\n",
    "    \"The First Book of the Chronicles\",\n",
    "    \"The Second Book of the Chronicles\",\n",
    "    \"Ezra\",\n",
    "    \"The Book of Nehemiah\",\n",
    "    \"The Book of Esther\",\n",
    "    \"The Book of Job\",\n",
    "    \"The Book of Psalms\",\n",
    "    \"The Proverbs\",\n",
    "    \"Ecclesiastes\",\n",
    "    \"The Song of Solomon\",\n",
    "    \"The Book of the Prophet Isaiah\",\n",
    "    \"The Book of the Prophet Jeremiah\",\n",
    "    \"The Lamentations of Jeremiah\",\n",
    "    \"The Book of the Prophet Ezekiel\",\n",
    "    \"The Book of Daniel\",\n",
    "    \"Hosea\",\n",
    "    \"Joel\",\n",
    "    \"Amos\",\n",
    "    \"Obadiah\",\n",
    "    \"Jonah\",\n",
    "    \"Micah\",\n",
    "    \"Nahum\",\n",
    "    \"Habakkuk\",\n",
    "    \"Zephaniah\",\n",
    "    \"Haggai\",\n",
    "    \"Zechariah\",\n",
    "    \"Malachi\"]\n",
    "\n",
    "CHAPTERS2 = [\n",
    "    \"The Gospel According to Saint Matthew\",\n",
    "    \"The Gospel According to Saint Mark\",\n",
    "    \"The Gospel According to Saint Luke\",\n",
    "    \"The Gospel According to Saint John\",\n",
    "    \"The Acts of the Apostles\",\n",
    "    \"The Epistle of Paul the Apostle to the Romans\",\n",
    "    \"The First Epistle of Paul the Apostle to the Corinthians\",\n",
    "    \"The Second Epistle of Paul the Apostle to the Corinthians\",\n",
    "    \"The Epistle of Paul the Apostle to the Galatians\",\n",
    "    \"The Epistle of Paul the Apostle to the Ephesians\",\n",
    "    \"The Epistle of Paul the Apostle to the Philippians\",\n",
    "    \"The Epistle of Paul the Apostle to the Colossians\",\n",
    "    \"The First Epistle of Paul the Apostle to the Thessalonians\",\n",
    "    \"The Second Epistle of Paul the Apostle to the Thessalonians\",\n",
    "    \"The First Epistle of Paul the Apostle to Timothy\",\n",
    "    \"The Second Epistle of Paul the Apostle to Timothy\",\n",
    "    \"The Epistle of Paul the Apostle to Titus\",\n",
    "    \"The Epistle of Paul the Apostle to Philemon\",\n",
    "    \"The Epistle of Paul the Apostle to the Hebrews\",\n",
    "    \"The General Epistle of James\",\n",
    "    \"The First Epistle General of Peter\",\n",
    "    \"The Second General Epistle of Peter\",\n",
    "    \"The First Epistle General of John\",\n",
    "    \"The Second Epistle General of John\",\n",
    "    \"The Third Epistle General of John\",\n",
    "    \"The General Epistle of Jude\",\n",
    "    \"The Revelation of Saint John the Devine\"\n",
    "]\n",
    "\n",
    "url = \"https://www.gutenberg.org/files/10/10-h/10-h.htm\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chapter in soup.find_all('div', attrs={'class':'chapter'})[1:]:\n",
    "    name = chapter.h2.get_text().replace('  ',' ')\n",
    "    nowChap = name.strip()\n",
    "    if name.strip() in CHAPTERS1:\n",
    "        with open(os.path.join(PATH, 'The Old Testament of the King James Version of the Bible/splitted by chapters', nowChap + '.txt'), 'a+') as f:\n",
    "            f.write(name + '\\n')\n",
    "            for p in [p.get_text() for p in chapter.find_all('p')]:\n",
    "                f.write(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH, 'The Old Testament of the King James Version of the Bible/The Old Testament.txt'), 'r') as f:\n",
    "    nowChap = ''\n",
    "    for line in f:\n",
    "        if line.strip() in CHAPTERS1:\n",
    "            with open(os.path.join(PATH, 'The Old Testament of the King James Version of the Bible/splitted by chapters', line.strip() + '.txt'), 'a+') as f:\n",
    "                f.write(line)\n",
    "                nowChap = line.strip()\n",
    "        else:\n",
    "            with open(os.path.join(PATH, 'The Old Testament of the King James Version of the Bible/splitted by chapters', nowChap+ '.txt'), 'a+') as f:\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'The King James Version of the Bible', 'url': 'https://www.gutenberg.org/files/10/10-h/10-h.htm'}\n",
    "with open('Download/Folktales and Myths/metadata/The King James Version of the Bible.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Epic of Atraḥasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://www.livius.org/sources/content/anet/104-106-the-epic-of-atrahasis/\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text)\n",
    "PATH = \"Download/Folktales and Myths/raw data/The Epic of Atraḥasis\"\n",
    "CHAPTERS = [a.get_text() for a in soup.select(\"#content h4 , p~ p+ h3 , h3+ h3\")]\n",
    "len(CHAPTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>The Epic of Atraḥasis</h1>\n"
     ]
    }
   ],
   "source": [
    "for article in soup.find_all(id=\"content\"):\n",
    "    print(article.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'The Epic of Atraḥasis', 'url': 'https://www.livius.org/sources/content/anet/104-106-the-epic-of-atrahasis/'}\n",
    "with open('Download/Folktales and Myths/metadata/The Epic of Atraḥasis.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 tablets of creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [{'title': 'Title Page', 'url': 'https://www.sacred-texts.com/ane/stc/stc00.htm'},\n",
    " {'title': 'Preface', 'url': 'https://www.sacred-texts.com/ane/stc/stc01.htm'},\n",
    " {'title': 'Content', 'url': 'https://www.sacred-texts.com/ane/stc/stc02.htm'},\n",
    " {'title': 'Introduction', 'url': 'https://www.sacred-texts.com/ane/stc/stc03.htm'},\n",
    " {'title': 'The First Tablet', 'url': 'https://www.sacred-texts.com/ane/stc/stc04.htm'},\n",
    " {'title': 'The Second Tablet', 'url': 'https://www.sacred-texts.com/ane/stc/stc05.htm'},\n",
    " {'title': 'The Third Tablet', 'url': 'https://www.sacred-texts.com/ane/stc/stc06.htm'},\n",
    " {'title': 'The Fourth Tablet', 'url': 'https://www.sacred-texts.com/ane/stc/stc07.htm'},\n",
    " {'title': 'The Fifth Tablet', 'url': 'https://www.sacred-texts.com/ane/stc/stc08.htm'},\n",
    " {'title': 'The Sixth Tablet', 'url': 'https://www.sacred-texts.com/ane/stc/stc09.htm'},\n",
    " {'title': 'The Seventh Tablet', 'url': 'https://www.sacred-texts.com/ane/stc/stc10.htm'},\n",
    " {'title': 'I. Another Version of the Dragon-Myth', 'url': 'https://www.sacred-texts.com/ane/stc/stc11.htm'},\n",
    " {'title': 'II. A Reference to the Creation of the Cattle and the Beasts of the Field', 'url': 'https://www.sacred-texts.com/ane/stc/stc12.htm'},\n",
    " {'title': 'III. A reference to the Creation of the Moon and the Sun', 'url': 'https://www.sacred-texts.com/ane/stc/stc13.htm'},\n",
    " {'title': 'IV. An Address to the River of Creation', 'url': 'https://www.sacred-texts.com/ane/stc/stc14.htm'},\n",
    " {'title': 'V. Another Version of the Creation of the World by Marduk', 'url': 'https://www.sacred-texts.com/ane/stc/stc15.htm'},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Download/Folktales and Myths/metadata/The Seven Tablets of Creation.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE METAMORPHOSES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'THE METAMORPHOSES', 'url': 'http://www.gutenberg.org/files/21765/21765-h/files/Met_IV-VII.html'}\n",
    "with open('Download/Folktales and Myths/metadata/THE METAMORPHOSES.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"http://www.gutenberg.org/files/21765/21765-h/files/Met_I-III.html\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text)\n",
    "\n",
    "PATH = \"Download/Folktales and Myths/raw data/THE METAMORPHOSES.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOOK THE FIRST.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c680af1540e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'span'\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hr'\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'pagenum mckay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linnum mckay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pagenum bell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linenum bell'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Research-Mapping-Uncanny-Valley-DSc8QBrC/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\n\u001b[1;32m   1405\u001b[0m         and throws an exception if it's not there.\"\"\"\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "for content in soup.find_all('span', attrs={'class':'pagenum mckay'}):\n",
    "    currentBOOK = None\n",
    "    while content.next_sibling:\n",
    "#         print(content.find_next())\n",
    "        content = content.next_sibling\n",
    "        \n",
    "        if isinstance(content, NavigableString):\n",
    "            continue\n",
    "        if isinstance(content, Tag):\n",
    "            if content.name == 'span' or \\\n",
    "                content.name == 'hr' or \\\n",
    "                content['class'] in ['pagenum mckay', 'linnum mckay', 'pagenum bell', 'linenum bell'] :\n",
    "                continue\n",
    "            \n",
    "            elif content.name == 'h4':\n",
    "                print(content.get_text())\n",
    "                currentBOOK = content.get_text().strip()\n",
    "                directory = os.path.join(PATH, currentBOOK)\n",
    "                if not os.path.exists(directory):\n",
    "                    os.makedirs(directory)\n",
    "            elif content.name == 'h5':\n",
    "                currentFILE = content.get_text().strip()\n",
    "                open(os.path.join(directory, currentFILE + \"txt\"), 'a').close()\n",
    "            else:\n",
    "                if content.name == 'span' or \\\n",
    "                    content.name == 'hr' or \\\n",
    "                    content['class'] in ['pagenum mckay', 'linnum mckay', 'pagenum bell', 'linenum bell']:\n",
    "                \n",
    "                    with open(os.path.join(directory, currentFILE + \"txt\"), 'a+') as f:\n",
    "                        f.write(content.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(os.path.join(PATH, 'splitted by books'))\n",
    "with open(os.path.join(PATH, \"Hesiod, The Homeric Hymns, and Homerica.txt\"), 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        if fname.startswith('.'):\n",
    "            continue\n",
    "        with open(os.path.join(PATH, 'splitted by books',fname)) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOOK XX.txt',\n",
       " 'BOOK XVI.txt',\n",
       " 'BOOK IV.txt',\n",
       " 'BOOK XXIV.txt',\n",
       " 'BOOK XII.txt',\n",
       " 'BOOK XV.txt',\n",
       " 'BOOK XIX.txt',\n",
       " 'BOOK XVII.txt',\n",
       " 'BOOK III.txt',\n",
       " 'BOOK VI.txt',\n",
       " 'BOOK XXII.txt',\n",
       " 'BOOK XIII.txt',\n",
       " 'BOOK V.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'BOOK XIV.txt',\n",
       " 'BOOK IX.txt',\n",
       " 'BOOK VII.txt',\n",
       " 'BOOK X.txt',\n",
       " 'BOOK VIII.txt',\n",
       " 'BOOK XI.txt',\n",
       " 'BOOK XXIII.txt',\n",
       " 'BOOK II.txt',\n",
       " 'BOOK XVIII.txt',\n",
       " 'BOOK I.txt',\n",
       " 'BOOK XXI.txt']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(PATH, 'splitted by books'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github-afr-neural-folktales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'github-afr-neural-folktales', 'url': 'https://github.com/GossaLo/afr-neural-folktales/'}\n",
    "with open('Download/Folktales and Myths/metadata/github-afr-neural-folktales.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Download/Folktales and Myths/raw data/github-afr-neural-folktales/input_eur.txt', 'r') as f:\n",
    "    stories = f.read().split('\\n\\n')\n",
    "    for i,story in enumerate(stories):\n",
    "        with open(f'Download/Folktales and Myths/raw data/github-afr-neural-folktales/splitted eur/{i}.txt', 'w') as f1:\n",
    "            f1.write(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eridu Genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'Eridu Genesis', 'url': 'https://www.livius.org/sources/content/oriental-varia/eridu-genesis/'}\n",
    "with open('Download/Folktales and Myths/metadata/Eridu Genesis.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOOK OF SONGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'BOOK OF SONGS', 'url': 'https://web.archive.org/web/20110828200801/http://mockingbird.creighton.edu/english/worldlit/wldocs/churchill/bksongs.htm'}\n",
    "with open('Download/Folktales and Myths/metadata/BOOK OF SONGS.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eridu Genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'Eridu Genesis', 'url': 'https://www.livius.org/sources/content/oriental-varia/eridu-genesis/'}\n",
    "with open('Download/Folktales and Myths/metadata/Eridu Genesis.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAPA AND THE FOOD OF LIFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'ADAPA AND THE FOOD OF LIFE', 'url': 'https://www.sacred-texts.com/ane/adapa.htm'}\n",
    "with open('Download/Folktales and Myths/metadata/ADAPA AND THE FOOD OF LIFE.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Epic Of Gilgamesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'The Epic Of Gilgamesh', 'url': 'https://archive.org/stream/TheEpicofGilgamesh_201606/eog_djvu.txt'}\n",
    "with open('Download/Folktales and Myths/metadata/The Epic Of Gilgamesh.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE ILIAD OF HOMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'THE ILIAD OF HOMER', 'url': 'https://www.gutenberg.org/files/2199/2199-h/2199-h.htm'}\n",
    "with open('Download/Folktales and Myths/metadata/THE ILIAD OF HOMER.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Odyssey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'The Odyssey', 'url': 'http://www.gutenberg.org/files/1727/1727-h/1727-h.htm'}\n",
    "with open('Download/Folktales and Myths/metadata/The Odyssey.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hesiod, The Homeric Hymns, and Homerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {'name': 'Hesiod, The Homeric Hymns, and Homerica', 'url': 'http://www.gutenberg.org/files/348/348-h/348-h.htm'}\n",
    "with open('Download/Folktales and Myths/metadata/Hesiod, The Homeric Hymns, and Homerica.json', 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepy-venv",
   "language": "python",
   "name": "creepy-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
