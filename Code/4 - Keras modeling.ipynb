{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "%rm -rf ../my_logs/\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy = pd.read_pickle('../pickles/new/creepy_with_log.pickle')\n",
    "noncreepy = pd.read_pickle('../pickles/new/non-creepy_with_log.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy_sum_vec_with_log_prepended = creepy.loc[:,'sum_vec_with_log_prepended'].copy()\n",
    "noncreepy_sum_vec_with_log_prepended = noncreepy.loc[:,'sum_vec_with_log_prepended'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "creepy_features = pd.DataFrame(creepy_sum_vec_with_log_prepended.to_list()).to_numpy(dtype = float)\n",
    "creepy_labels = np.ones(len(creepy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncreepy_features = pd.DataFrame(noncreepy_sum_vec_with_log_prepended.to_list()).to_numpy(dtype = float)\n",
    "noncreepy_labels = np.zeros(len(noncreepy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.69813472   2.94098592  -5.6173358  ...  -4.59305143   0.358845\n",
      "   -9.06916523]\n",
      " [  0.69813472   2.94098592  -5.6173358  ...  -4.59305143   0.358845\n",
      "   -9.06916523]\n",
      " [  0.69813472 -19.20127296 -13.71549892 ...  18.18037987 -16.4872303\n",
      "   -6.75176859]\n",
      " ...\n",
      " [  0.69813472  -0.78924334   0.29064384 ...   1.36802995  -3.79267383\n",
      "   -1.91743255]\n",
      " [  0.69813472   2.08661604  -1.43281949 ...  -1.90943027   3.40888762\n",
      "    0.54635704]\n",
      " [  0.69813472  -1.46298337  -2.17777109 ...   1.96948338  -0.8519302\n",
      "   -2.56011105]] [1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "features = np.concatenate((creepy_features, noncreepy_features))\n",
    "labels = np.concatenate((creepy_labels, noncreepy_labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37846, 769) (37846,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.69813472 -10.14688206  -2.69109821 ...   2.92665863   0.09598967\n",
      "   -0.98659277]\n",
      " [  0.69813472  15.80326176 -16.40266037 ...  10.43215942  -1.54072356\n",
      "  -45.22399139]\n",
      " [  0.69813472  -4.45459461 -16.06407356 ...   7.80358696  -9.96741962\n",
      "  -10.5227108 ]\n",
      " ...\n",
      " [  0.69813472   0.40160212   0.35084647 ...   0.34956357  -0.33810857\n",
      "   -0.39098385]\n",
      " [  0.69813472 -15.07464695   1.31229532 ...  -6.25344706  15.48017788\n",
      "  -51.77959061]\n",
      " [  0.69813472   4.75524092   0.67838889 ...   0.90226686  -6.84710979\n",
      "   -7.14033556]] [0. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "features, labels = shuffle(features, labels)\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.92331402 0.59881127 ... 0.84514068 0.4721195  0.42064573]\n",
      " [0.         0.9315895  0.5901235  ... 0.8505247  0.47071365 0.40511297]\n",
      " [0.         0.92512928 0.59033803 ... 0.84863911 0.4634756  0.41729738]\n",
      " ...\n",
      " [0.         0.92667792 0.60073868 ... 0.84329202 0.47174663 0.42085486]\n",
      " [0.         0.92174256 0.60134786 ... 0.83855539 0.48533363 0.40281115]\n",
      " [0.         0.92806629 0.60094621 ... 0.84368849 0.46615577 0.41848501]] [0. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "print(scaled_features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] 70% train, 15% val, 15% test\n",
    " - Train: 26500\n",
    " - Valid: 5677\n",
    " - Test: 5669\n",
    "- [ ] 80% train, 10% val, 10% test\n",
    "- [ ] 60% train, 20% val, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = scaled_features[:26500], scaled_features[26500:26500+5677], scaled_features[26500+5677:]\n",
    "y_train, y_valid, y_test = labels[:26500], labels[26500:26500+5677], labels[26500+5677:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KerasRegressor method to fine-tuning neural network hyperparameters (Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=2, n_neurons=300, learning_rate=3e-3, input_shape=(769,)):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid')) # here the units must be 1 in order for binary classifications to work\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(lr=learning_rate), # you can tune the learning rate here. Default lr = 0.01\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.7965 - val_loss: 0.2952 - val_accuracy: 0.8674\n",
      "Epoch 2/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8832 - val_loss: 0.2395 - val_accuracy: 0.9021\n",
      "Epoch 3/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.8916 - val_loss: 0.2449 - val_accuracy: 0.8961\n",
      "Epoch 4/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.9018 - val_loss: 0.3774 - val_accuracy: 0.8640\n",
      "Epoch 5/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9014 - val_loss: 0.2372 - val_accuracy: 0.9068\n",
      "Epoch 6/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9096 - val_loss: 0.2222 - val_accuracy: 0.9265\n",
      "Epoch 7/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9085 - val_loss: 0.2674 - val_accuracy: 0.9086\n",
      "Epoch 8/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.9096 - val_loss: 0.2587 - val_accuracy: 0.9137\n",
      "Epoch 9/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.9105 - val_loss: 0.2789 - val_accuracy: 0.9028\n",
      "Epoch 10/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2383 - accuracy: 0.9115 - val_loss: 0.2411 - val_accuracy: 0.9065\n",
      "Epoch 11/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2278 - accuracy: 0.9147 - val_loss: 0.1837 - val_accuracy: 0.9352\n",
      "Epoch 12/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2282 - accuracy: 0.9171 - val_loss: 0.1859 - val_accuracy: 0.9345\n",
      "Epoch 13/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2285 - accuracy: 0.9176 - val_loss: 0.1979 - val_accuracy: 0.9348\n",
      "Epoch 14/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9237 - val_loss: 0.2101 - val_accuracy: 0.9294\n",
      "Epoch 15/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2252 - accuracy: 0.9196 - val_loss: 0.2394 - val_accuracy: 0.9220\n",
      "Epoch 16/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2192 - accuracy: 0.9219 - val_loss: 0.1841 - val_accuracy: 0.9415\n",
      "Epoch 17/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2125 - accuracy: 0.9231 - val_loss: 0.1738 - val_accuracy: 0.9420\n",
      "Epoch 18/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9244 - val_loss: 0.1826 - val_accuracy: 0.9341\n",
      "Epoch 19/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2172 - accuracy: 0.9211 - val_loss: 0.1877 - val_accuracy: 0.9410\n",
      "Epoch 20/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2132 - accuracy: 0.9233 - val_loss: 0.1771 - val_accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2216 - accuracy: 0.9210 - val_loss: 0.1771 - val_accuracy: 0.9424\n",
      "Epoch 22/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2034 - accuracy: 0.9278 - val_loss: 0.3195 - val_accuracy: 0.8871\n",
      "Epoch 23/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2119 - accuracy: 0.9258 - val_loss: 0.1650 - val_accuracy: 0.9438\n",
      "Epoch 24/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.2056 - accuracy: 0.9281 - val_loss: 0.1704 - val_accuracy: 0.9438\n",
      "Epoch 25/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9302 - val_loss: 0.1622 - val_accuracy: 0.9466\n",
      "Epoch 26/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9301 - val_loss: 0.2033 - val_accuracy: 0.9271\n",
      "Epoch 27/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9315 - val_loss: 0.1600 - val_accuracy: 0.9472\n",
      "Epoch 28/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1911 - accuracy: 0.9332 - val_loss: 0.1977 - val_accuracy: 0.9336\n",
      "Epoch 29/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1973 - accuracy: 0.9297 - val_loss: 0.1859 - val_accuracy: 0.9338\n",
      "Epoch 30/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1946 - accuracy: 0.9323 - val_loss: 0.1605 - val_accuracy: 0.9475\n",
      "Epoch 31/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1900 - accuracy: 0.9342 - val_loss: 0.2721 - val_accuracy: 0.9036\n",
      "Epoch 32/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9353 - val_loss: 0.1592 - val_accuracy: 0.9486\n",
      "Epoch 33/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9340 - val_loss: 0.1549 - val_accuracy: 0.9498\n",
      "Epoch 34/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1843 - accuracy: 0.9363 - val_loss: 0.6189 - val_accuracy: 0.6089\n",
      "Epoch 35/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1923 - accuracy: 0.9330 - val_loss: 0.1603 - val_accuracy: 0.9456\n",
      "Epoch 36/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.9349 - val_loss: 0.1808 - val_accuracy: 0.9413\n",
      "Epoch 37/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9355 - val_loss: 0.1552 - val_accuracy: 0.9494\n",
      "Epoch 38/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.9337 - val_loss: 0.2332 - val_accuracy: 0.9146\n",
      "Epoch 39/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.9411 - val_loss: 0.1453 - val_accuracy: 0.9519\n",
      "Epoch 40/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1939 - accuracy: 0.9329 - val_loss: 0.1447 - val_accuracy: 0.9530\n",
      "Epoch 41/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.9388 - val_loss: 0.1481 - val_accuracy: 0.9521\n",
      "Epoch 42/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.9365 - val_loss: 0.2225 - val_accuracy: 0.9332\n",
      "Epoch 43/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.9424 - val_loss: 0.1387 - val_accuracy: 0.9553\n",
      "Epoch 44/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1719 - accuracy: 0.9408 - val_loss: 0.1374 - val_accuracy: 0.9558\n",
      "Epoch 45/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1715 - accuracy: 0.9421 - val_loss: 0.1397 - val_accuracy: 0.9568\n",
      "Epoch 46/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.9397 - val_loss: 0.1653 - val_accuracy: 0.9482\n",
      "Epoch 47/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9391 - val_loss: 0.1452 - val_accuracy: 0.9565\n",
      "Epoch 48/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1673 - accuracy: 0.9439 - val_loss: 0.1596 - val_accuracy: 0.9475\n",
      "Epoch 49/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1687 - accuracy: 0.9428 - val_loss: 0.1443 - val_accuracy: 0.9547\n",
      "Epoch 50/100\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1603 - accuracy: 0.9457 - val_loss: 0.1312 - val_accuracy: 0.9579\n",
      "Epoch 51/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1620 - accuracy: 0.9448 - val_loss: 0.1338 - val_accuracy: 0.9588\n",
      "Epoch 52/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9462 - val_loss: 0.1310 - val_accuracy: 0.9590\n",
      "Epoch 53/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1651 - accuracy: 0.9444 - val_loss: 0.2213 - val_accuracy: 0.9207\n",
      "Epoch 54/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1685 - accuracy: 0.9437 - val_loss: 0.1439 - val_accuracy: 0.9551\n",
      "Epoch 55/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1600 - accuracy: 0.9475 - val_loss: 0.3899 - val_accuracy: 0.8788\n",
      "Epoch 56/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1675 - accuracy: 0.9438 - val_loss: 0.1334 - val_accuracy: 0.9591\n",
      "Epoch 57/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1605 - accuracy: 0.9457 - val_loss: 0.1277 - val_accuracy: 0.9605\n",
      "Epoch 58/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9504 - val_loss: 0.2570 - val_accuracy: 0.9128\n",
      "Epoch 59/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1593 - accuracy: 0.9463 - val_loss: 0.2150 - val_accuracy: 0.9237\n",
      "Epoch 60/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1504 - accuracy: 0.9498 - val_loss: 0.1245 - val_accuracy: 0.9616\n",
      "Epoch 61/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1513 - accuracy: 0.9505 - val_loss: 0.5598 - val_accuracy: 0.8395\n",
      "Epoch 62/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9415 - val_loss: 0.3939 - val_accuracy: 0.8608\n",
      "Epoch 63/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1560 - accuracy: 0.9478 - val_loss: 0.2787 - val_accuracy: 0.9123\n",
      "Epoch 64/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9439 - val_loss: 0.1464 - val_accuracy: 0.9521\n",
      "Epoch 65/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1505 - accuracy: 0.9494 - val_loss: 0.2352 - val_accuracy: 0.9292\n",
      "Epoch 66/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1698 - accuracy: 0.9450 - val_loss: 0.1404 - val_accuracy: 0.9535\n",
      "Epoch 67/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1538 - accuracy: 0.9480 - val_loss: 0.1663 - val_accuracy: 0.9484\n",
      "Epoch 68/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9494 - val_loss: 0.1222 - val_accuracy: 0.9628\n",
      "Epoch 69/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9499 - val_loss: 0.1290 - val_accuracy: 0.9595\n",
      "Epoch 70/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1601 - accuracy: 0.9473 - val_loss: 0.1326 - val_accuracy: 0.9563\n",
      "Epoch 71/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1549 - accuracy: 0.9500 - val_loss: 0.1417 - val_accuracy: 0.9538\n",
      "Epoch 72/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1639 - accuracy: 0.9457 - val_loss: 0.2836 - val_accuracy: 0.9123\n",
      "Epoch 73/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9508 - val_loss: 0.1778 - val_accuracy: 0.9401\n",
      "Epoch 74/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9484 - val_loss: 0.1625 - val_accuracy: 0.9454\n",
      "Epoch 75/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9489 - val_loss: 0.2012 - val_accuracy: 0.9391\n",
      "Epoch 76/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1475 - accuracy: 0.9521 - val_loss: 0.1281 - val_accuracy: 0.9611\n",
      "Epoch 77/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1471 - accuracy: 0.9513 - val_loss: 0.1203 - val_accuracy: 0.9621\n",
      "Epoch 78/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9508 - val_loss: 0.1354 - val_accuracy: 0.9561\n",
      "Epoch 79/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9498 - val_loss: 0.2402 - val_accuracy: 0.9160\n",
      "Epoch 80/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9495 - val_loss: 0.1508 - val_accuracy: 0.9551\n",
      "Epoch 81/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1387 - accuracy: 0.9550 - val_loss: 0.1481 - val_accuracy: 0.9521\n",
      "Epoch 82/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1450 - accuracy: 0.9519 - val_loss: 0.1350 - val_accuracy: 0.9560\n",
      "Epoch 83/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1450 - accuracy: 0.9537 - val_loss: 0.4481 - val_accuracy: 0.8126\n",
      "Epoch 84/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1520 - accuracy: 0.9505 - val_loss: 0.1218 - val_accuracy: 0.9634\n",
      "Epoch 85/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1514 - accuracy: 0.9498 - val_loss: 0.1186 - val_accuracy: 0.9646\n",
      "Epoch 86/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9489 - val_loss: 0.1270 - val_accuracy: 0.9584\n",
      "Epoch 87/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1439 - accuracy: 0.9530 - val_loss: 0.1171 - val_accuracy: 0.9648\n",
      "Epoch 88/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9526 - val_loss: 0.1178 - val_accuracy: 0.9634\n",
      "Epoch 89/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1528 - accuracy: 0.9501 - val_loss: 0.2945 - val_accuracy: 0.9014\n",
      "Epoch 90/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1437 - accuracy: 0.9524 - val_loss: 0.1157 - val_accuracy: 0.9642\n",
      "Epoch 91/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1549 - accuracy: 0.9491 - val_loss: 0.1429 - val_accuracy: 0.9519\n",
      "Epoch 92/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1419 - accuracy: 0.9535 - val_loss: 0.1266 - val_accuracy: 0.9588\n",
      "Epoch 93/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9547 - val_loss: 0.1340 - val_accuracy: 0.9574\n",
      "Epoch 94/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9539 - val_loss: 0.1424 - val_accuracy: 0.9528\n",
      "Epoch 95/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1556 - accuracy: 0.9476 - val_loss: 0.1186 - val_accuracy: 0.9637\n",
      "Epoch 96/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9540 - val_loss: 0.1162 - val_accuracy: 0.9635\n",
      "Epoch 97/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1392 - accuracy: 0.9542 - val_loss: 0.1220 - val_accuracy: 0.9623\n",
      "Epoch 98/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9521 - val_loss: 0.1205 - val_accuracy: 0.9616\n",
      "Epoch 99/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9524 - val_loss: 0.1502 - val_accuracy: 0.9523\n",
      "Epoch 100/100\n",
      "829/829 [==============================] - 1s 2ms/step - loss: 0.1449 - accuracy: 0.9527 - val_loss: 0.1174 - val_accuracy: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f60f82fa370>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs = 100, \n",
    "             validation_data=(X_valid,y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6817 - accuracy: 0.5898 - val_loss: 0.6679 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6647 - accuracy: 0.5913 - val_loss: 0.6511 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6119 - accuracy: 0.6695 - val_loss: 0.5331 - val_accuracy: 0.7391\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3910 - accuracy: 0.8600 - val_loss: 0.3368 - val_accuracy: 0.9204\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.8914 - val_loss: 0.2612 - val_accuracy: 0.9031\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2669 - accuracy: 0.8979 - val_loss: 0.2899 - val_accuracy: 0.8744\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2598 - accuracy: 0.9009 - val_loss: 0.2475 - val_accuracy: 0.9207\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2518 - accuracy: 0.9043 - val_loss: 0.2816 - val_accuracy: 0.9193\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.9071 - val_loss: 0.2684 - val_accuracy: 0.9216\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9071 - val_loss: 0.2272 - val_accuracy: 0.9176\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2405 - accuracy: 0.9101 - val_loss: 0.2271 - val_accuracy: 0.9228\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.9086 - val_loss: 0.2442 - val_accuracy: 0.9228\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.9098 - val_loss: 0.2510 - val_accuracy: 0.8991\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.9114 - val_loss: 0.2261 - val_accuracy: 0.9265\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.9115 - val_loss: 0.2146 - val_accuracy: 0.9241\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.9128 - val_loss: 0.2198 - val_accuracy: 0.9139\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2309 - accuracy: 0.9133 - val_loss: 0.2185 - val_accuracy: 0.9273\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2288 - accuracy: 0.9126 - val_loss: 0.2157 - val_accuracy: 0.9195\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2261 - accuracy: 0.9140 - val_loss: 0.2125 - val_accuracy: 0.9269\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.9147 - val_loss: 0.2456 - val_accuracy: 0.9038\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2250 - accuracy: 0.9142 - val_loss: 0.2073 - val_accuracy: 0.9269\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2283 - accuracy: 0.9138 - val_loss: 0.2383 - val_accuracy: 0.9206\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9153 - val_loss: 0.2074 - val_accuracy: 0.9258\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2244 - accuracy: 0.9149 - val_loss: 0.2143 - val_accuracy: 0.9294\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2235 - accuracy: 0.9159 - val_loss: 0.2032 - val_accuracy: 0.9278\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2196 - accuracy: 0.9191 - val_loss: 0.2029 - val_accuracy: 0.9273\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2196 - accuracy: 0.9181 - val_loss: 0.2130 - val_accuracy: 0.9186\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2211 - accuracy: 0.9168 - val_loss: 0.2042 - val_accuracy: 0.9302\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2178 - accuracy: 0.9200 - val_loss: 0.2092 - val_accuracy: 0.9211\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2234 - accuracy: 0.9176 - val_loss: 0.2108 - val_accuracy: 0.9204\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2185 - accuracy: 0.9176 - val_loss: 0.2034 - val_accuracy: 0.9269\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2155 - accuracy: 0.9176 - val_loss: 0.1983 - val_accuracy: 0.9317\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9209 - val_loss: 0.2124 - val_accuracy: 0.9273\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9196 - val_loss: 0.2396 - val_accuracy: 0.9105\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2152 - accuracy: 0.9196 - val_loss: 0.2055 - val_accuracy: 0.9306\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9199 - val_loss: 0.2018 - val_accuracy: 0.9269\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9200 - val_loss: 0.1964 - val_accuracy: 0.9309\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2095 - accuracy: 0.9211 - val_loss: 0.1952 - val_accuracy: 0.9313\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2168 - accuracy: 0.9191 - val_loss: 0.1994 - val_accuracy: 0.9278\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9224 - val_loss: 0.1920 - val_accuracy: 0.9327\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9226 - val_loss: 0.1932 - val_accuracy: 0.9317\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9221 - val_loss: 0.1933 - val_accuracy: 0.9313\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2102 - accuracy: 0.9214 - val_loss: 0.2106 - val_accuracy: 0.9269\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9226 - val_loss: 0.1899 - val_accuracy: 0.9357\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9234 - val_loss: 0.1979 - val_accuracy: 0.9274\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2093 - accuracy: 0.9221 - val_loss: 0.1889 - val_accuracy: 0.9331\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9214 - val_loss: 0.1929 - val_accuracy: 0.9317\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9236 - val_loss: 0.1969 - val_accuracy: 0.9273\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2073 - accuracy: 0.9232 - val_loss: 0.1866 - val_accuracy: 0.9364\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2015 - accuracy: 0.9274 - val_loss: 0.1861 - val_accuracy: 0.9345\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9236 - val_loss: 0.1867 - val_accuracy: 0.9364\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9247 - val_loss: 0.2570 - val_accuracy: 0.9066\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2043 - accuracy: 0.9235 - val_loss: 0.1848 - val_accuracy: 0.9369\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2053 - accuracy: 0.9236 - val_loss: 0.2088 - val_accuracy: 0.9234\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9258 - val_loss: 0.1825 - val_accuracy: 0.9378\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9266 - val_loss: 0.1830 - val_accuracy: 0.9350\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1998 - accuracy: 0.9261 - val_loss: 0.2367 - val_accuracy: 0.9140\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9264 - val_loss: 0.2011 - val_accuracy: 0.9315\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2008 - accuracy: 0.9257 - val_loss: 0.2025 - val_accuracy: 0.9306\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9283 - val_loss: 0.1801 - val_accuracy: 0.9380\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.9272 - val_loss: 0.1802 - val_accuracy: 0.9387\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1982 - accuracy: 0.9271 - val_loss: 0.1789 - val_accuracy: 0.9392\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9278 - val_loss: 0.1794 - val_accuracy: 0.9364\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9287 - val_loss: 0.1801 - val_accuracy: 0.9362\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1980 - accuracy: 0.9277 - val_loss: 0.2188 - val_accuracy: 0.9195\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1938 - accuracy: 0.9288 - val_loss: 0.1770 - val_accuracy: 0.9403\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1914 - accuracy: 0.9311 - val_loss: 0.1978 - val_accuracy: 0.9278\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.9285 - val_loss: 0.1870 - val_accuracy: 0.9331\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9307 - val_loss: 0.1781 - val_accuracy: 0.9368\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.9288 - val_loss: 0.1749 - val_accuracy: 0.9398\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9317 - val_loss: 0.1820 - val_accuracy: 0.9346\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1917 - accuracy: 0.9305 - val_loss: 0.1907 - val_accuracy: 0.9348\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.9298 - val_loss: 0.1779 - val_accuracy: 0.9364\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9320 - val_loss: 0.1703 - val_accuracy: 0.9424\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1879 - accuracy: 0.9312 - val_loss: 0.1740 - val_accuracy: 0.9385\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.9317 - val_loss: 0.1807 - val_accuracy: 0.9387\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.9318 - val_loss: 0.1729 - val_accuracy: 0.9417\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.9347 - val_loss: 0.1686 - val_accuracy: 0.9445\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.9336 - val_loss: 0.1799 - val_accuracy: 0.9392\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.9328 - val_loss: 0.1715 - val_accuracy: 0.9403\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1844 - accuracy: 0.9349 - val_loss: 0.1825 - val_accuracy: 0.9361\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1805 - accuracy: 0.9350 - val_loss: 0.1668 - val_accuracy: 0.9440\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.9320 - val_loss: 0.1711 - val_accuracy: 0.9396\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.9360 - val_loss: 0.1990 - val_accuracy: 0.9318\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9362 - val_loss: 0.1630 - val_accuracy: 0.9447\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.9342 - val_loss: 0.1781 - val_accuracy: 0.9399\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.9359 - val_loss: 0.1621 - val_accuracy: 0.9443\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9350 - val_loss: 0.1701 - val_accuracy: 0.9405\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.9350 - val_loss: 0.1644 - val_accuracy: 0.9443\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.9335 - val_loss: 0.1636 - val_accuracy: 0.9454\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9390 - val_loss: 0.1630 - val_accuracy: 0.9459\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9372 - val_loss: 0.2051 - val_accuracy: 0.9308\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9372 - val_loss: 0.1581 - val_accuracy: 0.9465\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.9364 - val_loss: 0.1651 - val_accuracy: 0.9442\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.9368 - val_loss: 0.1564 - val_accuracy: 0.9491\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1713 - accuracy: 0.9395 - val_loss: 0.1574 - val_accuracy: 0.9459\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.9415 - val_loss: 0.1610 - val_accuracy: 0.9461\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9388 - val_loss: 0.1543 - val_accuracy: 0.9479\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9375 - val_loss: 0.2065 - val_accuracy: 0.9253\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1716 - accuracy: 0.9388 - val_loss: 0.1715 - val_accuracy: 0.9424\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9417\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6735 - accuracy: 0.5946 - val_loss: 0.6690 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6682 - accuracy: 0.5946 - val_loss: 0.6618 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6560 - accuracy: 0.5951 - val_loss: 0.6422 - val_accuracy: 0.6037\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6067 - accuracy: 0.6669 - val_loss: 0.5299 - val_accuracy: 0.7689\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8394 - val_loss: 0.3445 - val_accuracy: 0.8795\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8900 - val_loss: 0.2645 - val_accuracy: 0.8987\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.9030 - val_loss: 0.2459 - val_accuracy: 0.9200\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2392 - accuracy: 0.9083 - val_loss: 0.2273 - val_accuracy: 0.9197\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2341 - accuracy: 0.9119 - val_loss: 0.2197 - val_accuracy: 0.9200\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2310 - accuracy: 0.9141 - val_loss: 0.2279 - val_accuracy: 0.9072\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2254 - accuracy: 0.9146 - val_loss: 0.2209 - val_accuracy: 0.9246\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9154 - val_loss: 0.2160 - val_accuracy: 0.9236\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9154 - val_loss: 0.2136 - val_accuracy: 0.9221\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9159 - val_loss: 0.2096 - val_accuracy: 0.9239\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2198 - accuracy: 0.9171 - val_loss: 0.2140 - val_accuracy: 0.9174\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.9188 - val_loss: 0.2110 - val_accuracy: 0.9269\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9200 - val_loss: 0.2063 - val_accuracy: 0.9250\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9212 - val_loss: 0.2058 - val_accuracy: 0.9258\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2221 - accuracy: 0.9160 - val_loss: 0.2038 - val_accuracy: 0.9258\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2186 - accuracy: 0.9179 - val_loss: 0.2056 - val_accuracy: 0.9267\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9186 - val_loss: 0.2208 - val_accuracy: 0.9139\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.9193 - val_loss: 0.2077 - val_accuracy: 0.9230\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2204 - accuracy: 0.9175 - val_loss: 0.2529 - val_accuracy: 0.9017\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2130 - accuracy: 0.9200 - val_loss: 0.2095 - val_accuracy: 0.9276\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9213 - val_loss: 0.2039 - val_accuracy: 0.9297\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9199 - val_loss: 0.2002 - val_accuracy: 0.9280\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2119 - accuracy: 0.9215 - val_loss: 0.2262 - val_accuracy: 0.9211\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9212 - val_loss: 0.2015 - val_accuracy: 0.9276\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9222 - val_loss: 0.1988 - val_accuracy: 0.9308\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2104 - accuracy: 0.9234 - val_loss: 0.2032 - val_accuracy: 0.9301\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2068 - accuracy: 0.9239 - val_loss: 0.2424 - val_accuracy: 0.9140\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2062 - accuracy: 0.9244 - val_loss: 0.1970 - val_accuracy: 0.9278\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9239 - val_loss: 0.1954 - val_accuracy: 0.9288\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9230 - val_loss: 0.1959 - val_accuracy: 0.9313\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9236 - val_loss: 0.1960 - val_accuracy: 0.9308\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9258 - val_loss: 0.2129 - val_accuracy: 0.9258\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9232 - val_loss: 0.1943 - val_accuracy: 0.9317\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.9231 - val_loss: 0.2056 - val_accuracy: 0.9290\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9260 - val_loss: 0.1997 - val_accuracy: 0.9265\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 3ms/step - loss: 0.2056 - accuracy: 0.9256 - val_loss: 0.1985 - val_accuracy: 0.9264\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2027 - accuracy: 0.9235 - val_loss: 0.1929 - val_accuracy: 0.9327\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.9234 - val_loss: 0.1941 - val_accuracy: 0.9329\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9230 - val_loss: 0.1999 - val_accuracy: 0.9309\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9240 - val_loss: 0.1946 - val_accuracy: 0.9267\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1993 - accuracy: 0.9268 - val_loss: 0.1876 - val_accuracy: 0.9334\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1998 - accuracy: 0.9257 - val_loss: 0.1986 - val_accuracy: 0.9250\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9267 - val_loss: 0.1927 - val_accuracy: 0.9341\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9273 - val_loss: 0.2042 - val_accuracy: 0.9223\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9282 - val_loss: 0.1960 - val_accuracy: 0.9299\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1988 - accuracy: 0.9253 - val_loss: 0.1901 - val_accuracy: 0.9327\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1944 - accuracy: 0.9286 - val_loss: 0.1839 - val_accuracy: 0.9324\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1930 - accuracy: 0.9278 - val_loss: 0.1857 - val_accuracy: 0.9359\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9274 - val_loss: 0.1805 - val_accuracy: 0.9359\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9292 - val_loss: 0.1844 - val_accuracy: 0.9362\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9287 - val_loss: 0.1896 - val_accuracy: 0.9325\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.9311 - val_loss: 0.1763 - val_accuracy: 0.9362\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.9316 - val_loss: 0.2522 - val_accuracy: 0.9100\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9317 - val_loss: 0.1793 - val_accuracy: 0.9362\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.9305 - val_loss: 0.1800 - val_accuracy: 0.9361\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9311 - val_loss: 0.1782 - val_accuracy: 0.9424\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9304 - val_loss: 0.1980 - val_accuracy: 0.9280\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9324 - val_loss: 0.1688 - val_accuracy: 0.9373\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.9345 - val_loss: 0.1657 - val_accuracy: 0.9389\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.9335 - val_loss: 0.1849 - val_accuracy: 0.9366\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.9334 - val_loss: 0.1746 - val_accuracy: 0.9339\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.9352 - val_loss: 0.1621 - val_accuracy: 0.9387\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1720 - accuracy: 0.9363 - val_loss: 0.1805 - val_accuracy: 0.9420\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.9364 - val_loss: 0.1542 - val_accuracy: 0.9436\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1699 - accuracy: 0.9358 - val_loss: 0.1689 - val_accuracy: 0.9565\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9368 - val_loss: 0.1890 - val_accuracy: 0.9302\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9403 - val_loss: 0.1662 - val_accuracy: 0.9339\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1619 - accuracy: 0.9405 - val_loss: 0.2600 - val_accuracy: 0.8998\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1599 - accuracy: 0.9424 - val_loss: 0.1485 - val_accuracy: 0.9567\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1620 - accuracy: 0.9402 - val_loss: 0.1429 - val_accuracy: 0.9475\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1580 - accuracy: 0.9430 - val_loss: 0.1421 - val_accuracy: 0.9472\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9426 - val_loss: 0.1392 - val_accuracy: 0.9510\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9414 - val_loss: 0.1351 - val_accuracy: 0.9575\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9470 - val_loss: 0.1457 - val_accuracy: 0.9449\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1477 - accuracy: 0.9472 - val_loss: 0.1324 - val_accuracy: 0.9602\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9437 - val_loss: 0.2215 - val_accuracy: 0.8991\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9453 - val_loss: 0.1309 - val_accuracy: 0.9620\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1426 - accuracy: 0.9496 - val_loss: 0.1395 - val_accuracy: 0.9586\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1438 - accuracy: 0.9477 - val_loss: 0.1329 - val_accuracy: 0.9556\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9459 - val_loss: 0.1856 - val_accuracy: 0.9325\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1413 - accuracy: 0.9492 - val_loss: 0.1254 - val_accuracy: 0.9556\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9461 - val_loss: 0.1247 - val_accuracy: 0.9570\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1368 - accuracy: 0.9518 - val_loss: 0.1767 - val_accuracy: 0.9378\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9510 - val_loss: 0.1443 - val_accuracy: 0.9526\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1389 - accuracy: 0.9530 - val_loss: 0.1417 - val_accuracy: 0.9516\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9453 - val_loss: 0.1996 - val_accuracy: 0.9265\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1418 - accuracy: 0.9501 - val_loss: 0.1260 - val_accuracy: 0.9572\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9518 - val_loss: 0.1500 - val_accuracy: 0.9489\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.9520 - val_loss: 0.1342 - val_accuracy: 0.9583\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9489 - val_loss: 0.1188 - val_accuracy: 0.9605\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1399 - accuracy: 0.9515 - val_loss: 0.1881 - val_accuracy: 0.9324\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1394 - accuracy: 0.9516 - val_loss: 0.1234 - val_accuracy: 0.9611\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1311 - accuracy: 0.9548 - val_loss: 0.1186 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9525 - val_loss: 0.1680 - val_accuracy: 0.9436\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1335 - accuracy: 0.9524 - val_loss: 0.1262 - val_accuracy: 0.9595\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1350 - accuracy: 0.9538 - val_loss: 0.1153 - val_accuracy: 0.9627\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9608\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6792 - accuracy: 0.5916 - val_loss: 0.6719 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6748 - accuracy: 0.5916 - val_loss: 0.6701 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6724 - accuracy: 0.5916 - val_loss: 0.6665 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6639 - accuracy: 0.5916 - val_loss: 0.6438 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.6831 - val_loss: 0.4982 - val_accuracy: 0.8591\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4197 - accuracy: 0.8514 - val_loss: 0.3583 - val_accuracy: 0.8792\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8763 - val_loss: 0.3084 - val_accuracy: 0.9063\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2916 - accuracy: 0.8891 - val_loss: 0.2708 - val_accuracy: 0.8906\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.8962 - val_loss: 0.2661 - val_accuracy: 0.9190\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9005 - val_loss: 0.2580 - val_accuracy: 0.8873\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.9041 - val_loss: 0.2511 - val_accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2452 - accuracy: 0.9071 - val_loss: 0.2364 - val_accuracy: 0.9047\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2425 - accuracy: 0.9090 - val_loss: 0.2461 - val_accuracy: 0.9232\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.9096 - val_loss: 0.2431 - val_accuracy: 0.9237\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.9107 - val_loss: 0.2258 - val_accuracy: 0.9218\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2361 - accuracy: 0.9102 - val_loss: 0.2206 - val_accuracy: 0.9218\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2330 - accuracy: 0.9129 - val_loss: 0.2439 - val_accuracy: 0.8984\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2310 - accuracy: 0.9141 - val_loss: 0.2195 - val_accuracy: 0.9147\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9150 - val_loss: 0.2146 - val_accuracy: 0.9200\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.9141 - val_loss: 0.2185 - val_accuracy: 0.9149\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9174 - val_loss: 0.2112 - val_accuracy: 0.9236\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2240 - accuracy: 0.9179 - val_loss: 0.2139 - val_accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9168 - val_loss: 0.2089 - val_accuracy: 0.9241\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.9177 - val_loss: 0.2126 - val_accuracy: 0.9207\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2216 - accuracy: 0.9186 - val_loss: 0.2092 - val_accuracy: 0.9250\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2203 - accuracy: 0.9179 - val_loss: 0.2175 - val_accuracy: 0.9260\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9179 - val_loss: 0.2072 - val_accuracy: 0.9250\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2190 - accuracy: 0.9197 - val_loss: 0.2054 - val_accuracy: 0.9244\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2206 - accuracy: 0.9177 - val_loss: 0.2057 - val_accuracy: 0.9258\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9203 - val_loss: 0.2077 - val_accuracy: 0.9234\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9192 - val_loss: 0.2107 - val_accuracy: 0.9281\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2177 - accuracy: 0.9203 - val_loss: 0.2032 - val_accuracy: 0.9267\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9191 - val_loss: 0.2027 - val_accuracy: 0.9276\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2173 - accuracy: 0.9201 - val_loss: 0.2027 - val_accuracy: 0.9257\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2191 - accuracy: 0.9203 - val_loss: 0.2146 - val_accuracy: 0.9195\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2170 - accuracy: 0.9208 - val_loss: 0.2027 - val_accuracy: 0.9290\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2160 - accuracy: 0.9213 - val_loss: 0.2022 - val_accuracy: 0.9267\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2148 - accuracy: 0.9210 - val_loss: 0.2020 - val_accuracy: 0.9273\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9213 - val_loss: 0.2097 - val_accuracy: 0.9220\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2134 - accuracy: 0.9228 - val_loss: 0.2017 - val_accuracy: 0.9276\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2126 - accuracy: 0.9230 - val_loss: 0.2256 - val_accuracy: 0.9135\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.9221 - val_loss: 0.2024 - val_accuracy: 0.9276\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.9231 - val_loss: 0.2018 - val_accuracy: 0.9278\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9217 - val_loss: 0.1970 - val_accuracy: 0.9280\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.9227 - val_loss: 0.1981 - val_accuracy: 0.9302\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2113 - accuracy: 0.9223 - val_loss: 0.2064 - val_accuracy: 0.9276\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.9235 - val_loss: 0.1961 - val_accuracy: 0.9318\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2080 - accuracy: 0.9243 - val_loss: 0.2164 - val_accuracy: 0.9179\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9225 - val_loss: 0.2033 - val_accuracy: 0.9258\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9223 - val_loss: 0.1973 - val_accuracy: 0.9292\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9231 - val_loss: 0.1938 - val_accuracy: 0.9292\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9250 - val_loss: 0.2228 - val_accuracy: 0.9202\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9240 - val_loss: 0.2248 - val_accuracy: 0.9193\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9239 - val_loss: 0.1952 - val_accuracy: 0.9294\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9251 - val_loss: 0.1991 - val_accuracy: 0.9297\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2056 - accuracy: 0.9249 - val_loss: 0.1918 - val_accuracy: 0.9308\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9255 - val_loss: 0.2238 - val_accuracy: 0.9181\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2092 - accuracy: 0.9243 - val_loss: 0.2231 - val_accuracy: 0.9200\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2053 - accuracy: 0.9258 - val_loss: 0.1901 - val_accuracy: 0.9343\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9258 - val_loss: 0.2101 - val_accuracy: 0.9221\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9254 - val_loss: 0.1921 - val_accuracy: 0.9331\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2042 - accuracy: 0.9251 - val_loss: 0.1898 - val_accuracy: 0.9327\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.9239 - val_loss: 0.1997 - val_accuracy: 0.9285\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.9269 - val_loss: 0.1886 - val_accuracy: 0.9350\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9273 - val_loss: 0.1876 - val_accuracy: 0.9355\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2007 - accuracy: 0.9283 - val_loss: 0.1910 - val_accuracy: 0.9341\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2010 - accuracy: 0.9265 - val_loss: 0.2079 - val_accuracy: 0.9232\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9272 - val_loss: 0.1864 - val_accuracy: 0.9352\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2023 - accuracy: 0.9278 - val_loss: 0.1865 - val_accuracy: 0.9354\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9291 - val_loss: 0.1880 - val_accuracy: 0.9322\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9285 - val_loss: 0.1847 - val_accuracy: 0.9366\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9294 - val_loss: 0.1848 - val_accuracy: 0.9357\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.9272 - val_loss: 0.1838 - val_accuracy: 0.9373\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2020 - accuracy: 0.9264 - val_loss: 0.1861 - val_accuracy: 0.9357\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9291 - val_loss: 0.1880 - val_accuracy: 0.9355\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9300 - val_loss: 0.1833 - val_accuracy: 0.9359\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9295 - val_loss: 0.1829 - val_accuracy: 0.9366\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9295 - val_loss: 0.1845 - val_accuracy: 0.9380\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9285 - val_loss: 0.1846 - val_accuracy: 0.9341\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9291 - val_loss: 0.1826 - val_accuracy: 0.9380\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1953 - accuracy: 0.9296 - val_loss: 0.1884 - val_accuracy: 0.9329\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1949 - accuracy: 0.9313 - val_loss: 0.2037 - val_accuracy: 0.9262\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9294 - val_loss: 0.2132 - val_accuracy: 0.9207\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1943 - accuracy: 0.9309 - val_loss: 0.1791 - val_accuracy: 0.9376\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9303 - val_loss: 0.2065 - val_accuracy: 0.9250\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9293 - val_loss: 0.1785 - val_accuracy: 0.9394\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9308 - val_loss: 0.1791 - val_accuracy: 0.9383\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9318 - val_loss: 0.1870 - val_accuracy: 0.9371\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.9316 - val_loss: 0.1766 - val_accuracy: 0.9387\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9308 - val_loss: 0.1797 - val_accuracy: 0.9366\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1931 - accuracy: 0.9294 - val_loss: 0.1760 - val_accuracy: 0.9392\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9307 - val_loss: 0.1925 - val_accuracy: 0.9295\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9314 - val_loss: 0.1823 - val_accuracy: 0.9352\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.9296 - val_loss: 0.1813 - val_accuracy: 0.9354\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1907 - accuracy: 0.9321 - val_loss: 0.1845 - val_accuracy: 0.9357\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9319 - val_loss: 0.1948 - val_accuracy: 0.9318\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9305 - val_loss: 0.1839 - val_accuracy: 0.9350\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.9324 - val_loss: 0.1734 - val_accuracy: 0.9410\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1947 - accuracy: 0.9309 - val_loss: 0.1753 - val_accuracy: 0.9392\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.9326 - val_loss: 0.1868 - val_accuracy: 0.9343\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.9303\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6239 - val_loss: 0.6130 - val_accuracy: 0.6392\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.7022 - val_loss: 0.5751 - val_accuracy: 0.7486\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5595 - accuracy: 0.7379 - val_loss: 0.5413 - val_accuracy: 0.7405\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7599 - val_loss: 0.5176 - val_accuracy: 0.7384\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7766 - val_loss: 0.4980 - val_accuracy: 0.8082\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7893 - val_loss: 0.4803 - val_accuracy: 0.8194\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.8010 - val_loss: 0.4635 - val_accuracy: 0.7851\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8103 - val_loss: 0.4504 - val_accuracy: 0.8291\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8168 - val_loss: 0.4375 - val_accuracy: 0.8101\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.8257 - val_loss: 0.4271 - val_accuracy: 0.8122\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4215 - accuracy: 0.8293 - val_loss: 0.4186 - val_accuracy: 0.8101\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4123 - accuracy: 0.8349 - val_loss: 0.4114 - val_accuracy: 0.8085\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4043 - accuracy: 0.8383 - val_loss: 0.4006 - val_accuracy: 0.8432\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8423 - val_loss: 0.3954 - val_accuracy: 0.8612\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3895 - accuracy: 0.8439 - val_loss: 0.3882 - val_accuracy: 0.8614\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8484 - val_loss: 0.3806 - val_accuracy: 0.8504\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.8514 - val_loss: 0.3772 - val_accuracy: 0.8700\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8523 - val_loss: 0.3697 - val_accuracy: 0.8501\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3659 - accuracy: 0.8548 - val_loss: 0.3650 - val_accuracy: 0.8624\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8567 - val_loss: 0.3608 - val_accuracy: 0.8665\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8609 - val_loss: 0.3562 - val_accuracy: 0.8631\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8605 - val_loss: 0.3523 - val_accuracy: 0.8654\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8621 - val_loss: 0.3490 - val_accuracy: 0.8598\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8643 - val_loss: 0.3465 - val_accuracy: 0.8541\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8654 - val_loss: 0.3598 - val_accuracy: 0.9086\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8688 - val_loss: 0.3435 - val_accuracy: 0.8478\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3353 - accuracy: 0.8696 - val_loss: 0.3531 - val_accuracy: 0.8300\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8692 - val_loss: 0.3350 - val_accuracy: 0.8855\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8735 - val_loss: 0.3305 - val_accuracy: 0.8674\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8722 - val_loss: 0.3335 - val_accuracy: 0.8964\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8729 - val_loss: 0.3260 - val_accuracy: 0.8674\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8729 - val_loss: 0.3234 - val_accuracy: 0.8704\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8758 - val_loss: 0.3332 - val_accuracy: 0.8468\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.8753 - val_loss: 0.3194 - val_accuracy: 0.8704\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8761 - val_loss: 0.3168 - val_accuracy: 0.8767\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8775 - val_loss: 0.3264 - val_accuracy: 0.9095\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.8781 - val_loss: 0.3132 - val_accuracy: 0.8844\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3098 - accuracy: 0.8789 - val_loss: 0.3161 - val_accuracy: 0.9015\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8796 - val_loss: 0.3122 - val_accuracy: 0.8970\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8793 - val_loss: 0.3078 - val_accuracy: 0.8844\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8814 - val_loss: 0.3093 - val_accuracy: 0.8996\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8819 - val_loss: 0.3078 - val_accuracy: 0.8691\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8804 - val_loss: 0.3068 - val_accuracy: 0.9022\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8842 - val_loss: 0.3022 - val_accuracy: 0.8924\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2999 - accuracy: 0.8843 - val_loss: 0.3027 - val_accuracy: 0.8733\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8834 - val_loss: 0.3000 - val_accuracy: 0.8781\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2961 - accuracy: 0.8842 - val_loss: 0.2994 - val_accuracy: 0.8760\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2946 - accuracy: 0.8851 - val_loss: 0.2971 - val_accuracy: 0.8948\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2942 - accuracy: 0.8867 - val_loss: 0.2996 - val_accuracy: 0.8716\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8874 - val_loss: 0.2941 - val_accuracy: 0.8924\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2910 - accuracy: 0.8868 - val_loss: 0.2933 - val_accuracy: 0.8959\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8871 - val_loss: 0.2925 - val_accuracy: 0.8820\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.8871 - val_loss: 0.2909 - val_accuracy: 0.8860\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.8876 - val_loss: 0.2898 - val_accuracy: 0.8866\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8876 - val_loss: 0.2885 - val_accuracy: 0.8933\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8900 - val_loss: 0.2878 - val_accuracy: 0.8876\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.8896 - val_loss: 0.2888 - val_accuracy: 0.9054\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.8905 - val_loss: 0.2888 - val_accuracy: 0.8783\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8895 - val_loss: 0.2914 - val_accuracy: 0.9125\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.8900 - val_loss: 0.2848 - val_accuracy: 0.9029\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.8904 - val_loss: 0.2849 - val_accuracy: 0.9056\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.8912 - val_loss: 0.2827 - val_accuracy: 0.8881\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8917 - val_loss: 0.2814 - val_accuracy: 0.9012\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8933 - val_loss: 0.2803 - val_accuracy: 0.8934\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.8932 - val_loss: 0.2826 - val_accuracy: 0.8816\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8939 - val_loss: 0.2786 - val_accuracy: 0.8973\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.8935 - val_loss: 0.2779 - val_accuracy: 0.8955\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.8939 - val_loss: 0.2791 - val_accuracy: 0.9077\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8946 - val_loss: 0.2767 - val_accuracy: 0.8933\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.8931 - val_loss: 0.2854 - val_accuracy: 0.8737\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8944 - val_loss: 0.2753 - val_accuracy: 0.8933\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.8936 - val_loss: 0.2743 - val_accuracy: 0.9019\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.8936 - val_loss: 0.2735 - val_accuracy: 0.9019\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.8951 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.8952 - val_loss: 0.2722 - val_accuracy: 0.9021\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.8964 - val_loss: 0.2844 - val_accuracy: 0.8725\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8964 - val_loss: 0.2726 - val_accuracy: 0.8896\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.8956 - val_loss: 0.2703 - val_accuracy: 0.8994\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.8971 - val_loss: 0.2712 - val_accuracy: 0.9096\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.8975 - val_loss: 0.2704 - val_accuracy: 0.9095\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.8965 - val_loss: 0.2730 - val_accuracy: 0.9146\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.8982 - val_loss: 0.2701 - val_accuracy: 0.8901\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.8972 - val_loss: 0.2734 - val_accuracy: 0.9174\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.8984 - val_loss: 0.2688 - val_accuracy: 0.8910\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.8981 - val_loss: 0.2667 - val_accuracy: 0.9084\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.8992 - val_loss: 0.2721 - val_accuracy: 0.8827\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.9000 - val_loss: 0.2666 - val_accuracy: 0.8938\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2638 - accuracy: 0.8990 - val_loss: 0.2652 - val_accuracy: 0.8977\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.8998 - val_loss: 0.2686 - val_accuracy: 0.9163\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8996 - val_loss: 0.2652 - val_accuracy: 0.8941\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2624 - accuracy: 0.9000 - val_loss: 0.2633 - val_accuracy: 0.9012\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.8998 - val_loss: 0.2634 - val_accuracy: 0.9116\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9014 - val_loss: 0.2627 - val_accuracy: 0.9107\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.9003 - val_loss: 0.2614 - val_accuracy: 0.9058\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2606 - accuracy: 0.9002 - val_loss: 0.2611 - val_accuracy: 0.9045\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.9008 - val_loss: 0.2650 - val_accuracy: 0.8894\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.9017 - val_loss: 0.2610 - val_accuracy: 0.9126\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.9015 - val_loss: 0.2627 - val_accuracy: 0.8927\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2592 - accuracy: 0.9002 - val_loss: 0.2600 - val_accuracy: 0.9128\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9017 - val_loss: 0.2587 - val_accuracy: 0.9051\n",
      "277/277 [==============================] - 0s 926us/step - loss: 0.2491 - accuracy: 0.9049\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6572 - accuracy: 0.6083 - val_loss: 0.6271 - val_accuracy: 0.6747\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6062 - accuracy: 0.6823 - val_loss: 0.5831 - val_accuracy: 0.6775\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5666 - accuracy: 0.7281 - val_loss: 0.5505 - val_accuracy: 0.7546\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7536 - val_loss: 0.5244 - val_accuracy: 0.7897\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.7762 - val_loss: 0.5032 - val_accuracy: 0.8103\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.7945 - val_loss: 0.4818 - val_accuracy: 0.7895\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.8019 - val_loss: 0.4656 - val_accuracy: 0.7978\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4560 - accuracy: 0.8141 - val_loss: 0.4537 - val_accuracy: 0.8369\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.8197 - val_loss: 0.4394 - val_accuracy: 0.8237\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4297 - accuracy: 0.8265 - val_loss: 0.4359 - val_accuracy: 0.7810\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.8344 - val_loss: 0.4184 - val_accuracy: 0.8214\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4086 - accuracy: 0.8370 - val_loss: 0.4109 - val_accuracy: 0.8147\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8431 - val_loss: 0.4013 - val_accuracy: 0.8446\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3918 - accuracy: 0.8464 - val_loss: 0.3984 - val_accuracy: 0.8705\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3844 - accuracy: 0.8501 - val_loss: 0.3881 - val_accuracy: 0.8364\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3771 - accuracy: 0.8531 - val_loss: 0.3818 - val_accuracy: 0.8401\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3712 - accuracy: 0.8555 - val_loss: 0.3752 - val_accuracy: 0.8487\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8587 - val_loss: 0.3728 - val_accuracy: 0.8367\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8607 - val_loss: 0.3651 - val_accuracy: 0.8497\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8624 - val_loss: 0.3602 - val_accuracy: 0.8566\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8627 - val_loss: 0.3594 - val_accuracy: 0.8822\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8668 - val_loss: 0.3532 - val_accuracy: 0.8503\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8668 - val_loss: 0.3506 - val_accuracy: 0.8820\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8693 - val_loss: 0.3444 - val_accuracy: 0.8684\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8705 - val_loss: 0.3447 - val_accuracy: 0.8490\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8713 - val_loss: 0.3430 - val_accuracy: 0.8915\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8716 - val_loss: 0.3350 - val_accuracy: 0.8654\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8753 - val_loss: 0.3319 - val_accuracy: 0.8725\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.8759 - val_loss: 0.3312 - val_accuracy: 0.8608\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8768 - val_loss: 0.3270 - val_accuracy: 0.8679\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8777 - val_loss: 0.3241 - val_accuracy: 0.8741\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8780 - val_loss: 0.3267 - val_accuracy: 0.8578\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8799 - val_loss: 0.3200 - val_accuracy: 0.8848\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3088 - accuracy: 0.8810 - val_loss: 0.3173 - val_accuracy: 0.8807\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.8810 - val_loss: 0.3161 - val_accuracy: 0.8878\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8837 - val_loss: 0.3133 - val_accuracy: 0.8813\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.8828 - val_loss: 0.3160 - val_accuracy: 0.9007\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8828 - val_loss: 0.3126 - val_accuracy: 0.8674\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.8841 - val_loss: 0.3090 - val_accuracy: 0.8917\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8871 - val_loss: 0.3070 - val_accuracy: 0.8915\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8882 - val_loss: 0.3054 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.8857 - val_loss: 0.3096 - val_accuracy: 0.9058\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2920 - accuracy: 0.8868 - val_loss: 0.3033 - val_accuracy: 0.8748\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.8870 - val_loss: 0.3001 - val_accuracy: 0.8859\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8876 - val_loss: 0.3002 - val_accuracy: 0.8767\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.8884 - val_loss: 0.2997 - val_accuracy: 0.9008\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.8902 - val_loss: 0.2981 - val_accuracy: 0.8762\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8908 - val_loss: 0.3006 - val_accuracy: 0.8693\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.8906 - val_loss: 0.2959 - val_accuracy: 0.8765\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2818 - accuracy: 0.8907 - val_loss: 0.2929 - val_accuracy: 0.8957\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.8909 - val_loss: 0.2913 - val_accuracy: 0.8888\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2795 - accuracy: 0.8923 - val_loss: 0.2903 - val_accuracy: 0.8934\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.8916 - val_loss: 0.2920 - val_accuracy: 0.8774\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.8929 - val_loss: 0.2901 - val_accuracy: 0.8804\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8930 - val_loss: 0.2900 - val_accuracy: 0.9063\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.8938 - val_loss: 0.2861 - val_accuracy: 0.8911\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2738 - accuracy: 0.8946 - val_loss: 0.2851 - val_accuracy: 0.8913\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8948 - val_loss: 0.2841 - val_accuracy: 0.8934\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.8952 - val_loss: 0.2843 - val_accuracy: 0.8857\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.8954 - val_loss: 0.2888 - val_accuracy: 0.8744\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2708 - accuracy: 0.8951 - val_loss: 0.2887 - val_accuracy: 0.9149\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8960 - val_loss: 0.2868 - val_accuracy: 0.9125\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8956 - val_loss: 0.2950 - val_accuracy: 0.9207\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2679 - accuracy: 0.8977 - val_loss: 0.2790 - val_accuracy: 0.8973\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.8959 - val_loss: 0.2782 - val_accuracy: 0.8978\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.8968 - val_loss: 0.2775 - val_accuracy: 0.9003\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.8968 - val_loss: 0.2815 - val_accuracy: 0.8800\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.8979 - val_loss: 0.2804 - val_accuracy: 0.9117\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.8983 - val_loss: 0.2767 - val_accuracy: 0.9068\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2643 - accuracy: 0.8975 - val_loss: 0.2762 - val_accuracy: 0.8881\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.8986 - val_loss: 0.2738 - val_accuracy: 0.8982\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.8983 - val_loss: 0.2737 - val_accuracy: 0.8933\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2609 - accuracy: 0.9003 - val_loss: 0.2734 - val_accuracy: 0.8917\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.8996 - val_loss: 0.2725 - val_accuracy: 0.9061\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9009 - val_loss: 0.2713 - val_accuracy: 0.8992\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.8988 - val_loss: 0.2705 - val_accuracy: 0.9017\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.8997 - val_loss: 0.2721 - val_accuracy: 0.9112\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9003 - val_loss: 0.2700 - val_accuracy: 0.8952\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.9008 - val_loss: 0.2691 - val_accuracy: 0.8973\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.9012 - val_loss: 0.2682 - val_accuracy: 0.9019\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2566 - accuracy: 0.9007 - val_loss: 0.2678 - val_accuracy: 0.9005\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9009 - val_loss: 0.2726 - val_accuracy: 0.8848\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9008 - val_loss: 0.2667 - val_accuracy: 0.9061\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9022 - val_loss: 0.2663 - val_accuracy: 0.8998\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.9016 - val_loss: 0.2689 - val_accuracy: 0.8885\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9024 - val_loss: 0.2690 - val_accuracy: 0.9165\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9037 - val_loss: 0.2644 - val_accuracy: 0.9052\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.9037 - val_loss: 0.2678 - val_accuracy: 0.9165\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9025 - val_loss: 0.2642 - val_accuracy: 0.8980\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.9032 - val_loss: 0.2635 - val_accuracy: 0.8987\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.9028 - val_loss: 0.2645 - val_accuracy: 0.9133\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.9022 - val_loss: 0.2633 - val_accuracy: 0.9128\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.9038 - val_loss: 0.2696 - val_accuracy: 0.9221\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9047 - val_loss: 0.2613 - val_accuracy: 0.9014\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2500 - accuracy: 0.9050 - val_loss: 0.2645 - val_accuracy: 0.8901\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9042 - val_loss: 0.2637 - val_accuracy: 0.8908\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2486 - accuracy: 0.9036 - val_loss: 0.2602 - val_accuracy: 0.9007\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.9046 - val_loss: 0.2614 - val_accuracy: 0.8948\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9050 - val_loss: 0.2623 - val_accuracy: 0.9170\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9054 - val_loss: 0.2615 - val_accuracy: 0.9169\n",
      "277/277 [==============================] - 0s 910us/step - loss: 0.2731 - accuracy: 0.9124\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6442 - accuracy: 0.6239 - val_loss: 0.6159 - val_accuracy: 0.7166\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6945 - val_loss: 0.5740 - val_accuracy: 0.6778\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5613 - accuracy: 0.7344 - val_loss: 0.5403 - val_accuracy: 0.7460\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7545 - val_loss: 0.5164 - val_accuracy: 0.7428\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5101 - accuracy: 0.7753 - val_loss: 0.4951 - val_accuracy: 0.7717\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7906 - val_loss: 0.4777 - val_accuracy: 0.7888\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.8031 - val_loss: 0.4637 - val_accuracy: 0.7777\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.8088 - val_loss: 0.4527 - val_accuracy: 0.7763\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4471 - accuracy: 0.8162 - val_loss: 0.4380 - val_accuracy: 0.7992\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8242 - val_loss: 0.4347 - val_accuracy: 0.8700\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4258 - accuracy: 0.8315 - val_loss: 0.4249 - val_accuracy: 0.7874\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8342 - val_loss: 0.4112 - val_accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.8377 - val_loss: 0.4009 - val_accuracy: 0.8482\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8427 - val_loss: 0.3934 - val_accuracy: 0.8460\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8462 - val_loss: 0.3902 - val_accuracy: 0.8695\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3862 - accuracy: 0.8506 - val_loss: 0.3881 - val_accuracy: 0.8832\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3802 - accuracy: 0.8531 - val_loss: 0.3799 - val_accuracy: 0.8260\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3756 - accuracy: 0.8525 - val_loss: 0.3698 - val_accuracy: 0.8490\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8579 - val_loss: 0.3661 - val_accuracy: 0.8455\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8586 - val_loss: 0.3610 - val_accuracy: 0.8682\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8594 - val_loss: 0.3569 - val_accuracy: 0.8704\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3561 - accuracy: 0.8622 - val_loss: 0.3536 - val_accuracy: 0.8485\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8628 - val_loss: 0.3549 - val_accuracy: 0.8906\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8655 - val_loss: 0.3484 - val_accuracy: 0.8460\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8662 - val_loss: 0.3422 - val_accuracy: 0.8575\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8666 - val_loss: 0.3396 - val_accuracy: 0.8807\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8680 - val_loss: 0.3361 - val_accuracy: 0.8600\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8695 - val_loss: 0.3378 - val_accuracy: 0.8947\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8718 - val_loss: 0.3360 - val_accuracy: 0.8982\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8739 - val_loss: 0.3284 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8738 - val_loss: 0.3242 - val_accuracy: 0.8725\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8757 - val_loss: 0.3218 - val_accuracy: 0.8730\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8767 - val_loss: 0.3231 - val_accuracy: 0.8594\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8765 - val_loss: 0.3176 - val_accuracy: 0.8822\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.8784 - val_loss: 0.3223 - val_accuracy: 0.9019\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8792 - val_loss: 0.3131 - val_accuracy: 0.8779\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3141 - accuracy: 0.8806 - val_loss: 0.3127 - val_accuracy: 0.8688\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3128 - accuracy: 0.8807 - val_loss: 0.3097 - val_accuracy: 0.8744\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8808 - val_loss: 0.3076 - val_accuracy: 0.8832\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8836 - val_loss: 0.3057 - val_accuracy: 0.8799\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3073 - accuracy: 0.8828 - val_loss: 0.3061 - val_accuracy: 0.8961\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3054 - accuracy: 0.8840 - val_loss: 0.3036 - val_accuracy: 0.8929\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8850 - val_loss: 0.3008 - val_accuracy: 0.8871\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8854 - val_loss: 0.2999 - val_accuracy: 0.8765\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3010 - accuracy: 0.8854 - val_loss: 0.2977 - val_accuracy: 0.8890\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2994 - accuracy: 0.8867 - val_loss: 0.2963 - val_accuracy: 0.8894\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8869 - val_loss: 0.2951 - val_accuracy: 0.8911\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8871 - val_loss: 0.2952 - val_accuracy: 0.9001\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8874 - val_loss: 0.2928 - val_accuracy: 0.8938\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8889 - val_loss: 0.2910 - val_accuracy: 0.8887\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.8882 - val_loss: 0.2917 - val_accuracy: 0.9007\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8887 - val_loss: 0.2891 - val_accuracy: 0.8968\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.8897 - val_loss: 0.2899 - val_accuracy: 0.9040\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8912 - val_loss: 0.2864 - val_accuracy: 0.8871\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8902 - val_loss: 0.2910 - val_accuracy: 0.9105\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2870 - accuracy: 0.8905 - val_loss: 0.2843 - val_accuracy: 0.8878\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2866 - accuracy: 0.8923 - val_loss: 0.2874 - val_accuracy: 0.8746\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2859 - accuracy: 0.8912 - val_loss: 0.2821 - val_accuracy: 0.8920\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.8923 - val_loss: 0.2811 - val_accuracy: 0.8952\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8927 - val_loss: 0.2821 - val_accuracy: 0.9058\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8933 - val_loss: 0.2794 - val_accuracy: 0.8885\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2813 - accuracy: 0.8936 - val_loss: 0.2823 - val_accuracy: 0.9096\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.8942 - val_loss: 0.2792 - val_accuracy: 0.8823\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.8939 - val_loss: 0.2807 - val_accuracy: 0.8778\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8951 - val_loss: 0.2756 - val_accuracy: 0.8915\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.8948 - val_loss: 0.2764 - val_accuracy: 0.9066\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2773 - accuracy: 0.8949 - val_loss: 0.2742 - val_accuracy: 0.8910\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8962 - val_loss: 0.2729 - val_accuracy: 0.8968\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8965 - val_loss: 0.2722 - val_accuracy: 0.9005\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8960 - val_loss: 0.2715 - val_accuracy: 0.8938\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.8959 - val_loss: 0.2728 - val_accuracy: 0.8853\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8966 - val_loss: 0.2770 - val_accuracy: 0.8772\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2726 - accuracy: 0.8970 - val_loss: 0.2692 - val_accuracy: 0.9012\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.8979 - val_loss: 0.2692 - val_accuracy: 0.9063\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2714 - accuracy: 0.8968 - val_loss: 0.2776 - val_accuracy: 0.9202\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2709 - accuracy: 0.8977 - val_loss: 0.2669 - val_accuracy: 0.9005\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2705 - accuracy: 0.8976 - val_loss: 0.2662 - val_accuracy: 0.9005\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2698 - accuracy: 0.8986 - val_loss: 0.2655 - val_accuracy: 0.9003\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.8980 - val_loss: 0.2653 - val_accuracy: 0.8941\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.8977 - val_loss: 0.2651 - val_accuracy: 0.8933\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2681 - accuracy: 0.8994 - val_loss: 0.2722 - val_accuracy: 0.8779\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.8996 - val_loss: 0.2743 - val_accuracy: 0.9221\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.8996 - val_loss: 0.2627 - val_accuracy: 0.8966\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2661 - accuracy: 0.8984 - val_loss: 0.2670 - val_accuracy: 0.8829\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.9009 - val_loss: 0.2626 - val_accuracy: 0.8929\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.8999 - val_loss: 0.2609 - val_accuracy: 0.9068\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2649 - accuracy: 0.9004 - val_loss: 0.2621 - val_accuracy: 0.8913\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.8998 - val_loss: 0.2608 - val_accuracy: 0.9114\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.9005 - val_loss: 0.2624 - val_accuracy: 0.9154\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8999 - val_loss: 0.2590 - val_accuracy: 0.9107\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2621 - accuracy: 0.9019 - val_loss: 0.2581 - val_accuracy: 0.9001\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2618 - accuracy: 0.9012 - val_loss: 0.2575 - val_accuracy: 0.9015\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.9021 - val_loss: 0.2568 - val_accuracy: 0.9036\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9024 - val_loss: 0.2563 - val_accuracy: 0.9054\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.9020 - val_loss: 0.2591 - val_accuracy: 0.8908\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.9035 - val_loss: 0.2554 - val_accuracy: 0.9040\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.9036 - val_loss: 0.2602 - val_accuracy: 0.9190\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.9026 - val_loss: 0.2572 - val_accuracy: 0.8931\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2584 - accuracy: 0.9034 - val_loss: 0.2592 - val_accuracy: 0.8883\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.9028 - val_loss: 0.2540 - val_accuracy: 0.9123\n",
      "277/277 [==============================] - 0s 917us/step - loss: 0.2463 - accuracy: 0.9090\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6330 - accuracy: 0.6445 - val_loss: 0.5327 - val_accuracy: 0.7055\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3964 - accuracy: 0.8415 - val_loss: 0.2974 - val_accuracy: 0.8860\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2853 - accuracy: 0.8891 - val_loss: 0.2513 - val_accuracy: 0.9031\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2634 - accuracy: 0.9000 - val_loss: 0.2411 - val_accuracy: 0.9190\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2510 - accuracy: 0.9036 - val_loss: 0.2636 - val_accuracy: 0.9211\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.9080 - val_loss: 0.2266 - val_accuracy: 0.9096\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.9090 - val_loss: 0.2134 - val_accuracy: 0.9227\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2368 - accuracy: 0.9104 - val_loss: 0.2468 - val_accuracy: 0.9220\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2333 - accuracy: 0.9108 - val_loss: 0.2130 - val_accuracy: 0.9287\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2319 - accuracy: 0.9133 - val_loss: 0.2405 - val_accuracy: 0.9193\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.9166 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2241 - accuracy: 0.9164 - val_loss: 0.2318 - val_accuracy: 0.9088\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.9159 - val_loss: 0.2214 - val_accuracy: 0.9128\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2199 - accuracy: 0.9165 - val_loss: 0.2704 - val_accuracy: 0.8952\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2171 - accuracy: 0.9185 - val_loss: 0.2234 - val_accuracy: 0.9146\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2172 - accuracy: 0.9187 - val_loss: 0.2007 - val_accuracy: 0.9234\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9178 - val_loss: 0.1886 - val_accuracy: 0.9297\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2076 - accuracy: 0.9218 - val_loss: 0.1830 - val_accuracy: 0.9338\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2050 - accuracy: 0.9227 - val_loss: 0.1799 - val_accuracy: 0.9376\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2028 - accuracy: 0.9231 - val_loss: 0.2347 - val_accuracy: 0.9042\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2051 - accuracy: 0.9229 - val_loss: 0.1767 - val_accuracy: 0.9354\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9261 - val_loss: 0.1704 - val_accuracy: 0.9403\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9282 - val_loss: 0.1888 - val_accuracy: 0.9345\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.9270 - val_loss: 0.1693 - val_accuracy: 0.9389\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.9301 - val_loss: 0.1595 - val_accuracy: 0.9468\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.9324 - val_loss: 0.1556 - val_accuracy: 0.9479\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.9326 - val_loss: 0.1507 - val_accuracy: 0.9493\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.9363 - val_loss: 0.1457 - val_accuracy: 0.9510\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.9362 - val_loss: 0.1419 - val_accuracy: 0.9498\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1662 - accuracy: 0.9381 - val_loss: 0.1501 - val_accuracy: 0.9591\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1668 - accuracy: 0.9406 - val_loss: 0.1698 - val_accuracy: 0.9389\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9370 - val_loss: 0.1964 - val_accuracy: 0.9271\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9395 - val_loss: 0.1974 - val_accuracy: 0.9260\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1640 - accuracy: 0.9414 - val_loss: 0.1298 - val_accuracy: 0.9609\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1524 - accuracy: 0.9446 - val_loss: 0.1319 - val_accuracy: 0.9551\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1516 - accuracy: 0.9456 - val_loss: 0.8160 - val_accuracy: 0.5313\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1695 - accuracy: 0.9388 - val_loss: 0.1578 - val_accuracy: 0.9424\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9455 - val_loss: 0.1310 - val_accuracy: 0.9556\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.9465 - val_loss: 0.2203 - val_accuracy: 0.9221\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9484 - val_loss: 0.1210 - val_accuracy: 0.9598\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9487 - val_loss: 0.1201 - val_accuracy: 0.9627\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9512 - val_loss: 0.2102 - val_accuracy: 0.9253\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1602 - accuracy: 0.9432 - val_loss: 0.1445 - val_accuracy: 0.9484\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9451 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9447 - val_loss: 0.1262 - val_accuracy: 0.9579\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1485 - accuracy: 0.9480 - val_loss: 0.1374 - val_accuracy: 0.9577\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9511 - val_loss: 0.1148 - val_accuracy: 0.9628\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1552 - accuracy: 0.9447 - val_loss: 0.1362 - val_accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9498 - val_loss: 0.1426 - val_accuracy: 0.9501\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9491 - val_loss: 0.1625 - val_accuracy: 0.9459\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9492 - val_loss: 0.1239 - val_accuracy: 0.9595\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1536 - accuracy: 0.9455 - val_loss: 0.1972 - val_accuracy: 0.9174\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9494 - val_loss: 0.2133 - val_accuracy: 0.9267\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1407 - accuracy: 0.9505 - val_loss: 0.1285 - val_accuracy: 0.9553\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.9521 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9506 - val_loss: 0.1383 - val_accuracy: 0.9526\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.9534 - val_loss: 0.1132 - val_accuracy: 0.9635\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9514 - val_loss: 0.1357 - val_accuracy: 0.9524\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9485 - val_loss: 0.1264 - val_accuracy: 0.9563\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1340 - accuracy: 0.9531 - val_loss: 0.1451 - val_accuracy: 0.9482\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.9544 - val_loss: 0.1144 - val_accuracy: 0.9605\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1360 - accuracy: 0.9526 - val_loss: 0.1140 - val_accuracy: 0.9635\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9521 - val_loss: 0.1331 - val_accuracy: 0.9547\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9498 - val_loss: 0.1109 - val_accuracy: 0.9660\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1308 - accuracy: 0.9549 - val_loss: 0.1196 - val_accuracy: 0.9588\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1363 - accuracy: 0.9522 - val_loss: 0.1418 - val_accuracy: 0.9523\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1316 - accuracy: 0.9537 - val_loss: 0.1464 - val_accuracy: 0.9491\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1359 - accuracy: 0.9521 - val_loss: 0.1092 - val_accuracy: 0.9655\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9546 - val_loss: 0.1135 - val_accuracy: 0.9618\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9551 - val_loss: 0.1060 - val_accuracy: 0.9667\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9547 - val_loss: 0.1118 - val_accuracy: 0.9628\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.9541 - val_loss: 0.1177 - val_accuracy: 0.9611\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9585 - val_loss: 0.1094 - val_accuracy: 0.9639\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1318 - accuracy: 0.9548 - val_loss: 0.1217 - val_accuracy: 0.9590\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9558 - val_loss: 0.1200 - val_accuracy: 0.9581\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1235 - accuracy: 0.9586 - val_loss: 0.4309 - val_accuracy: 0.8723\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9529 - val_loss: 0.1622 - val_accuracy: 0.9417\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9541 - val_loss: 0.1225 - val_accuracy: 0.9581\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1266 - accuracy: 0.9557 - val_loss: 0.1100 - val_accuracy: 0.9648\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1272 - accuracy: 0.9557 - val_loss: 0.1335 - val_accuracy: 0.9531\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9516\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6158 - accuracy: 0.6621 - val_loss: 0.5504 - val_accuracy: 0.6981\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8631 - val_loss: 0.2759 - val_accuracy: 0.8885\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.8979 - val_loss: 0.2490 - val_accuracy: 0.9176\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9041 - val_loss: 0.2409 - val_accuracy: 0.9019\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.9085 - val_loss: 0.3186 - val_accuracy: 0.9035\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2329 - accuracy: 0.9109 - val_loss: 0.2245 - val_accuracy: 0.9276\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2286 - accuracy: 0.9147 - val_loss: 0.2183 - val_accuracy: 0.9290\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2240 - accuracy: 0.9145 - val_loss: 0.2179 - val_accuracy: 0.9285\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2183 - accuracy: 0.9182 - val_loss: 0.2067 - val_accuracy: 0.9306\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9178 - val_loss: 0.2113 - val_accuracy: 0.9169\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9189 - val_loss: 0.1959 - val_accuracy: 0.9290\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9195 - val_loss: 0.1950 - val_accuracy: 0.9260\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2148 - accuracy: 0.9195 - val_loss: 0.1919 - val_accuracy: 0.9290\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2075 - accuracy: 0.9229 - val_loss: 0.1908 - val_accuracy: 0.9331\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2049 - accuracy: 0.9237 - val_loss: 0.1868 - val_accuracy: 0.9343\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9238 - val_loss: 0.1890 - val_accuracy: 0.9281\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.9235 - val_loss: 0.2304 - val_accuracy: 0.9133\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2004 - accuracy: 0.9260 - val_loss: 0.1839 - val_accuracy: 0.9302\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1988 - accuracy: 0.9263 - val_loss: 0.2098 - val_accuracy: 0.9274\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9269 - val_loss: 0.1847 - val_accuracy: 0.9297\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9271 - val_loss: 0.1855 - val_accuracy: 0.9369\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9290 - val_loss: 0.1816 - val_accuracy: 0.9391\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9277 - val_loss: 0.1707 - val_accuracy: 0.9394\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.9284 - val_loss: 0.1689 - val_accuracy: 0.9413\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.9306 - val_loss: 0.1710 - val_accuracy: 0.9369\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1927 - accuracy: 0.9307 - val_loss: 0.1698 - val_accuracy: 0.9406\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.9354 - val_loss: 0.1755 - val_accuracy: 0.9355\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.9357 - val_loss: 0.2015 - val_accuracy: 0.9285\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.9353 - val_loss: 0.1533 - val_accuracy: 0.9466\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9385 - val_loss: 0.1464 - val_accuracy: 0.9501\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9381 - val_loss: 0.1462 - val_accuracy: 0.9491\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1728 - accuracy: 0.9371 - val_loss: 0.1650 - val_accuracy: 0.9408\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1574 - accuracy: 0.9442 - val_loss: 0.1463 - val_accuracy: 0.9472\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1539 - accuracy: 0.9442 - val_loss: 0.1656 - val_accuracy: 0.9413\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1565 - accuracy: 0.9430 - val_loss: 0.1510 - val_accuracy: 0.9489\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9433 - val_loss: 0.1296 - val_accuracy: 0.9542\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.9470 - val_loss: 0.1875 - val_accuracy: 0.9369\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9444 - val_loss: 0.1365 - val_accuracy: 0.9510\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9459 - val_loss: 0.1267 - val_accuracy: 0.9546\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9466 - val_loss: 0.1501 - val_accuracy: 0.9465\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1400 - accuracy: 0.9519 - val_loss: 0.1910 - val_accuracy: 0.9308\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1404 - accuracy: 0.9497 - val_loss: 0.1296 - val_accuracy: 0.9533\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1403 - accuracy: 0.9505 - val_loss: 0.2022 - val_accuracy: 0.9285\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1380 - accuracy: 0.9521 - val_loss: 0.1160 - val_accuracy: 0.9625\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1430 - accuracy: 0.9499 - val_loss: 0.1707 - val_accuracy: 0.9392\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1411 - accuracy: 0.9526 - val_loss: 0.1381 - val_accuracy: 0.9540\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1445 - accuracy: 0.9496 - val_loss: 0.1386 - val_accuracy: 0.9530\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9520 - val_loss: 0.1141 - val_accuracy: 0.9612\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9557 - val_loss: 0.1511 - val_accuracy: 0.9461\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1442 - accuracy: 0.9506 - val_loss: 0.1841 - val_accuracy: 0.9385\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1448 - accuracy: 0.9510 - val_loss: 0.1264 - val_accuracy: 0.9583\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9543 - val_loss: 0.1202 - val_accuracy: 0.9586\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1424 - accuracy: 0.9515 - val_loss: 0.1149 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1342 - accuracy: 0.9530 - val_loss: 0.1526 - val_accuracy: 0.9461\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1363 - accuracy: 0.9523 - val_loss: 0.1141 - val_accuracy: 0.9623\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9553 - val_loss: 0.3176 - val_accuracy: 0.8792\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9492 - val_loss: 0.1509 - val_accuracy: 0.9459\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1333 - accuracy: 0.9542 - val_loss: 0.2433 - val_accuracy: 0.9125\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1383 - accuracy: 0.9520 - val_loss: 0.1456 - val_accuracy: 0.9507\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1424 - accuracy: 0.9518 - val_loss: 0.1154 - val_accuracy: 0.9616\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9568 - val_loss: 0.1132 - val_accuracy: 0.9614\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1325 - accuracy: 0.9540 - val_loss: 0.1168 - val_accuracy: 0.9628\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1317 - accuracy: 0.9544 - val_loss: 0.1363 - val_accuracy: 0.9535\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9523 - val_loss: 0.1095 - val_accuracy: 0.9649\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1416 - accuracy: 0.9503 - val_loss: 0.1124 - val_accuracy: 0.9644\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1249 - accuracy: 0.9562 - val_loss: 0.1405 - val_accuracy: 0.9528\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1360 - accuracy: 0.9526 - val_loss: 0.1387 - val_accuracy: 0.9538\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1268 - accuracy: 0.9571 - val_loss: 0.1052 - val_accuracy: 0.9658\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9547 - val_loss: 0.1403 - val_accuracy: 0.9535\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9569 - val_loss: 0.1830 - val_accuracy: 0.9350\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9572 - val_loss: 0.1237 - val_accuracy: 0.9575\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1284 - accuracy: 0.9562 - val_loss: 0.1131 - val_accuracy: 0.9623\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1227 - accuracy: 0.9584 - val_loss: 0.1176 - val_accuracy: 0.9602\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9518 - val_loss: 0.1131 - val_accuracy: 0.9625\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.9586 - val_loss: 0.2207 - val_accuracy: 0.9232\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9536 - val_loss: 0.1118 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1352 - accuracy: 0.9540 - val_loss: 0.1222 - val_accuracy: 0.9579\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9593 - val_loss: 0.1020 - val_accuracy: 0.9685\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9521 - val_loss: 0.1047 - val_accuracy: 0.9657\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1260 - accuracy: 0.9574 - val_loss: 0.1326 - val_accuracy: 0.9563\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1219 - accuracy: 0.9591 - val_loss: 0.1057 - val_accuracy: 0.9649\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9551 - val_loss: 0.1098 - val_accuracy: 0.9635\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1281 - accuracy: 0.9570 - val_loss: 0.1087 - val_accuracy: 0.9644\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1288 - accuracy: 0.9559 - val_loss: 0.1020 - val_accuracy: 0.9701\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9560 - val_loss: 0.1096 - val_accuracy: 0.9646\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9521 - val_loss: 0.2058 - val_accuracy: 0.9304\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9577 - val_loss: 0.1037 - val_accuracy: 0.9688\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1296 - accuracy: 0.9553 - val_loss: 0.1988 - val_accuracy: 0.9301\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9586 - val_loss: 0.1108 - val_accuracy: 0.9637\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1200 - accuracy: 0.9595 - val_loss: 0.1066 - val_accuracy: 0.9676\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1194 - accuracy: 0.9590 - val_loss: 0.1015 - val_accuracy: 0.9685\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1263 - accuracy: 0.9575 - val_loss: 0.1304 - val_accuracy: 0.9567\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1226 - accuracy: 0.9585 - val_loss: 0.1652 - val_accuracy: 0.9431\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1269 - accuracy: 0.9573 - val_loss: 0.1244 - val_accuracy: 0.9593\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1162 - accuracy: 0.9617 - val_loss: 0.1097 - val_accuracy: 0.9641\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1244 - accuracy: 0.9582 - val_loss: 0.1909 - val_accuracy: 0.9362\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1175 - accuracy: 0.9608 - val_loss: 0.1354 - val_accuracy: 0.9549\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1220 - accuracy: 0.9585 - val_loss: 0.1134 - val_accuracy: 0.9620\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9578 - val_loss: 0.2542 - val_accuracy: 0.8903\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1264 - accuracy: 0.9576 - val_loss: 0.1028 - val_accuracy: 0.9672\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9660\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6386 - accuracy: 0.6340 - val_loss: 0.5499 - val_accuracy: 0.6928\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4001 - accuracy: 0.8430 - val_loss: 0.3474 - val_accuracy: 0.8295\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.8917 - val_loss: 0.3171 - val_accuracy: 0.8564\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.9033 - val_loss: 0.2376 - val_accuracy: 0.9244\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9089 - val_loss: 0.2411 - val_accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.9122 - val_loss: 0.2155 - val_accuracy: 0.9280\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2316 - accuracy: 0.9144 - val_loss: 0.2315 - val_accuracy: 0.9044\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2298 - accuracy: 0.9165 - val_loss: 0.2006 - val_accuracy: 0.9253\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2203 - accuracy: 0.9197 - val_loss: 0.3729 - val_accuracy: 0.8600\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.9193 - val_loss: 0.2338 - val_accuracy: 0.9059\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2150 - accuracy: 0.9221 - val_loss: 0.2212 - val_accuracy: 0.9133\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2227 - accuracy: 0.9182 - val_loss: 0.2145 - val_accuracy: 0.9281\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2159 - accuracy: 0.9215 - val_loss: 0.1975 - val_accuracy: 0.9331\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9258 - val_loss: 0.3483 - val_accuracy: 0.8682\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2104 - accuracy: 0.9248 - val_loss: 0.1835 - val_accuracy: 0.9320\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2097 - accuracy: 0.9253 - val_loss: 0.2580 - val_accuracy: 0.8927\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9245 - val_loss: 0.1954 - val_accuracy: 0.9258\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9270 - val_loss: 0.1905 - val_accuracy: 0.9288\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9259 - val_loss: 0.1943 - val_accuracy: 0.9288\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2024 - accuracy: 0.9245 - val_loss: 0.1719 - val_accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9281 - val_loss: 0.1905 - val_accuracy: 0.9387\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9337 - val_loss: 0.1830 - val_accuracy: 0.9399\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1978 - accuracy: 0.9289 - val_loss: 0.2493 - val_accuracy: 0.9059\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9343 - val_loss: 0.1606 - val_accuracy: 0.9475\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.9338 - val_loss: 0.1574 - val_accuracy: 0.9493\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9356 - val_loss: 0.1725 - val_accuracy: 0.9352\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.9363 - val_loss: 0.1472 - val_accuracy: 0.9523\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1693 - accuracy: 0.9390 - val_loss: 0.1557 - val_accuracy: 0.9450\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.9386 - val_loss: 0.1670 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1612 - accuracy: 0.9412 - val_loss: 0.1387 - val_accuracy: 0.9517\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1525 - accuracy: 0.9461 - val_loss: 0.2371 - val_accuracy: 0.9133\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9452 - val_loss: 0.2119 - val_accuracy: 0.9271\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1517 - accuracy: 0.9479 - val_loss: 0.1369 - val_accuracy: 0.9524\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1502 - accuracy: 0.9460 - val_loss: 0.2503 - val_accuracy: 0.9065\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9445 - val_loss: 0.1282 - val_accuracy: 0.9570\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9492 - val_loss: 0.1542 - val_accuracy: 0.9420\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1409 - accuracy: 0.9510 - val_loss: 0.1179 - val_accuracy: 0.9639\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1441 - accuracy: 0.9498 - val_loss: 0.1430 - val_accuracy: 0.9479\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1508 - accuracy: 0.9470 - val_loss: 0.2419 - val_accuracy: 0.9165\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1520 - accuracy: 0.9483 - val_loss: 0.2507 - val_accuracy: 0.9109\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1398 - accuracy: 0.9529 - val_loss: 0.1209 - val_accuracy: 0.9600\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9495 - val_loss: 0.1464 - val_accuracy: 0.9477\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1420 - accuracy: 0.9510 - val_loss: 0.2061 - val_accuracy: 0.9153\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1435 - accuracy: 0.9506 - val_loss: 0.1150 - val_accuracy: 0.9627\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9544 - val_loss: 0.1196 - val_accuracy: 0.9614\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1379 - accuracy: 0.9531 - val_loss: 0.1558 - val_accuracy: 0.9494\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9512 - val_loss: 0.1113 - val_accuracy: 0.9651\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1399 - accuracy: 0.9515 - val_loss: 0.2089 - val_accuracy: 0.9285\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9530 - val_loss: 0.1104 - val_accuracy: 0.9664\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9475 - val_loss: 0.1298 - val_accuracy: 0.9556\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1386 - accuracy: 0.9521 - val_loss: 0.1226 - val_accuracy: 0.9611\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9510 - val_loss: 0.1298 - val_accuracy: 0.9567\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9542 - val_loss: 0.1137 - val_accuracy: 0.9646\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9553 - val_loss: 0.2652 - val_accuracy: 0.9079\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9518 - val_loss: 0.1206 - val_accuracy: 0.9604\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1540 - accuracy: 0.9454 - val_loss: 0.1196 - val_accuracy: 0.9642\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1375 - accuracy: 0.9530 - val_loss: 0.1172 - val_accuracy: 0.9628\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1368 - accuracy: 0.9525 - val_loss: 0.1209 - val_accuracy: 0.9611\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1392 - accuracy: 0.9512 - val_loss: 0.1357 - val_accuracy: 0.9533\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9508\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6604 - accuracy: 0.5975 - val_loss: 0.6362 - val_accuracy: 0.6174\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6257 - accuracy: 0.6461 - val_loss: 0.6087 - val_accuracy: 0.6459\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6865 - val_loss: 0.5838 - val_accuracy: 0.6951\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5768 - accuracy: 0.7133 - val_loss: 0.5632 - val_accuracy: 0.7069\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5565 - accuracy: 0.7351 - val_loss: 0.5484 - val_accuracy: 0.7777\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7497 - val_loss: 0.5313 - val_accuracy: 0.7812\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5240 - accuracy: 0.7642 - val_loss: 0.5155 - val_accuracy: 0.7731\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5107 - accuracy: 0.7733 - val_loss: 0.5029 - val_accuracy: 0.7603\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4984 - accuracy: 0.7842 - val_loss: 0.4923 - val_accuracy: 0.7988\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7902 - val_loss: 0.4809 - val_accuracy: 0.7853\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7983 - val_loss: 0.4721 - val_accuracy: 0.7763\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.8037 - val_loss: 0.4629 - val_accuracy: 0.7856\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.8085 - val_loss: 0.4541 - val_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.8158 - val_loss: 0.4467 - val_accuracy: 0.8034\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.8179 - val_loss: 0.4431 - val_accuracy: 0.8492\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8217 - val_loss: 0.4332 - val_accuracy: 0.8092\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4290 - accuracy: 0.8233 - val_loss: 0.4300 - val_accuracy: 0.8526\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8288 - val_loss: 0.4212 - val_accuracy: 0.8344\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4180 - accuracy: 0.8323 - val_loss: 0.4161 - val_accuracy: 0.8386\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8337 - val_loss: 0.4116 - val_accuracy: 0.8468\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8375 - val_loss: 0.4064 - val_accuracy: 0.8448\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4030 - accuracy: 0.8381 - val_loss: 0.4019 - val_accuracy: 0.8469\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3984 - accuracy: 0.8391 - val_loss: 0.3978 - val_accuracy: 0.8339\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8415 - val_loss: 0.3943 - val_accuracy: 0.8564\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8434 - val_loss: 0.3915 - val_accuracy: 0.8279\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3862 - accuracy: 0.8453 - val_loss: 0.3857 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3826 - accuracy: 0.8472 - val_loss: 0.3862 - val_accuracy: 0.8254\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3787 - accuracy: 0.8490 - val_loss: 0.3801 - val_accuracy: 0.8383\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3754 - accuracy: 0.8517 - val_loss: 0.3855 - val_accuracy: 0.8138\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3723 - accuracy: 0.8517 - val_loss: 0.3810 - val_accuracy: 0.8173\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8538 - val_loss: 0.3698 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3657 - accuracy: 0.8553 - val_loss: 0.3668 - val_accuracy: 0.8619\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8573 - val_loss: 0.3671 - val_accuracy: 0.8395\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8575 - val_loss: 0.3616 - val_accuracy: 0.8651\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8586 - val_loss: 0.3611 - val_accuracy: 0.8765\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3553 - accuracy: 0.8600 - val_loss: 0.3594 - val_accuracy: 0.8793\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8610 - val_loss: 0.3542 - val_accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8619 - val_loss: 0.3523 - val_accuracy: 0.8688\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8630 - val_loss: 0.3506 - val_accuracy: 0.8735\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8630 - val_loss: 0.3492 - val_accuracy: 0.8772\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8641 - val_loss: 0.3459 - val_accuracy: 0.8624\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8669 - val_loss: 0.3476 - val_accuracy: 0.8482\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8652 - val_loss: 0.3422 - val_accuracy: 0.8633\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8682 - val_loss: 0.3419 - val_accuracy: 0.8823\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.8685 - val_loss: 0.3393 - val_accuracy: 0.8783\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8688 - val_loss: 0.3382 - val_accuracy: 0.8593\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8701 - val_loss: 0.3352 - val_accuracy: 0.8739\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8707 - val_loss: 0.3335 - val_accuracy: 0.8695\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8703 - val_loss: 0.3321 - val_accuracy: 0.8762\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8713 - val_loss: 0.3306 - val_accuracy: 0.8769\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8713 - val_loss: 0.3294 - val_accuracy: 0.8809\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8734 - val_loss: 0.3291 - val_accuracy: 0.8623\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8734 - val_loss: 0.3262 - val_accuracy: 0.8799\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8735 - val_loss: 0.3247 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8742 - val_loss: 0.3276 - val_accuracy: 0.8962\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8756 - val_loss: 0.3229 - val_accuracy: 0.8672\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8770 - val_loss: 0.3206 - val_accuracy: 0.8797\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3179 - accuracy: 0.8765 - val_loss: 0.3222 - val_accuracy: 0.8630\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8758 - val_loss: 0.3195 - val_accuracy: 0.8892\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8772 - val_loss: 0.3179 - val_accuracy: 0.8881\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8771 - val_loss: 0.3166 - val_accuracy: 0.8871\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8787 - val_loss: 0.3153 - val_accuracy: 0.8866\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.8789 - val_loss: 0.3145 - val_accuracy: 0.8887\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3104 - accuracy: 0.8785 - val_loss: 0.3143 - val_accuracy: 0.8924\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3099 - accuracy: 0.8802 - val_loss: 0.3122 - val_accuracy: 0.8739\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.8788 - val_loss: 0.3126 - val_accuracy: 0.8940\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8805 - val_loss: 0.3111 - val_accuracy: 0.8927\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3063 - accuracy: 0.8800 - val_loss: 0.3086 - val_accuracy: 0.8813\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3057 - accuracy: 0.8803 - val_loss: 0.3077 - val_accuracy: 0.8807\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3051 - accuracy: 0.8806 - val_loss: 0.3074 - val_accuracy: 0.8908\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8814 - val_loss: 0.3058 - val_accuracy: 0.8822\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3028 - accuracy: 0.8818 - val_loss: 0.3051 - val_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3020 - accuracy: 0.8816 - val_loss: 0.3041 - val_accuracy: 0.8862\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3011 - accuracy: 0.8824 - val_loss: 0.3043 - val_accuracy: 0.8756\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3003 - accuracy: 0.8828 - val_loss: 0.3040 - val_accuracy: 0.8739\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8831 - val_loss: 0.3015 - val_accuracy: 0.8874\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2987 - accuracy: 0.8845 - val_loss: 0.3059 - val_accuracy: 0.9058\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2981 - accuracy: 0.8827 - val_loss: 0.3001 - val_accuracy: 0.8818\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2970 - accuracy: 0.8842 - val_loss: 0.3012 - val_accuracy: 0.8741\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2957 - accuracy: 0.8838 - val_loss: 0.2985 - val_accuracy: 0.8832\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2951 - accuracy: 0.8843 - val_loss: 0.2977 - val_accuracy: 0.8904\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.8845 - val_loss: 0.2968 - val_accuracy: 0.8864\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8858 - val_loss: 0.2978 - val_accuracy: 0.8769\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.8851 - val_loss: 0.2957 - val_accuracy: 0.8829\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8851 - val_loss: 0.2947 - val_accuracy: 0.8918\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2920 - accuracy: 0.8861 - val_loss: 0.2941 - val_accuracy: 0.8931\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8870 - val_loss: 0.2941 - val_accuracy: 0.8813\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8870 - val_loss: 0.2964 - val_accuracy: 0.8742\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.8871 - val_loss: 0.2921 - val_accuracy: 0.8864\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8879 - val_loss: 0.2914 - val_accuracy: 0.8938\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.8876 - val_loss: 0.2916 - val_accuracy: 0.8823\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8881 - val_loss: 0.2922 - val_accuracy: 0.9036\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8885 - val_loss: 0.2897 - val_accuracy: 0.8962\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.8894 - val_loss: 0.2889 - val_accuracy: 0.8896\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2860 - accuracy: 0.8887 - val_loss: 0.2935 - val_accuracy: 0.8742\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2853 - accuracy: 0.8898 - val_loss: 0.2880 - val_accuracy: 0.8978\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.8889 - val_loss: 0.2879 - val_accuracy: 0.8843\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2845 - accuracy: 0.8897 - val_loss: 0.2866 - val_accuracy: 0.8908\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.8894 - val_loss: 0.2864 - val_accuracy: 0.8881\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.8902 - val_loss: 0.2859 - val_accuracy: 0.8881\n",
      "277/277 [==============================] - 0s 912us/step - loss: 0.2767 - accuracy: 0.8903\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6582 - accuracy: 0.6018 - val_loss: 0.6378 - val_accuracy: 0.6097\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.6469 - val_loss: 0.6079 - val_accuracy: 0.6512\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6875 - val_loss: 0.5844 - val_accuracy: 0.7205\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5738 - accuracy: 0.7134 - val_loss: 0.5620 - val_accuracy: 0.7129\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.7339 - val_loss: 0.5434 - val_accuracy: 0.7397\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7529 - val_loss: 0.5289 - val_accuracy: 0.7277\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5195 - accuracy: 0.7643 - val_loss: 0.5133 - val_accuracy: 0.7685\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5054 - accuracy: 0.7796 - val_loss: 0.5008 - val_accuracy: 0.7842\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4933 - accuracy: 0.7874 - val_loss: 0.4927 - val_accuracy: 0.7481\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.7946 - val_loss: 0.4794 - val_accuracy: 0.8076\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4705 - accuracy: 0.8016 - val_loss: 0.4800 - val_accuracy: 0.8638\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8100 - val_loss: 0.4604 - val_accuracy: 0.7890\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.8142 - val_loss: 0.4521 - val_accuracy: 0.8091\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8178 - val_loss: 0.4456 - val_accuracy: 0.8307\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4373 - accuracy: 0.8229 - val_loss: 0.4382 - val_accuracy: 0.8297\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8266 - val_loss: 0.4313 - val_accuracy: 0.8261\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4239 - accuracy: 0.8321 - val_loss: 0.4260 - val_accuracy: 0.8087\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4179 - accuracy: 0.8345 - val_loss: 0.4199 - val_accuracy: 0.8191\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4121 - accuracy: 0.8378 - val_loss: 0.4172 - val_accuracy: 0.8066\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8395 - val_loss: 0.4095 - val_accuracy: 0.8420\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8411 - val_loss: 0.4047 - val_accuracy: 0.8314\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3963 - accuracy: 0.8436 - val_loss: 0.4016 - val_accuracy: 0.8214\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3914 - accuracy: 0.8470 - val_loss: 0.3958 - val_accuracy: 0.8490\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8480 - val_loss: 0.3915 - val_accuracy: 0.8496\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8515 - val_loss: 0.3938 - val_accuracy: 0.8772\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.8520 - val_loss: 0.3839 - val_accuracy: 0.8540\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3750 - accuracy: 0.8539 - val_loss: 0.3806 - val_accuracy: 0.8434\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3713 - accuracy: 0.8551 - val_loss: 0.3769 - val_accuracy: 0.8476\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8561 - val_loss: 0.3736 - val_accuracy: 0.8594\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8584 - val_loss: 0.3705 - val_accuracy: 0.8496\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8587 - val_loss: 0.3673 - val_accuracy: 0.8556\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3579 - accuracy: 0.8613 - val_loss: 0.3645 - val_accuracy: 0.8557\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3554 - accuracy: 0.8624 - val_loss: 0.3619 - val_accuracy: 0.8533\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8625 - val_loss: 0.3614 - val_accuracy: 0.8448\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8629 - val_loss: 0.3575 - val_accuracy: 0.8503\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8649 - val_loss: 0.3547 - val_accuracy: 0.8559\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8652 - val_loss: 0.3521 - val_accuracy: 0.8665\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8684 - val_loss: 0.3517 - val_accuracy: 0.8497\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8678 - val_loss: 0.3495 - val_accuracy: 0.8501\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.8677 - val_loss: 0.3456 - val_accuracy: 0.8698\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8705 - val_loss: 0.3458 - val_accuracy: 0.8827\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8707 - val_loss: 0.3428 - val_accuracy: 0.8793\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8725 - val_loss: 0.3441 - val_accuracy: 0.8482\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8721 - val_loss: 0.3379 - val_accuracy: 0.8652\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8732 - val_loss: 0.3419 - val_accuracy: 0.8940\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8740 - val_loss: 0.3341 - val_accuracy: 0.8709\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8741 - val_loss: 0.3329 - val_accuracy: 0.8783\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3222 - accuracy: 0.8749 - val_loss: 0.3342 - val_accuracy: 0.8559\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3205 - accuracy: 0.8758 - val_loss: 0.3293 - val_accuracy: 0.8707\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8758 - val_loss: 0.3283 - val_accuracy: 0.8807\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8774 - val_loss: 0.3263 - val_accuracy: 0.8714\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3155 - accuracy: 0.8767 - val_loss: 0.3248 - val_accuracy: 0.8744\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3138 - accuracy: 0.8779 - val_loss: 0.3235 - val_accuracy: 0.8718\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.8795 - val_loss: 0.3227 - val_accuracy: 0.8841\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8787 - val_loss: 0.3252 - val_accuracy: 0.8587\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3098 - accuracy: 0.8802 - val_loss: 0.3194 - val_accuracy: 0.8744\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.8790 - val_loss: 0.3193 - val_accuracy: 0.8888\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8808 - val_loss: 0.3184 - val_accuracy: 0.8904\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.8816 - val_loss: 0.3163 - val_accuracy: 0.8864\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.8807 - val_loss: 0.3151 - val_accuracy: 0.8721\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.8822 - val_loss: 0.3164 - val_accuracy: 0.8658\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8822 - val_loss: 0.3123 - val_accuracy: 0.8807\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3012 - accuracy: 0.8832 - val_loss: 0.3143 - val_accuracy: 0.8661\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.8832 - val_loss: 0.3105 - val_accuracy: 0.8862\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.8833 - val_loss: 0.3097 - val_accuracy: 0.8885\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2978 - accuracy: 0.8844 - val_loss: 0.3088 - val_accuracy: 0.8749\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8836 - val_loss: 0.3086 - val_accuracy: 0.8920\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2959 - accuracy: 0.8859 - val_loss: 0.3064 - val_accuracy: 0.8869\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2952 - accuracy: 0.8869 - val_loss: 0.3057 - val_accuracy: 0.8892\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2939 - accuracy: 0.8860 - val_loss: 0.3045 - val_accuracy: 0.8866\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2930 - accuracy: 0.8876 - val_loss: 0.3042 - val_accuracy: 0.8917\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8864 - val_loss: 0.3027 - val_accuracy: 0.8852\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2913 - accuracy: 0.8872 - val_loss: 0.3018 - val_accuracy: 0.8866\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8864 - val_loss: 0.3059 - val_accuracy: 0.8670\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.8888 - val_loss: 0.3006 - val_accuracy: 0.8804\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2886 - accuracy: 0.8874 - val_loss: 0.3032 - val_accuracy: 0.9031\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.8897 - val_loss: 0.2988 - val_accuracy: 0.8910\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.8884 - val_loss: 0.2978 - val_accuracy: 0.8874\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8895 - val_loss: 0.2973 - val_accuracy: 0.8911\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8897 - val_loss: 0.2987 - val_accuracy: 0.9008\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.8902 - val_loss: 0.2969 - val_accuracy: 0.8991\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.8892 - val_loss: 0.2949 - val_accuracy: 0.8906\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8902 - val_loss: 0.2977 - val_accuracy: 0.9045\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2826 - accuracy: 0.8906 - val_loss: 0.2956 - val_accuracy: 0.9019\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.8910 - val_loss: 0.2942 - val_accuracy: 0.8800\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2812 - accuracy: 0.8914 - val_loss: 0.2922 - val_accuracy: 0.8873\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2804 - accuracy: 0.8899 - val_loss: 0.2917 - val_accuracy: 0.8860\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8914 - val_loss: 0.2908 - val_accuracy: 0.8892\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8915 - val_loss: 0.2915 - val_accuracy: 0.9008\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.8915 - val_loss: 0.2898 - val_accuracy: 0.8959\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2776 - accuracy: 0.8937 - val_loss: 0.2903 - val_accuracy: 0.9015\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8914 - val_loss: 0.2897 - val_accuracy: 0.9015\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.8944 - val_loss: 0.2881 - val_accuracy: 0.8869\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2756 - accuracy: 0.8925 - val_loss: 0.2872 - val_accuracy: 0.8954\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2751 - accuracy: 0.8936 - val_loss: 0.2945 - val_accuracy: 0.9135\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8939 - val_loss: 0.2859 - val_accuracy: 0.8920\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2736 - accuracy: 0.8941 - val_loss: 0.2878 - val_accuracy: 0.9056\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.8961 - val_loss: 0.2853 - val_accuracy: 0.8878\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8938 - val_loss: 0.2844 - val_accuracy: 0.8910\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.8941 - val_loss: 0.2838 - val_accuracy: 0.8913\n",
      "277/277 [==============================] - 0s 887us/step - loss: 0.2935 - accuracy: 0.8845\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6645 - accuracy: 0.5939 - val_loss: 0.6445 - val_accuracy: 0.6051\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6334 - accuracy: 0.6335 - val_loss: 0.6137 - val_accuracy: 0.6481\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.6762 - val_loss: 0.5942 - val_accuracy: 0.7513\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5830 - accuracy: 0.7042 - val_loss: 0.5724 - val_accuracy: 0.7714\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5635 - accuracy: 0.7311 - val_loss: 0.5500 - val_accuracy: 0.7492\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7432 - val_loss: 0.5336 - val_accuracy: 0.7317\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7557 - val_loss: 0.5223 - val_accuracy: 0.8015\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7682 - val_loss: 0.5071 - val_accuracy: 0.7465\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7789 - val_loss: 0.4940 - val_accuracy: 0.7680\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7875 - val_loss: 0.4846 - val_accuracy: 0.7640\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4827 - accuracy: 0.7926 - val_loss: 0.4742 - val_accuracy: 0.8078\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7990 - val_loss: 0.4654 - val_accuracy: 0.8149\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.8070 - val_loss: 0.4564 - val_accuracy: 0.8008\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.8109 - val_loss: 0.4505 - val_accuracy: 0.8362\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.8165 - val_loss: 0.4414 - val_accuracy: 0.8124\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8198 - val_loss: 0.4349 - val_accuracy: 0.8274\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4345 - accuracy: 0.8224 - val_loss: 0.4316 - val_accuracy: 0.8504\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.8283 - val_loss: 0.4230 - val_accuracy: 0.8131\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8303 - val_loss: 0.4172 - val_accuracy: 0.8388\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4172 - accuracy: 0.8325 - val_loss: 0.4125 - val_accuracy: 0.8194\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4120 - accuracy: 0.8365 - val_loss: 0.4072 - val_accuracy: 0.8434\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8388 - val_loss: 0.4024 - val_accuracy: 0.8418\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8396 - val_loss: 0.4011 - val_accuracy: 0.8631\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3980 - accuracy: 0.8430 - val_loss: 0.3955 - val_accuracy: 0.8242\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8464 - val_loss: 0.3902 - val_accuracy: 0.8376\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8476 - val_loss: 0.3860 - val_accuracy: 0.8482\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8476 - val_loss: 0.3849 - val_accuracy: 0.8665\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8494 - val_loss: 0.3790 - val_accuracy: 0.8483\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3797 - accuracy: 0.8512 - val_loss: 0.3758 - val_accuracy: 0.8510\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3762 - accuracy: 0.8520 - val_loss: 0.3727 - val_accuracy: 0.8564\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3730 - accuracy: 0.8564 - val_loss: 0.3711 - val_accuracy: 0.8672\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8558 - val_loss: 0.3667 - val_accuracy: 0.8587\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3673 - accuracy: 0.8565 - val_loss: 0.3638 - val_accuracy: 0.8570\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8593 - val_loss: 0.3615 - val_accuracy: 0.8508\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8601 - val_loss: 0.3586 - val_accuracy: 0.8623\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3591 - accuracy: 0.8595 - val_loss: 0.3560 - val_accuracy: 0.8623\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3566 - accuracy: 0.8612 - val_loss: 0.3538 - val_accuracy: 0.8665\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8637 - val_loss: 0.3517 - val_accuracy: 0.8547\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8636 - val_loss: 0.3533 - val_accuracy: 0.8855\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8651 - val_loss: 0.3470 - val_accuracy: 0.8603\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8660 - val_loss: 0.3463 - val_accuracy: 0.8772\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8662 - val_loss: 0.3430 - val_accuracy: 0.8700\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8674 - val_loss: 0.3408 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8675 - val_loss: 0.3392 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3401 - accuracy: 0.8694 - val_loss: 0.3412 - val_accuracy: 0.8887\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8691 - val_loss: 0.3360 - val_accuracy: 0.8760\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8702 - val_loss: 0.3338 - val_accuracy: 0.8733\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8709 - val_loss: 0.3331 - val_accuracy: 0.8815\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8722 - val_loss: 0.3345 - val_accuracy: 0.8526\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8734 - val_loss: 0.3298 - val_accuracy: 0.8623\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8735 - val_loss: 0.3299 - val_accuracy: 0.8878\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8735 - val_loss: 0.3262 - val_accuracy: 0.8792\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3266 - accuracy: 0.8737 - val_loss: 0.3284 - val_accuracy: 0.8924\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3254 - accuracy: 0.8745 - val_loss: 0.3248 - val_accuracy: 0.8869\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8754 - val_loss: 0.3224 - val_accuracy: 0.8852\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8764 - val_loss: 0.3201 - val_accuracy: 0.8725\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8763 - val_loss: 0.3252 - val_accuracy: 0.9010\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8787 - val_loss: 0.3175 - val_accuracy: 0.8776\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8777 - val_loss: 0.3237 - val_accuracy: 0.8543\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.3175 - accuracy: 0.8785 - val_loss: 0.3165 - val_accuracy: 0.8878\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8801 - val_loss: 0.3140 - val_accuracy: 0.8811\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8787 - val_loss: 0.3129 - val_accuracy: 0.8822\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3142 - accuracy: 0.8805 - val_loss: 0.3130 - val_accuracy: 0.8689\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8794 - val_loss: 0.3106 - val_accuracy: 0.8765\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3117 - accuracy: 0.8806 - val_loss: 0.3145 - val_accuracy: 0.9014\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3103 - accuracy: 0.8827 - val_loss: 0.3085 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.8810 - val_loss: 0.3079 - val_accuracy: 0.8876\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3092 - accuracy: 0.8818 - val_loss: 0.3064 - val_accuracy: 0.8853\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.8830 - val_loss: 0.3070 - val_accuracy: 0.8929\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3068 - accuracy: 0.8827 - val_loss: 0.3053 - val_accuracy: 0.8730\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.8825 - val_loss: 0.3034 - val_accuracy: 0.8829\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8834 - val_loss: 0.3025 - val_accuracy: 0.8830\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8825 - val_loss: 0.3017 - val_accuracy: 0.8790\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.8845 - val_loss: 0.3044 - val_accuracy: 0.8675\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.8848 - val_loss: 0.3007 - val_accuracy: 0.8760\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8849 - val_loss: 0.2990 - val_accuracy: 0.8818\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3009 - accuracy: 0.8859 - val_loss: 0.2982 - val_accuracy: 0.8880\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.8867 - val_loss: 0.2978 - val_accuracy: 0.8913\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8859 - val_loss: 0.2998 - val_accuracy: 0.8702\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2982 - accuracy: 0.8856 - val_loss: 0.2961 - val_accuracy: 0.8792\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.8874 - val_loss: 0.2955 - val_accuracy: 0.8929\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2963 - accuracy: 0.8870 - val_loss: 0.2941 - val_accuracy: 0.8871\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.8877 - val_loss: 0.2933 - val_accuracy: 0.8883\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2949 - accuracy: 0.8864 - val_loss: 0.3038 - val_accuracy: 0.9147\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8880 - val_loss: 0.2926 - val_accuracy: 0.8793\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8876 - val_loss: 0.2918 - val_accuracy: 0.8961\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8881 - val_loss: 0.2906 - val_accuracy: 0.8915\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2919 - accuracy: 0.8889 - val_loss: 0.2897 - val_accuracy: 0.8892\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2914 - accuracy: 0.8887 - val_loss: 0.2891 - val_accuracy: 0.8904\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2908 - accuracy: 0.8902 - val_loss: 0.2894 - val_accuracy: 0.8802\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.2905 - accuracy: 0.8897 - val_loss: 0.2876 - val_accuracy: 0.8896\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8893 - val_loss: 0.2877 - val_accuracy: 0.8825\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.8895 - val_loss: 0.2867 - val_accuracy: 0.8859\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8900 - val_loss: 0.2862 - val_accuracy: 0.8850\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2880 - accuracy: 0.8899 - val_loss: 0.2875 - val_accuracy: 0.9051\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8904 - val_loss: 0.2893 - val_accuracy: 0.9084\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8913 - val_loss: 0.2910 - val_accuracy: 0.9121\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2858 - accuracy: 0.8925 - val_loss: 0.2835 - val_accuracy: 0.8874\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.8912 - val_loss: 0.2826 - val_accuracy: 0.8913\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8917 - val_loss: 0.2830 - val_accuracy: 0.8844\n",
      "277/277 [==============================] - 0s 875us/step - loss: 0.2723 - accuracy: 0.8859\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6738 - accuracy: 0.5903 - val_loss: 0.6662 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6666 - accuracy: 0.5914 - val_loss: 0.6604 - val_accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6601 - accuracy: 0.5921 - val_loss: 0.6535 - val_accuracy: 0.6049\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6534 - accuracy: 0.5981 - val_loss: 0.6471 - val_accuracy: 0.6051\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6472 - accuracy: 0.6049 - val_loss: 0.6407 - val_accuracy: 0.6171\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6412 - accuracy: 0.6146 - val_loss: 0.6351 - val_accuracy: 0.6299\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6353 - accuracy: 0.6247 - val_loss: 0.6290 - val_accuracy: 0.6278\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6295 - accuracy: 0.6325 - val_loss: 0.6250 - val_accuracy: 0.6623\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6240 - accuracy: 0.6450 - val_loss: 0.6181 - val_accuracy: 0.6449\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6187 - accuracy: 0.6504 - val_loss: 0.6130 - val_accuracy: 0.6516\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6136 - accuracy: 0.6585 - val_loss: 0.6093 - val_accuracy: 0.6857\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6088 - accuracy: 0.6669 - val_loss: 0.6038 - val_accuracy: 0.6838\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6041 - accuracy: 0.6747 - val_loss: 0.5992 - val_accuracy: 0.6896\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6819 - val_loss: 0.5943 - val_accuracy: 0.6697\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6851 - val_loss: 0.5903 - val_accuracy: 0.7057\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5901 - accuracy: 0.6923 - val_loss: 0.5852 - val_accuracy: 0.6968\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5855 - accuracy: 0.6970 - val_loss: 0.5834 - val_accuracy: 0.7349\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5813 - accuracy: 0.7077 - val_loss: 0.5770 - val_accuracy: 0.6924\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5773 - accuracy: 0.7075 - val_loss: 0.5729 - val_accuracy: 0.7079\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5731 - accuracy: 0.7127 - val_loss: 0.5690 - val_accuracy: 0.7120\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.7167 - val_loss: 0.5654 - val_accuracy: 0.7065\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7201 - val_loss: 0.5622 - val_accuracy: 0.7375\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5617 - accuracy: 0.7258 - val_loss: 0.5580 - val_accuracy: 0.7261\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7301 - val_loss: 0.5545 - val_accuracy: 0.7226\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5546 - accuracy: 0.7320 - val_loss: 0.5512 - val_accuracy: 0.7215\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5511 - accuracy: 0.7372 - val_loss: 0.5478 - val_accuracy: 0.7333\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7402 - val_loss: 0.5447 - val_accuracy: 0.7284\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7430 - val_loss: 0.5415 - val_accuracy: 0.7426\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7476 - val_loss: 0.5384 - val_accuracy: 0.7367\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7482 - val_loss: 0.5355 - val_accuracy: 0.7354\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7497 - val_loss: 0.5334 - val_accuracy: 0.7666\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7553 - val_loss: 0.5298 - val_accuracy: 0.7573\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7578\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7610 - val_loss: 0.5241 - val_accuracy: 0.7544\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7620 - val_loss: 0.5216 - val_accuracy: 0.7638\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5210 - accuracy: 0.7638 - val_loss: 0.5190 - val_accuracy: 0.7643\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7672 - val_loss: 0.5163 - val_accuracy: 0.7552\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7680 - val_loss: 0.5138 - val_accuracy: 0.7594\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7702 - val_loss: 0.5117 - val_accuracy: 0.7735\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7730 - val_loss: 0.5094 - val_accuracy: 0.7782\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7732 - val_loss: 0.5072 - val_accuracy: 0.7837\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7765 - val_loss: 0.5042 - val_accuracy: 0.7724\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7791 - val_loss: 0.5019 - val_accuracy: 0.7724\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.7813 - val_loss: 0.5004 - val_accuracy: 0.7553\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4989 - accuracy: 0.7820 - val_loss: 0.4975 - val_accuracy: 0.7687\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4967 - accuracy: 0.7821 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.7855 - val_loss: 0.4931 - val_accuracy: 0.7761\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4925 - accuracy: 0.7850 - val_loss: 0.4912 - val_accuracy: 0.7735\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7860 - val_loss: 0.4898 - val_accuracy: 0.7953\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.7878 - val_loss: 0.4873 - val_accuracy: 0.7881\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7886 - val_loss: 0.4862 - val_accuracy: 0.8022\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7908 - val_loss: 0.4852 - val_accuracy: 0.8124\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4823 - accuracy: 0.7921 - val_loss: 0.4816 - val_accuracy: 0.7798\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7935 - val_loss: 0.4797 - val_accuracy: 0.7823\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.7963 - val_loss: 0.4790 - val_accuracy: 0.7694\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7951 - val_loss: 0.4761 - val_accuracy: 0.7951\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7982 - val_loss: 0.4742 - val_accuracy: 0.7883\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4731 - accuracy: 0.7972 - val_loss: 0.4727 - val_accuracy: 0.8017\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.7995 - val_loss: 0.4713 - val_accuracy: 0.8075\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4695 - accuracy: 0.8017 - val_loss: 0.4692 - val_accuracy: 0.8022\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4679 - accuracy: 0.8017 - val_loss: 0.4685 - val_accuracy: 0.8159\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4663 - accuracy: 0.8038 - val_loss: 0.4661 - val_accuracy: 0.8075\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.8034 - val_loss: 0.4642 - val_accuracy: 0.8018\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8053 - val_loss: 0.4627 - val_accuracy: 0.7951\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.8050 - val_loss: 0.4611 - val_accuracy: 0.7957\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.8062 - val_loss: 0.4598 - val_accuracy: 0.7918\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4583 - accuracy: 0.8068 - val_loss: 0.4583 - val_accuracy: 0.8108\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8094 - val_loss: 0.4566 - val_accuracy: 0.8047\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8082 - val_loss: 0.4552 - val_accuracy: 0.8096\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4536 - accuracy: 0.8110 - val_loss: 0.4537 - val_accuracy: 0.8092\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.8104 - val_loss: 0.4528 - val_accuracy: 0.8212\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.8122 - val_loss: 0.4508 - val_accuracy: 0.8039\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4491 - accuracy: 0.8130 - val_loss: 0.4495 - val_accuracy: 0.8154\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4477 - accuracy: 0.8157 - val_loss: 0.4480 - val_accuracy: 0.8096\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8156 - val_loss: 0.4467 - val_accuracy: 0.8047\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.8163 - val_loss: 0.4453 - val_accuracy: 0.8073\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8156 - val_loss: 0.4441 - val_accuracy: 0.8165\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4423 - accuracy: 0.8171 - val_loss: 0.4427 - val_accuracy: 0.8156\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8181 - val_loss: 0.4418 - val_accuracy: 0.8251\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4397 - accuracy: 0.8184 - val_loss: 0.4403 - val_accuracy: 0.8209\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8188 - val_loss: 0.4393 - val_accuracy: 0.8279\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.8217 - val_loss: 0.4379 - val_accuracy: 0.8254\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4359 - accuracy: 0.8208 - val_loss: 0.4369 - val_accuracy: 0.8305\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8207 - val_loss: 0.4353 - val_accuracy: 0.8205\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4333 - accuracy: 0.8226 - val_loss: 0.4343 - val_accuracy: 0.8110\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4322 - accuracy: 0.8225 - val_loss: 0.4329 - val_accuracy: 0.8202\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4309 - accuracy: 0.8225 - val_loss: 0.4320 - val_accuracy: 0.8302\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4298 - accuracy: 0.8243 - val_loss: 0.4306 - val_accuracy: 0.8202\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.8242 - val_loss: 0.4296 - val_accuracy: 0.8311\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4271 - accuracy: 0.8253 - val_loss: 0.4284 - val_accuracy: 0.8305\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4263 - accuracy: 0.8269 - val_loss: 0.4272 - val_accuracy: 0.8165\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8266 - val_loss: 0.4260 - val_accuracy: 0.8247\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4240 - accuracy: 0.8267 - val_loss: 0.4251 - val_accuracy: 0.8184\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4227 - accuracy: 0.8280 - val_loss: 0.4239 - val_accuracy: 0.8205\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4218 - accuracy: 0.8280 - val_loss: 0.4228 - val_accuracy: 0.8297\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4207 - accuracy: 0.8296 - val_loss: 0.4220 - val_accuracy: 0.8194\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4196 - accuracy: 0.8301 - val_loss: 0.4208 - val_accuracy: 0.8288\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4186 - accuracy: 0.8296 - val_loss: 0.4197 - val_accuracy: 0.8295\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4174 - accuracy: 0.8306 - val_loss: 0.4190 - val_accuracy: 0.8209\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4166 - accuracy: 0.8302 - val_loss: 0.4178 - val_accuracy: 0.8288\n",
      "277/277 [==============================] - 0s 882us/step - loss: 0.4147 - accuracy: 0.8329\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6721 - accuracy: 0.5942 - val_loss: 0.6663 - val_accuracy: 0.6005\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6650 - accuracy: 0.5947 - val_loss: 0.6593 - val_accuracy: 0.6005\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6583 - accuracy: 0.5955 - val_loss: 0.6533 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6516 - accuracy: 0.6000 - val_loss: 0.6463 - val_accuracy: 0.6081\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6454 - accuracy: 0.6087 - val_loss: 0.6401 - val_accuracy: 0.6139\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6393 - accuracy: 0.6154 - val_loss: 0.6343 - val_accuracy: 0.6241\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6332 - accuracy: 0.6274 - val_loss: 0.6292 - val_accuracy: 0.6218\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6275 - accuracy: 0.6338 - val_loss: 0.6250 - val_accuracy: 0.6651\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.6445 - val_loss: 0.6178 - val_accuracy: 0.6449\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6167 - accuracy: 0.6517 - val_loss: 0.6127 - val_accuracy: 0.6577\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6115 - accuracy: 0.6600 - val_loss: 0.6101 - val_accuracy: 0.7005\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6065 - accuracy: 0.6688 - val_loss: 0.6037 - val_accuracy: 0.6896\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6015 - accuracy: 0.6770 - val_loss: 0.5982 - val_accuracy: 0.6813\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6802 - val_loss: 0.5937 - val_accuracy: 0.6893\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6894 - val_loss: 0.5892 - val_accuracy: 0.6939\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5876 - accuracy: 0.6938 - val_loss: 0.5848 - val_accuracy: 0.6919\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7004 - val_loss: 0.5806 - val_accuracy: 0.6970\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5788 - accuracy: 0.7058 - val_loss: 0.5772 - val_accuracy: 0.6870\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7079 - val_loss: 0.5746 - val_accuracy: 0.7421\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5707 - accuracy: 0.7173 - val_loss: 0.5690 - val_accuracy: 0.6972\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5663 - accuracy: 0.7185 - val_loss: 0.5665 - val_accuracy: 0.7470\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7246 - val_loss: 0.5615 - val_accuracy: 0.7368\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5587 - accuracy: 0.7284 - val_loss: 0.5573 - val_accuracy: 0.7252\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5548 - accuracy: 0.7298 - val_loss: 0.5548 - val_accuracy: 0.7483\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5512 - accuracy: 0.7373 - val_loss: 0.5503 - val_accuracy: 0.7231\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7375 - val_loss: 0.5470 - val_accuracy: 0.7407\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7435 - val_loss: 0.5440 - val_accuracy: 0.7231\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7442 - val_loss: 0.5411 - val_accuracy: 0.7227\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7471 - val_loss: 0.5376 - val_accuracy: 0.7511\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7522 - val_loss: 0.5344 - val_accuracy: 0.7389\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7515 - val_loss: 0.5318 - val_accuracy: 0.7603\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5285 - accuracy: 0.7571 - val_loss: 0.5286 - val_accuracy: 0.7546\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7586 - val_loss: 0.5257 - val_accuracy: 0.7472\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5225 - accuracy: 0.7610 - val_loss: 0.5229 - val_accuracy: 0.7509\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7639 - val_loss: 0.5209 - val_accuracy: 0.7411\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5169 - accuracy: 0.7659 - val_loss: 0.5175 - val_accuracy: 0.7613\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.7680 - val_loss: 0.5150 - val_accuracy: 0.7548\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5116 - accuracy: 0.7710 - val_loss: 0.5127 - val_accuracy: 0.7745\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5088 - accuracy: 0.7739 - val_loss: 0.5099 - val_accuracy: 0.7622\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.7734 - val_loss: 0.5084 - val_accuracy: 0.7865\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7775 - val_loss: 0.5053 - val_accuracy: 0.7758\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5014 - accuracy: 0.7791 - val_loss: 0.5032 - val_accuracy: 0.7844\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.7798 - val_loss: 0.5005 - val_accuracy: 0.7742\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7819 - val_loss: 0.4983 - val_accuracy: 0.7721\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4944 - accuracy: 0.7843 - val_loss: 0.4962 - val_accuracy: 0.7823\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4921 - accuracy: 0.7859 - val_loss: 0.4951 - val_accuracy: 0.7999\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4900 - accuracy: 0.7910 - val_loss: 0.4920 - val_accuracy: 0.7692\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.7888 - val_loss: 0.4898 - val_accuracy: 0.7869\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.7920 - val_loss: 0.4886 - val_accuracy: 0.7636\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.7903 - val_loss: 0.4857 - val_accuracy: 0.7888\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4813 - accuracy: 0.7948 - val_loss: 0.4838 - val_accuracy: 0.7759\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.7948 - val_loss: 0.4817 - val_accuracy: 0.7890\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7957 - val_loss: 0.4806 - val_accuracy: 0.8059\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4752 - accuracy: 0.7999 - val_loss: 0.4779 - val_accuracy: 0.7860\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.7988 - val_loss: 0.4761 - val_accuracy: 0.7950\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.8018 - val_loss: 0.4743 - val_accuracy: 0.7826\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.8023 - val_loss: 0.4724 - val_accuracy: 0.7987\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.8036 - val_loss: 0.4705 - val_accuracy: 0.7965\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4658 - accuracy: 0.8055 - val_loss: 0.4688 - val_accuracy: 0.7930\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4639 - accuracy: 0.8057 - val_loss: 0.4671 - val_accuracy: 0.8018\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4622 - accuracy: 0.8066 - val_loss: 0.4653 - val_accuracy: 0.7962\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4603 - accuracy: 0.8082 - val_loss: 0.4641 - val_accuracy: 0.8119\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.8105 - val_loss: 0.4624 - val_accuracy: 0.8119\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4568 - accuracy: 0.8103 - val_loss: 0.4607 - val_accuracy: 0.8122\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8124 - val_loss: 0.4587 - val_accuracy: 0.8015\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.8139 - val_loss: 0.4572 - val_accuracy: 0.7978\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4518 - accuracy: 0.8141 - val_loss: 0.4558 - val_accuracy: 0.7951\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8137 - val_loss: 0.4542 - val_accuracy: 0.8018\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4486 - accuracy: 0.8150 - val_loss: 0.4528 - val_accuracy: 0.7992\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4472 - accuracy: 0.8163 - val_loss: 0.4512 - val_accuracy: 0.8047\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4456 - accuracy: 0.8191 - val_loss: 0.4509 - val_accuracy: 0.7899\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8180 - val_loss: 0.4483 - val_accuracy: 0.8061\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.8200 - val_loss: 0.4471 - val_accuracy: 0.8022\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4412 - accuracy: 0.8193 - val_loss: 0.4456 - val_accuracy: 0.8163\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8202 - val_loss: 0.4445 - val_accuracy: 0.8242\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4383 - accuracy: 0.8242 - val_loss: 0.4428 - val_accuracy: 0.8120\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4369 - accuracy: 0.8220 - val_loss: 0.4415 - val_accuracy: 0.8180\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4355 - accuracy: 0.8247 - val_loss: 0.4403 - val_accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.8248 - val_loss: 0.4393 - val_accuracy: 0.8286\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8263 - val_loss: 0.4377 - val_accuracy: 0.8112\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.8263 - val_loss: 0.4365 - val_accuracy: 0.8105\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8263 - val_loss: 0.4351 - val_accuracy: 0.8209\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.8270 - val_loss: 0.4339 - val_accuracy: 0.8193\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4277 - accuracy: 0.8273 - val_loss: 0.4331 - val_accuracy: 0.8087\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.8270 - val_loss: 0.4316 - val_accuracy: 0.8293\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4249 - accuracy: 0.8293 - val_loss: 0.4306 - val_accuracy: 0.8341\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4238 - accuracy: 0.8291 - val_loss: 0.4291 - val_accuracy: 0.8279\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4285 - val_accuracy: 0.8105\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4214 - accuracy: 0.8314 - val_loss: 0.4268 - val_accuracy: 0.8291\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4203 - accuracy: 0.8328 - val_loss: 0.4257 - val_accuracy: 0.8184\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4191 - accuracy: 0.8322 - val_loss: 0.4247 - val_accuracy: 0.8365\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4176 - accuracy: 0.8343 - val_loss: 0.4238 - val_accuracy: 0.8143\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4168 - accuracy: 0.8334 - val_loss: 0.4224 - val_accuracy: 0.8355\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4154 - accuracy: 0.8352 - val_loss: 0.4215 - val_accuracy: 0.8175\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.8349 - val_loss: 0.4203 - val_accuracy: 0.8210\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4133 - accuracy: 0.8343 - val_loss: 0.4193 - val_accuracy: 0.8371\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8346 - val_loss: 0.4185 - val_accuracy: 0.8408\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.8379 - val_loss: 0.4171 - val_accuracy: 0.8297\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8377 - val_loss: 0.4162 - val_accuracy: 0.8381\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8382 - val_loss: 0.4153 - val_accuracy: 0.8244\n",
      "277/277 [==============================] - 0s 850us/step - loss: 0.4216 - accuracy: 0.8151\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6808 - accuracy: 0.5699 - val_loss: 0.6626 - val_accuracy: 0.6003\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.5919 - val_loss: 0.6569 - val_accuracy: 0.6024\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6582 - accuracy: 0.5939 - val_loss: 0.6515 - val_accuracy: 0.6089\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6523 - accuracy: 0.6000 - val_loss: 0.6453 - val_accuracy: 0.6153\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6464 - accuracy: 0.6076 - val_loss: 0.6393 - val_accuracy: 0.6197\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6407 - accuracy: 0.6159 - val_loss: 0.6337 - val_accuracy: 0.6220\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6353 - accuracy: 0.6258 - val_loss: 0.6288 - val_accuracy: 0.6243\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6307 - val_loss: 0.6230 - val_accuracy: 0.6401\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.6412 - val_loss: 0.6188 - val_accuracy: 0.6646\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6198 - accuracy: 0.6491 - val_loss: 0.6139 - val_accuracy: 0.6766\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6148 - accuracy: 0.6587 - val_loss: 0.6100 - val_accuracy: 0.6961\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6102 - accuracy: 0.6658 - val_loss: 0.6034 - val_accuracy: 0.6634\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6056 - accuracy: 0.6722 - val_loss: 0.5987 - val_accuracy: 0.6752\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6784 - val_loss: 0.5943 - val_accuracy: 0.6748\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5967 - accuracy: 0.6832 - val_loss: 0.5902 - val_accuracy: 0.6806\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5925 - accuracy: 0.6891 - val_loss: 0.5861 - val_accuracy: 0.6930\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5885 - accuracy: 0.6932 - val_loss: 0.5825 - val_accuracy: 0.7085\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5844 - accuracy: 0.6962 - val_loss: 0.5804 - val_accuracy: 0.7361\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.7068 - val_loss: 0.5743 - val_accuracy: 0.7116\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.7086 - val_loss: 0.5705 - val_accuracy: 0.7180\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5729 - accuracy: 0.7125 - val_loss: 0.5667 - val_accuracy: 0.7226\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7152 - val_loss: 0.5641 - val_accuracy: 0.7395\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7242 - val_loss: 0.5596 - val_accuracy: 0.7120\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5619 - accuracy: 0.7220 - val_loss: 0.5568 - val_accuracy: 0.7430\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7307 - val_loss: 0.5526 - val_accuracy: 0.7330\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7327 - val_loss: 0.5502 - val_accuracy: 0.7486\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5518 - accuracy: 0.7374 - val_loss: 0.5463 - val_accuracy: 0.7375\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7393 - val_loss: 0.5432 - val_accuracy: 0.7340\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7413 - val_loss: 0.5412 - val_accuracy: 0.7611\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7453 - val_loss: 0.5379 - val_accuracy: 0.7596\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7476 - val_loss: 0.5348 - val_accuracy: 0.7597\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7522 - val_loss: 0.5315 - val_accuracy: 0.7509\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7518 - val_loss: 0.5301 - val_accuracy: 0.7745\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7545 - val_loss: 0.5259 - val_accuracy: 0.7516\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7566 - val_loss: 0.5242 - val_accuracy: 0.7733\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5254 - accuracy: 0.7601 - val_loss: 0.5210 - val_accuracy: 0.7675\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.7618 - val_loss: 0.5181 - val_accuracy: 0.7557\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5204 - accuracy: 0.7630 - val_loss: 0.5161 - val_accuracy: 0.7736\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7659 - val_loss: 0.5136 - val_accuracy: 0.7744\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7692 - val_loss: 0.5116 - val_accuracy: 0.7825\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.7702 - val_loss: 0.5100 - val_accuracy: 0.7916\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5106 - accuracy: 0.7734 - val_loss: 0.5062 - val_accuracy: 0.7752\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7821\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7757 - val_loss: 0.5015 - val_accuracy: 0.7766\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7777 - val_loss: 0.4998 - val_accuracy: 0.7870\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5013 - accuracy: 0.7781 - val_loss: 0.4970 - val_accuracy: 0.7751\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7799 - val_loss: 0.4953 - val_accuracy: 0.7872\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4969 - accuracy: 0.7823 - val_loss: 0.4934 - val_accuracy: 0.7928\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7844 - val_loss: 0.4906 - val_accuracy: 0.7768\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7844 - val_loss: 0.4891 - val_accuracy: 0.7918\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4908 - accuracy: 0.7867 - val_loss: 0.4867 - val_accuracy: 0.7830\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.7882 - val_loss: 0.4849 - val_accuracy: 0.7879\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4868 - accuracy: 0.7896 - val_loss: 0.4832 - val_accuracy: 0.7928\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7929 - val_loss: 0.4812 - val_accuracy: 0.7782\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4831 - accuracy: 0.7920 - val_loss: 0.4792 - val_accuracy: 0.7858\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4812 - accuracy: 0.7924 - val_loss: 0.4779 - val_accuracy: 0.8015\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4793 - accuracy: 0.7958 - val_loss: 0.4757 - val_accuracy: 0.7856\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4776 - accuracy: 0.7956 - val_loss: 0.4739 - val_accuracy: 0.7897\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7982 - val_loss: 0.4721 - val_accuracy: 0.7907\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4740 - accuracy: 0.7981 - val_loss: 0.4704 - val_accuracy: 0.7953\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4721 - accuracy: 0.8009 - val_loss: 0.4686 - val_accuracy: 0.7914\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.8012 - val_loss: 0.4672 - val_accuracy: 0.8059\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4687 - accuracy: 0.8006 - val_loss: 0.4657 - val_accuracy: 0.8082\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.8016 - val_loss: 0.4655 - val_accuracy: 0.8267\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.8047 - val_loss: 0.4621 - val_accuracy: 0.8054\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.8053 - val_loss: 0.4606 - val_accuracy: 0.7911\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.8047 - val_loss: 0.4591 - val_accuracy: 0.8087\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4605 - accuracy: 0.8062 - val_loss: 0.4582 - val_accuracy: 0.8196\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4591 - accuracy: 0.8078 - val_loss: 0.4559 - val_accuracy: 0.8069\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.8073 - val_loss: 0.4561 - val_accuracy: 0.8323\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4561 - accuracy: 0.8092 - val_loss: 0.4536 - val_accuracy: 0.8202\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4547 - accuracy: 0.8120 - val_loss: 0.4516 - val_accuracy: 0.8089\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8106 - val_loss: 0.4504 - val_accuracy: 0.8154\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4519 - accuracy: 0.8121 - val_loss: 0.4495 - val_accuracy: 0.8249\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.8145 - val_loss: 0.4474 - val_accuracy: 0.8069\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4490 - accuracy: 0.8143 - val_loss: 0.4461 - val_accuracy: 0.8083\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.8146 - val_loss: 0.4452 - val_accuracy: 0.8254\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4462 - accuracy: 0.8159 - val_loss: 0.4438 - val_accuracy: 0.8246\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4452 - accuracy: 0.8162 - val_loss: 0.4423 - val_accuracy: 0.8205\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8189 - val_loss: 0.4410 - val_accuracy: 0.8076\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.8171 - val_loss: 0.4400 - val_accuracy: 0.8263\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4411 - accuracy: 0.8188 - val_loss: 0.4384 - val_accuracy: 0.8124\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8185 - val_loss: 0.4374 - val_accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8222 - val_loss: 0.4360 - val_accuracy: 0.8177\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8214 - val_loss: 0.4348 - val_accuracy: 0.8173\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8216 - val_loss: 0.4343 - val_accuracy: 0.8355\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8226 - val_loss: 0.4329 - val_accuracy: 0.8325\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.8235 - val_loss: 0.4319 - val_accuracy: 0.8362\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4329 - accuracy: 0.8257 - val_loss: 0.4304 - val_accuracy: 0.8126\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8247 - val_loss: 0.4291 - val_accuracy: 0.8231\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.8262 - val_loss: 0.4284 - val_accuracy: 0.8346\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8256 - val_loss: 0.4278 - val_accuracy: 0.8408\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4284 - accuracy: 0.8286 - val_loss: 0.4259 - val_accuracy: 0.8274\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4273 - accuracy: 0.8275 - val_loss: 0.4251 - val_accuracy: 0.8362\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4260 - accuracy: 0.8285 - val_loss: 0.4245 - val_accuracy: 0.8413\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8288 - val_loss: 0.4250 - val_accuracy: 0.8494\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4241 - accuracy: 0.8302 - val_loss: 0.4218 - val_accuracy: 0.8360\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8317 - val_loss: 0.4212 - val_accuracy: 0.8143\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4220 - accuracy: 0.8293 - val_loss: 0.4197 - val_accuracy: 0.8323\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4209 - accuracy: 0.8312 - val_loss: 0.4187 - val_accuracy: 0.8263\n",
      "277/277 [==============================] - 0s 863us/step - loss: 0.4096 - accuracy: 0.8330\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6408 - accuracy: 0.6440 - val_loss: 0.6492 - val_accuracy: 0.6038\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.6914 - val_loss: 0.4105 - val_accuracy: 0.8848\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3683 - accuracy: 0.8499 - val_loss: 0.4837 - val_accuracy: 0.8284\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8881 - val_loss: 1.2219 - val_accuracy: 0.3995\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8709 - val_loss: 0.2268 - val_accuracy: 0.9110\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8915 - val_loss: 0.2480 - val_accuracy: 0.9232\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.8976 - val_loss: 0.4190 - val_accuracy: 0.8379\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2700 - accuracy: 0.8973 - val_loss: 0.2274 - val_accuracy: 0.9257\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.9062 - val_loss: 0.4164 - val_accuracy: 0.8712\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2550 - accuracy: 0.9048 - val_loss: 0.2234 - val_accuracy: 0.9154\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2700 - accuracy: 0.8986 - val_loss: 0.1966 - val_accuracy: 0.9352\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2593 - accuracy: 0.9044 - val_loss: 0.2092 - val_accuracy: 0.9297\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.9110 - val_loss: 0.1935 - val_accuracy: 0.9339\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2552 - accuracy: 0.9054 - val_loss: 0.2375 - val_accuracy: 0.9066\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9115 - val_loss: 0.2397 - val_accuracy: 0.9047\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.9125 - val_loss: 0.4916 - val_accuracy: 0.7129\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.9011 - val_loss: 0.1832 - val_accuracy: 0.9348\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2302 - accuracy: 0.9159 - val_loss: 0.1975 - val_accuracy: 0.9267\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.9115 - val_loss: 0.1877 - val_accuracy: 0.9327\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2317 - accuracy: 0.9171 - val_loss: 0.3127 - val_accuracy: 0.8732\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9211 - val_loss: 0.2588 - val_accuracy: 0.9028\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2118 - accuracy: 0.9227 - val_loss: 0.7392 - val_accuracy: 0.4696\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2198 - accuracy: 0.9230 - val_loss: 0.4134 - val_accuracy: 0.8138\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2270 - accuracy: 0.9174 - val_loss: 0.1753 - val_accuracy: 0.9405\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2145 - accuracy: 0.9236 - val_loss: 0.2886 - val_accuracy: 0.9112\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2141 - accuracy: 0.9227 - val_loss: 0.1730 - val_accuracy: 0.9376\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2228 - accuracy: 0.9196 - val_loss: 0.2487 - val_accuracy: 0.9003\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2076 - accuracy: 0.9243 - val_loss: 0.1776 - val_accuracy: 0.9368\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9246 - val_loss: 0.1699 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2064 - accuracy: 0.9252 - val_loss: 0.1966 - val_accuracy: 0.9339\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2048 - accuracy: 0.9269 - val_loss: 0.4174 - val_accuracy: 0.8718\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9250 - val_loss: 0.3182 - val_accuracy: 0.8818\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.9230 - val_loss: 0.2017 - val_accuracy: 0.9243\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2026 - accuracy: 0.9277 - val_loss: 0.1996 - val_accuracy: 0.9297\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9265 - val_loss: 0.1617 - val_accuracy: 0.9457\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.9279 - val_loss: 0.1770 - val_accuracy: 0.9357\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9306 - val_loss: 0.1628 - val_accuracy: 0.9454\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9305 - val_loss: 0.1602 - val_accuracy: 0.9452\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9323 - val_loss: 0.1715 - val_accuracy: 0.9440\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.9338 - val_loss: 0.1546 - val_accuracy: 0.9487\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1910 - accuracy: 0.9341 - val_loss: 0.1993 - val_accuracy: 0.9318\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9290 - val_loss: 0.1768 - val_accuracy: 0.9389\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1912 - accuracy: 0.9322 - val_loss: 0.1811 - val_accuracy: 0.9345\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.9352 - val_loss: 0.1713 - val_accuracy: 0.9394\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.9321 - val_loss: 0.1793 - val_accuracy: 0.9369\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.9388 - val_loss: 0.5573 - val_accuracy: 0.8508\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9320 - val_loss: 0.1767 - val_accuracy: 0.9389\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1852 - accuracy: 0.9362 - val_loss: 0.1475 - val_accuracy: 0.9526\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9342 - val_loss: 0.1615 - val_accuracy: 0.9470\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1945 - accuracy: 0.9317 - val_loss: 0.1687 - val_accuracy: 0.9419\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.9363 - val_loss: 0.1455 - val_accuracy: 0.9523\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.9398 - val_loss: 0.1562 - val_accuracy: 0.9480\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.9376 - val_loss: 0.1436 - val_accuracy: 0.9533\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9387 - val_loss: 0.1509 - val_accuracy: 0.9510\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.9376 - val_loss: 0.1687 - val_accuracy: 0.9447\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9391 - val_loss: 0.1401 - val_accuracy: 0.9542\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.9386 - val_loss: 0.1474 - val_accuracy: 0.9509\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1709 - accuracy: 0.9410 - val_loss: 0.2826 - val_accuracy: 0.9019\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9425 - val_loss: 0.1682 - val_accuracy: 0.9514\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.9410 - val_loss: 0.1745 - val_accuracy: 0.9454\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9369 - val_loss: 0.1501 - val_accuracy: 0.9489\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.9375 - val_loss: 0.1373 - val_accuracy: 0.9577\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9454 - val_loss: 0.1950 - val_accuracy: 0.9294\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1717 - accuracy: 0.9424 - val_loss: 0.1430 - val_accuracy: 0.9544\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1670 - accuracy: 0.9433 - val_loss: 0.2103 - val_accuracy: 0.9466\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9402 - val_loss: 0.2242 - val_accuracy: 0.9260\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.9416 - val_loss: 0.1389 - val_accuracy: 0.9553\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9415 - val_loss: 0.1408 - val_accuracy: 0.9505\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1712 - accuracy: 0.9412 - val_loss: 0.1456 - val_accuracy: 0.9509\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1495 - accuracy: 0.9503 - val_loss: 0.1339 - val_accuracy: 0.9584\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1681 - accuracy: 0.9439 - val_loss: 0.1883 - val_accuracy: 0.9309\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1695 - accuracy: 0.9434 - val_loss: 0.1502 - val_accuracy: 0.9521\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1602 - accuracy: 0.9453 - val_loss: 0.1304 - val_accuracy: 0.9590\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1636 - accuracy: 0.9446 - val_loss: 0.1450 - val_accuracy: 0.9517\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1697 - accuracy: 0.9444 - val_loss: 0.7122 - val_accuracy: 0.5094\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1645 - accuracy: 0.9444 - val_loss: 0.1932 - val_accuracy: 0.9324\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9465 - val_loss: 0.2458 - val_accuracy: 0.9169\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9433 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1585 - accuracy: 0.9473 - val_loss: 0.1377 - val_accuracy: 0.9542\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1691 - accuracy: 0.9432 - val_loss: 0.1311 - val_accuracy: 0.9593\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1594 - accuracy: 0.9462 - val_loss: 0.1717 - val_accuracy: 0.9428\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1513 - accuracy: 0.9489 - val_loss: 0.1696 - val_accuracy: 0.9431\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1736 - accuracy: 0.9411 - val_loss: 0.2917 - val_accuracy: 0.8955\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8906\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6621 - accuracy: 0.6105 - val_loss: 0.6386 - val_accuracy: 0.6465\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4170 - accuracy: 0.8193 - val_loss: 0.2279 - val_accuracy: 0.9128\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3030 - accuracy: 0.8836 - val_loss: 0.2794 - val_accuracy: 0.9100\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3064 - accuracy: 0.8848 - val_loss: 0.2300 - val_accuracy: 0.9114\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9014 - val_loss: 0.2688 - val_accuracy: 0.8964\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.8983 - val_loss: 0.2200 - val_accuracy: 0.9213\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2653 - accuracy: 0.9000 - val_loss: 0.3272 - val_accuracy: 0.8610\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9016 - val_loss: 0.2291 - val_accuracy: 0.9285\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9104 - val_loss: 0.2002 - val_accuracy: 0.9299\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2517 - accuracy: 0.9061 - val_loss: 0.2880 - val_accuracy: 0.8802\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.9089 - val_loss: 0.2152 - val_accuracy: 0.9246\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9061 - val_loss: 0.1973 - val_accuracy: 0.9317\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.9095 - val_loss: 0.2243 - val_accuracy: 0.9133\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2384 - accuracy: 0.9105 - val_loss: 0.2078 - val_accuracy: 0.9278\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2358 - accuracy: 0.9128 - val_loss: 0.2052 - val_accuracy: 0.9223\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9141 - val_loss: 0.2742 - val_accuracy: 0.8998\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2350 - accuracy: 0.9143 - val_loss: 0.2203 - val_accuracy: 0.9142\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2265 - accuracy: 0.9165 - val_loss: 0.1827 - val_accuracy: 0.9387\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.9141 - val_loss: 0.3089 - val_accuracy: 0.8645\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.9216 - val_loss: 0.2320 - val_accuracy: 0.9214\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.9218 - val_loss: 0.2049 - val_accuracy: 0.9239\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.9217 - val_loss: 0.6014 - val_accuracy: 0.8358\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2225 - accuracy: 0.9178 - val_loss: 0.1720 - val_accuracy: 0.9408\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2207 - accuracy: 0.9211 - val_loss: 0.1771 - val_accuracy: 0.9412\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9236 - val_loss: 0.2249 - val_accuracy: 0.9089\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.9266 - val_loss: 0.1978 - val_accuracy: 0.9251\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9238 - val_loss: 0.2363 - val_accuracy: 0.9105\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9232 - val_loss: 0.1964 - val_accuracy: 0.9309\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9259 - val_loss: 0.1736 - val_accuracy: 0.9436\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2022 - accuracy: 0.9269 - val_loss: 0.2709 - val_accuracy: 0.8952\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9230 - val_loss: 0.2702 - val_accuracy: 0.9228\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1989 - accuracy: 0.9286 - val_loss: 0.1705 - val_accuracy: 0.9422\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2027 - accuracy: 0.9292 - val_loss: 0.1652 - val_accuracy: 0.9452\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9290 - val_loss: 0.1690 - val_accuracy: 0.9445\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9224 - val_loss: 0.3213 - val_accuracy: 0.8809\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9311 - val_loss: 0.1616 - val_accuracy: 0.9459\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9298 - val_loss: 0.1650 - val_accuracy: 0.9454\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9307 - val_loss: 0.1737 - val_accuracy: 0.9389\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9310 - val_loss: 0.1867 - val_accuracy: 0.9308\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9344 - val_loss: 0.1656 - val_accuracy: 0.9413\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.9314 - val_loss: 0.1591 - val_accuracy: 0.9449\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9326 - val_loss: 0.2269 - val_accuracy: 0.9084\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.9339 - val_loss: 0.1742 - val_accuracy: 0.9410\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.9317 - val_loss: 0.2070 - val_accuracy: 0.9228\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9363 - val_loss: 0.2803 - val_accuracy: 0.9022\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.9379 - val_loss: 0.2348 - val_accuracy: 0.9095\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1945 - accuracy: 0.9306 - val_loss: 0.2094 - val_accuracy: 0.9258\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1874 - accuracy: 0.9341 - val_loss: 0.1776 - val_accuracy: 0.9383\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9357 - val_loss: 0.2320 - val_accuracy: 0.9132\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.9342 - val_loss: 0.2091 - val_accuracy: 0.9177\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.9364 - val_loss: 0.2103 - val_accuracy: 0.9251\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9206\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5804 - accuracy: 0.7112 - val_loss: 0.6838 - val_accuracy: 0.6491\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6886 - val_loss: 0.5969 - val_accuracy: 0.6436\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4428 - accuracy: 0.8080 - val_loss: 0.3290 - val_accuracy: 0.8864\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8863 - val_loss: 0.2221 - val_accuracy: 0.9179\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.8997 - val_loss: 0.3160 - val_accuracy: 0.8712\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.8952 - val_loss: 0.4119 - val_accuracy: 0.8473\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.9027 - val_loss: 0.4433 - val_accuracy: 0.8476\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.9070 - val_loss: 0.2716 - val_accuracy: 0.9007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2457 - accuracy: 0.9106 - val_loss: 0.2235 - val_accuracy: 0.9135\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.9118 - val_loss: 0.2025 - val_accuracy: 0.9290\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.9105 - val_loss: 0.1966 - val_accuracy: 0.9339\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2404 - accuracy: 0.9154 - val_loss: 0.2094 - val_accuracy: 0.9243\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.9126 - val_loss: 0.2375 - val_accuracy: 0.9089\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9100 - val_loss: 0.2175 - val_accuracy: 0.9186\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.9088 - val_loss: 0.2443 - val_accuracy: 0.9112\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2238 - accuracy: 0.9184 - val_loss: 0.4007 - val_accuracy: 0.8686\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2321 - accuracy: 0.9144 - val_loss: 0.2846 - val_accuracy: 0.9073\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.9115 - val_loss: 0.2094 - val_accuracy: 0.9237\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2328 - accuracy: 0.9166 - val_loss: 0.1877 - val_accuracy: 0.9378\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2291 - accuracy: 0.9166 - val_loss: 0.2178 - val_accuracy: 0.9158\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2249 - accuracy: 0.9196 - val_loss: 0.2083 - val_accuracy: 0.9230\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2225 - accuracy: 0.9192 - val_loss: 0.9636 - val_accuracy: 0.3997\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9042 - val_loss: 0.2211 - val_accuracy: 0.9230\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2164 - accuracy: 0.9214 - val_loss: 0.2782 - val_accuracy: 0.8933\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2171 - accuracy: 0.9201 - val_loss: 0.2126 - val_accuracy: 0.9223\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2156 - accuracy: 0.9219 - val_loss: 0.2217 - val_accuracy: 0.9239\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9260 - val_loss: 0.1805 - val_accuracy: 0.9394\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9270 - val_loss: 0.1696 - val_accuracy: 0.9420\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1992 - accuracy: 0.9278 - val_loss: 0.3083 - val_accuracy: 0.8973\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2143 - accuracy: 0.9228 - val_loss: 0.2044 - val_accuracy: 0.9239\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9246 - val_loss: 0.1832 - val_accuracy: 0.9336\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9268 - val_loss: 0.1980 - val_accuracy: 0.9369\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9279 - val_loss: 0.1631 - val_accuracy: 0.9435\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9312 - val_loss: 0.1605 - val_accuracy: 0.9461\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1985 - accuracy: 0.9285 - val_loss: 0.1914 - val_accuracy: 0.9280\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.9326 - val_loss: 0.3869 - val_accuracy: 0.8550\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2025 - accuracy: 0.9255 - val_loss: 0.1906 - val_accuracy: 0.9258\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.9340 - val_loss: 0.1600 - val_accuracy: 0.9440\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9352 - val_loss: 0.2175 - val_accuracy: 0.9181\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1928 - accuracy: 0.9311 - val_loss: 0.3344 - val_accuracy: 0.8802\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9332 - val_loss: 0.1488 - val_accuracy: 0.9482\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.9360 - val_loss: 0.1998 - val_accuracy: 0.9299\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.9366 - val_loss: 0.2388 - val_accuracy: 0.8962\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.9385 - val_loss: 0.1437 - val_accuracy: 0.9561\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1628 - accuracy: 0.9428 - val_loss: 0.1380 - val_accuracy: 0.9523\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.9380 - val_loss: 0.1375 - val_accuracy: 0.9609\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1915 - accuracy: 0.9344 - val_loss: 0.1676 - val_accuracy: 0.9375\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.9388 - val_loss: 0.1755 - val_accuracy: 0.9346\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.9410 - val_loss: 0.3600 - val_accuracy: 0.8790\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.9392 - val_loss: 0.1531 - val_accuracy: 0.9473\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.9415 - val_loss: 0.1339 - val_accuracy: 0.9577\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1618 - accuracy: 0.9460 - val_loss: 0.2296 - val_accuracy: 0.9230\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.9415 - val_loss: 0.1707 - val_accuracy: 0.9417\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1667 - accuracy: 0.9428 - val_loss: 0.1300 - val_accuracy: 0.9604\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1599 - accuracy: 0.9450 - val_loss: 0.1450 - val_accuracy: 0.9533\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.9392 - val_loss: 0.2399 - val_accuracy: 0.9035\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.9378 - val_loss: 0.1799 - val_accuracy: 0.9503\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9445 - val_loss: 0.2760 - val_accuracy: 0.9070\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1668 - accuracy: 0.9440 - val_loss: 0.1393 - val_accuracy: 0.9618\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.9405 - val_loss: 0.1354 - val_accuracy: 0.9575\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1591 - accuracy: 0.9478 - val_loss: 0.1367 - val_accuracy: 0.9547\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1628 - accuracy: 0.9463 - val_loss: 0.1470 - val_accuracy: 0.9494\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.9441 - val_loss: 0.1396 - val_accuracy: 0.9618\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9450 - val_loss: 0.2426 - val_accuracy: 0.9265\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2499 - accuracy: 0.9188\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5924 - accuracy: 0.6903 - val_loss: 0.4356 - val_accuracy: 0.7835\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8684 - val_loss: 0.3166 - val_accuracy: 0.9251\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.8939 - val_loss: 0.2508 - val_accuracy: 0.8896\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.9044 - val_loss: 0.2907 - val_accuracy: 0.8737\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.9070 - val_loss: 0.2627 - val_accuracy: 0.8869\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2333 - accuracy: 0.9101 - val_loss: 0.2153 - val_accuracy: 0.9139\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2304 - accuracy: 0.9129 - val_loss: 0.6316 - val_accuracy: 0.6701\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2318 - accuracy: 0.9131 - val_loss: 0.1970 - val_accuracy: 0.9317\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9175 - val_loss: 0.3991 - val_accuracy: 0.8459\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9104 - val_loss: 0.2295 - val_accuracy: 0.9260\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.9188 - val_loss: 0.2173 - val_accuracy: 0.9144\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2130 - accuracy: 0.9198 - val_loss: 0.4391 - val_accuracy: 0.8159\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2106 - accuracy: 0.9197 - val_loss: 0.1876 - val_accuracy: 0.9299\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2114 - accuracy: 0.9209 - val_loss: 0.2102 - val_accuracy: 0.9281\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2038 - accuracy: 0.9240 - val_loss: 0.2305 - val_accuracy: 0.9036\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2052 - accuracy: 0.9238 - val_loss: 0.1829 - val_accuracy: 0.9392\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2071 - accuracy: 0.9219 - val_loss: 0.1764 - val_accuracy: 0.9392\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9283 - val_loss: 0.1992 - val_accuracy: 0.9304\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1934 - accuracy: 0.9268 - val_loss: 0.1667 - val_accuracy: 0.9401\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9259 - val_loss: 0.1603 - val_accuracy: 0.9422\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1923 - accuracy: 0.9282 - val_loss: 0.1920 - val_accuracy: 0.9295\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.9311 - val_loss: 0.1584 - val_accuracy: 0.9415\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.9287 - val_loss: 0.1603 - val_accuracy: 0.9440\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.9329 - val_loss: 0.1740 - val_accuracy: 0.9355\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.9302 - val_loss: 0.2413 - val_accuracy: 0.9029\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.9354 - val_loss: 0.1945 - val_accuracy: 0.9264\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.9341 - val_loss: 0.1451 - val_accuracy: 0.9486\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9418 - val_loss: 0.1301 - val_accuracy: 0.9553\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1647 - accuracy: 0.9405 - val_loss: 0.1560 - val_accuracy: 0.9443\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.9393 - val_loss: 0.1472 - val_accuracy: 0.9486\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9420 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1593 - accuracy: 0.9442 - val_loss: 0.1444 - val_accuracy: 0.9472\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1431 - accuracy: 0.9493 - val_loss: 0.1224 - val_accuracy: 0.9597\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1529 - accuracy: 0.9443 - val_loss: 0.1293 - val_accuracy: 0.9540\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9466 - val_loss: 0.1462 - val_accuracy: 0.9482\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9492 - val_loss: 0.1161 - val_accuracy: 0.9627\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1459 - accuracy: 0.9488 - val_loss: 0.5809 - val_accuracy: 0.7506\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1524 - accuracy: 0.9470 - val_loss: 0.1455 - val_accuracy: 0.9501\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1660 - accuracy: 0.9414 - val_loss: 0.1235 - val_accuracy: 0.9591\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1465 - accuracy: 0.9494 - val_loss: 0.1684 - val_accuracy: 0.9346\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1412 - accuracy: 0.9495 - val_loss: 0.1684 - val_accuracy: 0.9394\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9500 - val_loss: 0.1549 - val_accuracy: 0.9472\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1473 - accuracy: 0.9488 - val_loss: 0.1150 - val_accuracy: 0.9639\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1580 - accuracy: 0.9439 - val_loss: 0.2789 - val_accuracy: 0.8832\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.9517 - val_loss: 0.1364 - val_accuracy: 0.9549\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9491 - val_loss: 0.1808 - val_accuracy: 0.9361\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1423 - accuracy: 0.9512 - val_loss: 0.1661 - val_accuracy: 0.9369\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1386 - accuracy: 0.9511 - val_loss: 0.1098 - val_accuracy: 0.9653\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1466 - accuracy: 0.9487 - val_loss: 0.3799 - val_accuracy: 0.8816\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9505 - val_loss: 0.1919 - val_accuracy: 0.9336\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1379 - accuracy: 0.9523 - val_loss: 0.2974 - val_accuracy: 0.9040\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9514 - val_loss: 0.1115 - val_accuracy: 0.9634\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1388 - accuracy: 0.9514 - val_loss: 0.1967 - val_accuracy: 0.9315\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1375 - accuracy: 0.9529 - val_loss: 0.1423 - val_accuracy: 0.9507\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1361 - accuracy: 0.9545 - val_loss: 0.2282 - val_accuracy: 0.9088\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1462 - accuracy: 0.9491 - val_loss: 0.1127 - val_accuracy: 0.9646\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9495 - val_loss: 0.1642 - val_accuracy: 0.9435\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9536 - val_loss: 0.1135 - val_accuracy: 0.9657\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9648\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.6924 - val_loss: 0.4146 - val_accuracy: 0.8714\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8750 - val_loss: 0.2673 - val_accuracy: 0.8881\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.8954 - val_loss: 0.2483 - val_accuracy: 0.9232\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2433 - accuracy: 0.9060 - val_loss: 0.2519 - val_accuracy: 0.9255\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2324 - accuracy: 0.9127 - val_loss: 0.2173 - val_accuracy: 0.9274\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2300 - accuracy: 0.9128 - val_loss: 0.2270 - val_accuracy: 0.9079\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2325 - accuracy: 0.9124 - val_loss: 0.3434 - val_accuracy: 0.8660\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.9159 - val_loss: 0.1990 - val_accuracy: 0.9295\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9198 - val_loss: 0.2158 - val_accuracy: 0.9144\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2214 - accuracy: 0.9175 - val_loss: 0.2020 - val_accuracy: 0.9214\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2074 - accuracy: 0.9254 - val_loss: 0.1886 - val_accuracy: 0.9315\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2079 - accuracy: 0.9227 - val_loss: 0.1893 - val_accuracy: 0.9304\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2033 - accuracy: 0.9249 - val_loss: 0.2678 - val_accuracy: 0.8982\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2040 - accuracy: 0.9253 - val_loss: 0.1819 - val_accuracy: 0.9339\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2004 - accuracy: 0.9253 - val_loss: 0.1913 - val_accuracy: 0.9355\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9259 - val_loss: 0.1843 - val_accuracy: 0.9362\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9275 - val_loss: 0.2220 - val_accuracy: 0.9223\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2080 - accuracy: 0.9239 - val_loss: 0.2028 - val_accuracy: 0.9288\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9285 - val_loss: 0.2068 - val_accuracy: 0.9225\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9266 - val_loss: 0.1721 - val_accuracy: 0.9373\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9297 - val_loss: 0.2285 - val_accuracy: 0.9197\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1894 - accuracy: 0.9302 - val_loss: 0.1664 - val_accuracy: 0.9401\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9303 - val_loss: 0.1981 - val_accuracy: 0.9376\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.9309 - val_loss: 0.1825 - val_accuracy: 0.9350\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.9328 - val_loss: 0.2085 - val_accuracy: 0.9251\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.9358 - val_loss: 0.2051 - val_accuracy: 0.9199\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.9352 - val_loss: 0.1816 - val_accuracy: 0.9324\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9383 - val_loss: 0.1482 - val_accuracy: 0.9491\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9337 - val_loss: 0.1543 - val_accuracy: 0.9436\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.9363 - val_loss: 0.2052 - val_accuracy: 0.9221\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9394 - val_loss: 0.1468 - val_accuracy: 0.9517\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1665 - accuracy: 0.9418 - val_loss: 0.1451 - val_accuracy: 0.9542\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9403 - val_loss: 0.1492 - val_accuracy: 0.9463\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1546 - accuracy: 0.9454 - val_loss: 0.2205 - val_accuracy: 0.9234\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1670 - accuracy: 0.9395 - val_loss: 0.1393 - val_accuracy: 0.9533\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1533 - accuracy: 0.9470 - val_loss: 0.1512 - val_accuracy: 0.9470\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1630 - accuracy: 0.9405 - val_loss: 0.1616 - val_accuracy: 0.9456\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1502 - accuracy: 0.9468 - val_loss: 0.1535 - val_accuracy: 0.9496\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1489 - accuracy: 0.9480 - val_loss: 0.1289 - val_accuracy: 0.9547\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1564 - accuracy: 0.9448 - val_loss: 0.1463 - val_accuracy: 0.9484\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9499 - val_loss: 0.1443 - val_accuracy: 0.9494\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9442 - val_loss: 0.1280 - val_accuracy: 0.9551\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9479 - val_loss: 0.1507 - val_accuracy: 0.9480\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9468 - val_loss: 0.1219 - val_accuracy: 0.9591\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9510 - val_loss: 0.1196 - val_accuracy: 0.9612\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9508 - val_loss: 0.1841 - val_accuracy: 0.9341\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1444 - accuracy: 0.9513 - val_loss: 0.1208 - val_accuracy: 0.9616\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1523 - accuracy: 0.9463 - val_loss: 0.2125 - val_accuracy: 0.9341\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9474 - val_loss: 0.1557 - val_accuracy: 0.9433\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1546 - accuracy: 0.9469 - val_loss: 0.1831 - val_accuracy: 0.9338\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1556 - accuracy: 0.9462 - val_loss: 0.1753 - val_accuracy: 0.9424\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.9490 - val_loss: 0.1311 - val_accuracy: 0.9560\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1405 - accuracy: 0.9512 - val_loss: 0.1183 - val_accuracy: 0.9616\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9519 - val_loss: 0.1363 - val_accuracy: 0.9538\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1391 - accuracy: 0.9515 - val_loss: 0.1599 - val_accuracy: 0.9461\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.9509 - val_loss: 0.1127 - val_accuracy: 0.9637\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1429 - accuracy: 0.9519 - val_loss: 0.1909 - val_accuracy: 0.9218\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.9518 - val_loss: 0.1367 - val_accuracy: 0.9537\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1319 - accuracy: 0.9552 - val_loss: 0.1287 - val_accuracy: 0.9563\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1376 - accuracy: 0.9527 - val_loss: 0.1132 - val_accuracy: 0.9653\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1391 - accuracy: 0.9518 - val_loss: 0.1318 - val_accuracy: 0.9637\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1316 - accuracy: 0.9552 - val_loss: 0.1173 - val_accuracy: 0.9628\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1327 - accuracy: 0.9553 - val_loss: 0.1160 - val_accuracy: 0.9632\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9512 - val_loss: 0.3334 - val_accuracy: 0.8684\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1370 - accuracy: 0.9528 - val_loss: 0.1319 - val_accuracy: 0.9570\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1345 - accuracy: 0.9545 - val_loss: 0.2119 - val_accuracy: 0.9246\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9210\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6211 - accuracy: 0.6606 - val_loss: 0.4920 - val_accuracy: 0.8140\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.3855 - accuracy: 0.8511 - val_loss: 0.3038 - val_accuracy: 0.8596\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2836 - accuracy: 0.8923 - val_loss: 0.3401 - val_accuracy: 0.9054\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.9023 - val_loss: 0.2388 - val_accuracy: 0.8999\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.9084 - val_loss: 0.2222 - val_accuracy: 0.9260\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.9099 - val_loss: 0.2248 - val_accuracy: 0.9265\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2321 - accuracy: 0.9128 - val_loss: 0.2097 - val_accuracy: 0.9280\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2317 - accuracy: 0.9135 - val_loss: 0.7143 - val_accuracy: 0.5799\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.9058 - val_loss: 0.2253 - val_accuracy: 0.9269\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2206 - accuracy: 0.9180 - val_loss: 0.2148 - val_accuracy: 0.9283\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2172 - accuracy: 0.9191 - val_loss: 0.2070 - val_accuracy: 0.9177\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2217 - accuracy: 0.9183 - val_loss: 0.1945 - val_accuracy: 0.9276\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.9210 - val_loss: 0.1983 - val_accuracy: 0.9239\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.9200 - val_loss: 0.2022 - val_accuracy: 0.9311\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2115 - accuracy: 0.9227 - val_loss: 0.2227 - val_accuracy: 0.9158\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2167 - accuracy: 0.9211 - val_loss: 0.1833 - val_accuracy: 0.9338\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2169 - accuracy: 0.9206 - val_loss: 0.1838 - val_accuracy: 0.9331\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2101 - accuracy: 0.9235 - val_loss: 0.1855 - val_accuracy: 0.9313\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2088 - accuracy: 0.9234 - val_loss: 0.1807 - val_accuracy: 0.9336\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2044 - accuracy: 0.9259 - val_loss: 0.7799 - val_accuracy: 0.4696\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2133 - accuracy: 0.9192 - val_loss: 0.1873 - val_accuracy: 0.9292\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9256 - val_loss: 0.1722 - val_accuracy: 0.9380\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9291 - val_loss: 0.1741 - val_accuracy: 0.9369\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1993 - accuracy: 0.9265 - val_loss: 0.2982 - val_accuracy: 0.8908\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1927 - accuracy: 0.9298 - val_loss: 0.1889 - val_accuracy: 0.9318\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.2001 - accuracy: 0.9273 - val_loss: 0.2329 - val_accuracy: 0.9112\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.9290 - val_loss: 0.1767 - val_accuracy: 0.9376\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9291 - val_loss: 0.1777 - val_accuracy: 0.9357\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9261 - val_loss: 0.1555 - val_accuracy: 0.9461\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.9334 - val_loss: 0.3359 - val_accuracy: 0.8733\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.9332 - val_loss: 0.2358 - val_accuracy: 0.9119\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1727 - accuracy: 0.9371 - val_loss: 0.1487 - val_accuracy: 0.9470\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1687 - accuracy: 0.9385 - val_loss: 0.1429 - val_accuracy: 0.9477\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.9349 - val_loss: 0.1904 - val_accuracy: 0.9334\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1662 - accuracy: 0.9404 - val_loss: 0.1360 - val_accuracy: 0.9560\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9411 - val_loss: 0.1307 - val_accuracy: 0.9565\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1625 - accuracy: 0.9407 - val_loss: 0.1476 - val_accuracy: 0.9503\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9445 - val_loss: 0.2330 - val_accuracy: 0.9153\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9433 - val_loss: 0.2453 - val_accuracy: 0.9081\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9469 - val_loss: 0.1998 - val_accuracy: 0.9184\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1606 - accuracy: 0.9419 - val_loss: 0.1216 - val_accuracy: 0.9611\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1496 - accuracy: 0.9477 - val_loss: 0.2789 - val_accuracy: 0.9040\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1569 - accuracy: 0.9448 - val_loss: 0.1747 - val_accuracy: 0.9373\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1596 - accuracy: 0.9445 - val_loss: 0.1204 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9515 - val_loss: 0.1272 - val_accuracy: 0.9561\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9484 - val_loss: 0.4208 - val_accuracy: 0.8765\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1515 - accuracy: 0.9466 - val_loss: 0.1314 - val_accuracy: 0.9546\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1472 - accuracy: 0.9490 - val_loss: 0.1633 - val_accuracy: 0.9410\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1538 - accuracy: 0.9467 - val_loss: 0.2403 - val_accuracy: 0.9121\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9429 - val_loss: 0.1667 - val_accuracy: 0.9383\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1503 - accuracy: 0.9497 - val_loss: 0.1242 - val_accuracy: 0.9634\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9488 - val_loss: 0.7029 - val_accuracy: 0.6044\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1477 - accuracy: 0.9498 - val_loss: 0.6583 - val_accuracy: 0.6775\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.1435 - accuracy: 0.9523 - val_loss: 0.2020 - val_accuracy: 0.9228\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.9256\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5886 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6775 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6736 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5949\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5937 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6760 - accuracy: 0.5946 - val_loss: 0.6725 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6745 - accuracy: 0.5946 - val_loss: 0.6702 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6744 - accuracy: 0.5946 - val_loss: 0.6716 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6759 - accuracy: 0.5946 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6737 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5884\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5888 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5916 - val_loss: 0.6742 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6839 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6763 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6763 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5942\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6806 - accuracy: 0.5899 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6771 - accuracy: 0.5913 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6735 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6734 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5913 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5949\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5935 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6756 - accuracy: 0.5946 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6757 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6755 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6754 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6732 - val_accuracy: 0.6007\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5946 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.5946 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5884\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.5897 - val_loss: 0.6737 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5916 - val_loss: 0.6739 - val_accuracy: 0.6007\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6767 - accuracy: 0.5916 - val_loss: 0.6739 - val_accuracy: 0.6007\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6731 - val_accuracy: 0.6007\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6733 - val_accuracy: 0.6007\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6730 - val_accuracy: 0.6007\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6727 - val_accuracy: 0.6007\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6729 - val_accuracy: 0.6007\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6764 - accuracy: 0.5916 - val_loss: 0.6728 - val_accuracy: 0.6007\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5942\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6934 - accuracy: 0.5597 - val_loss: 0.6758 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6771 - accuracy: 0.5914 - val_loss: 0.6706 - val_accuracy: 0.6005\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6714 - accuracy: 0.5914 - val_loss: 0.6647 - val_accuracy: 0.6005\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6658 - accuracy: 0.5916 - val_loss: 0.6598 - val_accuracy: 0.6023\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6603 - accuracy: 0.5934 - val_loss: 0.6541 - val_accuracy: 0.6049\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.5975 - val_loss: 0.6485 - val_accuracy: 0.6072\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6497 - accuracy: 0.6032 - val_loss: 0.6435 - val_accuracy: 0.6130\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6104 - val_loss: 0.6385 - val_accuracy: 0.6158\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6393 - accuracy: 0.6170 - val_loss: 0.6347 - val_accuracy: 0.6408\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6346 - accuracy: 0.6263 - val_loss: 0.6289 - val_accuracy: 0.6283\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6297 - accuracy: 0.6322 - val_loss: 0.6245 - val_accuracy: 0.6468\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6250 - accuracy: 0.6411 - val_loss: 0.6203 - val_accuracy: 0.6584\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6204 - accuracy: 0.6483 - val_loss: 0.6162 - val_accuracy: 0.6715\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6157 - accuracy: 0.6573 - val_loss: 0.6107 - val_accuracy: 0.6539\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6114 - accuracy: 0.6622 - val_loss: 0.6064 - val_accuracy: 0.6614\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6069 - accuracy: 0.6691 - val_loss: 0.6024 - val_accuracy: 0.6748\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6028 - accuracy: 0.6745 - val_loss: 0.5988 - val_accuracy: 0.6937\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5988 - accuracy: 0.6826 - val_loss: 0.5944 - val_accuracy: 0.6699\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5948 - accuracy: 0.6867 - val_loss: 0.5913 - val_accuracy: 0.6662\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6894 - val_loss: 0.5868 - val_accuracy: 0.6995\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5870 - accuracy: 0.6972 - val_loss: 0.5829 - val_accuracy: 0.6914\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5834 - accuracy: 0.7012 - val_loss: 0.5794 - val_accuracy: 0.7046\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5797 - accuracy: 0.7064 - val_loss: 0.5759 - val_accuracy: 0.7094\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5759 - accuracy: 0.7117 - val_loss: 0.5726 - val_accuracy: 0.6970\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.7142 - val_loss: 0.5691 - val_accuracy: 0.7192\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.7162 - val_loss: 0.5664 - val_accuracy: 0.7338\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5659 - accuracy: 0.7208 - val_loss: 0.5627 - val_accuracy: 0.7284\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5626 - accuracy: 0.7244 - val_loss: 0.5595 - val_accuracy: 0.7291\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5594 - accuracy: 0.7291 - val_loss: 0.5565 - val_accuracy: 0.7331\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.7293 - val_loss: 0.5540 - val_accuracy: 0.7423\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5534 - accuracy: 0.7336 - val_loss: 0.5513 - val_accuracy: 0.7486\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7372 - val_loss: 0.5479 - val_accuracy: 0.7305\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.7390 - val_loss: 0.5451 - val_accuracy: 0.7323\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7408 - val_loss: 0.5425 - val_accuracy: 0.7463\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7461 - val_loss: 0.5404 - val_accuracy: 0.7564\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7490 - val_loss: 0.5380 - val_accuracy: 0.7631\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7496 - val_loss: 0.5346 - val_accuracy: 0.7532\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7522 - val_loss: 0.5336 - val_accuracy: 0.7751\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7538 - val_loss: 0.5300 - val_accuracy: 0.7641\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7575 - val_loss: 0.5276 - val_accuracy: 0.7655\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7585 - val_loss: 0.5247 - val_accuracy: 0.7534\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7603 - val_loss: 0.5226 - val_accuracy: 0.7648\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5217 - accuracy: 0.7636 - val_loss: 0.5202 - val_accuracy: 0.7645\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5194 - accuracy: 0.7663 - val_loss: 0.5179 - val_accuracy: 0.7509\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7653 - val_loss: 0.5155 - val_accuracy: 0.7566\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7687 - val_loss: 0.5135 - val_accuracy: 0.7707\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5126 - accuracy: 0.7711 - val_loss: 0.5113 - val_accuracy: 0.7722\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5103 - accuracy: 0.7727 - val_loss: 0.5091 - val_accuracy: 0.7699\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7739 - val_loss: 0.5082 - val_accuracy: 0.7897\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5061 - accuracy: 0.7770 - val_loss: 0.5049 - val_accuracy: 0.7715\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7757 - val_loss: 0.5048 - val_accuracy: 0.7999\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7808 - val_loss: 0.5014 - val_accuracy: 0.7855\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7881\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4981 - accuracy: 0.7822 - val_loss: 0.4975 - val_accuracy: 0.7645\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4962 - accuracy: 0.7840 - val_loss: 0.4957 - val_accuracy: 0.7863\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7846 - val_loss: 0.4937 - val_accuracy: 0.7705\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4925 - accuracy: 0.7841 - val_loss: 0.4925 - val_accuracy: 0.7946\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7863 - val_loss: 0.4902 - val_accuracy: 0.7881\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.7895 - val_loss: 0.4884 - val_accuracy: 0.7759\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7872 - val_loss: 0.4871 - val_accuracy: 0.7964\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7904 - val_loss: 0.4864 - val_accuracy: 0.8094\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7938 - val_loss: 0.4835 - val_accuracy: 0.7932\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4820 - accuracy: 0.7941 - val_loss: 0.4816 - val_accuracy: 0.7823\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4805 - accuracy: 0.7932 - val_loss: 0.4800 - val_accuracy: 0.7890\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7950 - val_loss: 0.4793 - val_accuracy: 0.8078\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4769 - accuracy: 0.7962 - val_loss: 0.4769 - val_accuracy: 0.7818\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7969 - val_loss: 0.4753 - val_accuracy: 0.7948\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4738 - accuracy: 0.7985 - val_loss: 0.4737 - val_accuracy: 0.7976\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4723 - accuracy: 0.7999 - val_loss: 0.4722 - val_accuracy: 0.7855\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.7992 - val_loss: 0.4708 - val_accuracy: 0.8025\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4692 - accuracy: 0.8010 - val_loss: 0.4693 - val_accuracy: 0.8032\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.8030 - val_loss: 0.4683 - val_accuracy: 0.8120\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.8037 - val_loss: 0.4669 - val_accuracy: 0.8119\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.8044 - val_loss: 0.4649 - val_accuracy: 0.7955\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4634 - accuracy: 0.8034 - val_loss: 0.4636 - val_accuracy: 0.8048\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8048 - val_loss: 0.4627 - val_accuracy: 0.8143\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4606 - accuracy: 0.8073 - val_loss: 0.4612 - val_accuracy: 0.8117\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.8071 - val_loss: 0.4598 - val_accuracy: 0.8122\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8091 - val_loss: 0.4585 - val_accuracy: 0.7932\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4565 - accuracy: 0.8088 - val_loss: 0.4569 - val_accuracy: 0.8015\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4552 - accuracy: 0.8084 - val_loss: 0.4559 - val_accuracy: 0.8145\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4539 - accuracy: 0.8101 - val_loss: 0.4543 - val_accuracy: 0.8057\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4524 - accuracy: 0.8120 - val_loss: 0.4531 - val_accuracy: 0.8091\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4513 - accuracy: 0.8118 - val_loss: 0.4526 - val_accuracy: 0.8249\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8130 - val_loss: 0.4507 - val_accuracy: 0.8091\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.8134 - val_loss: 0.4496 - val_accuracy: 0.8136\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8143 - val_loss: 0.4483 - val_accuracy: 0.8129\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4464 - accuracy: 0.8145 - val_loss: 0.4472 - val_accuracy: 0.8142\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4453 - accuracy: 0.8143 - val_loss: 0.4460 - val_accuracy: 0.8126\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4440 - accuracy: 0.8156 - val_loss: 0.4449 - val_accuracy: 0.8122\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4429 - accuracy: 0.8168 - val_loss: 0.4438 - val_accuracy: 0.8180\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4418 - accuracy: 0.8179 - val_loss: 0.4428 - val_accuracy: 0.8230\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4405 - accuracy: 0.8195 - val_loss: 0.4415 - val_accuracy: 0.8165\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4394 - accuracy: 0.8194 - val_loss: 0.4404 - val_accuracy: 0.8126\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4382 - accuracy: 0.8197 - val_loss: 0.4393 - val_accuracy: 0.8142\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4372 - accuracy: 0.8199 - val_loss: 0.4386 - val_accuracy: 0.8288\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4360 - accuracy: 0.8215 - val_loss: 0.4372 - val_accuracy: 0.8145\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8202 - val_loss: 0.4361 - val_accuracy: 0.8226\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4338 - accuracy: 0.8210 - val_loss: 0.4355 - val_accuracy: 0.8323\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8221 - val_loss: 0.4340 - val_accuracy: 0.8198\n",
      "277/277 [==============================] - 0s 905us/step - loss: 0.4315 - accuracy: 0.8254\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6826 - accuracy: 0.5811 - val_loss: 0.6740 - val_accuracy: 0.6008\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6739 - accuracy: 0.5946 - val_loss: 0.6683 - val_accuracy: 0.6008\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6679 - accuracy: 0.5947 - val_loss: 0.6625 - val_accuracy: 0.6008\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6624 - accuracy: 0.5951 - val_loss: 0.6571 - val_accuracy: 0.6047\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6565 - accuracy: 0.5980 - val_loss: 0.6512 - val_accuracy: 0.6054\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6510 - accuracy: 0.6020 - val_loss: 0.6458 - val_accuracy: 0.6095\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6454 - accuracy: 0.6088 - val_loss: 0.6421 - val_accuracy: 0.6324\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6403 - accuracy: 0.6166 - val_loss: 0.6354 - val_accuracy: 0.6264\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6349 - accuracy: 0.6247 - val_loss: 0.6311 - val_accuracy: 0.6392\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6301 - accuracy: 0.6299 - val_loss: 0.6265 - val_accuracy: 0.6503\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6251 - accuracy: 0.6399 - val_loss: 0.6210 - val_accuracy: 0.6373\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6205 - accuracy: 0.6461 - val_loss: 0.6164 - val_accuracy: 0.6525\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6160 - accuracy: 0.6535 - val_loss: 0.6125 - val_accuracy: 0.6699\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6114 - accuracy: 0.6611 - val_loss: 0.6076 - val_accuracy: 0.6586\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6069 - accuracy: 0.6672 - val_loss: 0.6034 - val_accuracy: 0.6641\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6027 - accuracy: 0.6726 - val_loss: 0.5994 - val_accuracy: 0.6799\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5983 - accuracy: 0.6788 - val_loss: 0.5959 - val_accuracy: 0.6963\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6856 - val_loss: 0.5916 - val_accuracy: 0.6946\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5902 - accuracy: 0.6907 - val_loss: 0.5885 - val_accuracy: 0.7111\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5865 - accuracy: 0.6993 - val_loss: 0.5841 - val_accuracy: 0.6833\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5826 - accuracy: 0.7003 - val_loss: 0.5803 - val_accuracy: 0.6910\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5789 - accuracy: 0.7034 - val_loss: 0.5767 - val_accuracy: 0.7062\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5755 - accuracy: 0.7092 - val_loss: 0.5732 - val_accuracy: 0.7078\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5718 - accuracy: 0.7110 - val_loss: 0.5702 - val_accuracy: 0.7227\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.7156 - val_loss: 0.5677 - val_accuracy: 0.7381\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7206 - val_loss: 0.5633 - val_accuracy: 0.7256\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5615 - accuracy: 0.7249 - val_loss: 0.5601 - val_accuracy: 0.7108\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5581 - accuracy: 0.7275 - val_loss: 0.5568 - val_accuracy: 0.7305\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5548 - accuracy: 0.7312 - val_loss: 0.5539 - val_accuracy: 0.7171\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7322 - val_loss: 0.5512 - val_accuracy: 0.7402\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7378 - val_loss: 0.5484 - val_accuracy: 0.7456\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7426 - val_loss: 0.5450 - val_accuracy: 0.7358\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7433 - val_loss: 0.5424 - val_accuracy: 0.7305\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7449 - val_loss: 0.5395 - val_accuracy: 0.7386\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7493 - val_loss: 0.5369 - val_accuracy: 0.7416\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7490 - val_loss: 0.5344 - val_accuracy: 0.7395\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7516 - val_loss: 0.5326 - val_accuracy: 0.7645\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5293 - accuracy: 0.7578 - val_loss: 0.5301 - val_accuracy: 0.7340\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5270 - accuracy: 0.7562 - val_loss: 0.5274 - val_accuracy: 0.7648\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7609 - val_loss: 0.5248 - val_accuracy: 0.7416\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5218 - accuracy: 0.7600 - val_loss: 0.5224 - val_accuracy: 0.7652\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5192 - accuracy: 0.7627 - val_loss: 0.5198 - val_accuracy: 0.7571\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5169 - accuracy: 0.7658 - val_loss: 0.5175 - val_accuracy: 0.7650\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7691 - val_loss: 0.5161 - val_accuracy: 0.7414\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5123 - accuracy: 0.7675 - val_loss: 0.5130 - val_accuracy: 0.7675\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5098 - accuracy: 0.7718 - val_loss: 0.5110 - val_accuracy: 0.7721\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5076 - accuracy: 0.7744 - val_loss: 0.5086 - val_accuracy: 0.7685\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5052 - accuracy: 0.7756 - val_loss: 0.5072 - val_accuracy: 0.7842\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7778 - val_loss: 0.5044 - val_accuracy: 0.7689\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5010 - accuracy: 0.7793 - val_loss: 0.5025 - val_accuracy: 0.7648\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4990 - accuracy: 0.7804 - val_loss: 0.5005 - val_accuracy: 0.7652\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4969 - accuracy: 0.7811 - val_loss: 0.4988 - val_accuracy: 0.7846\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4948 - accuracy: 0.7847 - val_loss: 0.4965 - val_accuracy: 0.7687\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4928 - accuracy: 0.7846 - val_loss: 0.4946 - val_accuracy: 0.7770\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4907 - accuracy: 0.7864 - val_loss: 0.4927 - val_accuracy: 0.7749\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4889 - accuracy: 0.7891 - val_loss: 0.4913 - val_accuracy: 0.7670\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7875 - val_loss: 0.4891 - val_accuracy: 0.7800\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4852 - accuracy: 0.7909 - val_loss: 0.4873 - val_accuracy: 0.7839\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4834 - accuracy: 0.7925 - val_loss: 0.4858 - val_accuracy: 0.7909\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4815 - accuracy: 0.7942 - val_loss: 0.4839 - val_accuracy: 0.7789\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4798 - accuracy: 0.7940 - val_loss: 0.4839 - val_accuracy: 0.8113\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4782 - accuracy: 0.7976 - val_loss: 0.4806 - val_accuracy: 0.7913\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7971 - val_loss: 0.4789 - val_accuracy: 0.7876\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4747 - accuracy: 0.7983 - val_loss: 0.4778 - val_accuracy: 0.8034\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4729 - accuracy: 0.8005 - val_loss: 0.4757 - val_accuracy: 0.7862\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4715 - accuracy: 0.8017 - val_loss: 0.4743 - val_accuracy: 0.7839\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.8008 - val_loss: 0.4728 - val_accuracy: 0.7830\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8017 - val_loss: 0.4723 - val_accuracy: 0.8142\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4666 - accuracy: 0.8045 - val_loss: 0.4695 - val_accuracy: 0.7913\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.8057 - val_loss: 0.4681 - val_accuracy: 0.7899\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4635 - accuracy: 0.8059 - val_loss: 0.4666 - val_accuracy: 0.7930\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4617 - accuracy: 0.8082 - val_loss: 0.4655 - val_accuracy: 0.7865\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.8073 - val_loss: 0.4639 - val_accuracy: 0.8076\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4588 - accuracy: 0.8101 - val_loss: 0.4624 - val_accuracy: 0.7916\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4575 - accuracy: 0.8107 - val_loss: 0.4611 - val_accuracy: 0.7911\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4560 - accuracy: 0.8110 - val_loss: 0.4595 - val_accuracy: 0.8069\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4544 - accuracy: 0.8120 - val_loss: 0.4582 - val_accuracy: 0.7946\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4531 - accuracy: 0.8103 - val_loss: 0.4570 - val_accuracy: 0.8128\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4517 - accuracy: 0.8137 - val_loss: 0.4555 - val_accuracy: 0.8099\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4503 - accuracy: 0.8145 - val_loss: 0.4541 - val_accuracy: 0.8015\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4489 - accuracy: 0.8150 - val_loss: 0.4530 - val_accuracy: 0.7976\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8145 - val_loss: 0.4516 - val_accuracy: 0.8098\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4461 - accuracy: 0.8177 - val_loss: 0.4503 - val_accuracy: 0.8085\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.8178 - val_loss: 0.4491 - val_accuracy: 0.8017\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.8182 - val_loss: 0.4478 - val_accuracy: 0.8076\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4424 - accuracy: 0.8191 - val_loss: 0.4466 - val_accuracy: 0.8133\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4458 - val_accuracy: 0.8219\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4398 - accuracy: 0.8207 - val_loss: 0.4455 - val_accuracy: 0.8355\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8219 - val_loss: 0.4430 - val_accuracy: 0.8112\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4374 - accuracy: 0.8228 - val_loss: 0.4419 - val_accuracy: 0.8140\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4362 - accuracy: 0.8223 - val_loss: 0.4407 - val_accuracy: 0.8138\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4350 - accuracy: 0.8236 - val_loss: 0.4397 - val_accuracy: 0.8203\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4338 - accuracy: 0.8241 - val_loss: 0.4384 - val_accuracy: 0.8140\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4326 - accuracy: 0.8248 - val_loss: 0.4373 - val_accuracy: 0.8122\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4315 - accuracy: 0.8253 - val_loss: 0.4362 - val_accuracy: 0.8212\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4303 - accuracy: 0.8262 - val_loss: 0.4351 - val_accuracy: 0.8165\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.8280 - val_loss: 0.4340 - val_accuracy: 0.8165\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.8267 - val_loss: 0.4333 - val_accuracy: 0.8309\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4269 - accuracy: 0.8284 - val_loss: 0.4319 - val_accuracy: 0.8200\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4259 - accuracy: 0.8287 - val_loss: 0.4312 - val_accuracy: 0.8112\n",
      "277/277 [==============================] - 0s 833us/step - loss: 0.4376 - accuracy: 0.8035\n",
      "Epoch 1/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6774 - accuracy: 0.5844 - val_loss: 0.6693 - val_accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6702 - accuracy: 0.5916 - val_loss: 0.6646 - val_accuracy: 0.6012\n",
      "Epoch 3/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6645 - accuracy: 0.5921 - val_loss: 0.6588 - val_accuracy: 0.6035\n",
      "Epoch 4/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6593 - accuracy: 0.5941 - val_loss: 0.6525 - val_accuracy: 0.6044\n",
      "Epoch 5/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6541 - accuracy: 0.5976 - val_loss: 0.6475 - val_accuracy: 0.6105\n",
      "Epoch 6/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6488 - accuracy: 0.6043 - val_loss: 0.6424 - val_accuracy: 0.6179\n",
      "Epoch 7/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6436 - accuracy: 0.6116 - val_loss: 0.6376 - val_accuracy: 0.6296\n",
      "Epoch 8/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6388 - accuracy: 0.6182 - val_loss: 0.6325 - val_accuracy: 0.6333\n",
      "Epoch 9/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6340 - accuracy: 0.6256 - val_loss: 0.6277 - val_accuracy: 0.6385\n",
      "Epoch 10/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6294 - accuracy: 0.6328 - val_loss: 0.6229 - val_accuracy: 0.6366\n",
      "Epoch 11/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6247 - accuracy: 0.6396 - val_loss: 0.6198 - val_accuracy: 0.6729\n",
      "Epoch 12/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6203 - accuracy: 0.6499 - val_loss: 0.6138 - val_accuracy: 0.6549\n",
      "Epoch 13/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6158 - accuracy: 0.6556 - val_loss: 0.6094 - val_accuracy: 0.6634\n",
      "Epoch 14/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6114 - accuracy: 0.6631 - val_loss: 0.6052 - val_accuracy: 0.6685\n",
      "Epoch 15/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.6074 - accuracy: 0.6683 - val_loss: 0.6022 - val_accuracy: 0.6983\n",
      "Epoch 16/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.6031 - accuracy: 0.6742 - val_loss: 0.5975 - val_accuracy: 0.6949\n",
      "Epoch 17/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5993 - accuracy: 0.6819 - val_loss: 0.5933 - val_accuracy: 0.6935\n",
      "Epoch 18/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5955 - accuracy: 0.6836 - val_loss: 0.5894 - val_accuracy: 0.6902\n",
      "Epoch 19/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5916 - accuracy: 0.6890 - val_loss: 0.5865 - val_accuracy: 0.7120\n",
      "Epoch 20/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5881 - accuracy: 0.6951 - val_loss: 0.5821 - val_accuracy: 0.6946\n",
      "Epoch 21/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5843 - accuracy: 0.6983 - val_loss: 0.5799 - val_accuracy: 0.7264\n",
      "Epoch 22/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5810 - accuracy: 0.7045 - val_loss: 0.5756 - val_accuracy: 0.7159\n",
      "Epoch 23/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7057 - val_loss: 0.5725 - val_accuracy: 0.7257\n",
      "Epoch 24/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5744 - accuracy: 0.7077 - val_loss: 0.5690 - val_accuracy: 0.7249\n",
      "Epoch 25/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.7152 - val_loss: 0.5655 - val_accuracy: 0.7162\n",
      "Epoch 26/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5680 - accuracy: 0.7171 - val_loss: 0.5631 - val_accuracy: 0.7379\n",
      "Epoch 27/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5651 - accuracy: 0.7219 - val_loss: 0.5597 - val_accuracy: 0.7361\n",
      "Epoch 28/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5618 - accuracy: 0.7273 - val_loss: 0.5568 - val_accuracy: 0.7379\n",
      "Epoch 29/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5589 - accuracy: 0.7271 - val_loss: 0.5542 - val_accuracy: 0.7474\n",
      "Epoch 30/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5558 - accuracy: 0.7322 - val_loss: 0.5504 - val_accuracy: 0.7293\n",
      "Epoch 31/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.7344 - val_loss: 0.5475 - val_accuracy: 0.7296\n",
      "Epoch 32/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7354 - val_loss: 0.5455 - val_accuracy: 0.7534\n",
      "Epoch 33/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7395 - val_loss: 0.5420 - val_accuracy: 0.7492\n",
      "Epoch 34/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7434 - val_loss: 0.5398 - val_accuracy: 0.7566\n",
      "Epoch 35/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7456 - val_loss: 0.5372 - val_accuracy: 0.7622\n",
      "Epoch 36/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7476 - val_loss: 0.5345 - val_accuracy: 0.7622\n",
      "Epoch 37/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7494 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
      "Epoch 38/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7525 - val_loss: 0.5290 - val_accuracy: 0.7530\n",
      "Epoch 39/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7533 - val_loss: 0.5265 - val_accuracy: 0.7523\n",
      "Epoch 40/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5288 - accuracy: 0.7577 - val_loss: 0.5243 - val_accuracy: 0.7596\n",
      "Epoch 41/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5265 - accuracy: 0.7606 - val_loss: 0.5219 - val_accuracy: 0.7525\n",
      "Epoch 42/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7593 - val_loss: 0.5202 - val_accuracy: 0.7703\n",
      "Epoch 43/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5223 - accuracy: 0.7628 - val_loss: 0.5181 - val_accuracy: 0.7736\n",
      "Epoch 44/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7661 - val_loss: 0.5155 - val_accuracy: 0.7675\n",
      "Epoch 45/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5176 - accuracy: 0.7679 - val_loss: 0.5134 - val_accuracy: 0.7525\n",
      "Epoch 46/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7659 - val_loss: 0.5113 - val_accuracy: 0.7717\n",
      "Epoch 47/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5134 - accuracy: 0.7713 - val_loss: 0.5092 - val_accuracy: 0.7735\n",
      "Epoch 48/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5113 - accuracy: 0.7729 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 49/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5093 - accuracy: 0.7729 - val_loss: 0.5049 - val_accuracy: 0.7729\n",
      "Epoch 50/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5073 - accuracy: 0.7733 - val_loss: 0.5029 - val_accuracy: 0.7699\n",
      "Epoch 51/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5051 - accuracy: 0.7763 - val_loss: 0.5011 - val_accuracy: 0.7802\n",
      "Epoch 52/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5031 - accuracy: 0.7803 - val_loss: 0.4990 - val_accuracy: 0.7714\n",
      "Epoch 53/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.5014 - accuracy: 0.7786 - val_loss: 0.4972 - val_accuracy: 0.7754\n",
      "Epoch 54/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4993 - accuracy: 0.7806 - val_loss: 0.4959 - val_accuracy: 0.7900\n",
      "Epoch 55/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4976 - accuracy: 0.7820 - val_loss: 0.4935 - val_accuracy: 0.7715\n",
      "Epoch 56/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4957 - accuracy: 0.7839 - val_loss: 0.4920 - val_accuracy: 0.7883\n",
      "Epoch 57/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4940 - accuracy: 0.7856 - val_loss: 0.4901 - val_accuracy: 0.7842\n",
      "Epoch 58/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4921 - accuracy: 0.7881 - val_loss: 0.4884 - val_accuracy: 0.7712\n",
      "Epoch 59/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4905 - accuracy: 0.7866 - val_loss: 0.4868 - val_accuracy: 0.7906\n",
      "Epoch 60/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4887 - accuracy: 0.7894 - val_loss: 0.4850 - val_accuracy: 0.7897\n",
      "Epoch 61/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7905 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
      "Epoch 62/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7894 - val_loss: 0.4821 - val_accuracy: 0.7999\n",
      "Epoch 63/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4836 - accuracy: 0.7931 - val_loss: 0.4816 - val_accuracy: 0.8124\n",
      "Epoch 64/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4820 - accuracy: 0.7953 - val_loss: 0.4787 - val_accuracy: 0.7957\n",
      "Epoch 65/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4804 - accuracy: 0.7942 - val_loss: 0.4770 - val_accuracy: 0.7951\n",
      "Epoch 66/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4787 - accuracy: 0.7953 - val_loss: 0.4760 - val_accuracy: 0.8064\n",
      "Epoch 67/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4773 - accuracy: 0.7969 - val_loss: 0.4738 - val_accuracy: 0.7869\n",
      "Epoch 68/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.7973 - val_loss: 0.4726 - val_accuracy: 0.8024\n",
      "Epoch 69/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4743 - accuracy: 0.7981 - val_loss: 0.4708 - val_accuracy: 0.7950\n",
      "Epoch 70/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.7988 - val_loss: 0.4702 - val_accuracy: 0.8129\n",
      "Epoch 71/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4712 - accuracy: 0.8006 - val_loss: 0.4682 - val_accuracy: 0.8068\n",
      "Epoch 72/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.8026 - val_loss: 0.4671 - val_accuracy: 0.8122\n",
      "Epoch 73/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4684 - accuracy: 0.8018 - val_loss: 0.4656 - val_accuracy: 0.8117\n",
      "Epoch 74/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8038 - val_loss: 0.4637 - val_accuracy: 0.8020\n",
      "Epoch 75/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4656 - accuracy: 0.8045 - val_loss: 0.4623 - val_accuracy: 0.8038\n",
      "Epoch 76/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4641 - accuracy: 0.8038 - val_loss: 0.4626 - val_accuracy: 0.8265\n",
      "Epoch 77/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4629 - accuracy: 0.8058 - val_loss: 0.4597 - val_accuracy: 0.8066\n",
      "Epoch 78/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4613 - accuracy: 0.8070 - val_loss: 0.4587 - val_accuracy: 0.8138\n",
      "Epoch 79/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.8068 - val_loss: 0.4577 - val_accuracy: 0.8186\n",
      "Epoch 80/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4587 - accuracy: 0.8090 - val_loss: 0.4559 - val_accuracy: 0.7941\n",
      "Epoch 81/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4574 - accuracy: 0.8083 - val_loss: 0.4549 - val_accuracy: 0.8179\n",
      "Epoch 82/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4562 - accuracy: 0.8108 - val_loss: 0.4532 - val_accuracy: 0.8018\n",
      "Epoch 83/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4550 - accuracy: 0.8103 - val_loss: 0.4525 - val_accuracy: 0.8194\n",
      "Epoch 84/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4537 - accuracy: 0.8124 - val_loss: 0.4510 - val_accuracy: 0.8170\n",
      "Epoch 85/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4525 - accuracy: 0.8113 - val_loss: 0.4496 - val_accuracy: 0.8135\n",
      "Epoch 86/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4510 - accuracy: 0.8119 - val_loss: 0.4491 - val_accuracy: 0.8277\n",
      "Epoch 87/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4500 - accuracy: 0.8139 - val_loss: 0.4475 - val_accuracy: 0.8191\n",
      "Epoch 88/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4488 - accuracy: 0.8151 - val_loss: 0.4464 - val_accuracy: 0.8230\n",
      "Epoch 89/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8159 - val_loss: 0.4450 - val_accuracy: 0.8193\n",
      "Epoch 90/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4466 - accuracy: 0.8164 - val_loss: 0.4438 - val_accuracy: 0.8186\n",
      "Epoch 91/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4454 - accuracy: 0.8159 - val_loss: 0.4429 - val_accuracy: 0.8223\n",
      "Epoch 92/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4440 - accuracy: 0.8172 - val_loss: 0.4421 - val_accuracy: 0.8291\n",
      "Epoch 93/100\n",
      "553/553 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8192 - val_loss: 0.4408 - val_accuracy: 0.8272\n",
      "Epoch 94/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4420 - accuracy: 0.8188 - val_loss: 0.4393 - val_accuracy: 0.8124\n",
      "Epoch 95/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4409 - accuracy: 0.8191 - val_loss: 0.4385 - val_accuracy: 0.8247\n",
      "Epoch 96/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4399 - accuracy: 0.8203 - val_loss: 0.4372 - val_accuracy: 0.8165\n",
      "Epoch 97/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.8202 - val_loss: 0.4367 - val_accuracy: 0.8316\n",
      "Epoch 98/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4376 - accuracy: 0.8226 - val_loss: 0.4351 - val_accuracy: 0.8173\n",
      "Epoch 99/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4367 - accuracy: 0.8217 - val_loss: 0.4341 - val_accuracy: 0.8138\n",
      "Epoch 100/100\n",
      "553/553 [==============================] - 1s 1ms/step - loss: 0.4356 - accuracy: 0.8216 - val_loss: 0.4339 - val_accuracy: 0.8379\n",
      "277/277 [==============================] - 0s 848us/step - loss: 0.4254 - accuracy: 0.8411\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f61df81c100>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-beb0a2675d41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m rnd_search_cv.fit(X_train, y_train, epochs = 100, \n\u001b[0m\u001b[1;32m      9\u001b[0m              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f61df81c100>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3,4,5,6],\n",
    "    \"n_neurons\": np.arange(1,600),\n",
    "    \"learning_rate\": reciprocal(1e-5,0.01),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs = 100, \n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.2062939642434896e-05, 'n_hidden': 6, 'n_neurons': 426}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12700140476226807"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b8ba0c4ba001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run this line of code if you are sure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# run this line of code if you are sure \n",
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=32,\n",
    "                                        max_value=512,\n",
    "                                        step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=list(np.linspace(start=1e-5, stop=10, num=500)))),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 1e-05</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [1e-05, 0.020050060120240482, 0.04009012024048097, 0.06013018036072145, 0.08017024048096193, 0.10021030060120241, 0.12025036072144289, 0.1402904208416834, 0.16033048096192387, 0.18037054108216435, 0.20041060120240484, 0.22045066132264532, 0.2404907214428858, 0.2605307815631263, 0.28057084168336677, 0.3006109018036072, 0.32065096192384773, 0.34069102204408824, 0.3607310821643287, 0.38077114228456915, 0.40081120240480966, 0.4208512625250502, 0.44089132264529063, 0.4609313827655311, 0.4809714428857716, 0.501011503006012, 0.5210515631262526, 0.541091623246493, 0.5611316833667335, 0.581171743486974, 0.6012118036072144, 0.6212518637274549, 0.6412919238476954, 0.6613319839679359, 0.6813720440881764, 0.7014121042084168, 0.7214521643286573, 0.7414922244488978, 0.7615322845691382, 0.7815723446893788, 0.8016124048096193, 0.8216524649298598, 0.8416925250501003, 0.8617325851703407, 0.8817726452905812, 0.9018127054108217, 0.9218527655310621, 0.9418928256513026, 0.9619328857715431, 0.9819729458917836, 1.0020130060120243, 1.0220530661322647, 1.0420931262525053, 1.0621331863727457, 1.082173246492986, 1.1022133066132267, 1.122253366733467, 1.1422934268537075, 1.1623334869739481, 1.1823735470941885, 1.202413607214429, 1.2224536673346695, 1.24249372745491, 1.2625337875751506, 1.282573847695391, 1.3026139078156314, 1.322653967935872, 1.3426940280561124, 1.362734088176353, 1.3827741482965934, 1.4028142084168338, 1.4228542685370744, 1.4428943286573148, 1.4629343887775552, 1.4829744488977958, 1.5030145090180362, 1.5230545691382766, 1.5430946292585173, 1.5631346893787577, 1.5831747494989983, 1.6032148096192387, 1.623254869739479, 1.6432949298597197, 1.66333498997996, 1.6833750501002007, 1.7034151102204411, 1.7234551703406815, 1.7434952304609221, 1.7635352905811625, 1.783575350701403, 1.8036154108216436, 1.823655470941884, 1.8436955310621244, 1.863735591182365, 1.8837756513026054, 1.903815711422846, 1.9238557715430864, 1.9438958316633268, 1.9639358917835674, 1.9839759519038078, 2.0040160120240484, 2.0240560721442886, 2.0440961322645292, 2.06413619238477, 2.0841762525050105, 2.1042163126252507, 2.1242563727454913, 2.144296432865732, 2.164336492985972, 2.1843765531062127, 2.2044166132264533, 2.2244566733466935, 2.244496733466934, 2.2645367935871747, 2.284576853707415, 2.3046169138276555, 2.324656973947896, 2.3446970340681363, 2.364737094188377, 2.3847771543086176, 2.4048172144288578, 2.4248572745490984, 2.444897334669339, 2.4649373947895796, 2.48497745490982, 2.5050175150300604, 2.525057575150301, 2.5450976352705412, 2.565137695390782, 2.5851777555110225, 2.6052178156312626, 2.6252578757515033, 2.645297935871744, 2.665337995991984, 2.6853780561122247, 2.7054181162324653, 2.725458176352706, 2.745498236472946, 2.7655382965931867, 2.7855783567134274, 2.8056184168336675, 2.825658476953908, 2.8456985370741488, 2.865738597194389, 2.8857786573146296, 2.90581871743487, 2.9258587775551104, 2.945898837675351, 2.9659388977955916, 2.985978957915832, 3.0060190180360724, 3.026059078156313, 3.046099138276553, 3.066139198396794, 3.0861792585170345, 3.106219318637275, 3.1262593787575153, 3.146299438877756, 3.1663394989979965, 3.1863795591182367, 3.2064196192384773, 3.226459679358718, 3.246499739478958, 3.2665397995991987, 3.2865798597194393, 3.3066199198396795, 3.32665997995992, 3.3467000400801608, 3.3667401002004014, 3.3867801603206416, 3.406820220440882, 3.426860280561123, 3.446900340681363, 3.4669404008016036, 3.486980460921844, 3.5070205210420844, 3.527060581162325, 3.5471006412825656, 3.567140701402806, 3.5871807615230464, 3.607220821643287, 3.6272608817635272, 3.647300941883768, 3.6673410020040085, 3.6873810621242487, 3.7074211222444893, 3.72746118236473, 3.7475012424849705, 3.7675413026052107, 3.7875813627254513, 3.807621422845692, 3.827661482965932, 3.8477015430861727, 3.8677416032064134, 3.8877816633266535, 3.907821723446894, 3.927861783567135, 3.947901843687375, 3.9679419038076156, 3.987981963927856, 4.008022024048096, 4.0280620841683366, 4.048102144288577, 4.068142204408818, 4.088182264529058, 4.108222324649298, 4.128262384769539, 4.148302444889779, 4.1683425050100205, 4.188382565130261, 4.208422625250501, 4.228462685370742, 4.248502745490982, 4.268542805611222, 4.288582865731463, 4.3086229258517035, 4.328662985971944, 4.348703046092185, 4.368743106212425, 4.388783166332665, 4.408823226452906, 4.428863286573146, 4.4489033466933865, 4.468943406813628, 4.488983466933868, 4.509023527054108, 4.529063587174349, 4.549103647294589, 4.569143707414829, 4.58918376753507, 4.609223827655311, 4.629263887775551, 4.649303947895792, 4.669344008016032, 4.689384068136272, 4.709424128256513, 4.729464188376753, 4.749504248496994, 4.769544308617235, 4.789584368737475, 4.809624428857715, 4.829664488977956, 4.849704549098196, 4.869744609218437, 4.8897846693386775, 4.909824729458918, 4.929864789579159, 4.949904849699399, 4.969944909819639, 4.98998496993988, 5.01002503006012, 5.0300650901803605, 5.050105150300602, 5.070145210420842, 5.090185270541082, 5.110225330661323, 5.130265390781563, 5.150305450901803, 5.170345511022044, 5.190385571142285, 5.210425631262525, 5.230465691382766, 5.250505751503006, 5.270545811623246, 5.290585871743487, 5.3106259318637274, 5.330665991983968, 5.350706052104209, 5.370746112224449, 5.390786172344689, 5.41082623246493, 5.43086629258517, 5.450906352705411, 5.4709464128256515, 5.490986472945892, 5.511026533066133, 5.531066593186373, 5.551106653306613, 5.571146713426854, 5.591186773547094, 5.6112268336673345, 5.631266893787576, 5.651306953907816, 5.671347014028056, 5.691387074148297, 5.711427134268537, 5.731467194388777, 5.7515072545090185, 5.771547314629259, 5.791587374749499, 5.81162743486974, 5.83166749498998, 5.85170755511022, 5.871747615230461, 5.8917876753507015, 5.911827735470942, 5.931867795591183, 5.951907855711423, 5.971947915831663, 5.991987975951904, 6.012028036072144, 6.0320680961923845, 6.0521081563126256, 6.072148216432866, 6.092188276553106, 6.112228336673347, 6.132268396793587, 6.152308456913828, 6.172348517034068, 6.192388577154309, 6.21242863727455, 6.23246869739479, 6.25250875751503, 6.272548817635271, 6.292588877755511, 6.312628937875751, 6.3326689979959925, 6.352709058116233, 6.372749118236473, 6.392789178356714, 6.412829238476954, 6.432869298597194, 6.452909358717435, 6.4729494188376755, 6.492989478957916, 6.513029539078157, 6.533069599198397, 6.553109659318637, 6.573149719438878, 6.593189779559118, 6.6132298396793585, 6.6332698997996, 6.65330995991984, 6.67335002004008, 6.693390080160321, 6.713430140280561, 6.733470200400802, 6.753510260521042, 6.773550320641283, 6.793590380761524, 6.813630440881764, 6.833670501002004, 6.853710561122245, 6.873750621242485, 6.893790681362725, 6.9138307414829665, 6.933870801603207, 6.953910861723447, 6.973950921843688, 6.993990981963928, 7.014031042084168, 7.034071102204409, 7.0541111623246495, 7.07415122244489, 7.094191282565131, 7.114231342685371, 7.134271402805611, 7.154311462925852, 7.174351523046092, 7.1943915831663325, 7.214431643286574, 7.234471703406814, 7.254511763527054, 7.274551823647295, 7.294591883767535, 7.314631943887775, 7.334672004008016, 7.354712064128257, 7.374752124248497, 7.394792184368738, 7.414832244488978, 7.434872304609219, 7.454912364729459, 7.4749524248496995, 7.4949924849699405, 7.515032545090181, 7.535072605210421, 7.555112665330662, 7.575152725450902, 7.595192785571142, 7.615232845691383, 7.6352729058116235, 7.655312965931864, 7.675353026052105, 7.695393086172345, 7.715433146292585, 7.735473206412826, 7.755513266533066, 7.775553326653307, 7.795593386773548, 7.815633446893788, 7.835673507014028, 7.855713567134269, 7.875753627254509, 7.895793687374749, 7.9158337474949905, 7.935873807615231, 7.955913867735471, 7.975953927855712, 7.995993987975952, 8.016034048096193, 8.036074108216432, 8.056114168336673, 8.076154228456915, 8.096194288577154, 8.116234348697395, 8.136274408817636, 8.156314468937875, 8.176354529058116, 8.196394589178357, 8.216434649298597, 8.236474709418838, 8.256514769539079, 8.276554829659318, 8.29659488977956, 8.3166349498998, 8.336675010020041, 8.35671507014028, 8.376755130260522, 8.396795190380763, 8.416835250501002, 8.436875310621243, 8.456915370741484, 8.476955430861723, 8.496995490981964, 8.517035551102206, 8.537075611222445, 8.557115671342686, 8.577155731462927, 8.597195791583166, 8.617235851703407, 8.637275911823648, 8.657315971943888, 8.677356032064129, 8.69739609218437, 8.717436152304609, 8.73747621242485, 8.757516272545091, 8.77755633266533, 8.797596392785572, 8.817636452905813, 8.837676513026052, 8.857716573146293, 8.877756633266534, 8.897796693386773, 8.917836753507014, 8.937876813627256, 8.957916873747495, 8.977956933867736, 8.997996993987977, 9.018037054108216, 9.038077114228457, 9.058117174348698, 9.078157234468938, 9.098197294589179, 9.11823735470942, 9.138277414829659, 9.1583174749499, 9.178357535070141, 9.19839759519038, 9.218437655310622, 9.238477715430863, 9.258517775551102, 9.278557835671343, 9.298597895791584, 9.318637955911823, 9.338678016032064, 9.358718076152305, 9.378758136272545, 9.398798196392786, 9.418838256513027, 9.438878316633266, 9.458918376753507, 9.478958436873748, 9.498998496993988, 9.519038557114229, 9.53907861723447, 9.559118677354709, 9.57915873747495, 9.599198797595191, 9.61923885771543, 9.639278917835671, 9.659318977955913, 9.679359038076154, 9.699399098196393, 9.719439158316634, 9.739479218436875, 9.759519278557114, 9.779559338677355, 9.799599398797596, 9.819639458917836, 9.839679519038077, 9.859719579158318, 9.879759639278557, 9.899799699398798, 9.91983975951904, 9.939879819639279, 9.95991987975952, 9.97995993987976, 10.0]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.68 - ETA: 1s - loss: 259.0526 - accuracy: 0.52 - ETA: 1s - loss: 129.8933 - accuracy: 0.52 - ETA: 0s - loss: 89.1579 - accuracy: 0.5355 - ETA: 0s - loss: 68.9138 - accuracy: 0.529 - ETA: 0s - loss: 55.2876 - accuracy: 0.527 - ETA: 0s - loss: 46.2012 - accuracy: 0.529 - ETA: 0s - loss: 39.5601 - accuracy: 0.531 - ETA: 0s - loss: 34.9650 - accuracy: 0.534 - ETA: 0s - loss: 31.2495 - accuracy: 0.531 - ETA: 0s - loss: 28.1542 - accuracy: 0.534 - ETA: 0s - loss: 25.7879 - accuracy: 0.530 - ETA: 0s - loss: 23.6893 - accuracy: 0.530 - ETA: 0s - loss: 22.0484 - accuracy: 0.532 - ETA: 0s - loss: 20.5900 - accuracy: 0.532 - ETA: 0s - loss: 19.1786 - accuracy: 0.533 - ETA: 0s - loss: 18.0146 - accuracy: 0.532 - ETA: 0s - loss: 17.0464 - accuracy: 0.531 - ETA: 0s - loss: 16.1302 - accuracy: 0.531 - ETA: 0s - loss: 15.3555 - accuracy: 0.531 - ETA: 0s - loss: 14.6364 - accuracy: 0.530 - ETA: 0s - loss: 13.9350 - accuracy: 0.530 - ETA: 0s - loss: 13.3468 - accuracy: 0.529 - ETA: 0s - loss: 12.9143 - accuracy: 0.530 - 1s 2ms/step - loss: 12.7670 - accuracy: 0.5298 - val_loss: 0.7122 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6587 - accuracy: 0.65 - ETA: 1s - loss: 1.7838 - accuracy: 0.54 - ETA: 1s - loss: 1.2569 - accuracy: 0.54 - ETA: 1s - loss: 1.1267 - accuracy: 0.52 - ETA: 0s - loss: 1.0363 - accuracy: 0.52 - ETA: 0s - loss: 0.9892 - accuracy: 0.52 - ETA: 0s - loss: 0.9589 - accuracy: 0.52 - ETA: 0s - loss: 0.9468 - accuracy: 0.52 - ETA: 0s - loss: 0.9268 - accuracy: 0.52 - ETA: 0s - loss: 0.9047 - accuracy: 0.52 - ETA: 0s - loss: 0.8918 - accuracy: 0.52 - ETA: 0s - loss: 0.8851 - accuracy: 0.52 - ETA: 0s - loss: 0.8736 - accuracy: 0.52 - ETA: 0s - loss: 0.8655 - accuracy: 0.52 - ETA: 0s - loss: 0.8548 - accuracy: 0.53 - ETA: 0s - loss: 0.8493 - accuracy: 0.53 - ETA: 0s - loss: 0.8501 - accuracy: 0.52 - ETA: 0s - loss: 0.8497 - accuracy: 0.52 - ETA: 0s - loss: 0.8437 - accuracy: 0.52 - ETA: 0s - loss: 0.8377 - accuracy: 0.52 - ETA: 0s - loss: 0.8318 - accuracy: 0.53 - ETA: 0s - loss: 0.8280 - accuracy: 0.53 - ETA: 0s - loss: 0.8233 - accuracy: 0.53 - ETA: 0s - loss: 0.8221 - accuracy: 0.53 - ETA: 0s - loss: 0.8198 - accuracy: 0.53 - 1s 2ms/step - loss: 0.8196 - accuracy: 0.5311 - val_loss: 1.1006 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.1784 - accuracy: 0.34 - ETA: 1s - loss: 0.8403 - accuracy: 0.50 - ETA: 1s - loss: 0.8231 - accuracy: 0.52 - ETA: 1s - loss: 0.7898 - accuracy: 0.52 - ETA: 0s - loss: 0.7960 - accuracy: 0.52 - ETA: 0s - loss: 0.7839 - accuracy: 0.53 - ETA: 0s - loss: 0.7751 - accuracy: 0.53 - ETA: 0s - loss: 0.7744 - accuracy: 0.53 - ETA: 0s - loss: 0.7825 - accuracy: 0.53 - ETA: 0s - loss: 0.7756 - accuracy: 0.53 - ETA: 0s - loss: 0.7718 - accuracy: 0.53 - ETA: 0s - loss: 0.7749 - accuracy: 0.53 - ETA: 0s - loss: 0.7762 - accuracy: 0.52 - ETA: 0s - loss: 0.7724 - accuracy: 0.53 - ETA: 0s - loss: 0.7712 - accuracy: 0.53 - ETA: 0s - loss: 0.7699 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - ETA: 0s - loss: 0.7688 - accuracy: 0.53 - ETA: 0s - loss: 0.7716 - accuracy: 0.53 - ETA: 0s - loss: 0.7711 - accuracy: 0.53 - ETA: 0s - loss: 0.7677 - accuracy: 0.53 - ETA: 0s - loss: 0.7687 - accuracy: 0.53 - ETA: 0s - loss: 0.7685 - accuracy: 0.53 - ETA: 0s - loss: 0.7669 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7669 - accuracy: 0.5318 - val_loss: 0.7113 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7191 - accuracy: 0.34 - ETA: 1s - loss: 0.7945 - accuracy: 0.51 - ETA: 1s - loss: 0.7875 - accuracy: 0.50 - ETA: 1s - loss: 0.7869 - accuracy: 0.51 - ETA: 1s - loss: 0.7848 - accuracy: 0.51 - ETA: 0s - loss: 0.7750 - accuracy: 0.53 - ETA: 0s - loss: 0.7750 - accuracy: 0.53 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7742 - accuracy: 0.52 - ETA: 0s - loss: 0.7735 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7734 - accuracy: 0.52 - ETA: 0s - loss: 0.7773 - accuracy: 0.52 - ETA: 0s - loss: 0.7712 - accuracy: 0.52 - ETA: 0s - loss: 0.7768 - accuracy: 0.52 - ETA: 0s - loss: 0.7739 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7757 - accuracy: 0.52 - ETA: 0s - loss: 0.7735 - accuracy: 0.52 - ETA: 0s - loss: 0.7732 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.52 - ETA: 0s - loss: 0.7692 - accuracy: 0.52 - ETA: 0s - loss: 0.7683 - accuracy: 0.52 - ETA: 0s - loss: 0.7676 - accuracy: 0.52 - ETA: 0s - loss: 0.7680 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - 2s 2ms/step - loss: 0.7695 - accuracy: 0.5263 - val_loss: 0.7045 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.62 - ETA: 1s - loss: 0.7684 - accuracy: 0.50 - ETA: 1s - loss: 0.7439 - accuracy: 0.52 - ETA: 1s - loss: 0.7397 - accuracy: 0.52 - ETA: 1s - loss: 0.7430 - accuracy: 0.52 - ETA: 0s - loss: 0.7359 - accuracy: 0.53 - ETA: 0s - loss: 0.7559 - accuracy: 0.52 - ETA: 0s - loss: 0.7558 - accuracy: 0.52 - ETA: 0s - loss: 0.7547 - accuracy: 0.53 - ETA: 0s - loss: 0.7484 - accuracy: 0.53 - ETA: 0s - loss: 0.7527 - accuracy: 0.53 - ETA: 0s - loss: 0.7565 - accuracy: 0.53 - ETA: 0s - loss: 0.7535 - accuracy: 0.53 - ETA: 0s - loss: 0.7529 - accuracy: 0.53 - ETA: 0s - loss: 0.7583 - accuracy: 0.52 - ETA: 0s - loss: 0.7580 - accuracy: 0.52 - ETA: 0s - loss: 0.7582 - accuracy: 0.53 - ETA: 0s - loss: 0.7563 - accuracy: 0.53 - ETA: 0s - loss: 0.7589 - accuracy: 0.53 - ETA: 0s - loss: 0.7610 - accuracy: 0.53 - ETA: 0s - loss: 0.7587 - accuracy: 0.53 - ETA: 0s - loss: 0.7627 - accuracy: 0.53 - ETA: 0s - loss: 0.7626 - accuracy: 0.53 - ETA: 0s - loss: 0.7667 - accuracy: 0.52 - ETA: 0s - loss: 0.7656 - accuracy: 0.52 - 1s 2ms/step - loss: 0.7671 - accuracy: 0.5280 - val_loss: 0.9081 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6027 - accuracy: 0.75 - ETA: 1s - loss: 35.2568 - accuracy: 0.570 - ETA: 1s - loss: 19.3793 - accuracy: 0.561 - ETA: 1s - loss: 13.3368 - accuracy: 0.559 - ETA: 1s - loss: 10.3226 - accuracy: 0.559 - ETA: 0s - loss: 8.5132 - accuracy: 0.559 - ETA: 0s - loss: 7.2012 - accuracy: 0.54 - ETA: 0s - loss: 6.4227 - accuracy: 0.55 - ETA: 0s - loss: 5.7323 - accuracy: 0.55 - ETA: 0s - loss: 5.2025 - accuracy: 0.54 - ETA: 0s - loss: 4.7622 - accuracy: 0.54 - ETA: 0s - loss: 4.3730 - accuracy: 0.54 - ETA: 0s - loss: 4.0788 - accuracy: 0.54 - ETA: 0s - loss: 3.8141 - accuracy: 0.54 - ETA: 0s - loss: 3.5919 - accuracy: 0.54 - ETA: 0s - loss: 3.3992 - accuracy: 0.54 - ETA: 0s - loss: 3.2466 - accuracy: 0.54 - ETA: 0s - loss: 3.0937 - accuracy: 0.54 - ETA: 0s - loss: 2.9621 - accuracy: 0.54 - ETA: 0s - loss: 2.8468 - accuracy: 0.54 - ETA: 0s - loss: 2.7410 - accuracy: 0.54 - ETA: 0s - loss: 2.6550 - accuracy: 0.54 - ETA: 0s - loss: 2.5684 - accuracy: 0.54 - ETA: 0s - loss: 2.4857 - accuracy: 0.53 - ETA: 0s - loss: 2.4169 - accuracy: 0.53 - 1s 2ms/step - loss: 2.3683 - accuracy: 0.5357 - val_loss: 1.8196 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.4375 - accuracy: 0.68 - ETA: 1s - loss: 0.7785 - accuracy: 0.52 - ETA: 1s - loss: 0.7969 - accuracy: 0.51 - ETA: 1s - loss: 0.7795 - accuracy: 0.52 - ETA: 1s - loss: 0.7789 - accuracy: 0.52 - ETA: 1s - loss: 0.7670 - accuracy: 0.52 - ETA: 1s - loss: 0.7650 - accuracy: 0.53 - ETA: 1s - loss: 0.7647 - accuracy: 0.53 - ETA: 0s - loss: 0.7637 - accuracy: 0.53 - ETA: 0s - loss: 0.7654 - accuracy: 0.53 - ETA: 0s - loss: 0.7648 - accuracy: 0.53 - ETA: 0s - loss: 0.7665 - accuracy: 0.53 - ETA: 0s - loss: 0.7661 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7680 - accuracy: 0.53 - ETA: 0s - loss: 0.7700 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7644 - accuracy: 0.53 - ETA: 0s - loss: 0.7631 - accuracy: 0.53 - ETA: 0s - loss: 0.7941 - accuracy: 0.53 - ETA: 0s - loss: 0.7937 - accuracy: 0.53 - ETA: 0s - loss: 0.7939 - accuracy: 0.53 - ETA: 0s - loss: 0.7918 - accuracy: 0.53 - ETA: 0s - loss: 0.7914 - accuracy: 0.53 - ETA: 0s - loss: 0.7947 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7932 - accuracy: 0.5316 - val_loss: 0.7286 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.65 - ETA: 1s - loss: 0.8165 - accuracy: 0.53 - ETA: 1s - loss: 0.7916 - accuracy: 0.53 - ETA: 1s - loss: 0.8005 - accuracy: 0.52 - ETA: 1s - loss: 0.7966 - accuracy: 0.52 - ETA: 1s - loss: 0.7912 - accuracy: 0.52 - ETA: 0s - loss: 0.7811 - accuracy: 0.52 - ETA: 0s - loss: 0.7804 - accuracy: 0.52 - ETA: 0s - loss: 0.7844 - accuracy: 0.52 - ETA: 0s - loss: 0.7856 - accuracy: 0.52 - ETA: 0s - loss: 0.7802 - accuracy: 0.52 - ETA: 0s - loss: 0.7758 - accuracy: 0.52 - ETA: 0s - loss: 0.7747 - accuracy: 0.52 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7735 - accuracy: 0.53 - ETA: 0s - loss: 0.7750 - accuracy: 0.52 - ETA: 0s - loss: 0.7732 - accuracy: 0.52 - ETA: 0s - loss: 0.7751 - accuracy: 0.52 - ETA: 0s - loss: 0.7748 - accuracy: 0.52 - ETA: 0s - loss: 0.7761 - accuracy: 0.52 - ETA: 0s - loss: 0.7753 - accuracy: 0.52 - ETA: 0s - loss: 0.7762 - accuracy: 0.52 - ETA: 0s - loss: 0.7734 - accuracy: 0.52 - ETA: 0s - loss: 0.7722 - accuracy: 0.52 - ETA: 0s - loss: 0.7713 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7695 - accuracy: 0.5304 - val_loss: 1.1560 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.4429 - accuracy: 0.50 - ETA: 1s - loss: 0.7752 - accuracy: 0.52 - ETA: 1s - loss: 0.7651 - accuracy: 0.53 - ETA: 1s - loss: 0.7557 - accuracy: 0.53 - ETA: 0s - loss: 0.7595 - accuracy: 0.53 - ETA: 0s - loss: 0.7617 - accuracy: 0.52 - ETA: 0s - loss: 0.7713 - accuracy: 0.52 - ETA: 0s - loss: 0.7749 - accuracy: 0.52 - ETA: 0s - loss: 0.7795 - accuracy: 0.52 - ETA: 0s - loss: 0.7823 - accuracy: 0.52 - ETA: 0s - loss: 0.7755 - accuracy: 0.53 - ETA: 0s - loss: 0.7721 - accuracy: 0.53 - ETA: 0s - loss: 0.7728 - accuracy: 0.53 - ETA: 0s - loss: 0.7721 - accuracy: 0.53 - ETA: 0s - loss: 0.7727 - accuracy: 0.53 - ETA: 0s - loss: 0.7748 - accuracy: 0.53 - ETA: 0s - loss: 0.7756 - accuracy: 0.53 - ETA: 0s - loss: 0.7732 - accuracy: 0.53 - ETA: 0s - loss: 0.7726 - accuracy: 0.53 - ETA: 0s - loss: 0.7740 - accuracy: 0.53 - ETA: 0s - loss: 0.7729 - accuracy: 0.53 - ETA: 0s - loss: 0.7745 - accuracy: 0.53 - ETA: 0s - loss: 0.7739 - accuracy: 0.53 - ETA: 0s - loss: 0.7751 - accuracy: 0.53 - ETA: 0s - loss: 0.7738 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7757 - accuracy: 0.5329 - val_loss: 0.7497 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8415 - accuracy: 0.53 - ETA: 1s - loss: 0.8154 - accuracy: 0.50 - ETA: 1s - loss: 0.7759 - accuracy: 0.53 - ETA: 1s - loss: 0.7929 - accuracy: 0.51 - ETA: 1s - loss: 0.7880 - accuracy: 0.51 - ETA: 1s - loss: 0.7811 - accuracy: 0.52 - ETA: 0s - loss: 0.7747 - accuracy: 0.51 - ETA: 0s - loss: 0.7697 - accuracy: 0.52 - ETA: 0s - loss: 0.7759 - accuracy: 0.52 - ETA: 0s - loss: 0.7731 - accuracy: 0.52 - ETA: 0s - loss: 0.7696 - accuracy: 0.52 - ETA: 0s - loss: 0.7658 - accuracy: 0.52 - ETA: 0s - loss: 0.7678 - accuracy: 0.52 - ETA: 0s - loss: 0.7704 - accuracy: 0.52 - ETA: 0s - loss: 0.7655 - accuracy: 0.53 - ETA: 0s - loss: 0.7641 - accuracy: 0.53 - ETA: 0s - loss: 0.7677 - accuracy: 0.53 - ETA: 0s - loss: 0.7701 - accuracy: 0.52 - ETA: 0s - loss: 0.7671 - accuracy: 0.53 - ETA: 0s - loss: 0.7646 - accuracy: 0.53 - ETA: 0s - loss: 0.7635 - accuracy: 0.53 - ETA: 0s - loss: 0.7675 - accuracy: 0.53 - ETA: 0s - loss: 0.7658 - accuracy: 0.53 - ETA: 0s - loss: 0.7680 - accuracy: 0.53 - ETA: 0s - loss: 0.7693 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7679 - accuracy: 0.5331 - val_loss: 0.7551 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8811 - accuracy: 0.31 - ETA: 1s - loss: 77.9600 - accuracy: 0.500 - ETA: 1s - loss: 40.9788 - accuracy: 0.516 - ETA: 1s - loss: 26.9634 - accuracy: 0.519 - ETA: 0s - loss: 20.5983 - accuracy: 0.526 - ETA: 0s - loss: 16.7157 - accuracy: 0.526 - ETA: 0s - loss: 14.1277 - accuracy: 0.523 - ETA: 0s - loss: 12.3521 - accuracy: 0.527 - ETA: 0s - loss: 10.8843 - accuracy: 0.529 - ETA: 0s - loss: 9.8877 - accuracy: 0.530 - ETA: 0s - loss: 8.9790 - accuracy: 0.53 - ETA: 0s - loss: 8.2521 - accuracy: 0.53 - ETA: 0s - loss: 7.6584 - accuracy: 0.53 - ETA: 0s - loss: 7.1279 - accuracy: 0.52 - ETA: 0s - loss: 6.6953 - accuracy: 0.52 - ETA: 0s - loss: 6.2746 - accuracy: 0.52 - ETA: 0s - loss: 5.9560 - accuracy: 0.52 - ETA: 0s - loss: 5.6224 - accuracy: 0.52 - ETA: 0s - loss: 5.6493 - accuracy: 0.52 - ETA: 0s - loss: 5.3782 - accuracy: 0.52 - ETA: 0s - loss: 5.1446 - accuracy: 0.52 - ETA: 0s - loss: 4.9735 - accuracy: 0.52 - ETA: 0s - loss: 4.7923 - accuracy: 0.52 - ETA: 0s - loss: 4.5904 - accuracy: 0.52 - 1s 2ms/step - loss: 4.5202 - accuracy: 0.5280 - val_loss: 0.7238 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.62 - ETA: 1s - loss: 0.7918 - accuracy: 0.53 - ETA: 1s - loss: 0.7431 - accuracy: 0.55 - ETA: 1s - loss: 0.7387 - accuracy: 0.55 - ETA: 0s - loss: 0.7358 - accuracy: 0.55 - ETA: 0s - loss: 0.7386 - accuracy: 0.55 - ETA: 0s - loss: 0.8012 - accuracy: 0.54 - ETA: 0s - loss: 0.7932 - accuracy: 0.54 - ETA: 0s - loss: 0.7961 - accuracy: 0.53 - ETA: 0s - loss: 0.7966 - accuracy: 0.53 - ETA: 0s - loss: 0.7923 - accuracy: 0.53 - ETA: 0s - loss: 0.7909 - accuracy: 0.53 - ETA: 0s - loss: 0.7884 - accuracy: 0.53 - ETA: 0s - loss: 0.7865 - accuracy: 0.52 - ETA: 0s - loss: 0.7882 - accuracy: 0.52 - ETA: 0s - loss: 0.7869 - accuracy: 0.52 - ETA: 0s - loss: 0.7840 - accuracy: 0.52 - ETA: 0s - loss: 0.7796 - accuracy: 0.52 - ETA: 0s - loss: 0.7762 - accuracy: 0.53 - ETA: 0s - loss: 0.7752 - accuracy: 0.53 - ETA: 0s - loss: 0.7715 - accuracy: 0.53 - ETA: 0s - loss: 0.7710 - accuracy: 0.53 - ETA: 0s - loss: 0.7754 - accuracy: 0.53 - ETA: 0s - loss: 0.7738 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7738 - accuracy: 0.5322 - val_loss: 1.8063 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.5049 - accuracy: 0.50 - ETA: 1s - loss: 0.7232 - accuracy: 0.56 - ETA: 1s - loss: 0.7415 - accuracy: 0.55 - ETA: 1s - loss: 0.7582 - accuracy: 0.54 - ETA: 1s - loss: 0.7876 - accuracy: 0.53 - ETA: 0s - loss: 0.7829 - accuracy: 0.52 - ETA: 0s - loss: 0.7726 - accuracy: 0.53 - ETA: 0s - loss: 0.7757 - accuracy: 0.53 - ETA: 0s - loss: 0.7725 - accuracy: 0.53 - ETA: 0s - loss: 0.7740 - accuracy: 0.53 - ETA: 0s - loss: 0.7731 - accuracy: 0.52 - ETA: 0s - loss: 0.7698 - accuracy: 0.52 - ETA: 0s - loss: 0.8014 - accuracy: 0.52 - ETA: 0s - loss: 0.7961 - accuracy: 0.53 - ETA: 0s - loss: 0.7948 - accuracy: 0.52 - ETA: 0s - loss: 0.7943 - accuracy: 0.52 - ETA: 0s - loss: 0.7960 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7910 - accuracy: 0.53 - ETA: 0s - loss: 0.7908 - accuracy: 0.53 - ETA: 0s - loss: 0.7926 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7944 - accuracy: 0.52 - ETA: 0s - loss: 0.7939 - accuracy: 0.52 - ETA: 0s - loss: 0.7931 - accuracy: 0.52 - 1s 2ms/step - loss: 0.7926 - accuracy: 0.5257 - val_loss: 1.5704 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.6226 - accuracy: 0.37 - ETA: 1s - loss: 0.7855 - accuracy: 0.52 - ETA: 1s - loss: 0.7673 - accuracy: 0.52 - ETA: 1s - loss: 0.7626 - accuracy: 0.52 - ETA: 1s - loss: 0.7669 - accuracy: 0.52 - ETA: 0s - loss: 0.7653 - accuracy: 0.52 - ETA: 0s - loss: 0.7646 - accuracy: 0.53 - ETA: 0s - loss: 0.7616 - accuracy: 0.53 - ETA: 0s - loss: 0.7559 - accuracy: 0.53 - ETA: 0s - loss: 0.7524 - accuracy: 0.53 - ETA: 0s - loss: 0.7494 - accuracy: 0.53 - ETA: 0s - loss: 0.7479 - accuracy: 0.54 - ETA: 0s - loss: 0.7471 - accuracy: 0.53 - ETA: 0s - loss: 0.7463 - accuracy: 0.53 - ETA: 0s - loss: 0.7488 - accuracy: 0.53 - ETA: 0s - loss: 0.7511 - accuracy: 0.53 - ETA: 0s - loss: 0.7558 - accuracy: 0.53 - ETA: 0s - loss: 0.7567 - accuracy: 0.53 - ETA: 0s - loss: 0.7562 - accuracy: 0.53 - ETA: 0s - loss: 0.7544 - accuracy: 0.53 - ETA: 0s - loss: 0.7572 - accuracy: 0.53 - ETA: 0s - loss: 0.7563 - accuracy: 0.53 - ETA: 0s - loss: 0.7538 - accuracy: 0.53 - ETA: 0s - loss: 0.7532 - accuracy: 0.53 - ETA: 0s - loss: 0.7549 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7551 - accuracy: 0.5334 - val_loss: 1.3215 - val_accuracy: 0.3962\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9317 - accuracy: 0.59 - ETA: 1s - loss: 0.7485 - accuracy: 0.55 - ETA: 1s - loss: 0.7574 - accuracy: 0.54 - ETA: 0s - loss: 0.7621 - accuracy: 0.53 - ETA: 0s - loss: 0.7554 - accuracy: 0.53 - ETA: 0s - loss: 0.7668 - accuracy: 0.53 - ETA: 0s - loss: 0.7634 - accuracy: 0.53 - ETA: 0s - loss: 0.7681 - accuracy: 0.53 - ETA: 0s - loss: 0.7598 - accuracy: 0.53 - ETA: 0s - loss: 0.7595 - accuracy: 0.53 - ETA: 0s - loss: 0.7547 - accuracy: 0.53 - ETA: 0s - loss: 0.7554 - accuracy: 0.53 - ETA: 0s - loss: 0.7566 - accuracy: 0.53 - ETA: 0s - loss: 0.7578 - accuracy: 0.53 - ETA: 0s - loss: 0.7542 - accuracy: 0.53 - ETA: 0s - loss: 0.7567 - accuracy: 0.53 - ETA: 0s - loss: 0.7578 - accuracy: 0.53 - ETA: 0s - loss: 0.7580 - accuracy: 0.53 - ETA: 0s - loss: 0.7568 - accuracy: 0.53 - ETA: 0s - loss: 0.7574 - accuracy: 0.53 - ETA: 0s - loss: 0.7556 - accuracy: 0.53 - ETA: 0s - loss: 0.7618 - accuracy: 0.53 - ETA: 0s - loss: 0.7619 - accuracy: 0.53 - ETA: 0s - loss: 0.7613 - accuracy: 0.53 - 1s 2ms/step - loss: 0.7628 - accuracy: 0.5344 - val_loss: 0.7190 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3d3482d6602d7d2b7ef8e3c0e62f8297</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 7.835673507014028</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.56 - ETA: 1s - loss: 4.8114 - accuracy: 0.50 - ETA: 1s - loss: 2.8769 - accuracy: 0.55 - ETA: 1s - loss: 2.1776 - accuracy: 0.55 - ETA: 1s - loss: 1.8237 - accuracy: 0.55 - ETA: 0s - loss: 1.5811 - accuracy: 0.55 - ETA: 0s - loss: 1.4249 - accuracy: 0.55 - ETA: 0s - loss: 1.3253 - accuracy: 0.55 - ETA: 0s - loss: 1.2472 - accuracy: 0.55 - ETA: 0s - loss: 1.1999 - accuracy: 0.55 - ETA: 0s - loss: 1.1489 - accuracy: 0.55 - ETA: 0s - loss: 1.1038 - accuracy: 0.55 - ETA: 0s - loss: 1.0672 - accuracy: 0.55 - ETA: 0s - loss: 1.0354 - accuracy: 0.56 - ETA: 0s - loss: 1.0131 - accuracy: 0.55 - ETA: 0s - loss: 0.9907 - accuracy: 0.55 - ETA: 0s - loss: 0.9709 - accuracy: 0.56 - ETA: 0s - loss: 0.9621 - accuracy: 0.56 - ETA: 0s - loss: 0.9480 - accuracy: 0.56 - ETA: 0s - loss: 0.9342 - accuracy: 0.56 - ETA: 0s - loss: 0.9216 - accuracy: 0.56 - ETA: 0s - loss: 0.9113 - accuracy: 0.56 - ETA: 0s - loss: 0.9016 - accuracy: 0.56 - ETA: 0s - loss: 0.8926 - accuracy: 0.56 - 1s 2ms/step - loss: 0.8912 - accuracy: 0.5696 - val_loss: 0.7124 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.68 - ETA: 1s - loss: 0.6681 - accuracy: 0.61 - ETA: 1s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6828 - accuracy: 0.58 - ETA: 0s - loss: 0.6802 - accuracy: 0.58 - ETA: 0s - loss: 0.6803 - accuracy: 0.58 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5677 - val_loss: 0.7112 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8482 - accuracy: 0.46 - ETA: 1s - loss: 0.6850 - accuracy: 0.58 - ETA: 1s - loss: 0.6894 - accuracy: 0.57 - ETA: 1s - loss: 0.6932 - accuracy: 0.56 - ETA: 0s - loss: 0.6932 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5711 - val_loss: 0.6902 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.62 - ETA: 1s - loss: 0.6848 - accuracy: 0.60 - ETA: 1s - loss: 0.6864 - accuracy: 0.58 - ETA: 1s - loss: 0.6873 - accuracy: 0.57 - ETA: 1s - loss: 0.6882 - accuracy: 0.56 - ETA: 0s - loss: 0.6884 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5658 - val_loss: 0.7106 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7838 - accuracy: 0.53 - ETA: 1s - loss: 0.6780 - accuracy: 0.60 - ETA: 1s - loss: 0.6853 - accuracy: 0.58 - ETA: 1s - loss: 0.6834 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5719 - val_loss: 0.7107 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.28 - ETA: 1s - loss: 6.6690 - accuracy: 0.55 - ETA: 1s - loss: 3.7156 - accuracy: 0.57 - ETA: 1s - loss: 2.7373 - accuracy: 0.56 - ETA: 1s - loss: 2.2593 - accuracy: 0.56 - ETA: 0s - loss: 1.9611 - accuracy: 0.56 - ETA: 0s - loss: 1.7587 - accuracy: 0.56 - ETA: 0s - loss: 1.6052 - accuracy: 0.56 - ETA: 0s - loss: 1.4864 - accuracy: 0.56 - ETA: 0s - loss: 1.4002 - accuracy: 0.56 - ETA: 0s - loss: 1.3329 - accuracy: 0.56 - ETA: 0s - loss: 1.2759 - accuracy: 0.56 - ETA: 0s - loss: 1.2267 - accuracy: 0.56 - ETA: 0s - loss: 1.1870 - accuracy: 0.56 - ETA: 0s - loss: 1.1510 - accuracy: 0.56 - ETA: 0s - loss: 1.1200 - accuracy: 0.56 - ETA: 0s - loss: 1.0922 - accuracy: 0.56 - ETA: 0s - loss: 1.0685 - accuracy: 0.56 - ETA: 0s - loss: 1.0454 - accuracy: 0.56 - ETA: 0s - loss: 1.0260 - accuracy: 0.56 - ETA: 0s - loss: 1.0085 - accuracy: 0.56 - ETA: 0s - loss: 0.9964 - accuracy: 0.56 - ETA: 0s - loss: 0.9819 - accuracy: 0.56 - ETA: 0s - loss: 0.9693 - accuracy: 0.56 - ETA: 0s - loss: 0.9571 - accuracy: 0.56 - 1s 2ms/step - loss: 0.9508 - accuracy: 0.5661 - val_loss: 0.9137 - val_accuracy: 0.3962\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9347 - accuracy: 0.37 - ETA: 1s - loss: 0.6879 - accuracy: 0.58 - ETA: 1s - loss: 0.6889 - accuracy: 0.56 - ETA: 1s - loss: 0.6862 - accuracy: 0.57 - ETA: 1s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6898 - accuracy: 0.5693 - val_loss: 0.9197 - val_accuracy: 0.3962\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.9725 - accuracy: 0.34 - ETA: 1s - loss: 0.7012 - accuracy: 0.56 - ETA: 1s - loss: 0.6983 - accuracy: 0.55 - ETA: 1s - loss: 0.6945 - accuracy: 0.56 - ETA: 1s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6912 - accuracy: 0.57 - ETA: 0s - loss: 0.6912 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5682 - val_loss: 0.6924 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.68 - ETA: 1s - loss: 0.6798 - accuracy: 0.58 - ETA: 1s - loss: 0.6803 - accuracy: 0.57 - ETA: 1s - loss: 0.6865 - accuracy: 0.57 - ETA: 1s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6906 - accuracy: 0.5715 - val_loss: 0.6932 - val_accuracy: 0.3962\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.46 - ETA: 1s - loss: 0.6846 - accuracy: 0.59 - ETA: 1s - loss: 0.6907 - accuracy: 0.57 - ETA: 1s - loss: 0.6938 - accuracy: 0.56 - ETA: 1s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6910 - accuracy: 0.57 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5677 - val_loss: 0.7104 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.1146 - accuracy: 0.40 - ETA: 1s - loss: 11.9880 - accuracy: 0.568 - ETA: 1s - loss: 6.1816 - accuracy: 0.549 - ETA: 1s - loss: 4.4995 - accuracy: 0.55 - ETA: 1s - loss: 3.4777 - accuracy: 0.56 - ETA: 0s - loss: 2.9398 - accuracy: 0.56 - ETA: 0s - loss: 2.5856 - accuracy: 0.56 - ETA: 0s - loss: 2.3085 - accuracy: 0.56 - ETA: 0s - loss: 2.1021 - accuracy: 0.56 - ETA: 0s - loss: 1.9556 - accuracy: 0.55 - ETA: 0s - loss: 1.8339 - accuracy: 0.55 - ETA: 0s - loss: 1.7267 - accuracy: 0.55 - ETA: 0s - loss: 1.6351 - accuracy: 0.55 - ETA: 0s - loss: 1.5604 - accuracy: 0.55 - ETA: 0s - loss: 1.5018 - accuracy: 0.55 - ETA: 0s - loss: 1.4465 - accuracy: 0.55 - ETA: 0s - loss: 1.4033 - accuracy: 0.55 - ETA: 0s - loss: 1.3595 - accuracy: 0.56 - ETA: 0s - loss: 1.3228 - accuracy: 0.56 - ETA: 0s - loss: 1.2894 - accuracy: 0.56 - ETA: 0s - loss: 1.2610 - accuracy: 0.56 - ETA: 0s - loss: 1.2322 - accuracy: 0.56 - ETA: 0s - loss: 1.2078 - accuracy: 0.56 - ETA: 0s - loss: 1.1851 - accuracy: 0.56 - ETA: 0s - loss: 1.1641 - accuracy: 0.56 - 1s 2ms/step - loss: 1.1565 - accuracy: 0.5652 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.59 - ETA: 1s - loss: 0.6878 - accuracy: 0.56 - ETA: 1s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6935 - accuracy: 0.55 - ETA: 0s - loss: 0.6923 - accuracy: 0.55 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6923 - accuracy: 0.56 - ETA: 0s - loss: 0.6925 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5679 - val_loss: 0.6902 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.62 - ETA: 1s - loss: 0.6767 - accuracy: 0.59 - ETA: 1s - loss: 0.6840 - accuracy: 0.59 - ETA: 1s - loss: 0.6856 - accuracy: 0.58 - ETA: 1s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.56 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5689 - val_loss: 0.7106 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8153 - accuracy: 0.50 - ETA: 1s - loss: 0.6871 - accuracy: 0.58 - ETA: 1s - loss: 0.6923 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6889 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5699 - val_loss: 0.7127 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8833 - accuracy: 0.43 - ETA: 1s - loss: 0.6951 - accuracy: 0.56 - ETA: 1s - loss: 0.6925 - accuracy: 0.57 - ETA: 1s - loss: 0.6893 - accuracy: 0.58 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6891 - accuracy: 0.57 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5667 - val_loss: 0.6933 - val_accuracy: 0.3960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3e68b6d2d15e304a028985d2cd653aa1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 4.0280620841683366</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6671 - accuracy: 0.59 - ETA: 0s - loss: 0.7494 - accuracy: 0.57 - ETA: 0s - loss: 0.7132 - accuracy: 0.58 - ETA: 0s - loss: 0.7015 - accuracy: 0.59 - ETA: 0s - loss: 0.6927 - accuracy: 0.59 - ETA: 0s - loss: 0.6912 - accuracy: 0.59 - ETA: 0s - loss: 0.6899 - accuracy: 0.58 - ETA: 0s - loss: 0.6882 - accuracy: 0.59 - ETA: 0s - loss: 0.6868 - accuracy: 0.59 - ETA: 0s - loss: 0.6854 - accuracy: 0.59 - ETA: 0s - loss: 0.6843 - accuracy: 0.59 - ETA: 0s - loss: 0.6835 - accuracy: 0.59 - ETA: 0s - loss: 0.6831 - accuracy: 0.59 - ETA: 0s - loss: 0.6832 - accuracy: 0.59 - ETA: 0s - loss: 0.6827 - accuracy: 0.59 - ETA: 0s - loss: 0.6824 - accuracy: 0.59 - ETA: 0s - loss: 0.6820 - accuracy: 0.59 - ETA: 0s - loss: 0.6819 - accuracy: 0.59 - ETA: 0s - loss: 0.6818 - accuracy: 0.59 - ETA: 0s - loss: 0.6815 - accuracy: 0.59 - ETA: 0s - loss: 0.6812 - accuracy: 0.59 - ETA: 0s - loss: 0.6813 - accuracy: 0.59 - ETA: 0s - loss: 0.6809 - accuracy: 0.59 - ETA: 0s - loss: 0.6807 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6807 - accuracy: 0.5924 - val_loss: 0.6799 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.68 - ETA: 1s - loss: 0.6729 - accuracy: 0.60 - ETA: 1s - loss: 0.6739 - accuracy: 0.60 - ETA: 1s - loss: 0.6780 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6741 - accuracy: 0.60 - ETA: 0s - loss: 0.6736 - accuracy: 0.60 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6744 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6743 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6748 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6751 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6816 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.75 - ETA: 1s - loss: 0.6759 - accuracy: 0.60 - ETA: 1s - loss: 0.6786 - accuracy: 0.59 - ETA: 1s - loss: 0.6801 - accuracy: 0.58 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 0s - loss: 0.6796 - accuracy: 0.58 - ETA: 0s - loss: 0.6793 - accuracy: 0.58 - ETA: 0s - loss: 0.6790 - accuracy: 0.58 - ETA: 0s - loss: 0.6789 - accuracy: 0.58 - ETA: 0s - loss: 0.6781 - accuracy: 0.59 - ETA: 0s - loss: 0.6785 - accuracy: 0.58 - ETA: 0s - loss: 0.6785 - accuracy: 0.58 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6771 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7033 - accuracy: 0.53 - ETA: 1s - loss: 0.6757 - accuracy: 0.59 - ETA: 1s - loss: 0.6777 - accuracy: 0.58 - ETA: 1s - loss: 0.6783 - accuracy: 0.58 - ETA: 1s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6779 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6786 - accuracy: 0.58 - ETA: 0s - loss: 0.6784 - accuracy: 0.58 - ETA: 0s - loss: 0.6782 - accuracy: 0.58 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6731 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6193 - accuracy: 0.78 - ETA: 1s - loss: 0.6654 - accuracy: 0.62 - ETA: 1s - loss: 0.6750 - accuracy: 0.59 - ETA: 1s - loss: 0.6736 - accuracy: 0.60 - ETA: 1s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7609 - accuracy: 0.43 - ETA: 1s - loss: 0.8527 - accuracy: 0.58 - ETA: 1s - loss: 0.7676 - accuracy: 0.59 - ETA: 1s - loss: 0.7395 - accuracy: 0.58 - ETA: 0s - loss: 0.7233 - accuracy: 0.59 - ETA: 0s - loss: 0.7147 - accuracy: 0.58 - ETA: 0s - loss: 0.7060 - accuracy: 0.59 - ETA: 0s - loss: 0.7028 - accuracy: 0.59 - ETA: 0s - loss: 0.6998 - accuracy: 0.59 - ETA: 0s - loss: 0.6977 - accuracy: 0.59 - ETA: 0s - loss: 0.6955 - accuracy: 0.59 - ETA: 0s - loss: 0.6944 - accuracy: 0.59 - ETA: 0s - loss: 0.6924 - accuracy: 0.59 - ETA: 0s - loss: 0.6907 - accuracy: 0.59 - ETA: 0s - loss: 0.6896 - accuracy: 0.59 - ETA: 0s - loss: 0.6891 - accuracy: 0.59 - ETA: 0s - loss: 0.6884 - accuracy: 0.59 - ETA: 0s - loss: 0.6883 - accuracy: 0.59 - ETA: 0s - loss: 0.6875 - accuracy: 0.59 - ETA: 0s - loss: 0.6870 - accuracy: 0.59 - ETA: 0s - loss: 0.6860 - accuracy: 0.59 - ETA: 0s - loss: 0.6862 - accuracy: 0.59 - ETA: 0s - loss: 0.6860 - accuracy: 0.59 - ETA: 0s - loss: 0.6855 - accuracy: 0.59 - ETA: 0s - loss: 0.6850 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6850 - accuracy: 0.5924 - val_loss: 0.6717 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.50 - ETA: 1s - loss: 0.6802 - accuracy: 0.58 - ETA: 1s - loss: 0.6766 - accuracy: 0.59 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 1s - loss: 0.6783 - accuracy: 0.58 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6757 - accuracy: 0.59 - ETA: 0s - loss: 0.6751 - accuracy: 0.59 - ETA: 0s - loss: 0.6753 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6768 - accuracy: 0.5929 - val_loss: 0.6716 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 1s - loss: 0.6682 - accuracy: 0.61 - ETA: 1s - loss: 0.6775 - accuracy: 0.58 - ETA: 1s - loss: 0.6778 - accuracy: 0.58 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6749 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6773 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6715 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6344 - accuracy: 0.68 - ETA: 1s - loss: 0.6679 - accuracy: 0.61 - ETA: 1s - loss: 0.6752 - accuracy: 0.59 - ETA: 1s - loss: 0.6751 - accuracy: 0.59 - ETA: 1s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.75 - ETA: 1s - loss: 0.6788 - accuracy: 0.59 - ETA: 1s - loss: 0.6804 - accuracy: 0.58 - ETA: 1s - loss: 0.6788 - accuracy: 0.58 - ETA: 1s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6737 - accuracy: 0.59 - ETA: 0s - loss: 0.6742 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6746 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6750 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6754 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6772 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6719 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.62 - ETA: 1s - loss: 0.9888 - accuracy: 0.57 - ETA: 1s - loss: 0.8353 - accuracy: 0.58 - ETA: 0s - loss: 0.7834 - accuracy: 0.58 - ETA: 0s - loss: 0.7597 - accuracy: 0.58 - ETA: 0s - loss: 0.7451 - accuracy: 0.58 - ETA: 0s - loss: 0.7345 - accuracy: 0.58 - ETA: 0s - loss: 0.7265 - accuracy: 0.58 - ETA: 0s - loss: 0.7209 - accuracy: 0.58 - ETA: 0s - loss: 0.7169 - accuracy: 0.58 - ETA: 0s - loss: 0.7131 - accuracy: 0.58 - ETA: 0s - loss: 0.7096 - accuracy: 0.58 - ETA: 0s - loss: 0.7068 - accuracy: 0.58 - ETA: 0s - loss: 0.7047 - accuracy: 0.58 - ETA: 0s - loss: 0.7029 - accuracy: 0.58 - ETA: 0s - loss: 0.7008 - accuracy: 0.58 - ETA: 0s - loss: 0.6989 - accuracy: 0.59 - ETA: 0s - loss: 0.6982 - accuracy: 0.58 - ETA: 0s - loss: 0.6976 - accuracy: 0.58 - ETA: 0s - loss: 0.6959 - accuracy: 0.58 - ETA: 0s - loss: 0.6944 - accuracy: 0.59 - ETA: 0s - loss: 0.6935 - accuracy: 0.59 - ETA: 0s - loss: 0.6926 - accuracy: 0.59 - ETA: 0s - loss: 0.6918 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5921 - val_loss: 0.6727 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6288 - accuracy: 0.68 - ETA: 1s - loss: 0.6813 - accuracy: 0.58 - ETA: 1s - loss: 0.6717 - accuracy: 0.60 - ETA: 1s - loss: 0.6721 - accuracy: 0.60 - ETA: 0s - loss: 0.6733 - accuracy: 0.60 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6756 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5927 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.56 - ETA: 1s - loss: 0.6836 - accuracy: 0.57 - ETA: 1s - loss: 0.6814 - accuracy: 0.58 - ETA: 1s - loss: 0.6799 - accuracy: 0.58 - ETA: 1s - loss: 0.6789 - accuracy: 0.58 - ETA: 0s - loss: 0.6802 - accuracy: 0.58 - ETA: 0s - loss: 0.6793 - accuracy: 0.58 - ETA: 0s - loss: 0.6784 - accuracy: 0.59 - ETA: 0s - loss: 0.6782 - accuracy: 0.59 - ETA: 0s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6753 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5929 - val_loss: 0.6734 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.71 - ETA: 1s - loss: 0.6766 - accuracy: 0.59 - ETA: 1s - loss: 0.6794 - accuracy: 0.58 - ETA: 1s - loss: 0.6791 - accuracy: 0.58 - ETA: 1s - loss: 0.6778 - accuracy: 0.59 - ETA: 0s - loss: 0.6777 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6763 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6758 - accuracy: 0.59 - ETA: 0s - loss: 0.6761 - accuracy: 0.59 - ETA: 0s - loss: 0.6757 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6762 - accuracy: 0.59 - ETA: 0s - loss: 0.6764 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6769 - accuracy: 0.5929 - val_loss: 0.6714 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7509 - accuracy: 0.40 - ETA: 1s - loss: 0.6796 - accuracy: 0.58 - ETA: 1s - loss: 0.6781 - accuracy: 0.59 - ETA: 1s - loss: 0.6759 - accuracy: 0.59 - ETA: 0s - loss: 0.6768 - accuracy: 0.59 - ETA: 0s - loss: 0.6754 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6745 - accuracy: 0.59 - ETA: 0s - loss: 0.6731 - accuracy: 0.60 - ETA: 0s - loss: 0.6735 - accuracy: 0.60 - ETA: 0s - loss: 0.6741 - accuracy: 0.60 - ETA: 0s - loss: 0.6747 - accuracy: 0.59 - ETA: 0s - loss: 0.6749 - accuracy: 0.59 - ETA: 0s - loss: 0.6760 - accuracy: 0.59 - ETA: 0s - loss: 0.6765 - accuracy: 0.59 - ETA: 0s - loss: 0.6771 - accuracy: 0.59 - ETA: 0s - loss: 0.6767 - accuracy: 0.59 - ETA: 0s - loss: 0.6774 - accuracy: 0.59 - ETA: 0s - loss: 0.6775 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6766 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - ETA: 0s - loss: 0.6770 - accuracy: 0.59 - ETA: 0s - loss: 0.6769 - accuracy: 0.59 - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5929 - val_loss: 0.6733 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2e718f4b3965c573b66000c6c8ae9e7c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.5210515631262526</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.53 - ETA: 1s - loss: 129.4386 - accuracy: 0.58 - ETA: 1s - loss: 69.5942 - accuracy: 0.5814 - ETA: 1s - loss: 46.4181 - accuracy: 0.563 - ETA: 0s - loss: 34.6711 - accuracy: 0.564 - ETA: 0s - loss: 28.1818 - accuracy: 0.563 - ETA: 0s - loss: 23.6628 - accuracy: 0.568 - ETA: 0s - loss: 20.5813 - accuracy: 0.570 - ETA: 0s - loss: 17.9823 - accuracy: 0.570 - ETA: 0s - loss: 16.0805 - accuracy: 0.565 - ETA: 0s - loss: 14.5153 - accuracy: 0.565 - ETA: 0s - loss: 13.2129 - accuracy: 0.568 - ETA: 0s - loss: 12.1573 - accuracy: 0.566 - ETA: 0s - loss: 11.2890 - accuracy: 0.565 - ETA: 0s - loss: 10.6224 - accuracy: 0.566 - ETA: 0s - loss: 9.9314 - accuracy: 0.565 - ETA: 0s - loss: 9.4058 - accuracy: 0.56 - ETA: 0s - loss: 8.8949 - accuracy: 0.56 - ETA: 0s - loss: 8.4532 - accuracy: 0.56 - ETA: 0s - loss: 8.0570 - accuracy: 0.56 - ETA: 0s - loss: 7.6990 - accuracy: 0.56 - ETA: 0s - loss: 7.3558 - accuracy: 0.56 - ETA: 0s - loss: 7.0612 - accuracy: 0.56 - ETA: 0s - loss: 6.7840 - accuracy: 0.56 - 1s 2ms/step - loss: 6.6060 - accuracy: 0.5632 - val_loss: 0.7306 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7783 - accuracy: 0.56 - ETA: 1s - loss: 0.6951 - accuracy: 0.55 - ETA: 1s - loss: 0.6912 - accuracy: 0.56 - ETA: 1s - loss: 0.6947 - accuracy: 0.56 - ETA: 1s - loss: 0.6972 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6950 - accuracy: 0.55 - ETA: 0s - loss: 0.6957 - accuracy: 0.55 - ETA: 0s - loss: 0.6966 - accuracy: 0.55 - ETA: 0s - loss: 0.6954 - accuracy: 0.55 - ETA: 0s - loss: 0.6963 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6951 - accuracy: 0.55 - ETA: 0s - loss: 0.6952 - accuracy: 0.55 - ETA: 0s - loss: 0.6970 - accuracy: 0.55 - ETA: 0s - loss: 0.6972 - accuracy: 0.55 - ETA: 0s - loss: 0.6969 - accuracy: 0.55 - ETA: 0s - loss: 0.6965 - accuracy: 0.55 - ETA: 0s - loss: 0.6956 - accuracy: 0.55 - ETA: 0s - loss: 0.6955 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6950 - accuracy: 0.55 - 1s 2ms/step - loss: 0.6954 - accuracy: 0.5572 - val_loss: 0.6923 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - ETA: 1s - loss: 0.6972 - accuracy: 0.56 - ETA: 1s - loss: 0.6950 - accuracy: 0.56 - ETA: 1s - loss: 0.6926 - accuracy: 0.56 - ETA: 1s - loss: 0.6945 - accuracy: 0.55 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.7020 - accuracy: 0.55 - ETA: 0s - loss: 0.7008 - accuracy: 0.55 - ETA: 0s - loss: 0.6998 - accuracy: 0.55 - ETA: 0s - loss: 0.6974 - accuracy: 0.56 - ETA: 0s - loss: 0.6953 - accuracy: 0.56 - ETA: 0s - loss: 0.6958 - accuracy: 0.56 - ETA: 0s - loss: 0.6951 - accuracy: 0.56 - ETA: 0s - loss: 0.6942 - accuracy: 0.56 - ETA: 0s - loss: 0.6941 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.56 - ETA: 0s - loss: 0.6942 - accuracy: 0.56 - ETA: 0s - loss: 0.6943 - accuracy: 0.56 - ETA: 0s - loss: 0.6939 - accuracy: 0.56 - ETA: 0s - loss: 0.6940 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5624 - val_loss: 0.6940 - val_accuracy: 0.3962\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.37 - ETA: 1s - loss: 0.6873 - accuracy: 0.58 - ETA: 1s - loss: 0.6858 - accuracy: 0.57 - ETA: 1s - loss: 0.6881 - accuracy: 0.57 - ETA: 1s - loss: 0.6915 - accuracy: 0.55 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.56 - ETA: 0s - loss: 0.6879 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.56 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6894 - accuracy: 0.56 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5672 - val_loss: 33.8894 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 37.4407 - accuracy: 0.562 - ETA: 1s - loss: 1.7389 - accuracy: 0.565 - ETA: 1s - loss: 1.1906 - accuracy: 0.57 - ETA: 1s - loss: 1.0311 - accuracy: 0.55 - ETA: 0s - loss: 0.9494 - accuracy: 0.56 - ETA: 0s - loss: 0.9012 - accuracy: 0.56 - ETA: 0s - loss: 0.8674 - accuracy: 0.56 - ETA: 0s - loss: 0.8414 - accuracy: 0.57 - ETA: 0s - loss: 0.8227 - accuracy: 0.57 - ETA: 0s - loss: 0.8077 - accuracy: 0.57 - ETA: 0s - loss: 0.7972 - accuracy: 0.56 - ETA: 0s - loss: 0.7869 - accuracy: 0.57 - ETA: 0s - loss: 0.7792 - accuracy: 0.57 - ETA: 0s - loss: 0.7719 - accuracy: 0.57 - ETA: 0s - loss: 0.7668 - accuracy: 0.56 - ETA: 0s - loss: 0.7618 - accuracy: 0.57 - ETA: 0s - loss: 0.7578 - accuracy: 0.56 - ETA: 0s - loss: 0.7541 - accuracy: 0.56 - ETA: 0s - loss: 0.7508 - accuracy: 0.56 - ETA: 0s - loss: 0.7483 - accuracy: 0.56 - ETA: 0s - loss: 0.7455 - accuracy: 0.56 - ETA: 0s - loss: 0.7430 - accuracy: 0.56 - ETA: 0s - loss: 0.7402 - accuracy: 0.56 - ETA: 0s - loss: 0.7381 - accuracy: 0.56 - ETA: 0s - loss: 0.7359 - accuracy: 0.56 - 1s 2ms/step - loss: 0.7355 - accuracy: 0.5683 - val_loss: 0.9401 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8039 - accuracy: 0.50 - ETA: 1s - loss: 37.2861 - accuracy: 0.546 - ETA: 1s - loss: 19.2907 - accuracy: 0.563 - ETA: 1s - loss: 13.0343 - accuracy: 0.569 - ETA: 1s - loss: 10.1326 - accuracy: 0.562 - ETA: 1s - loss: 8.3341 - accuracy: 0.560 - ETA: 0s - loss: 7.1106 - accuracy: 0.56 - ETA: 0s - loss: 6.1782 - accuracy: 0.56 - ETA: 0s - loss: 5.4649 - accuracy: 0.56 - ETA: 0s - loss: 4.9149 - accuracy: 0.56 - ETA: 0s - loss: 4.4793 - accuracy: 0.56 - ETA: 0s - loss: 4.1242 - accuracy: 0.56 - ETA: 0s - loss: 3.8317 - accuracy: 0.56 - ETA: 0s - loss: 3.5976 - accuracy: 0.56 - ETA: 0s - loss: 3.3895 - accuracy: 0.56 - ETA: 0s - loss: 3.2082 - accuracy: 0.56 - ETA: 0s - loss: 3.0507 - accuracy: 0.56 - ETA: 0s - loss: 2.9156 - accuracy: 0.57 - ETA: 0s - loss: 2.7751 - accuracy: 0.56 - ETA: 0s - loss: 2.6694 - accuracy: 0.56 - ETA: 0s - loss: 2.5739 - accuracy: 0.56 - ETA: 0s - loss: 2.4922 - accuracy: 0.56 - ETA: 0s - loss: 2.4149 - accuracy: 0.56 - ETA: 0s - loss: 2.3334 - accuracy: 0.56 - ETA: 0s - loss: 2.2674 - accuracy: 0.56 - 1s 2ms/step - loss: 2.2446 - accuracy: 0.5667 - val_loss: 0.7157 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6608 - accuracy: 0.65 - ETA: 1s - loss: 0.6795 - accuracy: 0.59 - ETA: 1s - loss: 0.6875 - accuracy: 0.57 - ETA: 1s - loss: 0.6866 - accuracy: 0.57 - ETA: 1s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.58 - ETA: 0s - loss: 0.6866 - accuracy: 0.58 - ETA: 0s - loss: 0.6864 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.56 - ETA: 0s - loss: 0.6891 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6902 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5672 - val_loss: 0.7225 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8706 - accuracy: 0.46 - ETA: 1s - loss: 0.6806 - accuracy: 0.60 - ETA: 1s - loss: 0.6890 - accuracy: 0.56 - ETA: 1s - loss: 0.6925 - accuracy: 0.56 - ETA: 1s - loss: 0.6907 - accuracy: 0.57 - ETA: 1s - loss: 0.6880 - accuracy: 0.58 - ETA: 0s - loss: 0.6876 - accuracy: 0.58 - ETA: 0s - loss: 0.6871 - accuracy: 0.58 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6863 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.56 - ETA: 0s - loss: 0.6889 - accuracy: 0.56 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5698 - val_loss: 0.9378 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 1.0878 - accuracy: 0.53 - ETA: 1s - loss: 0.7048 - accuracy: 0.54 - ETA: 1s - loss: 0.6998 - accuracy: 0.55 - ETA: 1s - loss: 0.6995 - accuracy: 0.54 - ETA: 1s - loss: 0.6983 - accuracy: 0.54 - ETA: 1s - loss: 0.6960 - accuracy: 0.54 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6912 - accuracy: 0.55 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6899 - accuracy: 0.56 - ETA: 0s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6911 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6906 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6915 - accuracy: 0.5624 - val_loss: 0.9374 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8292 - accuracy: 0.65 - ETA: 1s - loss: 0.6958 - accuracy: 0.57 - ETA: 1s - loss: 0.6919 - accuracy: 0.57 - ETA: 1s - loss: 0.6918 - accuracy: 0.57 - ETA: 1s - loss: 0.6919 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6926 - accuracy: 0.55 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6923 - accuracy: 0.55 - ETA: 0s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6934 - accuracy: 0.55 - ETA: 0s - loss: 0.6922 - accuracy: 0.56 - ETA: 0s - loss: 0.6934 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6935 - accuracy: 0.55 - ETA: 0s - loss: 0.6947 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6943 - accuracy: 0.55 - ETA: 0s - loss: 0.6941 - accuracy: 0.55 - ETA: 0s - loss: 0.6931 - accuracy: 0.56 - ETA: 0s - loss: 0.6926 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5627 - val_loss: 0.7132 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7317 - accuracy: 0.50 - ETA: 1s - loss: 11.3495 - accuracy: 0.536 - ETA: 1s - loss: 6.3984 - accuracy: 0.537 - ETA: 1s - loss: 4.4460 - accuracy: 0.54 - ETA: 0s - loss: 3.5711 - accuracy: 0.53 - ETA: 0s - loss: 3.0405 - accuracy: 0.54 - ETA: 0s - loss: 2.6855 - accuracy: 0.54 - ETA: 0s - loss: 2.3903 - accuracy: 0.54 - ETA: 0s - loss: 2.1854 - accuracy: 0.54 - ETA: 0s - loss: 2.0291 - accuracy: 0.55 - ETA: 0s - loss: 1.8990 - accuracy: 0.55 - ETA: 0s - loss: 1.7863 - accuracy: 0.55 - ETA: 0s - loss: 1.6947 - accuracy: 0.55 - ETA: 0s - loss: 1.6185 - accuracy: 0.55 - ETA: 0s - loss: 1.5546 - accuracy: 0.55 - ETA: 0s - loss: 1.4956 - accuracy: 0.55 - ETA: 0s - loss: 1.4487 - accuracy: 0.55 - ETA: 0s - loss: 1.4043 - accuracy: 0.56 - ETA: 0s - loss: 1.3641 - accuracy: 0.55 - ETA: 0s - loss: 1.3282 - accuracy: 0.56 - ETA: 0s - loss: 1.2976 - accuracy: 0.55 - ETA: 0s - loss: 1.2693 - accuracy: 0.56 - ETA: 0s - loss: 1.2406 - accuracy: 0.56 - ETA: 0s - loss: 1.2176 - accuracy: 0.56 - ETA: 0s - loss: 1.1968 - accuracy: 0.56 - 1s 2ms/step - loss: 1.1900 - accuracy: 0.5611 - val_loss: 0.9374 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8937 - accuracy: 0.62 - ETA: 1s - loss: 0.6998 - accuracy: 0.54 - ETA: 1s - loss: 0.6911 - accuracy: 0.56 - ETA: 1s - loss: 0.6904 - accuracy: 0.57 - ETA: 1s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6967 - accuracy: 0.55 - ETA: 0s - loss: 0.6974 - accuracy: 0.55 - ETA: 0s - loss: 0.6953 - accuracy: 0.55 - ETA: 0s - loss: 0.6939 - accuracy: 0.56 - ETA: 0s - loss: 0.6933 - accuracy: 0.56 - ETA: 0s - loss: 0.6931 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6924 - accuracy: 0.56 - ETA: 0s - loss: 0.6936 - accuracy: 0.55 - ETA: 0s - loss: 0.6930 - accuracy: 0.56 - ETA: 0s - loss: 0.6945 - accuracy: 0.55 - ETA: 0s - loss: 0.6938 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6933 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6949 - accuracy: 0.55 - ETA: 0s - loss: 0.6947 - accuracy: 0.55 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5594 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.65 - ETA: 1s - loss: 0.6855 - accuracy: 0.57 - ETA: 1s - loss: 0.6848 - accuracy: 0.57 - ETA: 1s - loss: 0.6935 - accuracy: 0.56 - ETA: 1s - loss: 0.6950 - accuracy: 0.56 - ETA: 0s - loss: 0.6961 - accuracy: 0.55 - ETA: 0s - loss: 0.6973 - accuracy: 0.55 - ETA: 0s - loss: 0.6978 - accuracy: 0.55 - ETA: 0s - loss: 0.6955 - accuracy: 0.55 - ETA: 0s - loss: 0.7112 - accuracy: 0.55 - ETA: 0s - loss: 0.7077 - accuracy: 0.56 - ETA: 0s - loss: 0.7068 - accuracy: 0.56 - ETA: 0s - loss: 0.7047 - accuracy: 0.56 - ETA: 0s - loss: 0.7042 - accuracy: 0.56 - ETA: 0s - loss: 0.7024 - accuracy: 0.56 - ETA: 0s - loss: 0.7014 - accuracy: 0.56 - ETA: 0s - loss: 0.7013 - accuracy: 0.56 - ETA: 0s - loss: 0.7015 - accuracy: 0.56 - ETA: 0s - loss: 0.7017 - accuracy: 0.56 - ETA: 0s - loss: 0.7015 - accuracy: 0.56 - ETA: 0s - loss: 0.7007 - accuracy: 0.56 - ETA: 0s - loss: 0.7004 - accuracy: 0.56 - ETA: 0s - loss: 0.6995 - accuracy: 0.56 - ETA: 0s - loss: 0.6985 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6989 - accuracy: 0.5648 - val_loss: 0.7132 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.62 - ETA: 1s - loss: 0.7035 - accuracy: 0.55 - ETA: 1s - loss: 0.6968 - accuracy: 0.56 - ETA: 1s - loss: 0.6979 - accuracy: 0.55 - ETA: 0s - loss: 0.6973 - accuracy: 0.54 - ETA: 0s - loss: 0.6930 - accuracy: 0.55 - ETA: 0s - loss: 0.6948 - accuracy: 0.55 - ETA: 0s - loss: 0.6938 - accuracy: 0.55 - ETA: 0s - loss: 0.6930 - accuracy: 0.55 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6928 - accuracy: 0.56 - ETA: 0s - loss: 0.6929 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6925 - accuracy: 0.55 - ETA: 0s - loss: 0.6924 - accuracy: 0.55 - ETA: 0s - loss: 0.6915 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6917 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5626 - val_loss: 0.6941 - val_accuracy: 0.3960\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.46 - ETA: 1s - loss: 0.6964 - accuracy: 0.55 - ETA: 1s - loss: 0.6937 - accuracy: 0.55 - ETA: 0s - loss: 0.6921 - accuracy: 0.56 - ETA: 0s - loss: 0.6918 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6916 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6907 - accuracy: 0.56 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6901 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6908 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - ETA: 0s - loss: 0.6912 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.56 - ETA: 0s - loss: 0.6909 - accuracy: 0.56 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6910 - accuracy: 0.56 - ETA: 0s - loss: 0.6913 - accuracy: 0.56 - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5632 - val_loss: 0.6934 - val_accuracy: 0.3960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 37fbbe9491e17456b0a25398cfd9a2ef</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 4.148302444889779</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.59 - ETA: 1s - loss: 3.4077 - accuracy: 0.56 - ETA: 1s - loss: 2.1770 - accuracy: 0.56 - ETA: 1s - loss: 1.6833 - accuracy: 0.57 - ETA: 0s - loss: 1.4409 - accuracy: 0.57 - ETA: 0s - loss: 1.2902 - accuracy: 0.57 - ETA: 0s - loss: 1.1853 - accuracy: 0.57 - ETA: 0s - loss: 1.1163 - accuracy: 0.57 - ETA: 0s - loss: 1.0637 - accuracy: 0.57 - ETA: 0s - loss: 1.0239 - accuracy: 0.57 - ETA: 0s - loss: 0.9904 - accuracy: 0.57 - ETA: 0s - loss: 0.9643 - accuracy: 0.57 - ETA: 0s - loss: 0.9409 - accuracy: 0.57 - ETA: 0s - loss: 0.9223 - accuracy: 0.56 - ETA: 0s - loss: 0.9046 - accuracy: 0.56 - ETA: 0s - loss: 0.8909 - accuracy: 0.56 - ETA: 0s - loss: 0.8793 - accuracy: 0.56 - ETA: 0s - loss: 0.8692 - accuracy: 0.56 - ETA: 0s - loss: 0.8584 - accuracy: 0.57 - ETA: 0s - loss: 0.8498 - accuracy: 0.57 - ETA: 0s - loss: 0.8417 - accuracy: 0.57 - ETA: 0s - loss: 0.8353 - accuracy: 0.57 - ETA: 0s - loss: 0.8281 - accuracy: 0.57 - ETA: 0s - loss: 0.8221 - accuracy: 0.57 - 1s 2ms/step - loss: 0.8213 - accuracy: 0.5730 - val_loss: 0.6909 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.53 - ETA: 1s - loss: 0.6785 - accuracy: 0.59 - ETA: 1s - loss: 0.6838 - accuracy: 0.58 - ETA: 1s - loss: 0.6843 - accuracy: 0.58 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6890 - accuracy: 0.56 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6941 - accuracy: 0.56 - ETA: 0s - loss: 0.6949 - accuracy: 0.56 - ETA: 0s - loss: 0.6943 - accuracy: 0.56 - ETA: 0s - loss: 0.6927 - accuracy: 0.56 - ETA: 0s - loss: 0.6920 - accuracy: 0.56 - ETA: 0s - loss: 0.6919 - accuracy: 0.56 - ETA: 0s - loss: 0.6914 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.57 - ETA: 0s - loss: 0.6901 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6894 - accuracy: 0.57 - ETA: 0s - loss: 0.6896 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5711 - val_loss: 0.6873 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.65 - ETA: 1s - loss: 0.6892 - accuracy: 0.59 - ETA: 1s - loss: 0.6902 - accuracy: 0.57 - ETA: 1s - loss: 0.6902 - accuracy: 0.56 - ETA: 1s - loss: 0.6887 - accuracy: 0.56 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5748 - val_loss: 0.6850 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6723 - accuracy: 0.75 - ETA: 1s - loss: 0.6894 - accuracy: 0.57 - ETA: 1s - loss: 0.6892 - accuracy: 0.57 - ETA: 1s - loss: 0.6889 - accuracy: 0.57 - ETA: 1s - loss: 0.6897 - accuracy: 0.56 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - ETA: 0s - loss: 0.6904 - accuracy: 0.56 - ETA: 0s - loss: 0.6884 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6846 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6856 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5755 - val_loss: 0.6941 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.62 - ETA: 1s - loss: 0.6961 - accuracy: 0.57 - ETA: 1s - loss: 0.6892 - accuracy: 0.57 - ETA: 1s - loss: 0.6863 - accuracy: 0.58 - ETA: 1s - loss: 0.6899 - accuracy: 0.57 - ETA: 0s - loss: 0.6903 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6892 - accuracy: 0.57 - ETA: 0s - loss: 0.6905 - accuracy: 0.56 - ETA: 0s - loss: 0.6893 - accuracy: 0.57 - ETA: 0s - loss: 0.6887 - accuracy: 0.57 - ETA: 0s - loss: 0.6886 - accuracy: 0.57 - ETA: 0s - loss: 0.6885 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6888 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6881 - accuracy: 0.57 - ETA: 0s - loss: 0.6882 - accuracy: 0.57 - ETA: 0s - loss: 0.6877 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5740 - val_loss: 0.8312 - val_accuracy: 0.3962\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.68 - ETA: 1s - loss: 4.6411 - accuracy: 0.54 - ETA: 1s - loss: 2.8259 - accuracy: 0.55 - ETA: 0s - loss: 2.1241 - accuracy: 0.56 - ETA: 0s - loss: 1.7918 - accuracy: 0.56 - ETA: 0s - loss: 1.5689 - accuracy: 0.57 - ETA: 0s - loss: 1.4481 - accuracy: 0.57 - ETA: 0s - loss: 1.3416 - accuracy: 0.56 - ETA: 0s - loss: 1.2630 - accuracy: 0.57 - ETA: 0s - loss: 1.2078 - accuracy: 0.57 - ETA: 0s - loss: 1.1601 - accuracy: 0.57 - ETA: 0s - loss: 1.1196 - accuracy: 0.57 - ETA: 0s - loss: 1.0856 - accuracy: 0.57 - ETA: 0s - loss: 1.0573 - accuracy: 0.57 - ETA: 0s - loss: 1.0320 - accuracy: 0.57 - ETA: 0s - loss: 1.0099 - accuracy: 0.57 - ETA: 0s - loss: 0.9914 - accuracy: 0.57 - ETA: 0s - loss: 0.9747 - accuracy: 0.57 - ETA: 0s - loss: 0.9585 - accuracy: 0.57 - ETA: 0s - loss: 0.9448 - accuracy: 0.57 - ETA: 0s - loss: 0.9316 - accuracy: 0.57 - ETA: 0s - loss: 0.9204 - accuracy: 0.57 - ETA: 0s - loss: 0.9099 - accuracy: 0.57 - ETA: 0s - loss: 0.9001 - accuracy: 0.57 - ETA: 0s - loss: 0.8920 - accuracy: 0.57 - 1s 2ms/step - loss: 0.8918 - accuracy: 0.5758 - val_loss: 0.6846 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.68 - ETA: 1s - loss: 0.6881 - accuracy: 0.56 - ETA: 1s - loss: 0.6819 - accuracy: 0.58 - ETA: 1s - loss: 0.6827 - accuracy: 0.58 - ETA: 1s - loss: 0.6823 - accuracy: 0.59 - ETA: 0s - loss: 0.6844 - accuracy: 0.58 - ETA: 0s - loss: 0.6854 - accuracy: 0.58 - ETA: 0s - loss: 0.6849 - accuracy: 0.58 - ETA: 0s - loss: 0.6847 - accuracy: 0.58 - ETA: 0s - loss: 0.6854 - accuracy: 0.58 - ETA: 0s - loss: 0.6864 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6858 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.58 - ETA: 0s - loss: 0.6855 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5769 - val_loss: 0.7061 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7463 - accuracy: 0.56 - ETA: 1s - loss: 0.6901 - accuracy: 0.55 - ETA: 1s - loss: 0.6842 - accuracy: 0.57 - ETA: 1s - loss: 0.6816 - accuracy: 0.58 - ETA: 1s - loss: 0.6815 - accuracy: 0.58 - ETA: 0s - loss: 0.6841 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6849 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.56 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6844 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6843 - accuracy: 0.57 - ETA: 0s - loss: 0.6840 - accuracy: 0.57 - ETA: 0s - loss: 0.6846 - accuracy: 0.57 - ETA: 0s - loss: 0.6851 - accuracy: 0.57 - ETA: 0s - loss: 0.6852 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5726 - val_loss: 0.6885 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.62 - ETA: 1s - loss: 0.6888 - accuracy: 0.55 - ETA: 1s - loss: 0.6869 - accuracy: 0.55 - ETA: 1s - loss: 0.6825 - accuracy: 0.56 - ETA: 1s - loss: 0.6854 - accuracy: 0.56 - ETA: 1s - loss: 0.6869 - accuracy: 0.56 - ETA: 0s - loss: 0.6892 - accuracy: 0.56 - ETA: 0s - loss: 0.6871 - accuracy: 0.56 - ETA: 0s - loss: 0.6881 - accuracy: 0.56 - ETA: 0s - loss: 0.6875 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6876 - accuracy: 0.56 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6881 - accuracy: 0.56 - ETA: 0s - loss: 0.6872 - accuracy: 0.56 - ETA: 0s - loss: 0.6874 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5729 - val_loss: 0.8403 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.8574 - accuracy: 0.59 - ETA: 1s - loss: 0.6780 - accuracy: 0.59 - ETA: 1s - loss: 0.6806 - accuracy: 0.59 - ETA: 1s - loss: 0.6813 - accuracy: 0.59 - ETA: 0s - loss: 0.6833 - accuracy: 0.59 - ETA: 0s - loss: 0.6818 - accuracy: 0.59 - ETA: 0s - loss: 0.6815 - accuracy: 0.59 - ETA: 0s - loss: 0.6838 - accuracy: 0.58 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6851 - accuracy: 0.58 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6862 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5733 - val_loss: 0.7059 - val_accuracy: 0.6038\n",
      "Epoch 1/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6997 - accuracy: 0.46 - ETA: 1s - loss: 3.2013 - accuracy: 0.53 - ETA: 1s - loss: 1.9756 - accuracy: 0.55 - ETA: 1s - loss: 1.5774 - accuracy: 0.56 - ETA: 1s - loss: 1.3652 - accuracy: 0.55 - ETA: 0s - loss: 1.2262 - accuracy: 0.55 - ETA: 0s - loss: 1.1312 - accuracy: 0.56 - ETA: 0s - loss: 1.0752 - accuracy: 0.57 - ETA: 0s - loss: 1.0232 - accuracy: 0.57 - ETA: 0s - loss: 0.9827 - accuracy: 0.57 - ETA: 0s - loss: 0.9544 - accuracy: 0.57 - ETA: 0s - loss: 0.9305 - accuracy: 0.57 - ETA: 0s - loss: 0.9101 - accuracy: 0.57 - ETA: 0s - loss: 0.8929 - accuracy: 0.57 - ETA: 0s - loss: 0.8782 - accuracy: 0.57 - ETA: 0s - loss: 0.8650 - accuracy: 0.57 - ETA: 0s - loss: 0.8538 - accuracy: 0.57 - ETA: 0s - loss: 0.8440 - accuracy: 0.57 - ETA: 0s - loss: 0.8350 - accuracy: 0.57 - ETA: 0s - loss: 0.8261 - accuracy: 0.57 - ETA: 0s - loss: 0.8195 - accuracy: 0.57 - ETA: 0s - loss: 0.8131 - accuracy: 0.57 - ETA: 0s - loss: 0.8070 - accuracy: 0.57 - ETA: 0s - loss: 0.8024 - accuracy: 0.57 - 1s 2ms/step - loss: 0.7988 - accuracy: 0.5757 - val_loss: 0.6941 - val_accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.62 - ETA: 1s - loss: 0.6828 - accuracy: 0.59 - ETA: 1s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6895 - accuracy: 0.56 - ETA: 0s - loss: 0.6873 - accuracy: 0.56 - ETA: 0s - loss: 0.6888 - accuracy: 0.56 - ETA: 0s - loss: 0.6886 - accuracy: 0.56 - ETA: 0s - loss: 0.6876 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6870 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6878 - accuracy: 0.57 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6869 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6866 - accuracy: 0.5771 - val_loss: 0.6946 - val_accuracy: 0.6038\n",
      "Epoch 3/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.6762 - accuracy: 0.62 - ETA: 1s - loss: 0.6731 - accuracy: 0.61 - ETA: 1s - loss: 0.6824 - accuracy: 0.58 - ETA: 1s - loss: 0.6814 - accuracy: 0.58 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6847 - accuracy: 0.57 - ETA: 0s - loss: 0.6845 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6851 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6866 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6855 - accuracy: 0.57 - ETA: 0s - loss: 0.6859 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.57 - ETA: 0s - loss: 0.6863 - accuracy: 0.57 - ETA: 0s - loss: 0.6865 - accuracy: 0.57 - ETA: 0s - loss: 0.6868 - accuracy: 0.57 - ETA: 0s - loss: 0.6873 - accuracy: 0.57 - ETA: 0s - loss: 0.6872 - accuracy: 0.57 - ETA: 0s - loss: 0.6871 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5723 - val_loss: 0.6897 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.75 - ETA: 1s - loss: 0.6821 - accuracy: 0.56 - ETA: 1s - loss: 0.6852 - accuracy: 0.56 - ETA: 1s - loss: 0.6867 - accuracy: 0.56 - ETA: 1s - loss: 0.6867 - accuracy: 0.56 - ETA: 0s - loss: 0.6883 - accuracy: 0.56 - ETA: 0s - loss: 0.6877 - accuracy: 0.56 - ETA: 0s - loss: 0.6864 - accuracy: 0.57 - ETA: 0s - loss: 0.6842 - accuracy: 0.57 - ETA: 0s - loss: 0.6854 - accuracy: 0.57 - ETA: 0s - loss: 0.6844 - accuracy: 0.57 - ETA: 0s - loss: 0.6853 - accuracy: 0.57 - ETA: 0s - loss: 0.6857 - accuracy: 0.57 - ETA: 0s - loss: 0.6850 - accuracy: 0.57 - ETA: 0s - loss: 0.6848 - accuracy: 0.57 - ETA: 0s - loss: 0.6845 - accuracy: 0.58 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - ETA: 0s - loss: 0.6907 - accuracy: 0.57 - ETA: 0s - loss: 0.6902 - accuracy: 0.57 - ETA: 0s - loss: 0.6898 - accuracy: 0.57 - ETA: 0s - loss: 0.6911 - accuracy: 0.57 - ETA: 0s - loss: 0.6916 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6909 - accuracy: 0.57 - ETA: 0s - loss: 0.6906 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5774 - val_loss: 0.7030 - val_accuracy: 0.6038\n",
      "Epoch 5/5\n",
      "829/829 [==============================] - ETA: 0s - loss: 0.7422 - accuracy: 0.56 - ETA: 1s - loss: 0.7002 - accuracy: 0.56 - ETA: 1s - loss: 0.6956 - accuracy: 0.57 - ETA: 1s - loss: 0.6897 - accuracy: 0.57 - ETA: 0s - loss: 0.6860 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6861 - accuracy: 0.58 - ETA: 0s - loss: 0.6861 - accuracy: 0.58 - ETA: 0s - loss: 0.6867 - accuracy: 0.57 - ETA: 0s - loss: 0.6879 - accuracy: 0.57 - ETA: 0s - loss: 0.6874 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6880 - accuracy: 0.57 - ETA: 0s - loss: 0.6883 - accuracy: 0.57 - ETA: 0s - loss: 0.6900 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6898 - accuracy: 0.56 - ETA: 0s - loss: 0.6890 - accuracy: 0.57 - ETA: 0s - loss: 0.6948 - accuracy: 0.57 - ETA: 0s - loss: 0.6951 - accuracy: 0.57 - ETA: 0s - loss: 0.6954 - accuracy: 0.57 - ETA: 0s - loss: 0.6953 - accuracy: 0.57 - ETA: 0s - loss: 0.6952 - accuracy: 0.57 - ETA: 0s - loss: 0.6949 - accuracy: 0.57 - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5723 - val_loss: 0.6916 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d4210bc23e147226bbbf82e487a3a8f3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6038400530815125</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 3.32665997995992</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 448</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7f1074dcd520>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7f1074dcd880>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(keras.Sequential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units = 303, input_shape = (769,), activation = 'relu'),\n",
    "    keras.layers.Dense(units = 256, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 128, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 64, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 32, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 16, activation = 'relu'),\n",
    "    keras.layers.Dense(units = 1, activation = 'sigmoid') # here the units must be 1 in order for binary classifications to work\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 303)               233310    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               77824     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 354,911\n",
      "Trainable params: 354,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(lr=0.000959, beta_1 = 0.9, beta_2=0.999), # you can tune the learning rate here. Default lr = 0.01\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/829 [..............................] - ETA: 0s - loss: 0.6428 - accuracy: 0.7500WARNING:tensorflow:From /Users/anthony/Documents/GitHub/Research-Mapping-Uncanny-Valley/.venv/creepyvenv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
      "829/829 [==============================] - 2s 3ms/step - loss: 0.4727 - accuracy: 0.7740 - val_loss: 0.3482 - val_accuracy: 0.8431\n",
      "Epoch 2/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2987 - accuracy: 0.8876 - val_loss: 0.2608 - val_accuracy: 0.8894\n",
      "Epoch 3/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2928 - accuracy: 0.8909 - val_loss: 0.3139 - val_accuracy: 0.8778\n",
      "Epoch 4/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2702 - accuracy: 0.8977 - val_loss: 0.2348 - val_accuracy: 0.9186\n",
      "Epoch 5/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2731 - accuracy: 0.8972 - val_loss: 0.2609 - val_accuracy: 0.8948\n",
      "Epoch 6/30\n",
      "829/829 [==============================] - 2s 3ms/step - loss: 0.2521 - accuracy: 0.9065 - val_loss: 0.2560 - val_accuracy: 0.9040\n",
      "Epoch 7/30\n",
      "829/829 [==============================] - 2s 3ms/step - loss: 0.2397 - accuracy: 0.9108 - val_loss: 0.2696 - val_accuracy: 0.8959\n",
      "Epoch 8/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2412 - accuracy: 0.9126 - val_loss: 0.2079 - val_accuracy: 0.9221\n",
      "Epoch 9/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2271 - accuracy: 0.9178 - val_loss: 0.2234 - val_accuracy: 0.9172\n",
      "Epoch 10/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2382 - accuracy: 0.9114 - val_loss: 0.2085 - val_accuracy: 0.9301\n",
      "Epoch 11/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2326 - accuracy: 0.9158 - val_loss: 0.2008 - val_accuracy: 0.9285\n",
      "Epoch 12/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2251 - accuracy: 0.9194 - val_loss: 0.2044 - val_accuracy: 0.9292\n",
      "Epoch 13/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2266 - accuracy: 0.9188 - val_loss: 0.2033 - val_accuracy: 0.9304\n",
      "Epoch 14/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2285 - accuracy: 0.9169 - val_loss: 0.2014 - val_accuracy: 0.9230\n",
      "Epoch 15/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2227 - accuracy: 0.9183 - val_loss: 0.1871 - val_accuracy: 0.9341\n",
      "Epoch 16/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2126 - accuracy: 0.9237 - val_loss: 0.1892 - val_accuracy: 0.9354\n",
      "Epoch 17/30\n",
      "829/829 [==============================] - 2s 3ms/step - loss: 0.2098 - accuracy: 0.9244 - val_loss: 0.1858 - val_accuracy: 0.9313\n",
      "Epoch 18/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2173 - accuracy: 0.9249 - val_loss: 0.1862 - val_accuracy: 0.9366\n",
      "Epoch 19/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2064 - accuracy: 0.9281 - val_loss: 0.3840 - val_accuracy: 0.8765\n",
      "Epoch 20/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2118 - accuracy: 0.9229 - val_loss: 0.1873 - val_accuracy: 0.9380\n",
      "Epoch 21/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2111 - accuracy: 0.9241 - val_loss: 0.2679 - val_accuracy: 0.8992\n",
      "Epoch 22/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2029 - accuracy: 0.9282 - val_loss: 0.2669 - val_accuracy: 0.9093\n",
      "Epoch 23/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2042 - accuracy: 0.9265 - val_loss: 0.1745 - val_accuracy: 0.9389\n",
      "Epoch 24/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.2033 - accuracy: 0.9287 - val_loss: 0.1732 - val_accuracy: 0.9389\n",
      "Epoch 25/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1934 - accuracy: 0.9315 - val_loss: 0.1790 - val_accuracy: 0.9376\n",
      "Epoch 26/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1963 - accuracy: 0.9302 - val_loss: 0.3492 - val_accuracy: 0.8573\n",
      "Epoch 27/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1919 - accuracy: 0.9325 - val_loss: 0.1732 - val_accuracy: 0.9431\n",
      "Epoch 28/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1940 - accuracy: 0.9315 - val_loss: 0.1953 - val_accuracy: 0.9283\n",
      "Epoch 29/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1892 - accuracy: 0.9351 - val_loss: 0.1692 - val_accuracy: 0.9431\n",
      "Epoch 30/30\n",
      "829/829 [==============================] - 2s 2ms/step - loss: 0.1874 - accuracy: 0.9345 - val_loss: 0.1733 - val_accuracy: 0.9391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 39995), started 9:09:19 ago. (Use '!kill 39995' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5e3748b74774c7ff\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5e3748b74774c7ff\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_log_dir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_log_dir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 30, \n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[tensorboard_cb])\n",
    "\n",
    "%tensorboard --logdir my_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid = True\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.savefig('../Presentations/10-26-2020/loss&accuracy.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1832127869129181, 0.9356147646903992]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world Test (r/shortscarystories and r/self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_creepy = \"\"\"\n",
    "Irene (not her real name) was my first non-bot tinder match in three months. Things moved pretty fast—we chatted, I offered to cook dinner (Spaghetti puttanesca), then we hooked up.\n",
    "\n",
    "Irene was super hot but SUPER weird. She had a thick accent but insisted she grew up nearby, said it was a good night to make love because her ‘goddess cycle was aligned with the moons’, and totally starfished during sex.\n",
    "\n",
    "I figured - no big deal, I’ll just do the adult thing and ghost her.\n",
    "\n",
    "Well that pissed Irene off. She messaged calling me a fuckboy and said, ‘you’ll be sorry’. I blocked her number, but the messages didn’t stop. Eventually she baited me into replying:\n",
    "\n",
    "Her: Since you’re alone tonight how about we have a little fun? 😉\n",
    "\n",
    "Me: I’m not alone. My housemates here. (I was lying.)\n",
    "\n",
    "Her: Surrrrrreeeeee.\n",
    "\n",
    "My bedroom door creaked open. From behind it something whispered, ‘JJJJJJJJJJTTTTTTTBBBBBBBBBB6666666888888885555555’.\n",
    "\n",
    "I thought maybe my housemate had come back and went to check it out. A dark figure almost as tall as the ceiling was creeping through the hall. I closed my bedroom door and locked it.\n",
    "\n",
    "My phone dinged.\n",
    "\n",
    "Her: I see you’ve met the other man in my life 😊\n",
    "\n",
    "I thought, no big deal—just my imagination, or maybe a nightmare. I’ll stay here and everything’ll be alright in the morning.\n",
    "\n",
    "But I really needed to pee. Rather than wander through the empty house, I climbed out the window and urinated in the garden.\n",
    "\n",
    "When I returned, my phone dinged again.\n",
    "\n",
    "Her: What’s wrong? Afraid to go to the bathroom by yourself?\n",
    "\n",
    "Her: Look out the window. He’s outside. 😉\n",
    "\n",
    "The ‘figure’ appeared out of nowhere. Whatever it was, it wasn’t human. This is the only way I can describe it: picture a living shadow with pale eyes and a tongue that doesn’t fit in its mouth.\n",
    "\n",
    "It licked the window; I staggered back. The window opened (I don’t know how - it doesn’t unlock from the outside) and the figure poked its grinning head past the frame and into the room. I messaged Irene.\n",
    "\n",
    "Me: I’m sorry. Please make it stop. I’ll do ANYTHING.\n",
    "\n",
    "Her: I wish I could, but he hates seeing me upset. 😢 If only something cheered me up…Oh well…\n",
    "\n",
    "The figure climbed through the window and crawled along the floor, dragging its grotesque tongue across the carpet. It stood, leaned over me, then rocked it’s head like a seesaw.\n",
    "\n",
    "Me: Free tomorrow evening?\n",
    "\n",
    "Immediately the shadow turned and climbed back out the window.\n",
    "\n",
    "Her: Pick me up at eight. And we better have a magical time…Or else. X.\n",
    "\n",
    "So now we’re meeting tonight, and I have no idea what to do. I absolutely DO NOT want to date a girl who summons demons and probably gives shitty blowjobs.\n",
    "\n",
    "I need to figure out a way to make her both enjoy the date and never want to see me again.\n",
    "\n",
    "If anyone has any suggestions, I’d really really appreciate it…\n",
    "\"\"\"\n",
    "\n",
    "text_non_creepy = \"\"\"\n",
    "a few years ago my grandfather died and grandma was left to deal with finances for the first time in her life. mentally she was always sharp but in the months after his death she was so vulnerable. during this time some phone scammers managed to get her locked into a contract so she had to pay an extra $500/mo for electricity. i was royally pissed to say the least. worst of all, i couldn't do anything about it. eventually she was able to get out of the contract but not before she paid them thousands of dollars.\n",
    "\n",
    "as revenge, when someone tries to scam me i waste as much of their time as possible. i figure if i can slow them down for just 10-20 min it might be saving some other poor old lady from being taken advantage of. when i first started it wasn't easy. i could only keep them on the line for a few min before i broke down and started swearing at them. then i learned to keep my cool but they have ways of figuring out who is legit so i could only keep them on the line for 5 min before they would hang up. it sort of became a game where i would slowly figure out what they wanted to hear. with each call i get a little better. today i managed to keep them for 30+ min before they got frustrated and hung up.\n",
    "\n",
    "if everyone did this it would slow them down a lot. many old ladies would be saved.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.17855311,  0.99887389, -0.18185684, ..., -0.11338366,\n",
       "         0.3205308 , -0.53172874],\n",
       "       [ 7.03615729,  0.28519651, -0.21132587, ...,  0.20084164,\n",
       "        -0.19763809, -0.22631353]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creepy_vec = np.concatenate(([np.log(1310+1+0.01)],sbert_model.encode(text_creepy)))\n",
    "non_creepy_vec = np.concatenate(([np.log(1136+1+0.01)],sbert_model.encode(text_non_creepy)))\n",
    "vecs = np.array([creepy_vec, non_creepy_vec])\n",
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_vecs = scaler.fit_transform(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=100)\n",
    "scaled_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.2851690e-06],\n",
       "       [9.9999964e-01]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fbe95a0ef40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text_non_creepy)\n",
    "for idx, sents in enumerate(doc.sents):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creepyenv",
   "language": "python",
   "name": "creepyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
