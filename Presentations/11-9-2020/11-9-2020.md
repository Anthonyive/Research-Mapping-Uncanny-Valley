This week I were mostly cleaning the data.

In particular, I removed all the links, fixed all the encoding problems, and only kept English posts.

Another thing this how to convert our stories to vectors. I think averaging sentence embeddings may not be a good technique, so I did some research online and I found people also use the last layer's features to represent sentence embeddings. Therefore, I think it might be a good idea to implement to document embeddings.

Originally I was thinking there might be a lot of problems, but when I was making the Presentation, I realized problem solved. I will implement this idea next week.

Another idea is I want to construct a small corpus of sentences. Each sentence is like how I feel. I will compare each sentence in a post with sentences in this corpus. And extract all the maximum similarities to create a creepiness vector. Then maybe take this creepiness vector and the document embeddings together as our input. 

However, the probelm is each post has different number of sentences. This means that the creepiness vector will have different dimensions. 